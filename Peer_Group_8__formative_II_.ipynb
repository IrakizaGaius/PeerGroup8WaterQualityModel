{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrXv0rU9sIma"
      },
      "source": [
        "# Excercise - Creating our own custom Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJyZUDbzBTIG"
      },
      "source": [
        "This is a notebook that provides a quick overview of how to create your own custom model. You will be creating a simple model.\n",
        "You will be utilizing Keras and Tensorflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvLegMMvBZYg"
      },
      "source": [
        "## Water Quality Dataset\n",
        "\n",
        "This dataset contains water quality measurements and assessments related to potability, which is the suitability of water for human consumption. The dataset's primary objective is to provide insights into water quality parameters and assist in determining whether the water is potable or not. Each row in the dataset represents a water sample with specific attributes, and the \"Potability\" column indicates whether the water is suitable for consumption.\n",
        "\n",
        "https://www.kaggle.com/datasets/uom190346a/water-quality-and-potability?select=water_potability.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "Qvnx0_dT3JEq",
        "outputId": "85835eb4-6b3a-487e-edb5-0c86f04481ce"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 3276,\n  \"fields\": [\n    {\n      \"column\": \"ph\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5943195187088104,\n        \"min\": 0.0,\n        \"max\": 13.999999999999998,\n        \"num_unique_values\": 2785,\n        \"samples\": [\n          6.569053876389385,\n          9.271355446767778,\n          8.92790592593881\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hardness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32.879761476294156,\n        \"min\": 47.432,\n        \"max\": 323.124,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          183.5211070261417,\n          188.9135411469536,\n          224.05887682392927\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8768.570827785927,\n        \"min\": 320.942611274359,\n        \"max\": 61227.19600771213,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          20461.252710219946,\n          32873.820021715685,\n          23264.10996772913\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chloramines\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5830848890397096,\n        \"min\": 0.3520000000000003,\n        \"max\": 13.127000000000002,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          7.333212177578906,\n          6.791509363412849,\n          5.92236704115349\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sulfate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 41.416840461672706,\n        \"min\": 129.00000000000003,\n        \"max\": 481.0306423059972,\n        \"num_unique_values\": 2495,\n        \"samples\": [\n          324.64407957923544,\n          370.121384654358,\n          329.12773842254506\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conductivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80.8240640511118,\n        \"min\": 181.483753985146,\n        \"max\": 753.3426195583046,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          356.3690224100897,\n          336.56150104700754,\n          387.971335796834\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Organic_carbon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.308161999126874,\n        \"min\": 2.1999999999999886,\n        \"max\": 28.30000000000001,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          20.179028868493845,\n          14.706810313722087,\n          13.40673745495127\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Trihalomethanes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.175008422218657,\n        \"min\": 0.7379999999999995,\n        \"max\": 124.0,\n        \"num_unique_values\": 3114,\n        \"samples\": [\n          66.163439242252,\n          42.844510851301166,\n          47.06639219544294\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Turbidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7803824084854124,\n        \"min\": 1.45,\n        \"max\": 6.739,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          4.886633785371213,\n          4.562197671215202,\n          2.487968647002356\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Potability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-5e0eaebe-ef60-4b5f-be0e-a572bc1ae8f2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>204.890455</td>\n",
              "      <td>20791.318981</td>\n",
              "      <td>7.300212</td>\n",
              "      <td>368.516441</td>\n",
              "      <td>564.308654</td>\n",
              "      <td>10.379783</td>\n",
              "      <td>86.990970</td>\n",
              "      <td>2.963135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.716080</td>\n",
              "      <td>129.422921</td>\n",
              "      <td>18630.057858</td>\n",
              "      <td>6.635246</td>\n",
              "      <td>NaN</td>\n",
              "      <td>592.885359</td>\n",
              "      <td>15.180013</td>\n",
              "      <td>56.329076</td>\n",
              "      <td>4.500656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.099124</td>\n",
              "      <td>224.236259</td>\n",
              "      <td>19909.541732</td>\n",
              "      <td>9.275884</td>\n",
              "      <td>NaN</td>\n",
              "      <td>418.606213</td>\n",
              "      <td>16.868637</td>\n",
              "      <td>66.420093</td>\n",
              "      <td>3.055934</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.316766</td>\n",
              "      <td>214.373394</td>\n",
              "      <td>22018.417441</td>\n",
              "      <td>8.059332</td>\n",
              "      <td>356.886136</td>\n",
              "      <td>363.266516</td>\n",
              "      <td>18.436524</td>\n",
              "      <td>100.341674</td>\n",
              "      <td>4.628771</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.092223</td>\n",
              "      <td>181.101509</td>\n",
              "      <td>17978.986339</td>\n",
              "      <td>6.546600</td>\n",
              "      <td>310.135738</td>\n",
              "      <td>398.410813</td>\n",
              "      <td>11.558279</td>\n",
              "      <td>31.997993</td>\n",
              "      <td>4.075075</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.584087</td>\n",
              "      <td>188.313324</td>\n",
              "      <td>28748.687739</td>\n",
              "      <td>7.544869</td>\n",
              "      <td>326.678363</td>\n",
              "      <td>280.467916</td>\n",
              "      <td>8.399735</td>\n",
              "      <td>54.917862</td>\n",
              "      <td>2.559708</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10.223862</td>\n",
              "      <td>248.071735</td>\n",
              "      <td>28749.716544</td>\n",
              "      <td>7.513408</td>\n",
              "      <td>393.663396</td>\n",
              "      <td>283.651634</td>\n",
              "      <td>13.789695</td>\n",
              "      <td>84.603556</td>\n",
              "      <td>2.672989</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8.635849</td>\n",
              "      <td>203.361523</td>\n",
              "      <td>13672.091764</td>\n",
              "      <td>4.563009</td>\n",
              "      <td>303.309771</td>\n",
              "      <td>474.607645</td>\n",
              "      <td>12.363817</td>\n",
              "      <td>62.798309</td>\n",
              "      <td>4.401425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NaN</td>\n",
              "      <td>118.988579</td>\n",
              "      <td>14285.583854</td>\n",
              "      <td>7.804174</td>\n",
              "      <td>268.646941</td>\n",
              "      <td>389.375566</td>\n",
              "      <td>12.706049</td>\n",
              "      <td>53.928846</td>\n",
              "      <td>3.595017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>11.180284</td>\n",
              "      <td>227.231469</td>\n",
              "      <td>25484.508491</td>\n",
              "      <td>9.077200</td>\n",
              "      <td>404.041635</td>\n",
              "      <td>563.885481</td>\n",
              "      <td>17.927806</td>\n",
              "      <td>71.976601</td>\n",
              "      <td>4.370562</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>7.360640</td>\n",
              "      <td>165.520797</td>\n",
              "      <td>32452.614409</td>\n",
              "      <td>7.550701</td>\n",
              "      <td>326.624353</td>\n",
              "      <td>425.383419</td>\n",
              "      <td>15.586810</td>\n",
              "      <td>78.740016</td>\n",
              "      <td>3.662292</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>7.974522</td>\n",
              "      <td>218.693300</td>\n",
              "      <td>18767.656682</td>\n",
              "      <td>8.110385</td>\n",
              "      <td>NaN</td>\n",
              "      <td>364.098230</td>\n",
              "      <td>14.525746</td>\n",
              "      <td>76.485911</td>\n",
              "      <td>4.011718</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>7.119824</td>\n",
              "      <td>156.704993</td>\n",
              "      <td>18730.813653</td>\n",
              "      <td>3.606036</td>\n",
              "      <td>282.344050</td>\n",
              "      <td>347.715027</td>\n",
              "      <td>15.929536</td>\n",
              "      <td>79.500778</td>\n",
              "      <td>3.445756</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>NaN</td>\n",
              "      <td>150.174923</td>\n",
              "      <td>27331.361962</td>\n",
              "      <td>6.838223</td>\n",
              "      <td>299.415781</td>\n",
              "      <td>379.761835</td>\n",
              "      <td>19.370807</td>\n",
              "      <td>76.509996</td>\n",
              "      <td>4.413974</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>7.496232</td>\n",
              "      <td>205.344982</td>\n",
              "      <td>28388.004887</td>\n",
              "      <td>5.072558</td>\n",
              "      <td>NaN</td>\n",
              "      <td>444.645352</td>\n",
              "      <td>13.228311</td>\n",
              "      <td>70.300213</td>\n",
              "      <td>4.777382</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>6.347272</td>\n",
              "      <td>186.732881</td>\n",
              "      <td>41065.234765</td>\n",
              "      <td>9.629596</td>\n",
              "      <td>364.487687</td>\n",
              "      <td>516.743282</td>\n",
              "      <td>11.539781</td>\n",
              "      <td>75.071617</td>\n",
              "      <td>4.376348</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>7.051786</td>\n",
              "      <td>211.049406</td>\n",
              "      <td>30980.600787</td>\n",
              "      <td>10.094796</td>\n",
              "      <td>NaN</td>\n",
              "      <td>315.141267</td>\n",
              "      <td>20.397022</td>\n",
              "      <td>56.651604</td>\n",
              "      <td>4.268429</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>9.181560</td>\n",
              "      <td>273.813807</td>\n",
              "      <td>24041.326280</td>\n",
              "      <td>6.904990</td>\n",
              "      <td>398.350517</td>\n",
              "      <td>477.974642</td>\n",
              "      <td>13.387341</td>\n",
              "      <td>71.457362</td>\n",
              "      <td>4.503661</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>8.975464</td>\n",
              "      <td>279.357167</td>\n",
              "      <td>19460.398131</td>\n",
              "      <td>6.204321</td>\n",
              "      <td>NaN</td>\n",
              "      <td>431.443990</td>\n",
              "      <td>12.888759</td>\n",
              "      <td>63.821237</td>\n",
              "      <td>2.436086</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>7.371050</td>\n",
              "      <td>214.496610</td>\n",
              "      <td>25630.320037</td>\n",
              "      <td>4.432669</td>\n",
              "      <td>335.754439</td>\n",
              "      <td>469.914551</td>\n",
              "      <td>12.509164</td>\n",
              "      <td>62.797277</td>\n",
              "      <td>2.560299</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e0eaebe-ef60-4b5f-be0e-a572bc1ae8f2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5e0eaebe-ef60-4b5f-be0e-a572bc1ae8f2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5e0eaebe-ef60-4b5f-be0e-a572bc1ae8f2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8f4ec0b6-54d4-44bc-ac0d-2bc433265ba4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8f4ec0b6-54d4-44bc-ac0d-2bc433265ba4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8f4ec0b6-54d4-44bc-ac0d-2bc433265ba4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           ph    Hardness        Solids  Chloramines     Sulfate  \\\n",
              "0         NaN  204.890455  20791.318981     7.300212  368.516441   \n",
              "1    3.716080  129.422921  18630.057858     6.635246         NaN   \n",
              "2    8.099124  224.236259  19909.541732     9.275884         NaN   \n",
              "3    8.316766  214.373394  22018.417441     8.059332  356.886136   \n",
              "4    9.092223  181.101509  17978.986339     6.546600  310.135738   \n",
              "5    5.584087  188.313324  28748.687739     7.544869  326.678363   \n",
              "6   10.223862  248.071735  28749.716544     7.513408  393.663396   \n",
              "7    8.635849  203.361523  13672.091764     4.563009  303.309771   \n",
              "8         NaN  118.988579  14285.583854     7.804174  268.646941   \n",
              "9   11.180284  227.231469  25484.508491     9.077200  404.041635   \n",
              "10   7.360640  165.520797  32452.614409     7.550701  326.624353   \n",
              "11   7.974522  218.693300  18767.656682     8.110385         NaN   \n",
              "12   7.119824  156.704993  18730.813653     3.606036  282.344050   \n",
              "13        NaN  150.174923  27331.361962     6.838223  299.415781   \n",
              "14   7.496232  205.344982  28388.004887     5.072558         NaN   \n",
              "15   6.347272  186.732881  41065.234765     9.629596  364.487687   \n",
              "16   7.051786  211.049406  30980.600787    10.094796         NaN   \n",
              "17   9.181560  273.813807  24041.326280     6.904990  398.350517   \n",
              "18   8.975464  279.357167  19460.398131     6.204321         NaN   \n",
              "19   7.371050  214.496610  25630.320037     4.432669  335.754439   \n",
              "\n",
              "    Conductivity  Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
              "0     564.308654       10.379783        86.990970   2.963135           0  \n",
              "1     592.885359       15.180013        56.329076   4.500656           0  \n",
              "2     418.606213       16.868637        66.420093   3.055934           0  \n",
              "3     363.266516       18.436524       100.341674   4.628771           0  \n",
              "4     398.410813       11.558279        31.997993   4.075075           0  \n",
              "5     280.467916        8.399735        54.917862   2.559708           0  \n",
              "6     283.651634       13.789695        84.603556   2.672989           0  \n",
              "7     474.607645       12.363817        62.798309   4.401425           0  \n",
              "8     389.375566       12.706049        53.928846   3.595017           0  \n",
              "9     563.885481       17.927806        71.976601   4.370562           0  \n",
              "10    425.383419       15.586810        78.740016   3.662292           0  \n",
              "11    364.098230       14.525746        76.485911   4.011718           0  \n",
              "12    347.715027       15.929536        79.500778   3.445756           0  \n",
              "13    379.761835       19.370807        76.509996   4.413974           0  \n",
              "14    444.645352       13.228311        70.300213   4.777382           0  \n",
              "15    516.743282       11.539781        75.071617   4.376348           0  \n",
              "16    315.141267       20.397022        56.651604   4.268429           0  \n",
              "17    477.974642       13.387341        71.457362   4.503661           0  \n",
              "18    431.443990       12.888759        63.821237   2.436086           0  \n",
              "19    469.914551       12.509164        62.797277   2.560299           0  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#LOAD THE DATA\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"water_potability.csv\")\n",
        "\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "\n",
        "data.head(20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mn2ks1y4rG2i",
        "outputId": "3602f5a9-2c4d-4d00-f711-b914872430bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3276 entries, 0 to 3275\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   ph               2785 non-null   float64\n",
            " 1   Hardness         3276 non-null   float64\n",
            " 2   Solids           3276 non-null   float64\n",
            " 3   Chloramines      3276 non-null   float64\n",
            " 4   Sulfate          2495 non-null   float64\n",
            " 5   Conductivity     3276 non-null   float64\n",
            " 6   Organic_carbon   3276 non-null   float64\n",
            " 7   Trihalomethanes  3114 non-null   float64\n",
            " 8   Turbidity        3276 non-null   float64\n",
            " 9   Potability       3276 non-null   int64  \n",
            "dtypes: float64(9), int64(1)\n",
            "memory usage: 256.1 KB\n"
          ]
        }
      ],
      "source": [
        "# Information on the data\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "fJvnnIxav4N2",
        "outputId": "02d89ad2-bfb3-49ca-8fdb-85951b3ad5f3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"ph\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 982.4396919342113,\n        \"min\": 0.0,\n        \"max\": 2785.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          7.080794504276835,\n          7.036752103833548,\n          2785.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hardness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1102.077573149784,\n        \"min\": 32.879761476294156,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          196.36949601730151,\n          196.96762686363076,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19161.797748474182,\n        \"min\": 320.942611274359,\n        \"max\": 61227.19600771213,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          22014.092526077104,\n          20927.833606520187,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chloramines\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1156.047676013562,\n        \"min\": 0.3520000000000003,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          7.122276793425786,\n          7.130298973883081,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sulfate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 793.8602821876343,\n        \"min\": 41.416840461672706,\n        \"max\": 2495.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          333.7757766108135,\n          333.073545745888,\n          2495.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conductivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1040.8631085884185,\n        \"min\": 80.8240640511118,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          426.20511068255325,\n          421.8849682800544,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Organic_carbon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1153.6765632294614,\n        \"min\": 2.1999999999999886,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          14.284970247677318,\n          14.218337937208588,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Trihalomethanes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1081.0577228535572,\n        \"min\": 0.7379999999999995,\n        \"max\": 3114.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          66.39629294676803,\n          66.62248509808484,\n          3114.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Turbidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1156.9881922638972,\n        \"min\": 0.7803824084854124,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3.966786169791058,\n          3.955027562993039,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Potability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1158.0956231418108,\n        \"min\": 0.0,\n        \"max\": 3276.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3901098901098901,\n          1.0,\n          0.48784916967025516\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-44c794f1-5b30-4bc6-a7f7-4b8de3bf0f45\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2785.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>2495.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3114.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.080795</td>\n",
              "      <td>196.369496</td>\n",
              "      <td>22014.092526</td>\n",
              "      <td>7.122277</td>\n",
              "      <td>333.775777</td>\n",
              "      <td>426.205111</td>\n",
              "      <td>14.284970</td>\n",
              "      <td>66.396293</td>\n",
              "      <td>3.966786</td>\n",
              "      <td>0.390110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.594320</td>\n",
              "      <td>32.879761</td>\n",
              "      <td>8768.570828</td>\n",
              "      <td>1.583085</td>\n",
              "      <td>41.416840</td>\n",
              "      <td>80.824064</td>\n",
              "      <td>3.308162</td>\n",
              "      <td>16.175008</td>\n",
              "      <td>0.780382</td>\n",
              "      <td>0.487849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>47.432000</td>\n",
              "      <td>320.942611</td>\n",
              "      <td>0.352000</td>\n",
              "      <td>129.000000</td>\n",
              "      <td>181.483754</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>0.738000</td>\n",
              "      <td>1.450000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6.093092</td>\n",
              "      <td>176.850538</td>\n",
              "      <td>15666.690297</td>\n",
              "      <td>6.127421</td>\n",
              "      <td>307.699498</td>\n",
              "      <td>365.734414</td>\n",
              "      <td>12.065801</td>\n",
              "      <td>55.844536</td>\n",
              "      <td>3.439711</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7.036752</td>\n",
              "      <td>196.967627</td>\n",
              "      <td>20927.833607</td>\n",
              "      <td>7.130299</td>\n",
              "      <td>333.073546</td>\n",
              "      <td>421.884968</td>\n",
              "      <td>14.218338</td>\n",
              "      <td>66.622485</td>\n",
              "      <td>3.955028</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.062066</td>\n",
              "      <td>216.667456</td>\n",
              "      <td>27332.762127</td>\n",
              "      <td>8.114887</td>\n",
              "      <td>359.950170</td>\n",
              "      <td>481.792304</td>\n",
              "      <td>16.557652</td>\n",
              "      <td>77.337473</td>\n",
              "      <td>4.500320</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>14.000000</td>\n",
              "      <td>323.124000</td>\n",
              "      <td>61227.196008</td>\n",
              "      <td>13.127000</td>\n",
              "      <td>481.030642</td>\n",
              "      <td>753.342620</td>\n",
              "      <td>28.300000</td>\n",
              "      <td>124.000000</td>\n",
              "      <td>6.739000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44c794f1-5b30-4bc6-a7f7-4b8de3bf0f45')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-44c794f1-5b30-4bc6-a7f7-4b8de3bf0f45 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-44c794f1-5b30-4bc6-a7f7-4b8de3bf0f45');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a9e69951-7173-4df8-9422-ecc4a69106f0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a9e69951-7173-4df8-9422-ecc4a69106f0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a9e69951-7173-4df8-9422-ecc4a69106f0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                ph     Hardness        Solids  Chloramines      Sulfate  \\\n",
              "count  2785.000000  3276.000000   3276.000000  3276.000000  2495.000000   \n",
              "mean      7.080795   196.369496  22014.092526     7.122277   333.775777   \n",
              "std       1.594320    32.879761   8768.570828     1.583085    41.416840   \n",
              "min       0.000000    47.432000    320.942611     0.352000   129.000000   \n",
              "25%       6.093092   176.850538  15666.690297     6.127421   307.699498   \n",
              "50%       7.036752   196.967627  20927.833607     7.130299   333.073546   \n",
              "75%       8.062066   216.667456  27332.762127     8.114887   359.950170   \n",
              "max      14.000000   323.124000  61227.196008    13.127000   481.030642   \n",
              "\n",
              "       Conductivity  Organic_carbon  Trihalomethanes    Turbidity   Potability  \n",
              "count   3276.000000     3276.000000      3114.000000  3276.000000  3276.000000  \n",
              "mean     426.205111       14.284970        66.396293     3.966786     0.390110  \n",
              "std       80.824064        3.308162        16.175008     0.780382     0.487849  \n",
              "min      181.483754        2.200000         0.738000     1.450000     0.000000  \n",
              "25%      365.734414       12.065801        55.844536     3.439711     0.000000  \n",
              "50%      421.884968       14.218338        66.622485     3.955028     0.000000  \n",
              "75%      481.792304       16.557652        77.337473     4.500320     1.000000  \n",
              "max      753.342620       28.300000       124.000000     6.739000     1.000000  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Brief overview of the dataset statistics\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "f5Rjjxwg5XnF"
      },
      "outputs": [],
      "source": [
        "# drop duplicates rows of data\n",
        "\n",
        "data = data.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjFnkhc35ekL",
        "outputId": "030f3d29-27aa-4fdb-d87f-98e37ba0f9c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ph                 14.987790\n",
            "Hardness            0.000000\n",
            "Solids              0.000000\n",
            "Chloramines         0.000000\n",
            "Sulfate            23.840049\n",
            "Conductivity        0.000000\n",
            "Organic_carbon      0.000000\n",
            "Trihalomethanes     4.945055\n",
            "Turbidity           0.000000\n",
            "Potability          0.000000\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# percentage of missingness in the data for each column\n",
        "\n",
        "missing = data.isnull().mean()*100\n",
        "print(missing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "RlhnFruS2q0X",
        "outputId": "4af51e7d-ba7a-463d-a3ba-f82645c9c83e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data_imputed\",\n  \"rows\": 3276,\n  \"fields\": [\n    {\n      \"column\": \"ph\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.471574062911746,\n        \"min\": 0.0,\n        \"max\": 13.999999999999998,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          7.042483377815478,\n          6.643158712135614,\n          7.846057926337261\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hardness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32.879761476294156,\n        \"min\": 47.432,\n        \"max\": 323.124,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          183.5211070261417,\n          188.9135411469536,\n          224.05887682392927\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8768.570827785927,\n        \"min\": 320.942611274359,\n        \"max\": 61227.19600771213,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          20461.252710219946,\n          32873.820021715685,\n          23264.10996772913\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chloramines\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5830848890397096,\n        \"min\": 0.3520000000000003,\n        \"max\": 13.127000000000002,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          7.333212177578906,\n          6.791509363412849,\n          5.92236704115349\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sulfate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36.3878388853383,\n        \"min\": 129.00000000000003,\n        \"max\": 481.0306423059972,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          333.1194758732444,\n          333.8488418801131,\n          300.40262012672275\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conductivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80.8240640511118,\n        \"min\": 181.483753985146,\n        \"max\": 753.3426195583046,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          356.3690224100897,\n          336.56150104700754,\n          387.971335796834\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Organic_carbon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.308161999126874,\n        \"min\": 2.1999999999999886,\n        \"max\": 28.30000000000001,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          20.179028868493845,\n          14.706810313722087,\n          13.40673745495127\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Trihalomethanes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.769921510590818,\n        \"min\": 0.7379999999999995,\n        \"max\": 124.0,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          67.01990322225635,\n          67.84484886059036,\n          43.07518646611747\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Turbidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7803824084854124,\n        \"min\": 1.45,\n        \"max\": 6.739,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          4.886633785371213,\n          4.562197671215202,\n          2.487968647002356\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Potability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "data_imputed"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-71e35dd5-bea0-4c6f-aaf8-2b1177dd9764\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.190863</td>\n",
              "      <td>204.890455</td>\n",
              "      <td>20791.318981</td>\n",
              "      <td>7.300212</td>\n",
              "      <td>368.516441</td>\n",
              "      <td>564.308654</td>\n",
              "      <td>10.379783</td>\n",
              "      <td>86.990970</td>\n",
              "      <td>2.963135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.716080</td>\n",
              "      <td>129.422921</td>\n",
              "      <td>18630.057858</td>\n",
              "      <td>6.635246</td>\n",
              "      <td>344.836463</td>\n",
              "      <td>592.885359</td>\n",
              "      <td>15.180013</td>\n",
              "      <td>56.329076</td>\n",
              "      <td>4.500656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.099124</td>\n",
              "      <td>224.236259</td>\n",
              "      <td>19909.541732</td>\n",
              "      <td>9.275884</td>\n",
              "      <td>331.981769</td>\n",
              "      <td>418.606213</td>\n",
              "      <td>16.868637</td>\n",
              "      <td>66.420093</td>\n",
              "      <td>3.055934</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.316766</td>\n",
              "      <td>214.373394</td>\n",
              "      <td>22018.417441</td>\n",
              "      <td>8.059332</td>\n",
              "      <td>356.886136</td>\n",
              "      <td>363.266516</td>\n",
              "      <td>18.436524</td>\n",
              "      <td>100.341674</td>\n",
              "      <td>4.628771</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.092223</td>\n",
              "      <td>181.101509</td>\n",
              "      <td>17978.986339</td>\n",
              "      <td>6.546600</td>\n",
              "      <td>310.135738</td>\n",
              "      <td>398.410813</td>\n",
              "      <td>11.558279</td>\n",
              "      <td>31.997993</td>\n",
              "      <td>4.075075</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.584087</td>\n",
              "      <td>188.313324</td>\n",
              "      <td>28748.687739</td>\n",
              "      <td>7.544869</td>\n",
              "      <td>326.678363</td>\n",
              "      <td>280.467916</td>\n",
              "      <td>8.399735</td>\n",
              "      <td>54.917862</td>\n",
              "      <td>2.559708</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10.223862</td>\n",
              "      <td>248.071735</td>\n",
              "      <td>28749.716544</td>\n",
              "      <td>7.513408</td>\n",
              "      <td>393.663396</td>\n",
              "      <td>283.651634</td>\n",
              "      <td>13.789695</td>\n",
              "      <td>84.603556</td>\n",
              "      <td>2.672989</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8.635849</td>\n",
              "      <td>203.361523</td>\n",
              "      <td>13672.091764</td>\n",
              "      <td>4.563009</td>\n",
              "      <td>303.309771</td>\n",
              "      <td>474.607645</td>\n",
              "      <td>12.363817</td>\n",
              "      <td>62.798309</td>\n",
              "      <td>4.401425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6.927779</td>\n",
              "      <td>118.988579</td>\n",
              "      <td>14285.583854</td>\n",
              "      <td>7.804174</td>\n",
              "      <td>268.646941</td>\n",
              "      <td>389.375566</td>\n",
              "      <td>12.706049</td>\n",
              "      <td>53.928846</td>\n",
              "      <td>3.595017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>11.180284</td>\n",
              "      <td>227.231469</td>\n",
              "      <td>25484.508491</td>\n",
              "      <td>9.077200</td>\n",
              "      <td>404.041635</td>\n",
              "      <td>563.885481</td>\n",
              "      <td>17.927806</td>\n",
              "      <td>71.976601</td>\n",
              "      <td>4.370562</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71e35dd5-bea0-4c6f-aaf8-2b1177dd9764')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-71e35dd5-bea0-4c6f-aaf8-2b1177dd9764 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-71e35dd5-bea0-4c6f-aaf8-2b1177dd9764');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7fa1f6a9-8e69-4725-a2d2-ed4f2a56e995\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7fa1f6a9-8e69-4725-a2d2-ed4f2a56e995')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7fa1f6a9-8e69-4725-a2d2-ed4f2a56e995 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
              "0   7.190863  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
              "1   3.716080  129.422921  18630.057858     6.635246  344.836463    592.885359   \n",
              "2   8.099124  224.236259  19909.541732     9.275884  331.981769    418.606213   \n",
              "3   8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
              "4   9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
              "5   5.584087  188.313324  28748.687739     7.544869  326.678363    280.467916   \n",
              "6  10.223862  248.071735  28749.716544     7.513408  393.663396    283.651634   \n",
              "7   8.635849  203.361523  13672.091764     4.563009  303.309771    474.607645   \n",
              "8   6.927779  118.988579  14285.583854     7.804174  268.646941    389.375566   \n",
              "9  11.180284  227.231469  25484.508491     9.077200  404.041635    563.885481   \n",
              "\n",
              "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
              "0       10.379783        86.990970   2.963135           0  \n",
              "1       15.180013        56.329076   4.500656           0  \n",
              "2       16.868637        66.420093   3.055934           0  \n",
              "3       18.436524       100.341674   4.628771           0  \n",
              "4       11.558279        31.997993   4.075075           0  \n",
              "5        8.399735        54.917862   2.559708           0  \n",
              "6       13.789695        84.603556   2.672989           0  \n",
              "7       12.363817        62.798309   4.401425           0  \n",
              "8       12.706049        53.928846   3.595017           0  \n",
              "9       17.927806        71.976601   4.370562           0  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# MICE IMPUTATION to fill the missing data\n",
        "# create the imputer using MICE\n",
        "\n",
        "# separate the target variable from the rest of the data to make sure it is not changed or imputed\n",
        "features = data.drop(columns='Potability')\n",
        "target = data.Potability\n",
        "imputer = IterativeImputer(random_state=0)\n",
        "features_imputed = imputer.fit_transform(features)\n",
        "\n",
        "# convert the data back into a dataframe\n",
        "features_imputed = pd.DataFrame(features_imputed, columns=features.columns)\n",
        "\n",
        "# merge target variable and data\n",
        "data_imputed = pd.concat([features_imputed, target], axis=1)\n",
        "data_imputed.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58zqnGV23ZSx",
        "outputId": "f1d38ded-0d33-4423-8292-30564230bce0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3276 entries, 0 to 3275\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   ph               3276 non-null   float64\n",
            " 1   Hardness         3276 non-null   float64\n",
            " 2   Solids           3276 non-null   float64\n",
            " 3   Chloramines      3276 non-null   float64\n",
            " 4   Sulfate          3276 non-null   float64\n",
            " 5   Conductivity     3276 non-null   float64\n",
            " 6   Organic_carbon   3276 non-null   float64\n",
            " 7   Trihalomethanes  3276 non-null   float64\n",
            " 8   Turbidity        3276 non-null   float64\n",
            " 9   Potability       3276 non-null   int64  \n",
            "dtypes: float64(9), int64(1)\n",
            "memory usage: 256.1 KB\n"
          ]
        }
      ],
      "source": [
        "# confirm imputed data\n",
        "data_imputed.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIdMxexk47Qa",
        "outputId": "7cd39a1e-08cb-4b0f-dc57-e29a9e1a20ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0       204.890455\n",
            "1       129.422921\n",
            "2       224.236259\n",
            "3       214.373394\n",
            "4       181.101509\n",
            "           ...    \n",
            "3271    193.681735\n",
            "3272    193.553212\n",
            "3273    175.762646\n",
            "3274    230.603758\n",
            "3275    195.102299\n",
            "Name: Hardness, Length: 3276, dtype: float64\n",
            "Number of outliers: 83\n",
            "Percentage of outliers: 2.53%\n",
            "0       20791.318981\n",
            "1       18630.057858\n",
            "2       19909.541732\n",
            "3       22018.417441\n",
            "4       17978.986339\n",
            "            ...     \n",
            "3271    47580.991603\n",
            "3272    17329.802160\n",
            "3273    33155.578218\n",
            "3274    11983.869376\n",
            "3275    17404.177061\n",
            "Name: Solids, Length: 3193, dtype: float64\n",
            "Number of outliers: 42\n",
            "Percentage of outliers: 1.32%\n",
            "0       368.516441\n",
            "1       344.836463\n",
            "2       331.981769\n",
            "3       356.886136\n",
            "4       310.135738\n",
            "           ...    \n",
            "3270    345.700257\n",
            "3272    338.612062\n",
            "3273    326.848982\n",
            "3274    336.993878\n",
            "3275    338.025733\n",
            "Name: Sulfate, Length: 3151, dtype: float64\n",
            "Number of outliers: 230\n",
            "Percentage of outliers: 7.30%\n",
            "0       564.308654\n",
            "1       592.885359\n",
            "2       418.606213\n",
            "3       363.266516\n",
            "4       398.410813\n",
            "           ...    \n",
            "3270    415.886955\n",
            "3272    392.449580\n",
            "3273    432.044783\n",
            "3274    402.883113\n",
            "3275    327.459760\n",
            "Name: Conductivity, Length: 2921, dtype: float64\n",
            "Number of outliers: 9\n",
            "Percentage of outliers: 0.31%\n",
            "0       10.379783\n",
            "1       15.180013\n",
            "2       16.868637\n",
            "3       18.436524\n",
            "4       11.558279\n",
            "          ...    \n",
            "3270    12.067620\n",
            "3272    19.903225\n",
            "3273    11.039070\n",
            "3274    11.168946\n",
            "3275    16.140368\n",
            "Name: Organic_carbon, Length: 2912, dtype: float64\n",
            "Number of outliers: 18\n",
            "Percentage of outliers: 0.62%\n",
            "0        86.990970\n",
            "1        56.329076\n",
            "2        66.420093\n",
            "3       100.341674\n",
            "4        31.997993\n",
            "           ...    \n",
            "3270     60.419921\n",
            "3272     66.474992\n",
            "3273     69.845400\n",
            "3274     77.488213\n",
            "3275     78.698446\n",
            "Name: Trihalomethanes, Length: 2894, dtype: float64\n",
            "Number of outliers: 47\n",
            "Percentage of outliers: 1.62%\n",
            "0       2.963135\n",
            "1       4.500656\n",
            "2       3.055934\n",
            "3       4.628771\n",
            "4       4.075075\n",
            "          ...   \n",
            "3270    3.669712\n",
            "3272    2.798243\n",
            "3273    3.298875\n",
            "3274    4.708658\n",
            "3275    2.309149\n",
            "Name: Turbidity, Length: 2847, dtype: float64\n",
            "Number of outliers: 17\n",
            "Percentage of outliers: 0.60%\n"
          ]
        }
      ],
      "source": [
        "# Remove outliers that may affect the neural network's accuracy using IQR method\n",
        "def remove_outliers_iqr(df, column_name):\n",
        "    Q1 = df[column_name].quantile(0.25)\n",
        "    Q3 = df[column_name].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    # anything above or below this is an outlier\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # place outliers in a data frame\n",
        "    print(f\"{df[column_name]}\")\n",
        "    outliers = df[(df[column_name] < lower_bound) | (df[column_name] > upper_bound)]\n",
        "    print(f\"Number of outliers: {len(outliers)}\")\n",
        "    print(f\"Percentage of outliers: {len(outliers)/len(df)*100:.2f}%\")\n",
        "\n",
        "\n",
        "    # remove outliers\n",
        "\n",
        "    df_clean = df[(df[column_name] >= lower_bound) & (df[column_name] <= upper_bound)]\n",
        "\n",
        "\n",
        "\n",
        "    return df_clean\n",
        "\n",
        "# columns to remove outliers in\n",
        "columns = ['Hardness', 'Solids', 'Sulfate', 'Conductivity', 'Organic_carbon', 'Trihalomethanes', 'Turbidity']\n",
        "\n",
        "data_imputed_copy = data_imputed.copy()\n",
        "\n",
        "for i in columns:\n",
        "  data_imputed_copy = remove_outliers_iqr(data_imputed_copy, i)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QfR0r8cGVU7"
      },
      "source": [
        "Plot the Data Appropriately"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PF9lHguSY2vB",
        "outputId": "0528d182-3b46-4552-eea0-86bc4b22c7c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2830, 9)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# generate 2d classification dataset\n",
        "\n",
        "# X, y = pass\n",
        "\n",
        "# Transforms data to have mean=0 and standard deviation=1\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X = data_imputed_copy.drop(columns='Potability', axis=1)\n",
        "y= data_imputed_copy['Potability']\n",
        "\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# from sklearn.decomposition import PCA\n",
        "# pca = PCA(n_components=2)\n",
        "# X_2d_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "X_scaled.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfSk1lXRYjrh",
        "outputId": "31780e32-2bc4-4308-89df-bbaa68a67d92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== FINAL SHAPES ===\n",
            "X_train: (1981, 9)\n",
            "X_val: (424, 9)\n",
            "X_test: (425, 9)\n",
            "y_train: (1981,)\n",
            "y_val: (424,)\n",
            "y_test: (425,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Split the data into training validation and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3,random_state=42,\n",
        "    stratify=y               # Keep same class distribution in all splits\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5,stratify=y_temp)\n",
        "\n",
        "print(f\"\\n=== FINAL SHAPES ===\")\n",
        "print(f\"X_train: {X_train.shape}\")\n",
        "print(f\"X_val: {X_val.shape}\")\n",
        "print(f\"X_test: {X_test.shape}\")\n",
        "print(f\"y_train: {y_train.shape}\")\n",
        "print(f\"y_val: {y_val.shape}\")\n",
        "print(f\"y_test: {y_test.shape}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvjIHLrcGhzc"
      },
      "source": [
        "# Each Member Defines their model Here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLwYoJG9jvDa",
        "outputId": "68eb788e-30d1-470b-c651-609ee18c1382"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5115 - loss: 0.7321 - val_accuracy: 0.5802 - val_loss: 0.6845\n",
            "Epoch 2/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5391 - loss: 0.7130 - val_accuracy: 0.6061 - val_loss: 0.6777\n",
            "Epoch 3/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5447 - loss: 0.7101 - val_accuracy: 0.6203 - val_loss: 0.6749\n",
            "Epoch 4/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5656 - loss: 0.7034 - val_accuracy: 0.6250 - val_loss: 0.6721\n",
            "Epoch 5/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5569 - loss: 0.7131 - val_accuracy: 0.6297 - val_loss: 0.6711\n",
            "Epoch 6/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5952 - loss: 0.6885 - val_accuracy: 0.6297 - val_loss: 0.6703\n",
            "Epoch 7/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5694 - loss: 0.7031 - val_accuracy: 0.6297 - val_loss: 0.6703\n",
            "Epoch 8/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5643 - loss: 0.6963 - val_accuracy: 0.6297 - val_loss: 0.6699\n",
            "Epoch 9/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5715 - loss: 0.7027 - val_accuracy: 0.6297 - val_loss: 0.6704\n",
            "Epoch 10/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5793 - loss: 0.6930 - val_accuracy: 0.6297 - val_loss: 0.6701\n",
            "Epoch 11/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6018 - loss: 0.6830 - val_accuracy: 0.6297 - val_loss: 0.6699\n",
            "Epoch 12/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6044 - loss: 0.6796 - val_accuracy: 0.6297 - val_loss: 0.6702\n",
            "Epoch 13/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5981 - loss: 0.6813 - val_accuracy: 0.6297 - val_loss: 0.6702\n",
            "Epoch 14/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5707 - loss: 0.6947 - val_accuracy: 0.6297 - val_loss: 0.6704\n",
            "Epoch 15/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5848 - loss: 0.6845 - val_accuracy: 0.6297 - val_loss: 0.6702\n",
            "Epoch 16/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6121 - loss: 0.6790 - val_accuracy: 0.6297 - val_loss: 0.6700\n",
            "Epoch 17/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6107 - loss: 0.6881 - val_accuracy: 0.6297 - val_loss: 0.6703\n",
            "Epoch 18/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5982 - loss: 0.6903 - val_accuracy: 0.6297 - val_loss: 0.6708\n",
            "Epoch 19/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6089 - loss: 0.6809 - val_accuracy: 0.6297 - val_loss: 0.6713\n",
            "Epoch 20/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6046 - loss: 0.6829 - val_accuracy: 0.6297 - val_loss: 0.6715\n",
            "Epoch 21/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6315 - loss: 0.6652 - val_accuracy: 0.6297 - val_loss: 0.6707\n",
            "Epoch 22/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6188 - loss: 0.6736 - val_accuracy: 0.6297 - val_loss: 0.6706\n",
            "Epoch 23/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6090 - loss: 0.6720 - val_accuracy: 0.6297 - val_loss: 0.6703\n",
            "Epoch 24/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6232 - loss: 0.6714 - val_accuracy: 0.6297 - val_loss: 0.6703\n",
            "Epoch 25/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6171 - loss: 0.6773 - val_accuracy: 0.6297 - val_loss: 0.6704\n",
            "Epoch 26/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6105 - loss: 0.6712 - val_accuracy: 0.6297 - val_loss: 0.6701\n",
            "Epoch 27/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6276 - loss: 0.6771 - val_accuracy: 0.6297 - val_loss: 0.6697\n",
            "Epoch 28/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6246 - loss: 0.6675 - val_accuracy: 0.6297 - val_loss: 0.6696\n",
            "Epoch 29/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6213 - loss: 0.6687 - val_accuracy: 0.6297 - val_loss: 0.6696\n",
            "Epoch 30/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6338 - loss: 0.6609 - val_accuracy: 0.6297 - val_loss: 0.6696\n",
            "Epoch 31/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6272 - loss: 0.6640 - val_accuracy: 0.6297 - val_loss: 0.6690\n",
            "Epoch 32/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6357 - loss: 0.6692 - val_accuracy: 0.6297 - val_loss: 0.6689\n",
            "Epoch 33/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6214 - loss: 0.6682 - val_accuracy: 0.6297 - val_loss: 0.6683\n",
            "Epoch 34/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6288 - loss: 0.6642 - val_accuracy: 0.6297 - val_loss: 0.6677\n",
            "Epoch 35/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6255 - loss: 0.6663 - val_accuracy: 0.6297 - val_loss: 0.6672\n",
            "Epoch 36/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6228 - loss: 0.6665 - val_accuracy: 0.6297 - val_loss: 0.6672\n",
            "Epoch 37/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6281 - loss: 0.6628 - val_accuracy: 0.6297 - val_loss: 0.6664\n",
            "Epoch 38/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6265 - loss: 0.6592 - val_accuracy: 0.6297 - val_loss: 0.6661\n",
            "Epoch 39/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6271 - loss: 0.6683 - val_accuracy: 0.6297 - val_loss: 0.6658\n",
            "Epoch 40/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6214 - loss: 0.6704 - val_accuracy: 0.6297 - val_loss: 0.6659\n",
            "Epoch 41/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6409 - loss: 0.6562 - val_accuracy: 0.6297 - val_loss: 0.6656\n",
            "Epoch 42/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6417 - loss: 0.6565 - val_accuracy: 0.6297 - val_loss: 0.6652\n",
            "Epoch 43/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6052 - loss: 0.6734 - val_accuracy: 0.6297 - val_loss: 0.6653\n",
            "Epoch 44/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6284 - loss: 0.6746 - val_accuracy: 0.6297 - val_loss: 0.6652\n",
            "Epoch 45/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6521 - loss: 0.6506 - val_accuracy: 0.6297 - val_loss: 0.6647\n",
            "Epoch 46/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6358 - loss: 0.6646 - val_accuracy: 0.6297 - val_loss: 0.6645\n",
            "Epoch 47/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6311 - loss: 0.6601 - val_accuracy: 0.6297 - val_loss: 0.6646\n",
            "Epoch 48/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6318 - loss: 0.6679 - val_accuracy: 0.6297 - val_loss: 0.6647\n",
            "Epoch 49/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6489 - loss: 0.6522 - val_accuracy: 0.6297 - val_loss: 0.6641\n",
            "Epoch 50/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6275 - loss: 0.6720 - val_accuracy: 0.6297 - val_loss: 0.6639\n",
            "Epoch 51/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6185 - loss: 0.6616 - val_accuracy: 0.6297 - val_loss: 0.6636\n",
            "Epoch 52/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6368 - loss: 0.6578 - val_accuracy: 0.6297 - val_loss: 0.6632\n",
            "Epoch 53/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6242 - loss: 0.6668 - val_accuracy: 0.6297 - val_loss: 0.6624\n",
            "Epoch 54/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6395 - loss: 0.6500 - val_accuracy: 0.6297 - val_loss: 0.6615\n",
            "Epoch 55/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6504 - loss: 0.6495 - val_accuracy: 0.6297 - val_loss: 0.6616\n",
            "Epoch 56/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6208 - loss: 0.6604 - val_accuracy: 0.6297 - val_loss: 0.6611\n",
            "Epoch 57/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6301 - loss: 0.6627 - val_accuracy: 0.6297 - val_loss: 0.6608\n",
            "Epoch 58/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6398 - loss: 0.6514 - val_accuracy: 0.6297 - val_loss: 0.6605\n",
            "Epoch 59/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6288 - loss: 0.6602 - val_accuracy: 0.6297 - val_loss: 0.6600\n",
            "Epoch 60/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6278 - loss: 0.6527 - val_accuracy: 0.6297 - val_loss: 0.6598\n",
            "Epoch 61/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6301 - loss: 0.6561 - val_accuracy: 0.6297 - val_loss: 0.6598\n",
            "Epoch 62/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6343 - loss: 0.6573 - val_accuracy: 0.6297 - val_loss: 0.6599\n",
            "Epoch 63/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6304 - loss: 0.6594 - val_accuracy: 0.6297 - val_loss: 0.6601\n",
            "Epoch 64/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6394 - loss: 0.6644 - val_accuracy: 0.6297 - val_loss: 0.6601\n",
            "Epoch 65/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6356 - loss: 0.6550 - val_accuracy: 0.6297 - val_loss: 0.6595\n",
            "Epoch 66/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6409 - loss: 0.6522 - val_accuracy: 0.6297 - val_loss: 0.6590\n",
            "Epoch 67/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6483 - loss: 0.6447 - val_accuracy: 0.6297 - val_loss: 0.6584\n",
            "Epoch 68/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6379 - loss: 0.6529 - val_accuracy: 0.6297 - val_loss: 0.6581\n",
            "Epoch 69/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6464 - loss: 0.6512 - val_accuracy: 0.6297 - val_loss: 0.6579\n",
            "Epoch 70/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6188 - loss: 0.6648 - val_accuracy: 0.6297 - val_loss: 0.6577\n",
            "Epoch 71/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6363 - loss: 0.6582 - val_accuracy: 0.6297 - val_loss: 0.6575\n",
            "Epoch 72/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6353 - loss: 0.6494 - val_accuracy: 0.6297 - val_loss: 0.6575\n",
            "Epoch 73/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6446 - loss: 0.6452 - val_accuracy: 0.6297 - val_loss: 0.6565\n",
            "Epoch 74/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6358 - loss: 0.6563 - val_accuracy: 0.6297 - val_loss: 0.6563\n",
            "Epoch 75/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6338 - loss: 0.6498 - val_accuracy: 0.6297 - val_loss: 0.6560\n",
            "Epoch 76/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6311 - loss: 0.6489 - val_accuracy: 0.6297 - val_loss: 0.6557\n",
            "Epoch 77/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6218 - loss: 0.6595 - val_accuracy: 0.6297 - val_loss: 0.6552\n",
            "Epoch 78/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6178 - loss: 0.6588 - val_accuracy: 0.6297 - val_loss: 0.6549\n",
            "Epoch 79/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6127 - loss: 0.6652 - val_accuracy: 0.6297 - val_loss: 0.6547\n",
            "Epoch 80/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6151 - loss: 0.6559 - val_accuracy: 0.6297 - val_loss: 0.6542\n",
            "Epoch 81/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6217 - loss: 0.6612 - val_accuracy: 0.6297 - val_loss: 0.6542\n",
            "Epoch 82/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6333 - loss: 0.6467 - val_accuracy: 0.6297 - val_loss: 0.6539\n",
            "Epoch 83/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6256 - loss: 0.6504 - val_accuracy: 0.6297 - val_loss: 0.6537\n",
            "Epoch 84/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6172 - loss: 0.6680 - val_accuracy: 0.6297 - val_loss: 0.6538\n",
            "Epoch 85/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6376 - loss: 0.6583 - val_accuracy: 0.6297 - val_loss: 0.6534\n",
            "Epoch 86/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6247 - loss: 0.6567 - val_accuracy: 0.6297 - val_loss: 0.6533\n",
            "Epoch 87/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6315 - loss: 0.6480 - val_accuracy: 0.6297 - val_loss: 0.6529\n",
            "Epoch 88/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6196 - loss: 0.6580 - val_accuracy: 0.6297 - val_loss: 0.6527\n",
            "Epoch 89/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6162 - loss: 0.6631 - val_accuracy: 0.6297 - val_loss: 0.6523\n",
            "Epoch 90/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6197 - loss: 0.6595 - val_accuracy: 0.6297 - val_loss: 0.6522\n",
            "Epoch 91/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6387 - loss: 0.6405 - val_accuracy: 0.6297 - val_loss: 0.6516\n",
            "Epoch 92/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6430 - loss: 0.6368 - val_accuracy: 0.6297 - val_loss: 0.6512\n",
            "Epoch 93/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6360 - loss: 0.6489 - val_accuracy: 0.6297 - val_loss: 0.6510\n",
            "Epoch 94/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6499 - loss: 0.6448 - val_accuracy: 0.6297 - val_loss: 0.6506\n",
            "Epoch 95/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6449 - loss: 0.6350 - val_accuracy: 0.6297 - val_loss: 0.6504\n",
            "Epoch 96/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6446 - loss: 0.6462 - val_accuracy: 0.6297 - val_loss: 0.6503\n",
            "Epoch 97/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6481 - loss: 0.6374 - val_accuracy: 0.6297 - val_loss: 0.6500\n",
            "Epoch 98/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6299 - loss: 0.6460 - val_accuracy: 0.6297 - val_loss: 0.6496\n",
            "Epoch 99/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6335 - loss: 0.6466 - val_accuracy: 0.6297 - val_loss: 0.6489\n",
            "Epoch 100/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6495 - loss: 0.6390 - val_accuracy: 0.6297 - val_loss: 0.6489\n",
            "Epoch 101/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6360 - loss: 0.6538 - val_accuracy: 0.6297 - val_loss: 0.6488\n",
            "Epoch 102/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6386 - loss: 0.6450 - val_accuracy: 0.6297 - val_loss: 0.6481\n",
            "Epoch 103/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6208 - loss: 0.6577 - val_accuracy: 0.6297 - val_loss: 0.6482\n",
            "Epoch 104/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6482 - loss: 0.6423 - val_accuracy: 0.6297 - val_loss: 0.6481\n",
            "Epoch 105/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6551 - loss: 0.6324 - val_accuracy: 0.6297 - val_loss: 0.6479\n",
            "Epoch 106/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6276 - loss: 0.6527 - val_accuracy: 0.6297 - val_loss: 0.6475\n",
            "Epoch 107/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6458 - loss: 0.6406 - val_accuracy: 0.6297 - val_loss: 0.6475\n",
            "Epoch 108/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6440 - loss: 0.6418 - val_accuracy: 0.6297 - val_loss: 0.6472\n",
            "Epoch 109/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6351 - loss: 0.6397 - val_accuracy: 0.6297 - val_loss: 0.6467\n",
            "Epoch 110/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6434 - loss: 0.6410 - val_accuracy: 0.6297 - val_loss: 0.6466\n",
            "Epoch 111/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6299 - loss: 0.6409 - val_accuracy: 0.6297 - val_loss: 0.6461\n",
            "Epoch 112/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6099 - loss: 0.6536 - val_accuracy: 0.6297 - val_loss: 0.6455\n",
            "Epoch 113/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6409 - loss: 0.6376 - val_accuracy: 0.6297 - val_loss: 0.6451\n",
            "Epoch 114/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6334 - loss: 0.6429 - val_accuracy: 0.6297 - val_loss: 0.6449\n",
            "Epoch 115/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6205 - loss: 0.6539 - val_accuracy: 0.6297 - val_loss: 0.6447\n",
            "Epoch 116/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6414 - loss: 0.6411 - val_accuracy: 0.6321 - val_loss: 0.6445\n",
            "Epoch 117/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6518 - loss: 0.6406 - val_accuracy: 0.6321 - val_loss: 0.6442\n",
            "Epoch 118/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6441 - loss: 0.6393 - val_accuracy: 0.6321 - val_loss: 0.6440\n",
            "Epoch 119/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6408 - loss: 0.6412 - val_accuracy: 0.6321 - val_loss: 0.6442\n",
            "Epoch 120/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6398 - loss: 0.6446 - val_accuracy: 0.6321 - val_loss: 0.6439\n",
            "Epoch 121/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6270 - loss: 0.6500 - val_accuracy: 0.6321 - val_loss: 0.6436\n",
            "Epoch 122/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6259 - loss: 0.6445 - val_accuracy: 0.6321 - val_loss: 0.6430\n",
            "Epoch 123/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6263 - loss: 0.6488 - val_accuracy: 0.6321 - val_loss: 0.6427\n",
            "Epoch 124/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6591 - loss: 0.6238 - val_accuracy: 0.6321 - val_loss: 0.6420\n",
            "Epoch 125/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6472 - loss: 0.6409 - val_accuracy: 0.6321 - val_loss: 0.6421\n",
            "Epoch 126/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6372 - loss: 0.6460 - val_accuracy: 0.6321 - val_loss: 0.6424\n",
            "Epoch 127/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6548 - loss: 0.6293 - val_accuracy: 0.6321 - val_loss: 0.6421\n",
            "Epoch 128/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6448 - loss: 0.6410 - val_accuracy: 0.6321 - val_loss: 0.6417\n",
            "Epoch 129/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6294 - loss: 0.6551 - val_accuracy: 0.6344 - val_loss: 0.6412\n",
            "Epoch 130/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6387 - loss: 0.6441 - val_accuracy: 0.6344 - val_loss: 0.6410\n",
            "Epoch 131/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6369 - loss: 0.6472 - val_accuracy: 0.6368 - val_loss: 0.6407\n",
            "Epoch 132/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6287 - loss: 0.6374 - val_accuracy: 0.6368 - val_loss: 0.6405\n",
            "Epoch 133/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6346 - loss: 0.6432 - val_accuracy: 0.6368 - val_loss: 0.6405\n",
            "Epoch 134/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6278 - loss: 0.6522 - val_accuracy: 0.6368 - val_loss: 0.6408\n",
            "Epoch 135/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6585 - loss: 0.6379 - val_accuracy: 0.6368 - val_loss: 0.6403\n",
            "Epoch 136/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6234 - loss: 0.6513 - val_accuracy: 0.6368 - val_loss: 0.6400\n",
            "Epoch 137/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6331 - loss: 0.6466 - val_accuracy: 0.6368 - val_loss: 0.6400\n",
            "Epoch 138/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6419 - loss: 0.6270 - val_accuracy: 0.6344 - val_loss: 0.6394\n",
            "Epoch 139/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6365 - loss: 0.6384 - val_accuracy: 0.6368 - val_loss: 0.6391\n",
            "Epoch 140/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6497 - loss: 0.6280 - val_accuracy: 0.6344 - val_loss: 0.6388\n",
            "Epoch 141/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6239 - loss: 0.6455 - val_accuracy: 0.6368 - val_loss: 0.6385\n",
            "Epoch 142/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6368 - loss: 0.6399 - val_accuracy: 0.6368 - val_loss: 0.6383\n",
            "Epoch 143/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6399 - loss: 0.6370 - val_accuracy: 0.6392 - val_loss: 0.6382\n",
            "Epoch 144/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6437 - loss: 0.6360 - val_accuracy: 0.6392 - val_loss: 0.6380\n",
            "Epoch 145/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6448 - loss: 0.6305 - val_accuracy: 0.6392 - val_loss: 0.6377\n",
            "Epoch 146/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6397 - loss: 0.6431 - val_accuracy: 0.6392 - val_loss: 0.6374\n",
            "Epoch 147/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6563 - loss: 0.6364 - val_accuracy: 0.6392 - val_loss: 0.6375\n",
            "Epoch 148/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6450 - loss: 0.6365 - val_accuracy: 0.6392 - val_loss: 0.6372\n",
            "Epoch 149/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6267 - loss: 0.6440 - val_accuracy: 0.6415 - val_loss: 0.6368\n",
            "Epoch 150/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6525 - loss: 0.6303 - val_accuracy: 0.6415 - val_loss: 0.6363\n",
            "Epoch 151/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6313 - loss: 0.6327 - val_accuracy: 0.6415 - val_loss: 0.6362\n",
            "Epoch 152/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6481 - loss: 0.6379 - val_accuracy: 0.6462 - val_loss: 0.6361\n",
            "Epoch 153/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6303 - loss: 0.6470 - val_accuracy: 0.6462 - val_loss: 0.6358\n",
            "Epoch 154/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6526 - loss: 0.6333 - val_accuracy: 0.6486 - val_loss: 0.6353\n",
            "Epoch 155/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6406 - loss: 0.6391 - val_accuracy: 0.6486 - val_loss: 0.6357\n",
            "Epoch 156/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6442 - loss: 0.6271 - val_accuracy: 0.6486 - val_loss: 0.6358\n",
            "Epoch 157/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6625 - loss: 0.6334 - val_accuracy: 0.6486 - val_loss: 0.6357\n",
            "Epoch 158/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6290 - loss: 0.6385 - val_accuracy: 0.6509 - val_loss: 0.6357\n",
            "Epoch 159/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6548 - loss: 0.6284 - val_accuracy: 0.6486 - val_loss: 0.6354\n",
            "Epoch 160/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6509 - loss: 0.6367 - val_accuracy: 0.6509 - val_loss: 0.6353\n",
            "Epoch 161/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6530 - loss: 0.6351 - val_accuracy: 0.6533 - val_loss: 0.6352\n",
            "Epoch 162/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6467 - loss: 0.6301 - val_accuracy: 0.6533 - val_loss: 0.6350\n",
            "Epoch 163/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6502 - loss: 0.6399 - val_accuracy: 0.6533 - val_loss: 0.6349\n",
            "Epoch 164/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6410 - loss: 0.6347 - val_accuracy: 0.6533 - val_loss: 0.6346\n",
            "Epoch 165/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6328 - loss: 0.6331 - val_accuracy: 0.6533 - val_loss: 0.6343\n",
            "Epoch 166/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6289 - loss: 0.6543 - val_accuracy: 0.6533 - val_loss: 0.6341\n",
            "Epoch 167/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6365 - loss: 0.6330 - val_accuracy: 0.6509 - val_loss: 0.6339\n",
            "Epoch 168/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6424 - loss: 0.6420 - val_accuracy: 0.6509 - val_loss: 0.6337\n",
            "Epoch 169/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6398 - loss: 0.6378 - val_accuracy: 0.6509 - val_loss: 0.6336\n",
            "Epoch 170/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6530 - loss: 0.6333 - val_accuracy: 0.6509 - val_loss: 0.6334\n",
            "Epoch 171/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6473 - loss: 0.6303 - val_accuracy: 0.6509 - val_loss: 0.6332\n",
            "Epoch 172/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6557 - loss: 0.6303 - val_accuracy: 0.6509 - val_loss: 0.6334\n",
            "Epoch 173/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6560 - loss: 0.6307 - val_accuracy: 0.6509 - val_loss: 0.6332\n",
            "Epoch 174/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6517 - loss: 0.6296 - val_accuracy: 0.6509 - val_loss: 0.6335\n",
            "Epoch 175/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6478 - loss: 0.6341 - val_accuracy: 0.6509 - val_loss: 0.6334\n",
            "Epoch 176/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6549 - loss: 0.6354 - val_accuracy: 0.6509 - val_loss: 0.6330\n",
            "Epoch 177/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6588 - loss: 0.6287 - val_accuracy: 0.6509 - val_loss: 0.6326\n",
            "Epoch 178/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6508 - loss: 0.6340 - val_accuracy: 0.6509 - val_loss: 0.6319\n",
            "Epoch 179/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6559 - loss: 0.6381 - val_accuracy: 0.6533 - val_loss: 0.6318\n",
            "Epoch 180/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6635 - loss: 0.6294 - val_accuracy: 0.6533 - val_loss: 0.6318\n",
            "Epoch 181/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6381 - loss: 0.6361 - val_accuracy: 0.6509 - val_loss: 0.6317\n",
            "Epoch 182/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6537 - loss: 0.6284 - val_accuracy: 0.6509 - val_loss: 0.6316\n",
            "Epoch 183/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6545 - loss: 0.6196 - val_accuracy: 0.6509 - val_loss: 0.6311\n",
            "Epoch 184/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6559 - loss: 0.6282 - val_accuracy: 0.6509 - val_loss: 0.6309\n",
            "Epoch 185/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6416 - loss: 0.6416 - val_accuracy: 0.6533 - val_loss: 0.6307\n",
            "Epoch 186/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6399 - loss: 0.6221 - val_accuracy: 0.6509 - val_loss: 0.6305\n",
            "Epoch 187/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6410 - loss: 0.6346 - val_accuracy: 0.6533 - val_loss: 0.6299\n",
            "Epoch 188/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6376 - loss: 0.6350 - val_accuracy: 0.6557 - val_loss: 0.6299\n",
            "Epoch 189/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6741 - loss: 0.6082 - val_accuracy: 0.6557 - val_loss: 0.6295\n",
            "Epoch 190/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6723 - loss: 0.6260 - val_accuracy: 0.6557 - val_loss: 0.6291\n",
            "Epoch 191/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6556 - loss: 0.6304 - val_accuracy: 0.6557 - val_loss: 0.6290\n",
            "Epoch 192/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6091 - loss: 0.6388 - val_accuracy: 0.6557 - val_loss: 0.6294\n",
            "Epoch 193/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6501 - loss: 0.6361 - val_accuracy: 0.6557 - val_loss: 0.6294\n",
            "Epoch 194/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6453 - loss: 0.6189 - val_accuracy: 0.6580 - val_loss: 0.6294\n",
            "Epoch 195/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6465 - loss: 0.6336 - val_accuracy: 0.6557 - val_loss: 0.6293\n",
            "Epoch 196/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6442 - loss: 0.6279 - val_accuracy: 0.6580 - val_loss: 0.6290\n",
            "Epoch 197/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6455 - loss: 0.6328 - val_accuracy: 0.6580 - val_loss: 0.6286\n",
            "Epoch 198/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6798 - loss: 0.6080 - val_accuracy: 0.6557 - val_loss: 0.6282\n",
            "Epoch 199/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6563 - loss: 0.6259 - val_accuracy: 0.6557 - val_loss: 0.6281\n",
            "Epoch 200/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6200 - loss: 0.6490 - val_accuracy: 0.6557 - val_loss: 0.6282\n"
          ]
        }
      ],
      "source": [
        "#Model Definition by member 1\n",
        "def model_jeremiah_agbaje():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(128, input_shape=(X_train.shape[1],), name='dense_layer', activation=\"relu\",kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))  # 50% dropout after first layer\n",
        "  model.add(tf.keras.layers.Dense(64, name='dense_layer2', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))  # 50% dropout after second layer\n",
        "  model.add(tf.keras.layers.Dense(32, name='dense_layer3', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))\n",
        "  model.add(tf.keras.layers.Dense(1, name='output_layer', activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.00001)))\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "model = model_jeremiah_agbaje()\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "      monitor='val_loss',    # Monitor validation loss\n",
        "      patience=50,\n",
        "      restore_best_weights=True  # Restore weights from best epoch\n",
        "  )\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "  X_train, y_train,\n",
        "  validation_data=(X_val, y_val),\n",
        "  epochs=200,\n",
        "  batch_size=32,\n",
        "  verbose=1,\n",
        "  callbacks=[early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1z30otXZnPVI",
        "outputId": "953bf68a-ca91-4026-87c6-668e4b36e76d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Epoch: 200\n",
            "Train Accuracy at Best Epoch: 0.6683\n",
            "Val Accuracy at Best Epoch: 0.6722\n"
          ]
        }
      ],
      "source": [
        "best_epoch = np.argmin(history.history['val_loss'])\n",
        "print(f\"Best Epoch: {best_epoch+1}\")\n",
        "print(f\"Train Accuracy at Best Epoch: {history.history['accuracy'][best_epoch]:.4f}\")\n",
        "print(f\"Val Accuracy at Best Epoch: {history.history['val_accuracy'][best_epoch]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8-xUOoyJk5_",
        "outputId": "114afa8b-97e0-4a22-8ed0-d44cdf117491"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6520 - loss: 0.6207 \n",
            "Test Accuracy: 0.6659, Test Loss: 0.6151\n"
          ]
        }
      ],
      "source": [
        "# Evaluate\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}, Test Loss: {test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmWIUNw0-l0y",
        "outputId": "28fbca36-fe59-4252-b6e7-51be2cd485b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5860 - loss: 0.7496 - val_accuracy: 0.6297 - val_loss: 0.7254\n",
            "Epoch 2/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5890 - loss: 0.7457 - val_accuracy: 0.6297 - val_loss: 0.7221\n",
            "Epoch 3/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6204 - loss: 0.7336 - val_accuracy: 0.6297 - val_loss: 0.7213\n",
            "Epoch 4/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6124 - loss: 0.7195 - val_accuracy: 0.6297 - val_loss: 0.7191\n",
            "Epoch 5/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6316 - loss: 0.7206 - val_accuracy: 0.6297 - val_loss: 0.7178\n",
            "Epoch 6/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6279 - loss: 0.7217 - val_accuracy: 0.6297 - val_loss: 0.7177\n",
            "Epoch 7/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6315 - loss: 0.7102 - val_accuracy: 0.6297 - val_loss: 0.7145\n",
            "Epoch 8/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6173 - loss: 0.7159 - val_accuracy: 0.6297 - val_loss: 0.7106\n",
            "Epoch 9/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6204 - loss: 0.7243 - val_accuracy: 0.6321 - val_loss: 0.7055\n",
            "Epoch 10/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6290 - loss: 0.7016 - val_accuracy: 0.6321 - val_loss: 0.7036\n",
            "Epoch 11/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6409 - loss: 0.7073 - val_accuracy: 0.6344 - val_loss: 0.7004\n",
            "Epoch 12/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6274 - loss: 0.7037 - val_accuracy: 0.6344 - val_loss: 0.7000\n",
            "Epoch 13/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6411 - loss: 0.6987 - val_accuracy: 0.6415 - val_loss: 0.6975\n",
            "Epoch 14/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6277 - loss: 0.7035 - val_accuracy: 0.6415 - val_loss: 0.6941\n",
            "Epoch 15/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6446 - loss: 0.6833 - val_accuracy: 0.6462 - val_loss: 0.6884\n",
            "Epoch 16/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6497 - loss: 0.6862 - val_accuracy: 0.6509 - val_loss: 0.6865\n",
            "Epoch 17/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6637 - loss: 0.6777 - val_accuracy: 0.6533 - val_loss: 0.6843\n",
            "Epoch 18/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6455 - loss: 0.6917 - val_accuracy: 0.6604 - val_loss: 0.6824\n",
            "Epoch 19/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6369 - loss: 0.6900 - val_accuracy: 0.6557 - val_loss: 0.6796\n",
            "Epoch 20/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6407 - loss: 0.6829 - val_accuracy: 0.6580 - val_loss: 0.6792\n",
            "Epoch 21/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6559 - loss: 0.6632 - val_accuracy: 0.6698 - val_loss: 0.6773\n",
            "Epoch 22/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6391 - loss: 0.6882 - val_accuracy: 0.6651 - val_loss: 0.6740\n",
            "Epoch 23/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6697 - loss: 0.6749 - val_accuracy: 0.6580 - val_loss: 0.6738\n",
            "Epoch 24/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6698 - loss: 0.6777 - val_accuracy: 0.6651 - val_loss: 0.6718\n",
            "Epoch 25/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6357 - loss: 0.6882 - val_accuracy: 0.6698 - val_loss: 0.6723\n",
            "Epoch 26/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6663 - loss: 0.6774 - val_accuracy: 0.6627 - val_loss: 0.6723\n",
            "Epoch 27/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6656 - loss: 0.6724 - val_accuracy: 0.6698 - val_loss: 0.6715\n",
            "Epoch 28/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6745 - loss: 0.6618 - val_accuracy: 0.6816 - val_loss: 0.6698\n",
            "Epoch 29/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6748 - loss: 0.6641 - val_accuracy: 0.6816 - val_loss: 0.6675\n",
            "Epoch 30/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6713 - loss: 0.6710 - val_accuracy: 0.6816 - val_loss: 0.6672\n",
            "Epoch 31/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6674 - loss: 0.6592 - val_accuracy: 0.6745 - val_loss: 0.6652\n",
            "Epoch 32/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6350 - loss: 0.6810 - val_accuracy: 0.6745 - val_loss: 0.6648\n",
            "Epoch 33/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6750 - loss: 0.6622 - val_accuracy: 0.6840 - val_loss: 0.6652\n",
            "Epoch 34/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6660 - loss: 0.6651 - val_accuracy: 0.6863 - val_loss: 0.6636\n",
            "Epoch 35/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6671 - loss: 0.6522 - val_accuracy: 0.6745 - val_loss: 0.6623\n",
            "Epoch 36/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6803 - loss: 0.6534 - val_accuracy: 0.6840 - val_loss: 0.6615\n",
            "Epoch 37/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6554 - loss: 0.6530 - val_accuracy: 0.6722 - val_loss: 0.6610\n",
            "Epoch 38/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6665 - loss: 0.6648 - val_accuracy: 0.6769 - val_loss: 0.6614\n",
            "Epoch 39/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6880 - loss: 0.6518 - val_accuracy: 0.6769 - val_loss: 0.6586\n",
            "Epoch 40/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6566 - loss: 0.6546 - val_accuracy: 0.6769 - val_loss: 0.6612\n",
            "Epoch 41/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6890 - loss: 0.6498 - val_accuracy: 0.6769 - val_loss: 0.6593\n",
            "Epoch 42/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6753 - loss: 0.6442 - val_accuracy: 0.6792 - val_loss: 0.6576\n",
            "Epoch 43/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6883 - loss: 0.6334 - val_accuracy: 0.6722 - val_loss: 0.6577\n",
            "Epoch 44/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6877 - loss: 0.6407 - val_accuracy: 0.6651 - val_loss: 0.6593\n",
            "Epoch 45/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6631 - loss: 0.6624 - val_accuracy: 0.6722 - val_loss: 0.6602\n",
            "Epoch 46/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6751 - loss: 0.6444 - val_accuracy: 0.6675 - val_loss: 0.6588\n",
            "Epoch 47/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6861 - loss: 0.6394 - val_accuracy: 0.6722 - val_loss: 0.6580\n",
            "Epoch 48/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6834 - loss: 0.6523 - val_accuracy: 0.6745 - val_loss: 0.6571\n",
            "Epoch 49/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6661 - loss: 0.6536 - val_accuracy: 0.6769 - val_loss: 0.6564\n",
            "Epoch 50/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6649 - loss: 0.6572 - val_accuracy: 0.6722 - val_loss: 0.6602\n",
            "Epoch 51/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6693 - loss: 0.6418 - val_accuracy: 0.6580 - val_loss: 0.6590\n",
            "Epoch 52/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7113 - loss: 0.6167 - val_accuracy: 0.6792 - val_loss: 0.6587\n",
            "Epoch 53/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6965 - loss: 0.6389 - val_accuracy: 0.6651 - val_loss: 0.6580\n",
            "Epoch 54/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6947 - loss: 0.6372 - val_accuracy: 0.6816 - val_loss: 0.6561\n",
            "Epoch 55/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6882 - loss: 0.6301 - val_accuracy: 0.6698 - val_loss: 0.6579\n",
            "Epoch 56/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6685 - loss: 0.6397 - val_accuracy: 0.6745 - val_loss: 0.6557\n",
            "Epoch 57/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7048 - loss: 0.6202 - val_accuracy: 0.6792 - val_loss: 0.6528\n",
            "Epoch 58/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6483 - loss: 0.6492 - val_accuracy: 0.6745 - val_loss: 0.6537\n",
            "Epoch 59/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6849 - loss: 0.6428 - val_accuracy: 0.6745 - val_loss: 0.6549\n",
            "Epoch 60/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6769 - loss: 0.6463 - val_accuracy: 0.6769 - val_loss: 0.6567\n",
            "Epoch 61/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6868 - loss: 0.6300 - val_accuracy: 0.6698 - val_loss: 0.6545\n",
            "Epoch 62/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6742 - loss: 0.6431 - val_accuracy: 0.6745 - val_loss: 0.6540\n",
            "Epoch 63/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7001 - loss: 0.6237 - val_accuracy: 0.6745 - val_loss: 0.6552\n",
            "Epoch 64/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6808 - loss: 0.6318 - val_accuracy: 0.6840 - val_loss: 0.6542\n",
            "Epoch 65/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6770 - loss: 0.6352 - val_accuracy: 0.6604 - val_loss: 0.6568\n",
            "Epoch 66/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7063 - loss: 0.6300 - val_accuracy: 0.6722 - val_loss: 0.6533\n",
            "Epoch 67/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6982 - loss: 0.6223 - val_accuracy: 0.6627 - val_loss: 0.6547\n",
            "Epoch 68/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6729 - loss: 0.6396 - val_accuracy: 0.6745 - val_loss: 0.6520\n",
            "Epoch 69/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6953 - loss: 0.6152 - val_accuracy: 0.6792 - val_loss: 0.6504\n",
            "Epoch 70/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7107 - loss: 0.6154 - val_accuracy: 0.6698 - val_loss: 0.6508\n",
            "Epoch 71/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6971 - loss: 0.6203 - val_accuracy: 0.6675 - val_loss: 0.6516\n",
            "Epoch 72/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7053 - loss: 0.6036 - val_accuracy: 0.6675 - val_loss: 0.6533\n",
            "Epoch 73/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6957 - loss: 0.6228 - val_accuracy: 0.6604 - val_loss: 0.6511\n",
            "Epoch 74/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6643 - loss: 0.6388 - val_accuracy: 0.6722 - val_loss: 0.6523\n",
            "Epoch 75/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7039 - loss: 0.6163 - val_accuracy: 0.6557 - val_loss: 0.6538\n",
            "Epoch 76/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6831 - loss: 0.6241 - val_accuracy: 0.6604 - val_loss: 0.6521\n",
            "Epoch 77/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6793 - loss: 0.6263 - val_accuracy: 0.6698 - val_loss: 0.6524\n",
            "Epoch 78/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6894 - loss: 0.6220 - val_accuracy: 0.6745 - val_loss: 0.6496\n",
            "Epoch 79/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7071 - loss: 0.6155 - val_accuracy: 0.6769 - val_loss: 0.6500\n",
            "Epoch 80/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6925 - loss: 0.6355 - val_accuracy: 0.6722 - val_loss: 0.6524\n",
            "Epoch 81/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6735 - loss: 0.6484 - val_accuracy: 0.6675 - val_loss: 0.6511\n",
            "Epoch 82/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6933 - loss: 0.6327 - val_accuracy: 0.6816 - val_loss: 0.6492\n",
            "Epoch 83/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7032 - loss: 0.6038 - val_accuracy: 0.6840 - val_loss: 0.6476\n",
            "Epoch 84/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6981 - loss: 0.6107 - val_accuracy: 0.6769 - val_loss: 0.6467\n",
            "Epoch 85/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6882 - loss: 0.6200 - val_accuracy: 0.6792 - val_loss: 0.6451\n",
            "Epoch 86/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6671 - loss: 0.6347 - val_accuracy: 0.6769 - val_loss: 0.6473\n",
            "Epoch 87/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7265 - loss: 0.5872 - val_accuracy: 0.6816 - val_loss: 0.6479\n",
            "Epoch 88/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6960 - loss: 0.6113 - val_accuracy: 0.6651 - val_loss: 0.6505\n",
            "Epoch 89/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6867 - loss: 0.6236 - val_accuracy: 0.6675 - val_loss: 0.6500\n",
            "Epoch 90/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6829 - loss: 0.6290 - val_accuracy: 0.6745 - val_loss: 0.6494\n",
            "Epoch 91/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6893 - loss: 0.6283 - val_accuracy: 0.6698 - val_loss: 0.6504\n",
            "Epoch 92/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6923 - loss: 0.6164 - val_accuracy: 0.6675 - val_loss: 0.6503\n",
            "Epoch 93/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6954 - loss: 0.6233 - val_accuracy: 0.6698 - val_loss: 0.6482\n",
            "Epoch 94/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7020 - loss: 0.6115 - val_accuracy: 0.6580 - val_loss: 0.6488\n",
            "Epoch 95/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6914 - loss: 0.6176 - val_accuracy: 0.6462 - val_loss: 0.6483\n",
            "Epoch 96/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7068 - loss: 0.6059 - val_accuracy: 0.6675 - val_loss: 0.6501\n",
            "Epoch 97/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7125 - loss: 0.6061 - val_accuracy: 0.6580 - val_loss: 0.6483\n",
            "Epoch 98/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7036 - loss: 0.6139 - val_accuracy: 0.6792 - val_loss: 0.6491\n",
            "Epoch 99/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7090 - loss: 0.6170 - val_accuracy: 0.6745 - val_loss: 0.6493\n",
            "Epoch 100/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6926 - loss: 0.6117 - val_accuracy: 0.6675 - val_loss: 0.6489\n",
            "Epoch 101/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7016 - loss: 0.6119 - val_accuracy: 0.6580 - val_loss: 0.6487\n",
            "Epoch 102/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6914 - loss: 0.6176 - val_accuracy: 0.6722 - val_loss: 0.6507\n",
            "Epoch 103/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7309 - loss: 0.5827 - val_accuracy: 0.6580 - val_loss: 0.6506\n",
            "Epoch 104/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7004 - loss: 0.6156 - val_accuracy: 0.6698 - val_loss: 0.6482\n",
            "Epoch 105/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6948 - loss: 0.6123 - val_accuracy: 0.6745 - val_loss: 0.6479\n",
            "Epoch 106/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6904 - loss: 0.6177 - val_accuracy: 0.6651 - val_loss: 0.6481\n",
            "Epoch 107/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7056 - loss: 0.5970 - val_accuracy: 0.6604 - val_loss: 0.6509\n",
            "Epoch 108/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6978 - loss: 0.6028 - val_accuracy: 0.6580 - val_loss: 0.6527\n",
            "Epoch 109/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7091 - loss: 0.6121 - val_accuracy: 0.6580 - val_loss: 0.6516\n",
            "Epoch 110/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7129 - loss: 0.6009 - val_accuracy: 0.6651 - val_loss: 0.6520\n",
            "Epoch 111/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7118 - loss: 0.5862 - val_accuracy: 0.6627 - val_loss: 0.6476\n",
            "Epoch 112/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6989 - loss: 0.6027 - val_accuracy: 0.6698 - val_loss: 0.6515\n",
            "Epoch 113/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7192 - loss: 0.5889 - val_accuracy: 0.6580 - val_loss: 0.6504\n",
            "Epoch 114/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7116 - loss: 0.5950 - val_accuracy: 0.6533 - val_loss: 0.6505\n",
            "Epoch 115/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7104 - loss: 0.6025 - val_accuracy: 0.6604 - val_loss: 0.6525\n"
          ]
        }
      ],
      "source": [
        "# Model Definition by member Rene Ntabana\n",
        "def model_rene_ntabana():\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(128, input_shape=(X_train.shape[1],),\n",
        "        activation=\"relu\",\n",
        "        kernel_regularizer=tf.keras.regularizers.l1(0.0001),\n",
        "        name='dense_layer'))\n",
        "    model.add(tf.keras.layers.Dropout(0.4))  # Slightly less dropout\n",
        "    model.add(tf.keras.layers.Dense(64,\n",
        "        activation='relu',\n",
        "        kernel_regularizer=tf.keras.regularizers.l1(0.00005),\n",
        "        name='dense_layer2'))\n",
        "    model.add(tf.keras.layers.Dropout(0.4))\n",
        "    model.add(tf.keras.layers.Dense(32,\n",
        "        activation='relu',\n",
        "        kernel_regularizer=tf.keras.regularizers.l1(0.00005),\n",
        "        name='dense_layer3'))\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "    model.add(tf.keras.layers.Dense(1,\n",
        "        activation='sigmoid',\n",
        "        kernel_regularizer=tf.keras.regularizers.l1(0.00001),\n",
        "        name='output_layer'))\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "model = model_rene_ntabana()\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=30,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=200,\n",
        "    batch_size=32,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sG6LfoyEE2n",
        "outputId": "580e3dde-afa3-42ca-ff67-83fdf676f6ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Epoch: 85\n",
            "Train Accuracy at Best Epoch: 0.6981\n",
            "Val Accuracy at Best Epoch: 0.6792\n"
          ]
        }
      ],
      "source": [
        "best_epoch = np.argmin(history.history['val_loss'])\n",
        "print(f\"Best Epoch: {best_epoch+1}\")\n",
        "print(f\"Train Accuracy at Best Epoch: {history.history['accuracy'][best_epoch]:.4f}\")\n",
        "print(f\"Val Accuracy at Best Epoch: {history.history['val_accuracy'][best_epoch]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItV6pZ_aENPH",
        "outputId": "59348ae8-b10f-4bab-ae8e-2ece3923fe92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6743 - loss: 0.6525 \n",
            "Test Loss: 0.6415, Test Accuracy: 0.6800\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "uONld83TEn8z",
        "outputId": "438cb482-fe05-4b7e-b68d-eecbc5189d59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7075    0.8396    0.7679       268\n",
            "           1     0.5981    0.4076    0.4848       157\n",
            "\n",
            "    accuracy                         0.6800       425\n",
            "   macro avg     0.6528    0.6236    0.6264       425\n",
            "weighted avg     0.6671    0.6800    0.6633       425\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Classification report and Confusion Matrix\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_probs = model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to binary class predictions (threshold = 0.5)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "# Classification report\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize confusion matrix\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Pred 0\", \"Pred 1\"], yticklabels=[\"True 0\", \"True 1\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0R8q1MuJ-mJd"
      },
      "outputs": [],
      "source": [
        "#Model Definition by member 3\n",
        "def model_name_of_student():\n",
        "\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKoFpxX6_B7D"
      },
      "outputs": [],
      "source": [
        "#Model Definition by member 4\n",
        "def model_name_of_student():\n",
        "\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dd3m8M3dKcfe"
      },
      "outputs": [],
      "source": [
        "#Model Definition by member 5\n",
        "def model_name_of_student():\n",
        "\n",
        "  return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDSPmAB9jkrG"
      },
      "source": [
        "# Start the training Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "OWQHapf3jlYH",
        "outputId": "f621cc01-0e17-4201-d942-b77fa0307966"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 225: early stopping\n",
            "Train: 0.967, Test: 0.814\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "Reuse this codeif necessary\n",
        "#fit model\n",
        "history = model.fit(X, Y, validation_data=(testX, testy), epochs=4000, verbose=0, callbacks=[es])\n",
        "# evaluate the model\n",
        "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
        "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
        "# plot training history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKZ2T8TOIYxL"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMNag3BGIuwZ"
      },
      "outputs": [],
      "source": [
        "#Data Loading and Preprocessing\n",
        "# The coach will never do this!!\n",
        "regularizer = 'l1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsmEC739I4lG",
        "outputId": "50c0a5fc-a263-43aa-ee4c-94da2c302a56"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(32, activation ='relu', kernel_regularizer= regularizer , input_shape = (2224,224)))\n",
        "model.add(Dropout(0.2))\n",
        "#adding Dropout\n",
        "model.add(Dense(64, activation ='relu', kernel_regularizer= regularizer , input_shape = (2224,224)))\n",
        "#adding Dropout\n",
        "model.add(Dense(128, activation ='relu', kernel_regularizer= regularizer , input_shape = (2224,224)))\n",
        "model.add(Dropout(0.2))\n",
        "#adding Dropout\n",
        "model.add(Dense(2, activation = 'sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbyPgkZlLu37"
      },
      "outputs": [],
      "source": [
        "callback =EarlyStopping(monitor='loss',patience=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fw9XQj_ZMWUs"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss= 'rmse', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "GPhb-1k7LGx8",
        "outputId": "bbc89c67-0a3c-47fe-80ce-9baa5562a08e"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-b1f8fa258a36>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ],
      "source": [
        "model.fit(X, Y, epochs=1000, batch_size= 128, callbacks=[callback], verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "wLlhrOCpJWF5",
        "outputId": "e4f07eba-484f-46b7-d406-b7433fb048f2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2224\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │         \u001b[38;5;34m7,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2224\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2224\u001b[0m, \u001b[38;5;34m2\u001b[0m)        │            \u001b[38;5;34m66\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,266</span> (28.38 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,266\u001b[0m (28.38 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,266</span> (28.38 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,266\u001b[0m (28.38 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
