{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrXv0rU9sIma"
      },
      "source": [
        "# Excercise - Creating our own custom Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJyZUDbzBTIG"
      },
      "source": [
        "This is a notebook that provides a quick overview of how to create your own custom model. You will be creating a simple model.\n",
        "You will be utilizing Keras and Tensorflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvLegMMvBZYg"
      },
      "source": [
        "## Water Quality Dataset\n",
        "\n",
        "This dataset contains water quality measurements and assessments related to potability, which is the suitability of water for human consumption. The dataset's primary objective is to provide insights into water quality parameters and assist in determining whether the water is potable or not. Each row in the dataset represents a water sample with specific attributes, and the \"Potability\" column indicates whether the water is suitable for consumption.\n",
        "\n",
        "https://www.kaggle.com/datasets/uom190346a/water-quality-and-potability?select=water_potability.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Qvnx0_dT3JEq",
        "outputId": "4b5a3027-ba7d-4787-eb24-d6f955670886"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.72.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 3276,\n  \"fields\": [\n    {\n      \"column\": \"ph\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5943195187088117,\n        \"min\": 0.0,\n        \"max\": 13.999999999999998,\n        \"num_unique_values\": 2785,\n        \"samples\": [\n          6.569053876389385,\n          9.271355446767778,\n          8.92790592593881\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hardness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32.879761476294185,\n        \"min\": 47.432,\n        \"max\": 323.124,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          183.5211070261417,\n          188.9135411469536,\n          224.05887682392927\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8768.570827785932,\n        \"min\": 320.942611274359,\n        \"max\": 61227.19600771213,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          20461.252710219946,\n          32873.820021715685,\n          23264.10996772913\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chloramines\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.58308488903971,\n        \"min\": 0.3520000000000003,\n        \"max\": 13.127000000000002,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          7.333212177578906,\n          6.791509363412849,\n          5.92236704115349\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sulfate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 41.416840461672685,\n        \"min\": 129.00000000000003,\n        \"max\": 481.0306423059972,\n        \"num_unique_values\": 2495,\n        \"samples\": [\n          324.64407957923544,\n          370.121384654358,\n          329.12773842254506\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conductivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80.82406405111182,\n        \"min\": 181.483753985146,\n        \"max\": 753.3426195583046,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          356.3690224100897,\n          336.56150104700754,\n          387.971335796834\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Organic_carbon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.308161999126868,\n        \"min\": 2.1999999999999886,\n        \"max\": 28.30000000000001,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          20.179028868493845,\n          14.706810313722087,\n          13.40673745495127\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Trihalomethanes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.17500842221865,\n        \"min\": 0.7379999999999995,\n        \"max\": 124.0,\n        \"num_unique_values\": 3114,\n        \"samples\": [\n          66.163439242252,\n          42.844510851301166,\n          47.06639219544294\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Turbidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7803824084854116,\n        \"min\": 1.45,\n        \"max\": 6.739,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          4.886633785371213,\n          4.562197671215202,\n          2.487968647002356\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Potability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3a53a673-5918-4f0d-be66-b870c07dc1d5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>204.890455</td>\n",
              "      <td>20791.318981</td>\n",
              "      <td>7.300212</td>\n",
              "      <td>368.516441</td>\n",
              "      <td>564.308654</td>\n",
              "      <td>10.379783</td>\n",
              "      <td>86.990970</td>\n",
              "      <td>2.963135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.716080</td>\n",
              "      <td>129.422921</td>\n",
              "      <td>18630.057858</td>\n",
              "      <td>6.635246</td>\n",
              "      <td>NaN</td>\n",
              "      <td>592.885359</td>\n",
              "      <td>15.180013</td>\n",
              "      <td>56.329076</td>\n",
              "      <td>4.500656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.099124</td>\n",
              "      <td>224.236259</td>\n",
              "      <td>19909.541732</td>\n",
              "      <td>9.275884</td>\n",
              "      <td>NaN</td>\n",
              "      <td>418.606213</td>\n",
              "      <td>16.868637</td>\n",
              "      <td>66.420093</td>\n",
              "      <td>3.055934</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.316766</td>\n",
              "      <td>214.373394</td>\n",
              "      <td>22018.417441</td>\n",
              "      <td>8.059332</td>\n",
              "      <td>356.886136</td>\n",
              "      <td>363.266516</td>\n",
              "      <td>18.436524</td>\n",
              "      <td>100.341674</td>\n",
              "      <td>4.628771</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.092223</td>\n",
              "      <td>181.101509</td>\n",
              "      <td>17978.986339</td>\n",
              "      <td>6.546600</td>\n",
              "      <td>310.135738</td>\n",
              "      <td>398.410813</td>\n",
              "      <td>11.558279</td>\n",
              "      <td>31.997993</td>\n",
              "      <td>4.075075</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.584087</td>\n",
              "      <td>188.313324</td>\n",
              "      <td>28748.687739</td>\n",
              "      <td>7.544869</td>\n",
              "      <td>326.678363</td>\n",
              "      <td>280.467916</td>\n",
              "      <td>8.399735</td>\n",
              "      <td>54.917862</td>\n",
              "      <td>2.559708</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10.223862</td>\n",
              "      <td>248.071735</td>\n",
              "      <td>28749.716544</td>\n",
              "      <td>7.513408</td>\n",
              "      <td>393.663396</td>\n",
              "      <td>283.651634</td>\n",
              "      <td>13.789695</td>\n",
              "      <td>84.603556</td>\n",
              "      <td>2.672989</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8.635849</td>\n",
              "      <td>203.361523</td>\n",
              "      <td>13672.091764</td>\n",
              "      <td>4.563009</td>\n",
              "      <td>303.309771</td>\n",
              "      <td>474.607645</td>\n",
              "      <td>12.363817</td>\n",
              "      <td>62.798309</td>\n",
              "      <td>4.401425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NaN</td>\n",
              "      <td>118.988579</td>\n",
              "      <td>14285.583854</td>\n",
              "      <td>7.804174</td>\n",
              "      <td>268.646941</td>\n",
              "      <td>389.375566</td>\n",
              "      <td>12.706049</td>\n",
              "      <td>53.928846</td>\n",
              "      <td>3.595017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>11.180284</td>\n",
              "      <td>227.231469</td>\n",
              "      <td>25484.508491</td>\n",
              "      <td>9.077200</td>\n",
              "      <td>404.041635</td>\n",
              "      <td>563.885481</td>\n",
              "      <td>17.927806</td>\n",
              "      <td>71.976601</td>\n",
              "      <td>4.370562</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a53a673-5918-4f0d-be66-b870c07dc1d5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3a53a673-5918-4f0d-be66-b870c07dc1d5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3a53a673-5918-4f0d-be66-b870c07dc1d5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b4ceb8ab-4fce-4dfa-b0dc-92b0538b3eb3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b4ceb8ab-4fce-4dfa-b0dc-92b0538b3eb3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b4ceb8ab-4fce-4dfa-b0dc-92b0538b3eb3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
              "0        NaN  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
              "1   3.716080  129.422921  18630.057858     6.635246         NaN    592.885359   \n",
              "2   8.099124  224.236259  19909.541732     9.275884         NaN    418.606213   \n",
              "3   8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
              "4   9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
              "5   5.584087  188.313324  28748.687739     7.544869  326.678363    280.467916   \n",
              "6  10.223862  248.071735  28749.716544     7.513408  393.663396    283.651634   \n",
              "7   8.635849  203.361523  13672.091764     4.563009  303.309771    474.607645   \n",
              "8        NaN  118.988579  14285.583854     7.804174  268.646941    389.375566   \n",
              "9  11.180284  227.231469  25484.508491     9.077200  404.041635    563.885481   \n",
              "\n",
              "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
              "0       10.379783        86.990970   2.963135           0  \n",
              "1       15.180013        56.329076   4.500656           0  \n",
              "2       16.868637        66.420093   3.055934           0  \n",
              "3       18.436524       100.341674   4.628771           0  \n",
              "4       11.558279        31.997993   4.075075           0  \n",
              "5        8.399735        54.917862   2.559708           0  \n",
              "6       13.789695        84.603556   2.672989           0  \n",
              "7       12.363817        62.798309   4.401425           0  \n",
              "8       12.706049        53.928846   3.595017           0  \n",
              "9       17.927806        71.976601   4.370562           0  "
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#LOAD THE DATA\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "data = pd.read_csv(\"/content/water_potability.csv\")\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, roc_auc_score, f1_score\n",
        "\n",
        "data.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mn2ks1y4rG2i",
        "outputId": "aa09406e-38bd-4a5d-94f1-994505eab028"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3276 entries, 0 to 3275\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   ph               2785 non-null   float64\n",
            " 1   Hardness         3276 non-null   float64\n",
            " 2   Solids           3276 non-null   float64\n",
            " 3   Chloramines      3276 non-null   float64\n",
            " 4   Sulfate          2495 non-null   float64\n",
            " 5   Conductivity     3276 non-null   float64\n",
            " 6   Organic_carbon   3276 non-null   float64\n",
            " 7   Trihalomethanes  3114 non-null   float64\n",
            " 8   Turbidity        3276 non-null   float64\n",
            " 9   Potability       3276 non-null   int64  \n",
            "dtypes: float64(9), int64(1)\n",
            "memory usage: 256.1 KB\n"
          ]
        }
      ],
      "source": [
        "# Information on the data\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "fJvnnIxav4N2",
        "outputId": "3efa99b9-48cd-42a4-e037-729927c41057"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"ph\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 982.4396919342113,\n        \"min\": 0.0,\n        \"max\": 2785.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          7.080794504276835,\n          7.036752103833548,\n          2785.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hardness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1102.077573149784,\n        \"min\": 32.879761476294185,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          196.36949601730151,\n          196.96762686363076,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19161.79774847418,\n        \"min\": 320.942611274359,\n        \"max\": 61227.19600771213,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          22014.092526077104,\n          20927.833606520187,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chloramines\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1156.0476760135623,\n        \"min\": 0.3520000000000003,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          7.122276793425786,\n          7.130298973883081,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sulfate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 793.8602821876343,\n        \"min\": 41.416840461672685,\n        \"max\": 2495.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          333.7757766108135,\n          333.073545745888,\n          2495.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conductivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1040.8631085884185,\n        \"min\": 80.82406405111182,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          426.20511068255325,\n          421.8849682800544,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Organic_carbon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1153.6765632294614,\n        \"min\": 2.1999999999999886,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          14.284970247677318,\n          14.218337937208588,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Trihalomethanes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1081.0577228535572,\n        \"min\": 0.7379999999999995,\n        \"max\": 3114.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          66.39629294676803,\n          66.62248509808484,\n          3114.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Turbidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1156.9881922638967,\n        \"min\": 0.7803824084854116,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3.966786169791058,\n          3.955027562993039,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Potability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1158.0956231418108,\n        \"min\": 0.0,\n        \"max\": 3276.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3901098901098901,\n          1.0,\n          0.4878491696702489\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-32e54c1f-ea7e-4c83-8e0d-8e05152ac8ad\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2785.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>2495.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3114.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.080795</td>\n",
              "      <td>196.369496</td>\n",
              "      <td>22014.092526</td>\n",
              "      <td>7.122277</td>\n",
              "      <td>333.775777</td>\n",
              "      <td>426.205111</td>\n",
              "      <td>14.284970</td>\n",
              "      <td>66.396293</td>\n",
              "      <td>3.966786</td>\n",
              "      <td>0.390110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.594320</td>\n",
              "      <td>32.879761</td>\n",
              "      <td>8768.570828</td>\n",
              "      <td>1.583085</td>\n",
              "      <td>41.416840</td>\n",
              "      <td>80.824064</td>\n",
              "      <td>3.308162</td>\n",
              "      <td>16.175008</td>\n",
              "      <td>0.780382</td>\n",
              "      <td>0.487849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>47.432000</td>\n",
              "      <td>320.942611</td>\n",
              "      <td>0.352000</td>\n",
              "      <td>129.000000</td>\n",
              "      <td>181.483754</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>0.738000</td>\n",
              "      <td>1.450000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6.093092</td>\n",
              "      <td>176.850538</td>\n",
              "      <td>15666.690297</td>\n",
              "      <td>6.127421</td>\n",
              "      <td>307.699498</td>\n",
              "      <td>365.734414</td>\n",
              "      <td>12.065801</td>\n",
              "      <td>55.844536</td>\n",
              "      <td>3.439711</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7.036752</td>\n",
              "      <td>196.967627</td>\n",
              "      <td>20927.833607</td>\n",
              "      <td>7.130299</td>\n",
              "      <td>333.073546</td>\n",
              "      <td>421.884968</td>\n",
              "      <td>14.218338</td>\n",
              "      <td>66.622485</td>\n",
              "      <td>3.955028</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.062066</td>\n",
              "      <td>216.667456</td>\n",
              "      <td>27332.762127</td>\n",
              "      <td>8.114887</td>\n",
              "      <td>359.950170</td>\n",
              "      <td>481.792304</td>\n",
              "      <td>16.557652</td>\n",
              "      <td>77.337473</td>\n",
              "      <td>4.500320</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>14.000000</td>\n",
              "      <td>323.124000</td>\n",
              "      <td>61227.196008</td>\n",
              "      <td>13.127000</td>\n",
              "      <td>481.030642</td>\n",
              "      <td>753.342620</td>\n",
              "      <td>28.300000</td>\n",
              "      <td>124.000000</td>\n",
              "      <td>6.739000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32e54c1f-ea7e-4c83-8e0d-8e05152ac8ad')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-32e54c1f-ea7e-4c83-8e0d-8e05152ac8ad button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-32e54c1f-ea7e-4c83-8e0d-8e05152ac8ad');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7b53295b-9539-4dd4-96b9-610ef98cfd42\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7b53295b-9539-4dd4-96b9-610ef98cfd42')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7b53295b-9539-4dd4-96b9-610ef98cfd42 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                ph     Hardness        Solids  Chloramines      Sulfate  \\\n",
              "count  2785.000000  3276.000000   3276.000000  3276.000000  2495.000000   \n",
              "mean      7.080795   196.369496  22014.092526     7.122277   333.775777   \n",
              "std       1.594320    32.879761   8768.570828     1.583085    41.416840   \n",
              "min       0.000000    47.432000    320.942611     0.352000   129.000000   \n",
              "25%       6.093092   176.850538  15666.690297     6.127421   307.699498   \n",
              "50%       7.036752   196.967627  20927.833607     7.130299   333.073546   \n",
              "75%       8.062066   216.667456  27332.762127     8.114887   359.950170   \n",
              "max      14.000000   323.124000  61227.196008    13.127000   481.030642   \n",
              "\n",
              "       Conductivity  Organic_carbon  Trihalomethanes    Turbidity   Potability  \n",
              "count   3276.000000     3276.000000      3114.000000  3276.000000  3276.000000  \n",
              "mean     426.205111       14.284970        66.396293     3.966786     0.390110  \n",
              "std       80.824064        3.308162        16.175008     0.780382     0.487849  \n",
              "min      181.483754        2.200000         0.738000     1.450000     0.000000  \n",
              "25%      365.734414       12.065801        55.844536     3.439711     0.000000  \n",
              "50%      421.884968       14.218338        66.622485     3.955028     0.000000  \n",
              "75%      481.792304       16.557652        77.337473     4.500320     1.000000  \n",
              "max      753.342620       28.300000       124.000000     6.739000     1.000000  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Brief overview of the dataset statistics\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "f5Rjjxwg5XnF"
      },
      "outputs": [],
      "source": [
        "# drop duplicates rows of data\n",
        "\n",
        "data = data.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjFnkhc35ekL",
        "outputId": "e57266f4-0ef6-433e-a283-9c43b59dff63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ph                 14.987790\n",
            "Hardness            0.000000\n",
            "Solids              0.000000\n",
            "Chloramines         0.000000\n",
            "Sulfate            23.840049\n",
            "Conductivity        0.000000\n",
            "Organic_carbon      0.000000\n",
            "Trihalomethanes     4.945055\n",
            "Turbidity           0.000000\n",
            "Potability          0.000000\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# percentage of missingness in the data for each column\n",
        "\n",
        "missing = data.isnull().mean()*100\n",
        "print(missing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "RlhnFruS2q0X",
        "outputId": "b2b166f7-4f66-41fd-941a-201700ddee77"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data_imputed\",\n  \"rows\": 3276,\n  \"fields\": [\n    {\n      \"column\": \"ph\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4715740629117464,\n        \"min\": 0.0,\n        \"max\": 13.999999999999998,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          7.042483377815478,\n          6.643158712135614,\n          7.846057926337261\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hardness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32.879761476294185,\n        \"min\": 47.432,\n        \"max\": 323.124,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          183.5211070261417,\n          188.9135411469536,\n          224.05887682392927\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8768.570827785932,\n        \"min\": 320.942611274359,\n        \"max\": 61227.19600771213,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          20461.252710219946,\n          32873.820021715685,\n          23264.10996772913\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chloramines\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.58308488903971,\n        \"min\": 0.3520000000000003,\n        \"max\": 13.127000000000002,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          7.333212177578906,\n          6.791509363412849,\n          5.92236704115349\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sulfate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36.38783888533828,\n        \"min\": 129.00000000000003,\n        \"max\": 481.0306423059972,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          333.1194758732444,\n          333.8488418801131,\n          300.40262012672275\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conductivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80.82406405111182,\n        \"min\": 181.483753985146,\n        \"max\": 753.3426195583046,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          356.3690224100897,\n          336.56150104700754,\n          387.971335796834\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Organic_carbon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.308161999126868,\n        \"min\": 2.1999999999999886,\n        \"max\": 28.30000000000001,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          20.179028868493845,\n          14.706810313722087,\n          13.40673745495127\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Trihalomethanes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.769921510590814,\n        \"min\": 0.7379999999999995,\n        \"max\": 124.0,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          67.01990322225635,\n          67.84484886059036,\n          43.07518646611747\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Turbidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7803824084854116,\n        \"min\": 1.45,\n        \"max\": 6.739,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          4.886633785371213,\n          4.562197671215202,\n          2.487968647002356\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Potability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "data_imputed"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-e1a6dd87-bf06-4431-86c3-cecf1a6fba75\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.190863</td>\n",
              "      <td>204.890455</td>\n",
              "      <td>20791.318981</td>\n",
              "      <td>7.300212</td>\n",
              "      <td>368.516441</td>\n",
              "      <td>564.308654</td>\n",
              "      <td>10.379783</td>\n",
              "      <td>86.990970</td>\n",
              "      <td>2.963135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.716080</td>\n",
              "      <td>129.422921</td>\n",
              "      <td>18630.057858</td>\n",
              "      <td>6.635246</td>\n",
              "      <td>344.836463</td>\n",
              "      <td>592.885359</td>\n",
              "      <td>15.180013</td>\n",
              "      <td>56.329076</td>\n",
              "      <td>4.500656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.099124</td>\n",
              "      <td>224.236259</td>\n",
              "      <td>19909.541732</td>\n",
              "      <td>9.275884</td>\n",
              "      <td>331.981769</td>\n",
              "      <td>418.606213</td>\n",
              "      <td>16.868637</td>\n",
              "      <td>66.420093</td>\n",
              "      <td>3.055934</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.316766</td>\n",
              "      <td>214.373394</td>\n",
              "      <td>22018.417441</td>\n",
              "      <td>8.059332</td>\n",
              "      <td>356.886136</td>\n",
              "      <td>363.266516</td>\n",
              "      <td>18.436524</td>\n",
              "      <td>100.341674</td>\n",
              "      <td>4.628771</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.092223</td>\n",
              "      <td>181.101509</td>\n",
              "      <td>17978.986339</td>\n",
              "      <td>6.546600</td>\n",
              "      <td>310.135738</td>\n",
              "      <td>398.410813</td>\n",
              "      <td>11.558279</td>\n",
              "      <td>31.997993</td>\n",
              "      <td>4.075075</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.584087</td>\n",
              "      <td>188.313324</td>\n",
              "      <td>28748.687739</td>\n",
              "      <td>7.544869</td>\n",
              "      <td>326.678363</td>\n",
              "      <td>280.467916</td>\n",
              "      <td>8.399735</td>\n",
              "      <td>54.917862</td>\n",
              "      <td>2.559708</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10.223862</td>\n",
              "      <td>248.071735</td>\n",
              "      <td>28749.716544</td>\n",
              "      <td>7.513408</td>\n",
              "      <td>393.663396</td>\n",
              "      <td>283.651634</td>\n",
              "      <td>13.789695</td>\n",
              "      <td>84.603556</td>\n",
              "      <td>2.672989</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8.635849</td>\n",
              "      <td>203.361523</td>\n",
              "      <td>13672.091764</td>\n",
              "      <td>4.563009</td>\n",
              "      <td>303.309771</td>\n",
              "      <td>474.607645</td>\n",
              "      <td>12.363817</td>\n",
              "      <td>62.798309</td>\n",
              "      <td>4.401425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6.927779</td>\n",
              "      <td>118.988579</td>\n",
              "      <td>14285.583854</td>\n",
              "      <td>7.804174</td>\n",
              "      <td>268.646941</td>\n",
              "      <td>389.375566</td>\n",
              "      <td>12.706049</td>\n",
              "      <td>53.928846</td>\n",
              "      <td>3.595017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>11.180284</td>\n",
              "      <td>227.231469</td>\n",
              "      <td>25484.508491</td>\n",
              "      <td>9.077200</td>\n",
              "      <td>404.041635</td>\n",
              "      <td>563.885481</td>\n",
              "      <td>17.927806</td>\n",
              "      <td>71.976601</td>\n",
              "      <td>4.370562</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1a6dd87-bf06-4431-86c3-cecf1a6fba75')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e1a6dd87-bf06-4431-86c3-cecf1a6fba75 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e1a6dd87-bf06-4431-86c3-cecf1a6fba75');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e367de9a-acef-4e66-bad3-61ad8e6b4085\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e367de9a-acef-4e66-bad3-61ad8e6b4085')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e367de9a-acef-4e66-bad3-61ad8e6b4085 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
              "0   7.190863  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
              "1   3.716080  129.422921  18630.057858     6.635246  344.836463    592.885359   \n",
              "2   8.099124  224.236259  19909.541732     9.275884  331.981769    418.606213   \n",
              "3   8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
              "4   9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
              "5   5.584087  188.313324  28748.687739     7.544869  326.678363    280.467916   \n",
              "6  10.223862  248.071735  28749.716544     7.513408  393.663396    283.651634   \n",
              "7   8.635849  203.361523  13672.091764     4.563009  303.309771    474.607645   \n",
              "8   6.927779  118.988579  14285.583854     7.804174  268.646941    389.375566   \n",
              "9  11.180284  227.231469  25484.508491     9.077200  404.041635    563.885481   \n",
              "\n",
              "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
              "0       10.379783        86.990970   2.963135           0  \n",
              "1       15.180013        56.329076   4.500656           0  \n",
              "2       16.868637        66.420093   3.055934           0  \n",
              "3       18.436524       100.341674   4.628771           0  \n",
              "4       11.558279        31.997993   4.075075           0  \n",
              "5        8.399735        54.917862   2.559708           0  \n",
              "6       13.789695        84.603556   2.672989           0  \n",
              "7       12.363817        62.798309   4.401425           0  \n",
              "8       12.706049        53.928846   3.595017           0  \n",
              "9       17.927806        71.976601   4.370562           0  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# MICE IMPUTATION to fill the missing data\n",
        "# create the imputer using MICE\n",
        "\n",
        "# separate the target variable from the rest of the data to make sure it is not changed or imputed\n",
        "features = data.drop(columns='Potability')\n",
        "target = data.Potability\n",
        "imputer = IterativeImputer(random_state=0)\n",
        "features_imputed = imputer.fit_transform(features)\n",
        "\n",
        "# convert the data back into a dataframe\n",
        "features_imputed = pd.DataFrame(features_imputed, columns=features.columns)\n",
        "\n",
        "# merge target variable and data\n",
        "data_imputed = pd.concat([features_imputed, target], axis=1)\n",
        "data_imputed.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58zqnGV23ZSx",
        "outputId": "9dd2e628-9ece-4afa-90bb-4f9f5d3037c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3276 entries, 0 to 3275\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   ph               3276 non-null   float64\n",
            " 1   Hardness         3276 non-null   float64\n",
            " 2   Solids           3276 non-null   float64\n",
            " 3   Chloramines      3276 non-null   float64\n",
            " 4   Sulfate          3276 non-null   float64\n",
            " 5   Conductivity     3276 non-null   float64\n",
            " 6   Organic_carbon   3276 non-null   float64\n",
            " 7   Trihalomethanes  3276 non-null   float64\n",
            " 8   Turbidity        3276 non-null   float64\n",
            " 9   Potability       3276 non-null   int64  \n",
            "dtypes: float64(9), int64(1)\n",
            "memory usage: 256.1 KB\n"
          ]
        }
      ],
      "source": [
        "# confirm imputed data\n",
        "data_imputed.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIdMxexk47Qa",
        "outputId": "3b66250a-ceec-4e54-def4-63c5b43a7309"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0       204.890455\n",
            "1       129.422921\n",
            "2       224.236259\n",
            "3       214.373394\n",
            "4       181.101509\n",
            "           ...    \n",
            "3271    193.681735\n",
            "3272    193.553212\n",
            "3273    175.762646\n",
            "3274    230.603758\n",
            "3275    195.102299\n",
            "Name: Hardness, Length: 3276, dtype: float64\n",
            "Number of outliers: 83\n",
            "Percentage of outliers: 2.53%\n",
            "0       20791.318981\n",
            "1       18630.057858\n",
            "2       19909.541732\n",
            "3       22018.417441\n",
            "4       17978.986339\n",
            "            ...     \n",
            "3271    47580.991603\n",
            "3272    17329.802160\n",
            "3273    33155.578218\n",
            "3274    11983.869376\n",
            "3275    17404.177061\n",
            "Name: Solids, Length: 3193, dtype: float64\n",
            "Number of outliers: 42\n",
            "Percentage of outliers: 1.32%\n",
            "0       368.516441\n",
            "1       344.836463\n",
            "2       331.981769\n",
            "3       356.886136\n",
            "4       310.135738\n",
            "           ...    \n",
            "3270    345.700257\n",
            "3272    338.612062\n",
            "3273    326.848982\n",
            "3274    336.993878\n",
            "3275    338.025733\n",
            "Name: Sulfate, Length: 3151, dtype: float64\n",
            "Number of outliers: 230\n",
            "Percentage of outliers: 7.30%\n",
            "0       564.308654\n",
            "1       592.885359\n",
            "2       418.606213\n",
            "3       363.266516\n",
            "4       398.410813\n",
            "           ...    \n",
            "3270    415.886955\n",
            "3272    392.449580\n",
            "3273    432.044783\n",
            "3274    402.883113\n",
            "3275    327.459760\n",
            "Name: Conductivity, Length: 2921, dtype: float64\n",
            "Number of outliers: 9\n",
            "Percentage of outliers: 0.31%\n",
            "0       10.379783\n",
            "1       15.180013\n",
            "2       16.868637\n",
            "3       18.436524\n",
            "4       11.558279\n",
            "          ...    \n",
            "3270    12.067620\n",
            "3272    19.903225\n",
            "3273    11.039070\n",
            "3274    11.168946\n",
            "3275    16.140368\n",
            "Name: Organic_carbon, Length: 2912, dtype: float64\n",
            "Number of outliers: 18\n",
            "Percentage of outliers: 0.62%\n",
            "0        86.990970\n",
            "1        56.329076\n",
            "2        66.420093\n",
            "3       100.341674\n",
            "4        31.997993\n",
            "           ...    \n",
            "3270     60.419921\n",
            "3272     66.474992\n",
            "3273     69.845400\n",
            "3274     77.488213\n",
            "3275     78.698446\n",
            "Name: Trihalomethanes, Length: 2894, dtype: float64\n",
            "Number of outliers: 47\n",
            "Percentage of outliers: 1.62%\n",
            "0       2.963135\n",
            "1       4.500656\n",
            "2       3.055934\n",
            "3       4.628771\n",
            "4       4.075075\n",
            "          ...   \n",
            "3270    3.669712\n",
            "3272    2.798243\n",
            "3273    3.298875\n",
            "3274    4.708658\n",
            "3275    2.309149\n",
            "Name: Turbidity, Length: 2847, dtype: float64\n",
            "Number of outliers: 17\n",
            "Percentage of outliers: 0.60%\n"
          ]
        }
      ],
      "source": [
        "# Remove outliers that may affect the neural network's accuracy using IQR method\n",
        "def remove_outliers_iqr(df, column_name):\n",
        "    Q1 = df[column_name].quantile(0.25)\n",
        "    Q3 = df[column_name].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    # anything above or below this is an outlier\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # place outliers in a data frame\n",
        "    print(f\"{df[column_name]}\")\n",
        "    outliers = df[(df[column_name] < lower_bound) | (df[column_name] > upper_bound)]\n",
        "    print(f\"Number of outliers: {len(outliers)}\")\n",
        "    print(f\"Percentage of outliers: {len(outliers)/len(df)*100:.2f}%\")\n",
        "\n",
        "    # remove outliers\n",
        "\n",
        "    df_clean = df[(df[column_name] >= lower_bound) & (df[column_name] <= upper_bound)]\n",
        "\n",
        "    return df_clean\n",
        "\n",
        "# columns to remove outliers in\n",
        "columns = ['Hardness', 'Solids', 'Sulfate', 'Conductivity', 'Organic_carbon', 'Trihalomethanes', 'Turbidity']\n",
        "\n",
        "data_imputed_copy = data_imputed.copy()\n",
        "\n",
        "for i in columns:\n",
        "  data_imputed_copy = remove_outliers_iqr(data_imputed_copy, i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QfR0r8cGVU7"
      },
      "source": [
        "Plot the Data Appropriately"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PF9lHguSY2vB",
        "outputId": "d1978f02-ec04-4dca-db5a-bb08caf53b07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2830, 9)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# generate 2d classification dataset\n",
        "# X, y = pass\n",
        "\n",
        "# Transforms data to have mean=0 and standard deviation=1\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X = data_imputed_copy.drop(columns='Potability', axis=1)\n",
        "y= data_imputed_copy['Potability']\n",
        "\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# from sklearn.decomposition import PCA\n",
        "# pca = PCA(n_components=2)\n",
        "# X_2d_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "X_scaled.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfSk1lXRYjrh",
        "outputId": "977d7ecc-3e32-4393-9912-683a33430ad8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== FINAL SHAPES ===\n",
            "X_train: (1981, 9)\n",
            "X_val: (424, 9)\n",
            "X_test: (425, 9)\n",
            "y_train: (1981,)\n",
            "y_val: (424,)\n",
            "y_test: (425,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Split the data into training validation and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3,random_state=42,\n",
        "    stratify=y               # Keep same class distribution in all splits\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5,stratify=y_temp)\n",
        "\n",
        "print(f\"\\n=== FINAL SHAPES ===\")\n",
        "print(f\"X_train: {X_train.shape}\")\n",
        "print(f\"X_val: {X_val.shape}\")\n",
        "print(f\"X_test: {X_test.shape}\")\n",
        "print(f\"y_train: {y_train.shape}\")\n",
        "print(f\"y_val: {y_val.shape}\")\n",
        "print(f\"y_test: {y_test.shape}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvjIHLrcGhzc"
      },
      "source": [
        "# Each Member Defines their model Here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLwYoJG9jvDa",
        "outputId": "f9b4b5c5-fd5a-4387-b3fe-6ad26dbfe09a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.4754 - loss: 0.7438 - val_accuracy: 0.5967 - val_loss: 0.6872\n",
            "Epoch 2/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5063 - loss: 0.7272 - val_accuracy: 0.6038 - val_loss: 0.6781\n",
            "Epoch 3/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5313 - loss: 0.7222 - val_accuracy: 0.6226 - val_loss: 0.6734\n",
            "Epoch 4/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5490 - loss: 0.7020 - val_accuracy: 0.6297 - val_loss: 0.6708\n",
            "Epoch 5/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5666 - loss: 0.6994 - val_accuracy: 0.6297 - val_loss: 0.6694\n",
            "Epoch 6/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5678 - loss: 0.6878 - val_accuracy: 0.6297 - val_loss: 0.6693\n",
            "Epoch 7/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5630 - loss: 0.7052 - val_accuracy: 0.6297 - val_loss: 0.6689\n",
            "Epoch 8/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5869 - loss: 0.6803 - val_accuracy: 0.6297 - val_loss: 0.6680\n",
            "Epoch 9/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5649 - loss: 0.6875 - val_accuracy: 0.6297 - val_loss: 0.6679\n",
            "Epoch 10/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5732 - loss: 0.7063 - val_accuracy: 0.6297 - val_loss: 0.6681\n",
            "Epoch 11/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6136 - loss: 0.6798 - val_accuracy: 0.6297 - val_loss: 0.6677\n",
            "Epoch 12/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6077 - loss: 0.6859 - val_accuracy: 0.6297 - val_loss: 0.6677\n",
            "Epoch 13/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6108 - loss: 0.6700 - val_accuracy: 0.6297 - val_loss: 0.6673\n",
            "Epoch 14/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5879 - loss: 0.6838 - val_accuracy: 0.6297 - val_loss: 0.6672\n",
            "Epoch 15/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6205 - loss: 0.6719 - val_accuracy: 0.6297 - val_loss: 0.6672\n",
            "Epoch 16/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5927 - loss: 0.6827 - val_accuracy: 0.6297 - val_loss: 0.6673\n",
            "Epoch 17/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6060 - loss: 0.6857 - val_accuracy: 0.6297 - val_loss: 0.6675\n",
            "Epoch 18/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6047 - loss: 0.6875 - val_accuracy: 0.6297 - val_loss: 0.6676\n",
            "Epoch 19/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6316 - loss: 0.6640 - val_accuracy: 0.6297 - val_loss: 0.6671\n",
            "Epoch 20/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6064 - loss: 0.6808 - val_accuracy: 0.6297 - val_loss: 0.6670\n",
            "Epoch 21/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6171 - loss: 0.6758 - val_accuracy: 0.6297 - val_loss: 0.6668\n",
            "Epoch 22/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5972 - loss: 0.6837 - val_accuracy: 0.6297 - val_loss: 0.6670\n",
            "Epoch 23/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6052 - loss: 0.6831 - val_accuracy: 0.6297 - val_loss: 0.6669\n",
            "Epoch 24/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5928 - loss: 0.6870 - val_accuracy: 0.6297 - val_loss: 0.6672\n",
            "Epoch 25/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6118 - loss: 0.6793 - val_accuracy: 0.6297 - val_loss: 0.6668\n",
            "Epoch 26/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6354 - loss: 0.6580 - val_accuracy: 0.6297 - val_loss: 0.6663\n",
            "Epoch 27/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6181 - loss: 0.6805 - val_accuracy: 0.6297 - val_loss: 0.6664\n",
            "Epoch 28/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6109 - loss: 0.6813 - val_accuracy: 0.6297 - val_loss: 0.6667\n",
            "Epoch 29/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6111 - loss: 0.6708 - val_accuracy: 0.6297 - val_loss: 0.6668\n",
            "Epoch 30/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6206 - loss: 0.6674 - val_accuracy: 0.6297 - val_loss: 0.6667\n",
            "Epoch 31/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6314 - loss: 0.6682 - val_accuracy: 0.6297 - val_loss: 0.6668\n",
            "Epoch 32/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6357 - loss: 0.6574 - val_accuracy: 0.6297 - val_loss: 0.6666\n",
            "Epoch 33/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6245 - loss: 0.6654 - val_accuracy: 0.6297 - val_loss: 0.6668\n",
            "Epoch 34/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6156 - loss: 0.6703 - val_accuracy: 0.6297 - val_loss: 0.6664\n",
            "Epoch 35/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6165 - loss: 0.6754 - val_accuracy: 0.6297 - val_loss: 0.6662\n",
            "Epoch 36/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6285 - loss: 0.6641 - val_accuracy: 0.6297 - val_loss: 0.6660\n",
            "Epoch 37/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6319 - loss: 0.6621 - val_accuracy: 0.6297 - val_loss: 0.6658\n",
            "Epoch 38/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6030 - loss: 0.6720 - val_accuracy: 0.6297 - val_loss: 0.6653\n",
            "Epoch 39/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6310 - loss: 0.6637 - val_accuracy: 0.6297 - val_loss: 0.6651\n",
            "Epoch 40/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6277 - loss: 0.6687 - val_accuracy: 0.6297 - val_loss: 0.6650\n",
            "Epoch 41/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6385 - loss: 0.6591 - val_accuracy: 0.6297 - val_loss: 0.6648\n",
            "Epoch 42/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6345 - loss: 0.6643 - val_accuracy: 0.6297 - val_loss: 0.6648\n",
            "Epoch 43/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6191 - loss: 0.6628 - val_accuracy: 0.6297 - val_loss: 0.6646\n",
            "Epoch 44/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6296 - loss: 0.6617 - val_accuracy: 0.6297 - val_loss: 0.6642\n",
            "Epoch 45/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6379 - loss: 0.6609 - val_accuracy: 0.6297 - val_loss: 0.6638\n",
            "Epoch 46/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6287 - loss: 0.6723 - val_accuracy: 0.6297 - val_loss: 0.6635\n",
            "Epoch 47/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6237 - loss: 0.6688 - val_accuracy: 0.6297 - val_loss: 0.6636\n",
            "Epoch 48/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6202 - loss: 0.6774 - val_accuracy: 0.6297 - val_loss: 0.6632\n",
            "Epoch 49/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6275 - loss: 0.6588 - val_accuracy: 0.6297 - val_loss: 0.6627\n",
            "Epoch 50/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6192 - loss: 0.6700 - val_accuracy: 0.6297 - val_loss: 0.6629\n",
            "Epoch 51/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6172 - loss: 0.6688 - val_accuracy: 0.6297 - val_loss: 0.6625\n",
            "Epoch 52/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6155 - loss: 0.6646 - val_accuracy: 0.6297 - val_loss: 0.6622\n",
            "Epoch 53/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6334 - loss: 0.6608 - val_accuracy: 0.6297 - val_loss: 0.6621\n",
            "Epoch 54/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6332 - loss: 0.6602 - val_accuracy: 0.6297 - val_loss: 0.6617\n",
            "Epoch 55/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6265 - loss: 0.6615 - val_accuracy: 0.6297 - val_loss: 0.6614\n",
            "Epoch 56/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6276 - loss: 0.6582 - val_accuracy: 0.6297 - val_loss: 0.6611\n",
            "Epoch 57/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6326 - loss: 0.6573 - val_accuracy: 0.6297 - val_loss: 0.6606\n",
            "Epoch 58/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6320 - loss: 0.6565 - val_accuracy: 0.6297 - val_loss: 0.6600\n",
            "Epoch 59/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6384 - loss: 0.6573 - val_accuracy: 0.6297 - val_loss: 0.6598\n",
            "Epoch 60/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6221 - loss: 0.6594 - val_accuracy: 0.6297 - val_loss: 0.6596\n",
            "Epoch 61/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6282 - loss: 0.6547 - val_accuracy: 0.6297 - val_loss: 0.6594\n",
            "Epoch 62/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6178 - loss: 0.6651 - val_accuracy: 0.6297 - val_loss: 0.6592\n",
            "Epoch 63/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6228 - loss: 0.6642 - val_accuracy: 0.6297 - val_loss: 0.6588\n",
            "Epoch 64/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6453 - loss: 0.6489 - val_accuracy: 0.6297 - val_loss: 0.6584\n",
            "Epoch 65/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6441 - loss: 0.6568 - val_accuracy: 0.6297 - val_loss: 0.6584\n",
            "Epoch 66/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6337 - loss: 0.6562 - val_accuracy: 0.6297 - val_loss: 0.6583\n",
            "Epoch 67/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6353 - loss: 0.6526 - val_accuracy: 0.6297 - val_loss: 0.6579\n",
            "Epoch 68/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6377 - loss: 0.6583 - val_accuracy: 0.6297 - val_loss: 0.6579\n",
            "Epoch 69/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6314 - loss: 0.6554 - val_accuracy: 0.6297 - val_loss: 0.6574\n",
            "Epoch 70/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6260 - loss: 0.6568 - val_accuracy: 0.6297 - val_loss: 0.6570\n",
            "Epoch 71/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6227 - loss: 0.6618 - val_accuracy: 0.6297 - val_loss: 0.6567\n",
            "Epoch 72/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6099 - loss: 0.6680 - val_accuracy: 0.6297 - val_loss: 0.6564\n",
            "Epoch 73/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6151 - loss: 0.6572 - val_accuracy: 0.6297 - val_loss: 0.6559\n",
            "Epoch 74/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6392 - loss: 0.6513 - val_accuracy: 0.6297 - val_loss: 0.6556\n",
            "Epoch 75/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6306 - loss: 0.6547 - val_accuracy: 0.6297 - val_loss: 0.6553\n",
            "Epoch 76/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6302 - loss: 0.6582 - val_accuracy: 0.6297 - val_loss: 0.6551\n",
            "Epoch 77/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6055 - loss: 0.6676 - val_accuracy: 0.6297 - val_loss: 0.6548\n",
            "Epoch 78/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6205 - loss: 0.6668 - val_accuracy: 0.6297 - val_loss: 0.6548\n",
            "Epoch 79/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6349 - loss: 0.6499 - val_accuracy: 0.6297 - val_loss: 0.6544\n",
            "Epoch 80/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6270 - loss: 0.6577 - val_accuracy: 0.6297 - val_loss: 0.6540\n",
            "Epoch 81/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6396 - loss: 0.6446 - val_accuracy: 0.6297 - val_loss: 0.6540\n",
            "Epoch 82/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6430 - loss: 0.6531 - val_accuracy: 0.6297 - val_loss: 0.6539\n",
            "Epoch 83/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6476 - loss: 0.6496 - val_accuracy: 0.6297 - val_loss: 0.6535\n",
            "Epoch 84/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6266 - loss: 0.6568 - val_accuracy: 0.6297 - val_loss: 0.6533\n",
            "Epoch 85/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6228 - loss: 0.6580 - val_accuracy: 0.6297 - val_loss: 0.6533\n",
            "Epoch 86/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6369 - loss: 0.6513 - val_accuracy: 0.6297 - val_loss: 0.6528\n",
            "Epoch 87/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6373 - loss: 0.6452 - val_accuracy: 0.6297 - val_loss: 0.6523\n",
            "Epoch 88/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6351 - loss: 0.6593 - val_accuracy: 0.6297 - val_loss: 0.6522\n",
            "Epoch 89/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6096 - loss: 0.6651 - val_accuracy: 0.6297 - val_loss: 0.6521\n",
            "Epoch 90/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6284 - loss: 0.6494 - val_accuracy: 0.6297 - val_loss: 0.6513\n",
            "Epoch 91/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6244 - loss: 0.6576 - val_accuracy: 0.6297 - val_loss: 0.6512\n",
            "Epoch 92/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6228 - loss: 0.6651 - val_accuracy: 0.6297 - val_loss: 0.6509\n",
            "Epoch 93/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6564 - loss: 0.6430 - val_accuracy: 0.6297 - val_loss: 0.6509\n",
            "Epoch 94/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6437 - loss: 0.6492 - val_accuracy: 0.6297 - val_loss: 0.6509\n",
            "Epoch 95/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6172 - loss: 0.6565 - val_accuracy: 0.6297 - val_loss: 0.6505\n",
            "Epoch 96/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6322 - loss: 0.6553 - val_accuracy: 0.6297 - val_loss: 0.6503\n",
            "Epoch 97/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6318 - loss: 0.6508 - val_accuracy: 0.6297 - val_loss: 0.6497\n",
            "Epoch 98/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6489 - loss: 0.6484 - val_accuracy: 0.6297 - val_loss: 0.6492\n",
            "Epoch 99/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6480 - loss: 0.6445 - val_accuracy: 0.6297 - val_loss: 0.6490\n",
            "Epoch 100/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6342 - loss: 0.6528 - val_accuracy: 0.6297 - val_loss: 0.6490\n",
            "Epoch 101/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6283 - loss: 0.6507 - val_accuracy: 0.6297 - val_loss: 0.6486\n",
            "Epoch 102/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6380 - loss: 0.6505 - val_accuracy: 0.6297 - val_loss: 0.6483\n",
            "Epoch 103/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6318 - loss: 0.6523 - val_accuracy: 0.6297 - val_loss: 0.6484\n",
            "Epoch 104/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6233 - loss: 0.6530 - val_accuracy: 0.6297 - val_loss: 0.6484\n",
            "Epoch 105/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6347 - loss: 0.6508 - val_accuracy: 0.6297 - val_loss: 0.6478\n",
            "Epoch 106/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6275 - loss: 0.6526 - val_accuracy: 0.6297 - val_loss: 0.6477\n",
            "Epoch 107/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6530 - loss: 0.6382 - val_accuracy: 0.6297 - val_loss: 0.6474\n",
            "Epoch 108/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6217 - loss: 0.6575 - val_accuracy: 0.6297 - val_loss: 0.6473\n",
            "Epoch 109/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6352 - loss: 0.6525 - val_accuracy: 0.6297 - val_loss: 0.6473\n",
            "Epoch 110/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6334 - loss: 0.6426 - val_accuracy: 0.6297 - val_loss: 0.6468\n",
            "Epoch 111/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6458 - loss: 0.6418 - val_accuracy: 0.6297 - val_loss: 0.6469\n",
            "Epoch 112/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6335 - loss: 0.6493 - val_accuracy: 0.6297 - val_loss: 0.6469\n",
            "Epoch 113/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6508 - loss: 0.6406 - val_accuracy: 0.6297 - val_loss: 0.6467\n",
            "Epoch 114/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6331 - loss: 0.6458 - val_accuracy: 0.6297 - val_loss: 0.6460\n",
            "Epoch 115/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6375 - loss: 0.6480 - val_accuracy: 0.6297 - val_loss: 0.6456\n",
            "Epoch 116/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6551 - loss: 0.6388 - val_accuracy: 0.6297 - val_loss: 0.6451\n",
            "Epoch 117/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6240 - loss: 0.6494 - val_accuracy: 0.6297 - val_loss: 0.6446\n",
            "Epoch 118/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6410 - loss: 0.6399 - val_accuracy: 0.6297 - val_loss: 0.6438\n",
            "Epoch 119/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6211 - loss: 0.6539 - val_accuracy: 0.6297 - val_loss: 0.6439\n",
            "Epoch 120/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6323 - loss: 0.6481 - val_accuracy: 0.6297 - val_loss: 0.6437\n",
            "Epoch 121/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6424 - loss: 0.6454 - val_accuracy: 0.6297 - val_loss: 0.6430\n",
            "Epoch 122/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6340 - loss: 0.6396 - val_accuracy: 0.6297 - val_loss: 0.6424\n",
            "Epoch 123/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6315 - loss: 0.6480 - val_accuracy: 0.6297 - val_loss: 0.6421\n",
            "Epoch 124/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6394 - loss: 0.6390 - val_accuracy: 0.6297 - val_loss: 0.6421\n",
            "Epoch 125/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6335 - loss: 0.6506 - val_accuracy: 0.6297 - val_loss: 0.6420\n",
            "Epoch 126/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6311 - loss: 0.6436 - val_accuracy: 0.6297 - val_loss: 0.6417\n",
            "Epoch 127/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6427 - loss: 0.6537 - val_accuracy: 0.6297 - val_loss: 0.6420\n",
            "Epoch 128/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6205 - loss: 0.6518 - val_accuracy: 0.6321 - val_loss: 0.6415\n",
            "Epoch 129/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6231 - loss: 0.6460 - val_accuracy: 0.6321 - val_loss: 0.6412\n",
            "Epoch 130/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6315 - loss: 0.6429 - val_accuracy: 0.6321 - val_loss: 0.6404\n",
            "Epoch 131/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6414 - loss: 0.6353 - val_accuracy: 0.6321 - val_loss: 0.6400\n",
            "Epoch 132/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6478 - loss: 0.6425 - val_accuracy: 0.6321 - val_loss: 0.6399\n",
            "Epoch 133/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6230 - loss: 0.6565 - val_accuracy: 0.6321 - val_loss: 0.6395\n",
            "Epoch 134/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6352 - loss: 0.6458 - val_accuracy: 0.6321 - val_loss: 0.6393\n",
            "Epoch 135/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6352 - loss: 0.6395 - val_accuracy: 0.6321 - val_loss: 0.6389\n",
            "Epoch 136/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6361 - loss: 0.6373 - val_accuracy: 0.6321 - val_loss: 0.6386\n",
            "Epoch 137/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6536 - loss: 0.6381 - val_accuracy: 0.6344 - val_loss: 0.6387\n",
            "Epoch 138/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6461 - loss: 0.6305 - val_accuracy: 0.6344 - val_loss: 0.6382\n",
            "Epoch 139/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6526 - loss: 0.6255 - val_accuracy: 0.6344 - val_loss: 0.6379\n",
            "Epoch 140/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6399 - loss: 0.6418 - val_accuracy: 0.6344 - val_loss: 0.6377\n",
            "Epoch 141/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6161 - loss: 0.6578 - val_accuracy: 0.6344 - val_loss: 0.6378\n",
            "Epoch 142/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6333 - loss: 0.6399 - val_accuracy: 0.6344 - val_loss: 0.6373\n",
            "Epoch 143/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6390 - loss: 0.6413 - val_accuracy: 0.6344 - val_loss: 0.6371\n",
            "Epoch 144/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6409 - loss: 0.6405 - val_accuracy: 0.6344 - val_loss: 0.6369\n",
            "Epoch 145/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6355 - loss: 0.6426 - val_accuracy: 0.6368 - val_loss: 0.6368\n",
            "Epoch 146/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6440 - loss: 0.6412 - val_accuracy: 0.6368 - val_loss: 0.6368\n",
            "Epoch 147/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6241 - loss: 0.6464 - val_accuracy: 0.6368 - val_loss: 0.6363\n",
            "Epoch 148/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6319 - loss: 0.6354 - val_accuracy: 0.6439 - val_loss: 0.6357\n",
            "Epoch 149/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6299 - loss: 0.6438 - val_accuracy: 0.6392 - val_loss: 0.6355\n",
            "Epoch 150/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6391 - loss: 0.6418 - val_accuracy: 0.6415 - val_loss: 0.6350\n",
            "Epoch 151/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6254 - loss: 0.6431 - val_accuracy: 0.6415 - val_loss: 0.6347\n",
            "Epoch 152/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6352 - loss: 0.6389 - val_accuracy: 0.6415 - val_loss: 0.6343\n",
            "Epoch 153/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6429 - loss: 0.6366 - val_accuracy: 0.6415 - val_loss: 0.6341\n",
            "Epoch 154/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6511 - loss: 0.6374 - val_accuracy: 0.6415 - val_loss: 0.6340\n",
            "Epoch 155/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6647 - loss: 0.6324 - val_accuracy: 0.6415 - val_loss: 0.6341\n",
            "Epoch 156/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6403 - loss: 0.6291 - val_accuracy: 0.6415 - val_loss: 0.6337\n",
            "Epoch 157/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6500 - loss: 0.6486 - val_accuracy: 0.6415 - val_loss: 0.6338\n",
            "Epoch 158/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6504 - loss: 0.6291 - val_accuracy: 0.6415 - val_loss: 0.6335\n",
            "Epoch 159/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6612 - loss: 0.6293 - val_accuracy: 0.6368 - val_loss: 0.6333\n",
            "Epoch 160/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6412 - loss: 0.6412 - val_accuracy: 0.6368 - val_loss: 0.6328\n",
            "Epoch 161/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6419 - loss: 0.6413 - val_accuracy: 0.6368 - val_loss: 0.6328\n",
            "Epoch 162/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6511 - loss: 0.6358 - val_accuracy: 0.6368 - val_loss: 0.6325\n",
            "Epoch 163/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6573 - loss: 0.6264 - val_accuracy: 0.6368 - val_loss: 0.6324\n",
            "Epoch 164/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6433 - loss: 0.6385 - val_accuracy: 0.6368 - val_loss: 0.6319\n",
            "Epoch 165/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6422 - loss: 0.6356 - val_accuracy: 0.6392 - val_loss: 0.6316\n",
            "Epoch 166/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6403 - loss: 0.6414 - val_accuracy: 0.6392 - val_loss: 0.6315\n",
            "Epoch 167/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6613 - loss: 0.6289 - val_accuracy: 0.6392 - val_loss: 0.6314\n",
            "Epoch 168/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6487 - loss: 0.6346 - val_accuracy: 0.6392 - val_loss: 0.6313\n",
            "Epoch 169/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6531 - loss: 0.6285 - val_accuracy: 0.6392 - val_loss: 0.6311\n",
            "Epoch 170/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6346 - loss: 0.6486 - val_accuracy: 0.6392 - val_loss: 0.6309\n",
            "Epoch 171/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6426 - loss: 0.6312 - val_accuracy: 0.6392 - val_loss: 0.6305\n",
            "Epoch 172/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6693 - loss: 0.6143 - val_accuracy: 0.6415 - val_loss: 0.6301\n",
            "Epoch 173/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6394 - loss: 0.6393 - val_accuracy: 0.6439 - val_loss: 0.6301\n",
            "Epoch 174/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6340 - loss: 0.6307 - val_accuracy: 0.6439 - val_loss: 0.6297\n",
            "Epoch 175/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6507 - loss: 0.6270 - val_accuracy: 0.6439 - val_loss: 0.6292\n",
            "Epoch 176/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6380 - loss: 0.6318 - val_accuracy: 0.6462 - val_loss: 0.6283\n",
            "Epoch 177/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6535 - loss: 0.6220 - val_accuracy: 0.6462 - val_loss: 0.6276\n",
            "Epoch 178/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6417 - loss: 0.6424 - val_accuracy: 0.6486 - val_loss: 0.6275\n",
            "Epoch 179/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6530 - loss: 0.6338 - val_accuracy: 0.6486 - val_loss: 0.6272\n",
            "Epoch 180/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6453 - loss: 0.6292 - val_accuracy: 0.6509 - val_loss: 0.6270\n",
            "Epoch 181/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6541 - loss: 0.6311 - val_accuracy: 0.6533 - val_loss: 0.6274\n",
            "Epoch 182/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6715 - loss: 0.6197 - val_accuracy: 0.6533 - val_loss: 0.6270\n",
            "Epoch 183/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6550 - loss: 0.6279 - val_accuracy: 0.6509 - val_loss: 0.6265\n",
            "Epoch 184/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6347 - loss: 0.6285 - val_accuracy: 0.6580 - val_loss: 0.6258\n",
            "Epoch 185/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6497 - loss: 0.6341 - val_accuracy: 0.6580 - val_loss: 0.6256\n",
            "Epoch 186/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6553 - loss: 0.6268 - val_accuracy: 0.6580 - val_loss: 0.6256\n",
            "Epoch 187/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6611 - loss: 0.6234 - val_accuracy: 0.6604 - val_loss: 0.6257\n",
            "Epoch 188/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6447 - loss: 0.6211 - val_accuracy: 0.6580 - val_loss: 0.6254\n",
            "Epoch 189/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6499 - loss: 0.6272 - val_accuracy: 0.6580 - val_loss: 0.6251\n",
            "Epoch 190/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6443 - loss: 0.6342 - val_accuracy: 0.6580 - val_loss: 0.6250\n",
            "Epoch 191/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6426 - loss: 0.6258 - val_accuracy: 0.6604 - val_loss: 0.6243\n",
            "Epoch 192/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6384 - loss: 0.6324 - val_accuracy: 0.6580 - val_loss: 0.6237\n",
            "Epoch 193/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6454 - loss: 0.6288 - val_accuracy: 0.6604 - val_loss: 0.6236\n",
            "Epoch 194/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6462 - loss: 0.6368 - val_accuracy: 0.6604 - val_loss: 0.6237\n",
            "Epoch 195/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6714 - loss: 0.6108 - val_accuracy: 0.6627 - val_loss: 0.6237\n",
            "Epoch 196/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6487 - loss: 0.6167 - val_accuracy: 0.6627 - val_loss: 0.6236\n",
            "Epoch 197/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6289 - loss: 0.6472 - val_accuracy: 0.6651 - val_loss: 0.6239\n",
            "Epoch 198/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6349 - loss: 0.6349 - val_accuracy: 0.6627 - val_loss: 0.6236\n",
            "Epoch 199/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6520 - loss: 0.6380 - val_accuracy: 0.6627 - val_loss: 0.6237\n",
            "Epoch 200/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6498 - loss: 0.6228 - val_accuracy: 0.6698 - val_loss: 0.6235\n"
          ]
        }
      ],
      "source": [
        "#Model Definition by member 1\n",
        "def model_jeremiah_agbaje():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(128, input_shape=(X_train.shape[1],), name='dense_layer', activation=\"relu\",kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))  # 50% dropout after first layer\n",
        "  model.add(tf.keras.layers.Dense(64, name='dense_layer2', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))  # 50% dropout after second layer\n",
        "  model.add(tf.keras.layers.Dense(32, name='dense_layer3', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))\n",
        "  model.add(tf.keras.layers.Dense(1, name='output_layer', activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.00001)))\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "model = model_jeremiah_agbaje()\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "      monitor='val_loss',    # Monitor validation loss\n",
        "      patience=50,\n",
        "      restore_best_weights=True  # Restore weights from best epoch\n",
        "  )\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "  X_train, y_train,\n",
        "  validation_data=(X_val, y_val),\n",
        "  epochs=200,\n",
        "  batch_size=32,\n",
        "  verbose=1,\n",
        "  callbacks=[early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1z30otXZnPVI",
        "outputId": "acfc16b0-a97a-4e66-9ab6-bbbe5bcee83f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Epoch: 200\n",
            "Train Accuracy at Best Epoch: 0.6552\n",
            "Val Accuracy at Best Epoch: 0.6698\n"
          ]
        }
      ],
      "source": [
        "best_epoch = np.argmin(history.history['val_loss'])\n",
        "print(f\"Best Epoch: {best_epoch+1}\")\n",
        "print(f\"Train Accuracy at Best Epoch: {history.history['accuracy'][best_epoch]:.4f}\")\n",
        "print(f\"Val Accuracy at Best Epoch: {history.history['val_accuracy'][best_epoch]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8-xUOoyJk5_",
        "outputId": "e9110139-589a-4b69-fc47-ee8b3cf74a3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6558 - loss: 0.6084 \n",
            "Test Accuracy: 0.6424, Test Loss: 0.6254\n"
          ]
        }
      ],
      "source": [
        "# Evaluate\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}, Test Loss: {test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4_lP3dgBPhU",
        "outputId": "10bec183-ddef-4548-8886-fe208b4deea7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Precision: 0.5806\n",
            "Recall: 0.1146\n",
            "F1 Score: 0.1915\n"
          ]
        }
      ],
      "source": [
        "# calculate precision, recall and f1_score\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# set a class threshold of 0.5 if the prediction probabilites are > 0.5 = positive, else = neagative\n",
        "y_pred_classes = (y_pred > 0.5).astype(\"int32\")\n",
        "\n",
        "precision= precision_score(y_test, y_pred_classes)\n",
        "\n",
        "recall = recall_score(y_test, y_pred_classes)\n",
        "\n",
        "f1 = f1_score(y_test, y_pred_classes)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmWIUNw0-l0y",
        "outputId": "dac043d6-afe3-4907-e9d4-ac33988912cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.5743 - auc: 0.5435 - loss: 0.6844 - precision: 0.4177 - recall: 0.3650 - val_accuracy: 0.5330 - val_auc: 0.5028 - val_loss: 0.6892 - val_precision: 0.3815 - val_recall: 0.4204\n",
            "Epoch 2/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5440 - auc: 0.4892 - loss: 0.7024 - precision: 0.3417 - recall: 0.2853 - val_accuracy: 0.4953 - val_auc: 0.4990 - val_loss: 0.6924 - val_precision: 0.3662 - val_recall: 0.4968\n",
            "Epoch 3/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5692 - auc: 0.4871 - loss: 0.7011 - precision: 0.3785 - recall: 0.2747 - val_accuracy: 0.5212 - val_auc: 0.5064 - val_loss: 0.6898 - val_precision: 0.3814 - val_recall: 0.4713\n",
            "Epoch 4/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5814 - auc: 0.4988 - loss: 0.6880 - precision: 0.3755 - recall: 0.2337 - val_accuracy: 0.5259 - val_auc: 0.5081 - val_loss: 0.6870 - val_precision: 0.3706 - val_recall: 0.4013\n",
            "Epoch 5/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5719 - auc: 0.4812 - loss: 0.6910 - precision: 0.3373 - recall: 0.1806 - val_accuracy: 0.5519 - val_auc: 0.5132 - val_loss: 0.6818 - val_precision: 0.3636 - val_recall: 0.2803\n",
            "Epoch 6/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6031 - auc: 0.4877 - loss: 0.6853 - precision: 0.3873 - recall: 0.1899 - val_accuracy: 0.5991 - val_auc: 0.5251 - val_loss: 0.6766 - val_precision: 0.4270 - val_recall: 0.2420\n",
            "Epoch 7/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5922 - auc: 0.5110 - loss: 0.6790 - precision: 0.3716 - recall: 0.1484 - val_accuracy: 0.5991 - val_auc: 0.5272 - val_loss: 0.6737 - val_precision: 0.4133 - val_recall: 0.1975\n",
            "Epoch 8/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5826 - auc: 0.4709 - loss: 0.6901 - precision: 0.3005 - recall: 0.1028 - val_accuracy: 0.6179 - val_auc: 0.5365 - val_loss: 0.6697 - val_precision: 0.4510 - val_recall: 0.1465\n",
            "Epoch 9/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5903 - auc: 0.5210 - loss: 0.6796 - precision: 0.4036 - recall: 0.1537 - val_accuracy: 0.6203 - val_auc: 0.5421 - val_loss: 0.6661 - val_precision: 0.4500 - val_recall: 0.1146\n",
            "Epoch 10/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6218 - auc: 0.5248 - loss: 0.6659 - precision: 0.4192 - recall: 0.1491 - val_accuracy: 0.6274 - val_auc: 0.5441 - val_loss: 0.6635 - val_precision: 0.4848 - val_recall: 0.1019\n",
            "Epoch 11/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6020 - auc: 0.5290 - loss: 0.6764 - precision: 0.4472 - recall: 0.1592 - val_accuracy: 0.6226 - val_auc: 0.5545 - val_loss: 0.6608 - val_precision: 0.4444 - val_recall: 0.0764\n",
            "Epoch 12/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6110 - auc: 0.5624 - loss: 0.6546 - precision: 0.3835 - recall: 0.0981 - val_accuracy: 0.6203 - val_auc: 0.5595 - val_loss: 0.6591 - val_precision: 0.4091 - val_recall: 0.0573\n",
            "Epoch 13/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5976 - auc: 0.5097 - loss: 0.6764 - precision: 0.3770 - recall: 0.1170 - val_accuracy: 0.6226 - val_auc: 0.5629 - val_loss: 0.6583 - val_precision: 0.4348 - val_recall: 0.0637\n",
            "Epoch 14/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6242 - auc: 0.5435 - loss: 0.6616 - precision: 0.4352 - recall: 0.1251 - val_accuracy: 0.6179 - val_auc: 0.5638 - val_loss: 0.6574 - val_precision: 0.3684 - val_recall: 0.0446\n",
            "Epoch 15/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6231 - auc: 0.5309 - loss: 0.6708 - precision: 0.5059 - recall: 0.1180 - val_accuracy: 0.6156 - val_auc: 0.5592 - val_loss: 0.6580 - val_precision: 0.3500 - val_recall: 0.0446\n",
            "Epoch 16/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6138 - auc: 0.5525 - loss: 0.6610 - precision: 0.3961 - recall: 0.0928 - val_accuracy: 0.6203 - val_auc: 0.5643 - val_loss: 0.6564 - val_precision: 0.3750 - val_recall: 0.0382\n",
            "Epoch 17/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6234 - auc: 0.5365 - loss: 0.6633 - precision: 0.4061 - recall: 0.1275 - val_accuracy: 0.6203 - val_auc: 0.5699 - val_loss: 0.6552 - val_precision: 0.3333 - val_recall: 0.0255\n",
            "Epoch 18/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6097 - auc: 0.5302 - loss: 0.6678 - precision: 0.3609 - recall: 0.0898 - val_accuracy: 0.6179 - val_auc: 0.5743 - val_loss: 0.6534 - val_precision: 0.2727 - val_recall: 0.0191\n",
            "Epoch 19/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6156 - auc: 0.5294 - loss: 0.6661 - precision: 0.3919 - recall: 0.0634 - val_accuracy: 0.6179 - val_auc: 0.5764 - val_loss: 0.6524 - val_precision: 0.2727 - val_recall: 0.0191\n",
            "Epoch 20/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6354 - auc: 0.5764 - loss: 0.6475 - precision: 0.4688 - recall: 0.1189 - val_accuracy: 0.6250 - val_auc: 0.5773 - val_loss: 0.6518 - val_precision: 0.3750 - val_recall: 0.0191\n",
            "Epoch 21/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6353 - auc: 0.5628 - loss: 0.6537 - precision: 0.4911 - recall: 0.0919 - val_accuracy: 0.6250 - val_auc: 0.5771 - val_loss: 0.6515 - val_precision: 0.3750 - val_recall: 0.0191\n",
            "Epoch 22/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6326 - auc: 0.5412 - loss: 0.6546 - precision: 0.4356 - recall: 0.0926 - val_accuracy: 0.6226 - val_auc: 0.5785 - val_loss: 0.6503 - val_precision: 0.3333 - val_recall: 0.0191\n",
            "Epoch 23/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6249 - auc: 0.5561 - loss: 0.6564 - precision: 0.4308 - recall: 0.0776 - val_accuracy: 0.6226 - val_auc: 0.5821 - val_loss: 0.6497 - val_precision: 0.2857 - val_recall: 0.0127\n",
            "Epoch 24/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6319 - auc: 0.5818 - loss: 0.6432 - precision: 0.4219 - recall: 0.0765 - val_accuracy: 0.6226 - val_auc: 0.5816 - val_loss: 0.6498 - val_precision: 0.2857 - val_recall: 0.0127\n",
            "Epoch 25/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6192 - auc: 0.5629 - loss: 0.6544 - precision: 0.4105 - recall: 0.0780 - val_accuracy: 0.6250 - val_auc: 0.5817 - val_loss: 0.6491 - val_precision: 0.3333 - val_recall: 0.0127\n",
            "Epoch 26/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6039 - auc: 0.5596 - loss: 0.6628 - precision: 0.4045 - recall: 0.0715 - val_accuracy: 0.6226 - val_auc: 0.5822 - val_loss: 0.6487 - val_precision: 0.2857 - val_recall: 0.0127\n",
            "Epoch 27/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6149 - auc: 0.6000 - loss: 0.6460 - precision: 0.3760 - recall: 0.0601 - val_accuracy: 0.6274 - val_auc: 0.5851 - val_loss: 0.6477 - val_precision: 0.4000 - val_recall: 0.0127\n",
            "Epoch 28/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6446 - auc: 0.5412 - loss: 0.6482 - precision: 0.4174 - recall: 0.0699 - val_accuracy: 0.6297 - val_auc: 0.5836 - val_loss: 0.6473 - val_precision: 0.5000 - val_recall: 0.0191\n",
            "Epoch 29/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6396 - auc: 0.5444 - loss: 0.6502 - precision: 0.3894 - recall: 0.0737 - val_accuracy: 0.6274 - val_auc: 0.5880 - val_loss: 0.6465 - val_precision: 0.4000 - val_recall: 0.0127\n",
            "Epoch 30/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6501 - auc: 0.5495 - loss: 0.6547 - precision: 0.5984 - recall: 0.0963 - val_accuracy: 0.6297 - val_auc: 0.5864 - val_loss: 0.6460 - val_precision: 0.5000 - val_recall: 0.0191\n",
            "Epoch 31/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6165 - auc: 0.5628 - loss: 0.6568 - precision: 0.4007 - recall: 0.0701 - val_accuracy: 0.6274 - val_auc: 0.5882 - val_loss: 0.6457 - val_precision: 0.4000 - val_recall: 0.0127\n",
            "Epoch 32/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6202 - auc: 0.5495 - loss: 0.6679 - precision: 0.5134 - recall: 0.0870 - val_accuracy: 0.6274 - val_auc: 0.5914 - val_loss: 0.6448 - val_precision: 0.4000 - val_recall: 0.0127\n",
            "Epoch 33/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6083 - auc: 0.5540 - loss: 0.6598 - precision: 0.3420 - recall: 0.0522 - val_accuracy: 0.6297 - val_auc: 0.5960 - val_loss: 0.6439 - val_precision: 0.5000 - val_recall: 0.0191\n",
            "Epoch 34/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6177 - auc: 0.5785 - loss: 0.6506 - precision: 0.4184 - recall: 0.0730 - val_accuracy: 0.6321 - val_auc: 0.5968 - val_loss: 0.6435 - val_precision: 0.6000 - val_recall: 0.0191\n",
            "Epoch 35/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6296 - auc: 0.5329 - loss: 0.6529 - precision: 0.3674 - recall: 0.0557 - val_accuracy: 0.6274 - val_auc: 0.5984 - val_loss: 0.6428 - val_precision: 0.4286 - val_recall: 0.0191\n",
            "Epoch 36/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6277 - auc: 0.5429 - loss: 0.6581 - precision: 0.4316 - recall: 0.0608 - val_accuracy: 0.6297 - val_auc: 0.5992 - val_loss: 0.6422 - val_precision: 0.5000 - val_recall: 0.0255\n",
            "Epoch 37/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6509 - auc: 0.5892 - loss: 0.6429 - precision: 0.5835 - recall: 0.0858 - val_accuracy: 0.6344 - val_auc: 0.5991 - val_loss: 0.6420 - val_precision: 0.6667 - val_recall: 0.0255\n",
            "Epoch 38/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6320 - auc: 0.5862 - loss: 0.6485 - precision: 0.5545 - recall: 0.0717 - val_accuracy: 0.6297 - val_auc: 0.5965 - val_loss: 0.6419 - val_precision: 0.5000 - val_recall: 0.0255\n",
            "Epoch 39/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6308 - auc: 0.5881 - loss: 0.6457 - precision: 0.5103 - recall: 0.0839 - val_accuracy: 0.6321 - val_auc: 0.5990 - val_loss: 0.6413 - val_precision: 0.5714 - val_recall: 0.0255\n",
            "Epoch 40/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6298 - auc: 0.5708 - loss: 0.6503 - precision: 0.4642 - recall: 0.0841 - val_accuracy: 0.6321 - val_auc: 0.6030 - val_loss: 0.6404 - val_precision: 0.5714 - val_recall: 0.0255\n",
            "Epoch 41/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6327 - auc: 0.5839 - loss: 0.6370 - precision: 0.3452 - recall: 0.0613 - val_accuracy: 0.6297 - val_auc: 0.6053 - val_loss: 0.6402 - val_precision: 0.5000 - val_recall: 0.0255\n",
            "Epoch 42/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6314 - auc: 0.5685 - loss: 0.6486 - precision: 0.3352 - recall: 0.0386 - val_accuracy: 0.6321 - val_auc: 0.6021 - val_loss: 0.6405 - val_precision: 0.5556 - val_recall: 0.0318\n",
            "Epoch 43/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6201 - auc: 0.5947 - loss: 0.6535 - precision: 0.5908 - recall: 0.0650 - val_accuracy: 0.6321 - val_auc: 0.6034 - val_loss: 0.6405 - val_precision: 0.5556 - val_recall: 0.0318\n",
            "Epoch 44/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6221 - auc: 0.5899 - loss: 0.6456 - precision: 0.4263 - recall: 0.0592 - val_accuracy: 0.6368 - val_auc: 0.6087 - val_loss: 0.6388 - val_precision: 0.6667 - val_recall: 0.0382\n",
            "Epoch 45/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6209 - auc: 0.5667 - loss: 0.6558 - precision: 0.4285 - recall: 0.0664 - val_accuracy: 0.6321 - val_auc: 0.6049 - val_loss: 0.6391 - val_precision: 0.5455 - val_recall: 0.0382\n",
            "Epoch 46/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6374 - auc: 0.5987 - loss: 0.6397 - precision: 0.4840 - recall: 0.0694 - val_accuracy: 0.6321 - val_auc: 0.6038 - val_loss: 0.6389 - val_precision: 0.5455 - val_recall: 0.0382\n",
            "Epoch 47/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6219 - auc: 0.6085 - loss: 0.6467 - precision: 0.5149 - recall: 0.0919 - val_accuracy: 0.6321 - val_auc: 0.6041 - val_loss: 0.6393 - val_precision: 0.5455 - val_recall: 0.0382\n",
            "Epoch 48/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6291 - auc: 0.5709 - loss: 0.6502 - precision: 0.4189 - recall: 0.0602 - val_accuracy: 0.6392 - val_auc: 0.6058 - val_loss: 0.6384 - val_precision: 0.7000 - val_recall: 0.0446\n",
            "Epoch 49/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6479 - auc: 0.6036 - loss: 0.6377 - precision: 0.5610 - recall: 0.0905 - val_accuracy: 0.6368 - val_auc: 0.6082 - val_loss: 0.6372 - val_precision: 0.6667 - val_recall: 0.0382\n",
            "Epoch 50/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6198 - auc: 0.5907 - loss: 0.6534 - precision: 0.5189 - recall: 0.0838 - val_accuracy: 0.6415 - val_auc: 0.6084 - val_loss: 0.6368 - val_precision: 0.7273 - val_recall: 0.0510\n",
            "Epoch 51/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6308 - auc: 0.6167 - loss: 0.6343 - precision: 0.4581 - recall: 0.0758 - val_accuracy: 0.6392 - val_auc: 0.6114 - val_loss: 0.6365 - val_precision: 0.7000 - val_recall: 0.0446\n",
            "Epoch 52/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6484 - auc: 0.6384 - loss: 0.6304 - precision: 0.6441 - recall: 0.1095 - val_accuracy: 0.6439 - val_auc: 0.6092 - val_loss: 0.6357 - val_precision: 0.7500 - val_recall: 0.0573\n",
            "Epoch 53/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6441 - auc: 0.5874 - loss: 0.6455 - precision: 0.6077 - recall: 0.0904 - val_accuracy: 0.6415 - val_auc: 0.6115 - val_loss: 0.6354 - val_precision: 0.7273 - val_recall: 0.0510\n",
            "Epoch 54/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6515 - auc: 0.6109 - loss: 0.6336 - precision: 0.5688 - recall: 0.1098 - val_accuracy: 0.6415 - val_auc: 0.6092 - val_loss: 0.6360 - val_precision: 0.6923 - val_recall: 0.0573\n",
            "Epoch 55/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6370 - auc: 0.5882 - loss: 0.6461 - precision: 0.5296 - recall: 0.0903 - val_accuracy: 0.6392 - val_auc: 0.6094 - val_loss: 0.6360 - val_precision: 0.6429 - val_recall: 0.0573\n",
            "Epoch 56/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6474 - auc: 0.6024 - loss: 0.6437 - precision: 0.6350 - recall: 0.1080 - val_accuracy: 0.6392 - val_auc: 0.6054 - val_loss: 0.6369 - val_precision: 0.6429 - val_recall: 0.0573\n",
            "Epoch 57/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6538 - auc: 0.6008 - loss: 0.6320 - precision: 0.4680 - recall: 0.0738 - val_accuracy: 0.6392 - val_auc: 0.6039 - val_loss: 0.6370 - val_precision: 0.6429 - val_recall: 0.0573\n",
            "Epoch 58/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6448 - auc: 0.6027 - loss: 0.6450 - precision: 0.5829 - recall: 0.1123 - val_accuracy: 0.6439 - val_auc: 0.6064 - val_loss: 0.6366 - val_precision: 0.6875 - val_recall: 0.0701\n",
            "Epoch 59/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6404 - auc: 0.6179 - loss: 0.6333 - precision: 0.5035 - recall: 0.1036 - val_accuracy: 0.6439 - val_auc: 0.6044 - val_loss: 0.6366 - val_precision: 0.6875 - val_recall: 0.0701\n",
            "Epoch 60/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6318 - auc: 0.6069 - loss: 0.6401 - precision: 0.4877 - recall: 0.0969 - val_accuracy: 0.6415 - val_auc: 0.6086 - val_loss: 0.6355 - val_precision: 0.6667 - val_recall: 0.0637\n",
            "Epoch 61/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6232 - auc: 0.6066 - loss: 0.6452 - precision: 0.5348 - recall: 0.1145 - val_accuracy: 0.6462 - val_auc: 0.6052 - val_loss: 0.6359 - val_precision: 0.7059 - val_recall: 0.0764\n",
            "Epoch 62/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6663 - auc: 0.6229 - loss: 0.6224 - precision: 0.5680 - recall: 0.1033 - val_accuracy: 0.6415 - val_auc: 0.6060 - val_loss: 0.6353 - val_precision: 0.6471 - val_recall: 0.0701\n",
            "Epoch 63/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6471 - auc: 0.6228 - loss: 0.6364 - precision: 0.5940 - recall: 0.1207 - val_accuracy: 0.6439 - val_auc: 0.6074 - val_loss: 0.6350 - val_precision: 0.6875 - val_recall: 0.0701\n",
            "Epoch 64/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6455 - auc: 0.6225 - loss: 0.6347 - precision: 0.5586 - recall: 0.1176 - val_accuracy: 0.6509 - val_auc: 0.6122 - val_loss: 0.6335 - val_precision: 0.7143 - val_recall: 0.0955\n",
            "Epoch 65/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6365 - auc: 0.6172 - loss: 0.6354 - precision: 0.5207 - recall: 0.1176 - val_accuracy: 0.6462 - val_auc: 0.6117 - val_loss: 0.6335 - val_precision: 0.6667 - val_recall: 0.0892\n",
            "Epoch 66/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6306 - auc: 0.6218 - loss: 0.6435 - precision: 0.5736 - recall: 0.1278 - val_accuracy: 0.6462 - val_auc: 0.6166 - val_loss: 0.6325 - val_precision: 0.6667 - val_recall: 0.0892\n",
            "Epoch 67/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6292 - auc: 0.5936 - loss: 0.6459 - precision: 0.5075 - recall: 0.1236 - val_accuracy: 0.6486 - val_auc: 0.6169 - val_loss: 0.6323 - val_precision: 0.6818 - val_recall: 0.0955\n",
            "Epoch 68/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6286 - auc: 0.6211 - loss: 0.6460 - precision: 0.5598 - recall: 0.1367 - val_accuracy: 0.6509 - val_auc: 0.6176 - val_loss: 0.6319 - val_precision: 0.6957 - val_recall: 0.1019\n",
            "Epoch 69/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6473 - auc: 0.6184 - loss: 0.6374 - precision: 0.6075 - recall: 0.1537 - val_accuracy: 0.6486 - val_auc: 0.6177 - val_loss: 0.6315 - val_precision: 0.6538 - val_recall: 0.1083\n",
            "Epoch 70/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6428 - auc: 0.6354 - loss: 0.6244 - precision: 0.5010 - recall: 0.1437 - val_accuracy: 0.6486 - val_auc: 0.6172 - val_loss: 0.6312 - val_precision: 0.6538 - val_recall: 0.1083\n",
            "Epoch 71/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6235 - auc: 0.6200 - loss: 0.6410 - precision: 0.5043 - recall: 0.1325 - val_accuracy: 0.6415 - val_auc: 0.6204 - val_loss: 0.6305 - val_precision: 0.5806 - val_recall: 0.1146\n",
            "Epoch 72/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6470 - auc: 0.6047 - loss: 0.6336 - precision: 0.5021 - recall: 0.1555 - val_accuracy: 0.6462 - val_auc: 0.6208 - val_loss: 0.6302 - val_precision: 0.6207 - val_recall: 0.1146\n",
            "Epoch 73/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6273 - auc: 0.6054 - loss: 0.6493 - precision: 0.5397 - recall: 0.1706 - val_accuracy: 0.6439 - val_auc: 0.6227 - val_loss: 0.6298 - val_precision: 0.6000 - val_recall: 0.1146\n",
            "Epoch 74/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6405 - auc: 0.6375 - loss: 0.6309 - precision: 0.5506 - recall: 0.1412 - val_accuracy: 0.6462 - val_auc: 0.6233 - val_loss: 0.6298 - val_precision: 0.6207 - val_recall: 0.1146\n",
            "Epoch 75/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6531 - auc: 0.6411 - loss: 0.6281 - precision: 0.6023 - recall: 0.1774 - val_accuracy: 0.6557 - val_auc: 0.6212 - val_loss: 0.6298 - val_precision: 0.6774 - val_recall: 0.1338\n",
            "Epoch 76/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6379 - auc: 0.6086 - loss: 0.6394 - precision: 0.5322 - recall: 0.1765 - val_accuracy: 0.6557 - val_auc: 0.6243 - val_loss: 0.6293 - val_precision: 0.6667 - val_recall: 0.1401\n",
            "Epoch 77/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6435 - auc: 0.6226 - loss: 0.6399 - precision: 0.5984 - recall: 0.1857 - val_accuracy: 0.6580 - val_auc: 0.6266 - val_loss: 0.6288 - val_precision: 0.6667 - val_recall: 0.1529\n",
            "Epoch 78/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6406 - auc: 0.6104 - loss: 0.6383 - precision: 0.5349 - recall: 0.1647 - val_accuracy: 0.6533 - val_auc: 0.6290 - val_loss: 0.6279 - val_precision: 0.6316 - val_recall: 0.1529\n",
            "Epoch 79/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6635 - auc: 0.6279 - loss: 0.6203 - precision: 0.5524 - recall: 0.2107 - val_accuracy: 0.6651 - val_auc: 0.6311 - val_loss: 0.6270 - val_precision: 0.6829 - val_recall: 0.1783\n",
            "Epoch 80/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6495 - auc: 0.6632 - loss: 0.6160 - precision: 0.5764 - recall: 0.1962 - val_accuracy: 0.6627 - val_auc: 0.6318 - val_loss: 0.6266 - val_precision: 0.6522 - val_recall: 0.1911\n",
            "Epoch 81/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6519 - auc: 0.6243 - loss: 0.6347 - precision: 0.5483 - recall: 0.1921 - val_accuracy: 0.6627 - val_auc: 0.6310 - val_loss: 0.6268 - val_precision: 0.6522 - val_recall: 0.1911\n",
            "Epoch 82/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6438 - auc: 0.6332 - loss: 0.6310 - precision: 0.5456 - recall: 0.1969 - val_accuracy: 0.6651 - val_auc: 0.6323 - val_loss: 0.6264 - val_precision: 0.6531 - val_recall: 0.2038\n",
            "Epoch 83/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6635 - auc: 0.6570 - loss: 0.6101 - precision: 0.5599 - recall: 0.2016 - val_accuracy: 0.6745 - val_auc: 0.6329 - val_loss: 0.6262 - val_precision: 0.6939 - val_recall: 0.2166\n",
            "Epoch 84/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6561 - auc: 0.6607 - loss: 0.6281 - precision: 0.6526 - recall: 0.2222 - val_accuracy: 0.6722 - val_auc: 0.6354 - val_loss: 0.6248 - val_precision: 0.6800 - val_recall: 0.2166\n",
            "Epoch 85/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6603 - auc: 0.6597 - loss: 0.6268 - precision: 0.6565 - recall: 0.2283 - val_accuracy: 0.6698 - val_auc: 0.6362 - val_loss: 0.6250 - val_precision: 0.6809 - val_recall: 0.2038\n",
            "Epoch 86/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6446 - auc: 0.6288 - loss: 0.6426 - precision: 0.6210 - recall: 0.2279 - val_accuracy: 0.6698 - val_auc: 0.6365 - val_loss: 0.6250 - val_precision: 0.6735 - val_recall: 0.2102\n",
            "Epoch 87/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6273 - auc: 0.6418 - loss: 0.6338 - precision: 0.5282 - recall: 0.1827 - val_accuracy: 0.6698 - val_auc: 0.6342 - val_loss: 0.6256 - val_precision: 0.6809 - val_recall: 0.2038\n",
            "Epoch 88/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6477 - auc: 0.6656 - loss: 0.6178 - precision: 0.5767 - recall: 0.1971 - val_accuracy: 0.6769 - val_auc: 0.6358 - val_loss: 0.6249 - val_precision: 0.7083 - val_recall: 0.2166\n",
            "Epoch 89/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6727 - auc: 0.6515 - loss: 0.6133 - precision: 0.5671 - recall: 0.2270 - val_accuracy: 0.6816 - val_auc: 0.6357 - val_loss: 0.6252 - val_precision: 0.7292 - val_recall: 0.2229\n",
            "Epoch 90/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6724 - auc: 0.6633 - loss: 0.6077 - precision: 0.6003 - recall: 0.2399 - val_accuracy: 0.6816 - val_auc: 0.6368 - val_loss: 0.6249 - val_precision: 0.7200 - val_recall: 0.2293\n",
            "Epoch 91/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6521 - auc: 0.6352 - loss: 0.6334 - precision: 0.5671 - recall: 0.2223 - val_accuracy: 0.6769 - val_auc: 0.6348 - val_loss: 0.6261 - val_precision: 0.7000 - val_recall: 0.2229\n",
            "Epoch 92/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6391 - auc: 0.6729 - loss: 0.6185 - precision: 0.5779 - recall: 0.2402 - val_accuracy: 0.6769 - val_auc: 0.6334 - val_loss: 0.6264 - val_precision: 0.6852 - val_recall: 0.2357\n",
            "Epoch 93/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6451 - auc: 0.6369 - loss: 0.6274 - precision: 0.5334 - recall: 0.2153 - val_accuracy: 0.6792 - val_auc: 0.6352 - val_loss: 0.6249 - val_precision: 0.6981 - val_recall: 0.2357\n",
            "Epoch 94/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6500 - auc: 0.6462 - loss: 0.6174 - precision: 0.5097 - recall: 0.2305 - val_accuracy: 0.6769 - val_auc: 0.6346 - val_loss: 0.6252 - val_precision: 0.6852 - val_recall: 0.2357\n",
            "Epoch 95/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6520 - auc: 0.6638 - loss: 0.6147 - precision: 0.5609 - recall: 0.2340 - val_accuracy: 0.6745 - val_auc: 0.6359 - val_loss: 0.6242 - val_precision: 0.6727 - val_recall: 0.2357\n",
            "Epoch 96/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6457 - auc: 0.6459 - loss: 0.6324 - precision: 0.5532 - recall: 0.2470 - val_accuracy: 0.6769 - val_auc: 0.6383 - val_loss: 0.6234 - val_precision: 0.6852 - val_recall: 0.2357\n",
            "Epoch 97/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6740 - auc: 0.6653 - loss: 0.6104 - precision: 0.6050 - recall: 0.2849 - val_accuracy: 0.6698 - val_auc: 0.6362 - val_loss: 0.6252 - val_precision: 0.6491 - val_recall: 0.2357\n",
            "Epoch 98/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6410 - auc: 0.6411 - loss: 0.6303 - precision: 0.5502 - recall: 0.2194 - val_accuracy: 0.6769 - val_auc: 0.6326 - val_loss: 0.6268 - val_precision: 0.6667 - val_recall: 0.2548\n",
            "Epoch 99/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6178 - auc: 0.6409 - loss: 0.6401 - precision: 0.5099 - recall: 0.2183 - val_accuracy: 0.6722 - val_auc: 0.6330 - val_loss: 0.6263 - val_precision: 0.6500 - val_recall: 0.2484\n",
            "Epoch 100/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6345 - auc: 0.6344 - loss: 0.6323 - precision: 0.5278 - recall: 0.2316 - val_accuracy: 0.6722 - val_auc: 0.6325 - val_loss: 0.6270 - val_precision: 0.6500 - val_recall: 0.2484\n",
            "Epoch 101/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6614 - auc: 0.6678 - loss: 0.6137 - precision: 0.5447 - recall: 0.2629 - val_accuracy: 0.6745 - val_auc: 0.6333 - val_loss: 0.6271 - val_precision: 0.6610 - val_recall: 0.2484\n",
            "Epoch 102/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6792 - auc: 0.6827 - loss: 0.6142 - precision: 0.6462 - recall: 0.2991 - val_accuracy: 0.6745 - val_auc: 0.6329 - val_loss: 0.6275 - val_precision: 0.6557 - val_recall: 0.2548\n",
            "Epoch 103/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6586 - auc: 0.6935 - loss: 0.6074 - precision: 0.6070 - recall: 0.2828 - val_accuracy: 0.6792 - val_auc: 0.6330 - val_loss: 0.6279 - val_precision: 0.6721 - val_recall: 0.2611\n",
            "Epoch 104/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6439 - auc: 0.6665 - loss: 0.6204 - precision: 0.5608 - recall: 0.2456 - val_accuracy: 0.6840 - val_auc: 0.6339 - val_loss: 0.6276 - val_precision: 0.6949 - val_recall: 0.2611\n",
            "Epoch 105/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6582 - auc: 0.6640 - loss: 0.6165 - precision: 0.5753 - recall: 0.2691 - val_accuracy: 0.6792 - val_auc: 0.6354 - val_loss: 0.6271 - val_precision: 0.6667 - val_recall: 0.2675\n",
            "Epoch 106/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6348 - auc: 0.6637 - loss: 0.6190 - precision: 0.5249 - recall: 0.2330 - val_accuracy: 0.6769 - val_auc: 0.6365 - val_loss: 0.6263 - val_precision: 0.6613 - val_recall: 0.2611\n",
            "Epoch 107/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6674 - auc: 0.6616 - loss: 0.6198 - precision: 0.6310 - recall: 0.2711 - val_accuracy: 0.6816 - val_auc: 0.6381 - val_loss: 0.6256 - val_precision: 0.6774 - val_recall: 0.2675\n",
            "Epoch 108/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6499 - auc: 0.6614 - loss: 0.6213 - precision: 0.5512 - recall: 0.2493 - val_accuracy: 0.6722 - val_auc: 0.6365 - val_loss: 0.6258 - val_precision: 0.6364 - val_recall: 0.2675\n",
            "Epoch 109/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6623 - auc: 0.6601 - loss: 0.6192 - precision: 0.5949 - recall: 0.2670 - val_accuracy: 0.6769 - val_auc: 0.6384 - val_loss: 0.6252 - val_precision: 0.6562 - val_recall: 0.2675\n",
            "Epoch 110/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6830 - auc: 0.6877 - loss: 0.6001 - precision: 0.6136 - recall: 0.2913 - val_accuracy: 0.6604 - val_auc: 0.6390 - val_loss: 0.6246 - val_precision: 0.5915 - val_recall: 0.2675\n",
            "Epoch 111/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6587 - auc: 0.6765 - loss: 0.6097 - precision: 0.5624 - recall: 0.2791 - val_accuracy: 0.6651 - val_auc: 0.6374 - val_loss: 0.6248 - val_precision: 0.6056 - val_recall: 0.2739\n",
            "Epoch 112/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6734 - auc: 0.6709 - loss: 0.6064 - precision: 0.5713 - recall: 0.2860 - val_accuracy: 0.6675 - val_auc: 0.6401 - val_loss: 0.6235 - val_precision: 0.6143 - val_recall: 0.2739\n",
            "Epoch 113/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6491 - auc: 0.6585 - loss: 0.6233 - precision: 0.5604 - recall: 0.2646 - val_accuracy: 0.6675 - val_auc: 0.6393 - val_loss: 0.6249 - val_precision: 0.6143 - val_recall: 0.2739\n",
            "Epoch 114/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6670 - auc: 0.6694 - loss: 0.6239 - precision: 0.6661 - recall: 0.2876 - val_accuracy: 0.6792 - val_auc: 0.6407 - val_loss: 0.6244 - val_precision: 0.6615 - val_recall: 0.2739\n",
            "Epoch 115/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6539 - auc: 0.6492 - loss: 0.6274 - precision: 0.5863 - recall: 0.2613 - val_accuracy: 0.6769 - val_auc: 0.6421 - val_loss: 0.6239 - val_precision: 0.6515 - val_recall: 0.2739\n",
            "Epoch 116/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6438 - auc: 0.6788 - loss: 0.6142 - precision: 0.5589 - recall: 0.2591 - val_accuracy: 0.6698 - val_auc: 0.6419 - val_loss: 0.6243 - val_precision: 0.6232 - val_recall: 0.2739\n",
            "Epoch 117/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6620 - auc: 0.6906 - loss: 0.6070 - precision: 0.6104 - recall: 0.2659 - val_accuracy: 0.6651 - val_auc: 0.6459 - val_loss: 0.6229 - val_precision: 0.6056 - val_recall: 0.2739\n",
            "Epoch 118/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6454 - auc: 0.6681 - loss: 0.6194 - precision: 0.5729 - recall: 0.2625 - val_accuracy: 0.6627 - val_auc: 0.6441 - val_loss: 0.6238 - val_precision: 0.5972 - val_recall: 0.2739\n",
            "Epoch 119/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6613 - auc: 0.6692 - loss: 0.6148 - precision: 0.5822 - recall: 0.2933 - val_accuracy: 0.6651 - val_auc: 0.6459 - val_loss: 0.6234 - val_precision: 0.6027 - val_recall: 0.2803\n",
            "Epoch 120/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6370 - auc: 0.6510 - loss: 0.6284 - precision: 0.5535 - recall: 0.2435 - val_accuracy: 0.6745 - val_auc: 0.6466 - val_loss: 0.6232 - val_precision: 0.6377 - val_recall: 0.2803\n",
            "Epoch 121/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6634 - auc: 0.6890 - loss: 0.6063 - precision: 0.6084 - recall: 0.2862 - val_accuracy: 0.6698 - val_auc: 0.6469 - val_loss: 0.6228 - val_precision: 0.6232 - val_recall: 0.2739\n",
            "Epoch 122/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6635 - auc: 0.6891 - loss: 0.6018 - precision: 0.5747 - recall: 0.2879 - val_accuracy: 0.6698 - val_auc: 0.6450 - val_loss: 0.6245 - val_precision: 0.6197 - val_recall: 0.2803\n",
            "Epoch 123/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6740 - auc: 0.6586 - loss: 0.6213 - precision: 0.5936 - recall: 0.3144 - val_accuracy: 0.6651 - val_auc: 0.6466 - val_loss: 0.6236 - val_precision: 0.6027 - val_recall: 0.2803\n",
            "Epoch 124/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6648 - auc: 0.6656 - loss: 0.6176 - precision: 0.6081 - recall: 0.2930 - val_accuracy: 0.6698 - val_auc: 0.6464 - val_loss: 0.6238 - val_precision: 0.6164 - val_recall: 0.2866\n",
            "Epoch 125/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6644 - auc: 0.6928 - loss: 0.6121 - precision: 0.6516 - recall: 0.2869 - val_accuracy: 0.6651 - val_auc: 0.6446 - val_loss: 0.6246 - val_precision: 0.6027 - val_recall: 0.2803\n",
            "Epoch 126/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6600 - auc: 0.6647 - loss: 0.6128 - precision: 0.5714 - recall: 0.2714 - val_accuracy: 0.6651 - val_auc: 0.6438 - val_loss: 0.6248 - val_precision: 0.6000 - val_recall: 0.2866\n",
            "Epoch 127/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6799 - auc: 0.6836 - loss: 0.6069 - precision: 0.6316 - recall: 0.3041 - val_accuracy: 0.6792 - val_auc: 0.6444 - val_loss: 0.6245 - val_precision: 0.6438 - val_recall: 0.2994\n",
            "Epoch 128/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6577 - auc: 0.6691 - loss: 0.6141 - precision: 0.5839 - recall: 0.2775 - val_accuracy: 0.6745 - val_auc: 0.6426 - val_loss: 0.6250 - val_precision: 0.6267 - val_recall: 0.2994\n",
            "Epoch 129/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6514 - auc: 0.6737 - loss: 0.6164 - precision: 0.5802 - recall: 0.2608 - val_accuracy: 0.6698 - val_auc: 0.6423 - val_loss: 0.6249 - val_precision: 0.6104 - val_recall: 0.2994\n",
            "Epoch 130/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6635 - auc: 0.6807 - loss: 0.6117 - precision: 0.6153 - recall: 0.2886 - val_accuracy: 0.6651 - val_auc: 0.6413 - val_loss: 0.6254 - val_precision: 0.6000 - val_recall: 0.2866\n",
            "Epoch 131/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6749 - auc: 0.6671 - loss: 0.6096 - precision: 0.5964 - recall: 0.2932 - val_accuracy: 0.6627 - val_auc: 0.6398 - val_loss: 0.6257 - val_precision: 0.5897 - val_recall: 0.2930\n",
            "Epoch 132/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6649 - auc: 0.6656 - loss: 0.6123 - precision: 0.5917 - recall: 0.2780 - val_accuracy: 0.6651 - val_auc: 0.6399 - val_loss: 0.6260 - val_precision: 0.5949 - val_recall: 0.2994\n",
            "Epoch 133/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6739 - auc: 0.7114 - loss: 0.5928 - precision: 0.6132 - recall: 0.3225 - val_accuracy: 0.6627 - val_auc: 0.6435 - val_loss: 0.6249 - val_precision: 0.5897 - val_recall: 0.2930\n",
            "Epoch 134/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6481 - auc: 0.6650 - loss: 0.6206 - precision: 0.5876 - recall: 0.2632 - val_accuracy: 0.6627 - val_auc: 0.6449 - val_loss: 0.6238 - val_precision: 0.5875 - val_recall: 0.2994\n",
            "Epoch 135/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6594 - auc: 0.6658 - loss: 0.6231 - precision: 0.5900 - recall: 0.2970 - val_accuracy: 0.6604 - val_auc: 0.6456 - val_loss: 0.6235 - val_precision: 0.5823 - val_recall: 0.2930\n",
            "Epoch 136/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6531 - auc: 0.6790 - loss: 0.6156 - precision: 0.6039 - recall: 0.3015 - val_accuracy: 0.6627 - val_auc: 0.6472 - val_loss: 0.6233 - val_precision: 0.5897 - val_recall: 0.2930\n",
            "Epoch 137/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6724 - auc: 0.6870 - loss: 0.6027 - precision: 0.6059 - recall: 0.3191 - val_accuracy: 0.6580 - val_auc: 0.6464 - val_loss: 0.6240 - val_precision: 0.5750 - val_recall: 0.2930\n",
            "Epoch 138/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6869 - auc: 0.7071 - loss: 0.5904 - precision: 0.6184 - recall: 0.3161 - val_accuracy: 0.6533 - val_auc: 0.6459 - val_loss: 0.6234 - val_precision: 0.5595 - val_recall: 0.2994\n",
            "Epoch 139/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6820 - auc: 0.6968 - loss: 0.6045 - precision: 0.6331 - recall: 0.3351 - val_accuracy: 0.6557 - val_auc: 0.6430 - val_loss: 0.6245 - val_precision: 0.5663 - val_recall: 0.2994\n",
            "Epoch 140/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6645 - auc: 0.6694 - loss: 0.6084 - precision: 0.5540 - recall: 0.3049 - val_accuracy: 0.6604 - val_auc: 0.6453 - val_loss: 0.6233 - val_precision: 0.5802 - val_recall: 0.2994\n",
            "Epoch 141/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6850 - auc: 0.6900 - loss: 0.6015 - precision: 0.6467 - recall: 0.3193 - val_accuracy: 0.6580 - val_auc: 0.6424 - val_loss: 0.6248 - val_precision: 0.5750 - val_recall: 0.2930\n",
            "Epoch 142/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6597 - auc: 0.6748 - loss: 0.6136 - precision: 0.5843 - recall: 0.3087 - val_accuracy: 0.6533 - val_auc: 0.6430 - val_loss: 0.6250 - val_precision: 0.5610 - val_recall: 0.2930\n",
            "Epoch 143/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6668 - auc: 0.6741 - loss: 0.6095 - precision: 0.6117 - recall: 0.3161 - val_accuracy: 0.6557 - val_auc: 0.6440 - val_loss: 0.6249 - val_precision: 0.5679 - val_recall: 0.2930\n",
            "Epoch 144/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6740 - auc: 0.6607 - loss: 0.6135 - precision: 0.6092 - recall: 0.3084 - val_accuracy: 0.6533 - val_auc: 0.6425 - val_loss: 0.6257 - val_precision: 0.5610 - val_recall: 0.2930\n",
            "Epoch 145/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6704 - auc: 0.6856 - loss: 0.6000 - precision: 0.5900 - recall: 0.2990 - val_accuracy: 0.6462 - val_auc: 0.6425 - val_loss: 0.6254 - val_precision: 0.5412 - val_recall: 0.2930\n",
            "Epoch 146/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6481 - auc: 0.6691 - loss: 0.6217 - precision: 0.5607 - recall: 0.2747 - val_accuracy: 0.6392 - val_auc: 0.6437 - val_loss: 0.6250 - val_precision: 0.5233 - val_recall: 0.2866\n",
            "Epoch 147/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6837 - auc: 0.6963 - loss: 0.5983 - precision: 0.6263 - recall: 0.3179 - val_accuracy: 0.6439 - val_auc: 0.6455 - val_loss: 0.6247 - val_precision: 0.5357 - val_recall: 0.2866\n"
          ]
        }
      ],
      "source": [
        "def model_gaius_irakiza():\n",
        "    model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Nadam(learning_rate=0.0001)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            tf.keras.metrics.Precision(name='precision'),\n",
        "            tf.keras.metrics.Recall(name='recall'),\n",
        "            tf.keras.metrics.AUC(name='auc')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "gaius_model = model_gaius_irakiza()\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=30,\n",
        "    min_delta=0.0001,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "history = gaius_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=300,\n",
        "    batch_size=32,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIQiApSSMZR8",
        "outputId": "974af313-a129-4da2-f189-5182c0cfaeb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Epoch: 267\n",
            "Train Accuracy at Best Epoch: 0.7017\n",
            "Val Accuracy at Best Epoch: 0.6863\n"
          ]
        }
      ],
      "source": [
        "best_epoch = np.argmin(history.history['val_loss'])\n",
        "print(f\"Best Epoch: {best_epoch+1}\")\n",
        "print(f\"Train Accuracy at Best Epoch: {history.history['accuracy'][best_epoch]:.4f}\")\n",
        "print(f\"Val Accuracy at Best Epoch: {history.history['val_accuracy'][best_epoch]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaanMjPsMpYH",
        "outputId": "01b244ac-fbe9-429f-9862-f42cf01ecec9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6774 - auc: 0.6722 - loss: 0.6024 - precision: 0.6296 - recall: 0.2362 \n",
            "\n",
            "Test Evaluation Metrics:\n",
            "  Loss      : 0.6084\n",
            "  Accuracy  : 0.6706\n",
            "  Precision : 0.6491\n",
            "  Recall    : 0.2357\n",
            "  AUC       : 0.6794\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy, test_precision, test_recall, test_auc = gaius_model.evaluate(X_test, y_test, verbose=1)\n",
        "\n",
        "# Print results with clear formatting\n",
        "print(\"\\nTest Evaluation Metrics:\")\n",
        "print(f\"  Loss      : {test_loss:.4f}\")\n",
        "print(f\"  Accuracy  : {test_accuracy:.4f}\")\n",
        "print(f\"  Precision : {test_precision:.4f}\")\n",
        "print(f\"  Recall    : {test_recall:.4f}\")\n",
        "print(f\"  AUC       : {test_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0R8q1MuJ-mJd",
        "outputId": "ec70c1af-61b9-4070-8d24-33b83221736d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6406 - loss: 0.7338 - val_accuracy: 0.6321 - val_loss: 0.7122\n",
            "Epoch 2/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6311 - loss: 0.7081 - val_accuracy: 0.6344 - val_loss: 0.6951\n",
            "Epoch 3/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6729 - loss: 0.6631 - val_accuracy: 0.6439 - val_loss: 0.6850\n",
            "Epoch 4/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6774 - loss: 0.6631 - val_accuracy: 0.6533 - val_loss: 0.6786\n",
            "Epoch 5/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6874 - loss: 0.6464 - val_accuracy: 0.6462 - val_loss: 0.6752\n",
            "Epoch 6/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6850 - loss: 0.6381 - val_accuracy: 0.6533 - val_loss: 0.6671\n",
            "Epoch 7/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6927 - loss: 0.6384 - val_accuracy: 0.6533 - val_loss: 0.6712\n",
            "Epoch 8/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7044 - loss: 0.6256 - val_accuracy: 0.6557 - val_loss: 0.6732\n",
            "Epoch 9/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7039 - loss: 0.6230 - val_accuracy: 0.6627 - val_loss: 0.6727\n",
            "Epoch 10/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7088 - loss: 0.6178 - val_accuracy: 0.6604 - val_loss: 0.6743\n",
            "Epoch 11/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7219 - loss: 0.6029 - val_accuracy: 0.6462 - val_loss: 0.6713\n",
            "Epoch 12/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7166 - loss: 0.6015 - val_accuracy: 0.6509 - val_loss: 0.6727\n",
            "Epoch 13/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7170 - loss: 0.5997 - val_accuracy: 0.6392 - val_loss: 0.6888\n",
            "Epoch 14/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7244 - loss: 0.5910 - val_accuracy: 0.6462 - val_loss: 0.6853\n",
            "Epoch 15/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7243 - loss: 0.5945 - val_accuracy: 0.6179 - val_loss: 0.6847\n",
            "Epoch 16/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7578 - loss: 0.5670 - val_accuracy: 0.6392 - val_loss: 0.6786\n",
            "Epoch 17/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7427 - loss: 0.5679 - val_accuracy: 0.6392 - val_loss: 0.6947\n",
            "Epoch 18/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7325 - loss: 0.5774 - val_accuracy: 0.6297 - val_loss: 0.6976\n",
            "Epoch 19/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7319 - loss: 0.5691 - val_accuracy: 0.6509 - val_loss: 0.7088\n",
            "Epoch 20/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7340 - loss: 0.5707 - val_accuracy: 0.6085 - val_loss: 0.7160\n",
            "Epoch 21/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7684 - loss: 0.5518 - val_accuracy: 0.6321 - val_loss: 0.7163\n",
            "Epoch 22/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7625 - loss: 0.5487 - val_accuracy: 0.5849 - val_loss: 0.7235\n",
            "Epoch 23/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7788 - loss: 0.5301 - val_accuracy: 0.6108 - val_loss: 0.7179\n",
            "Epoch 24/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7634 - loss: 0.5349 - val_accuracy: 0.6368 - val_loss: 0.7088\n",
            "Epoch 25/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7874 - loss: 0.5174 - val_accuracy: 0.6061 - val_loss: 0.7135\n",
            "Epoch 26/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8019 - loss: 0.5081 - val_accuracy: 0.5943 - val_loss: 0.7313\n",
            "Epoch 27/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7943 - loss: 0.5082 - val_accuracy: 0.6392 - val_loss: 0.7315\n",
            "Epoch 28/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7968 - loss: 0.5081 - val_accuracy: 0.6321 - val_loss: 0.7443\n",
            "Epoch 29/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8052 - loss: 0.4921 - val_accuracy: 0.6321 - val_loss: 0.7536\n",
            "Epoch 30/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8003 - loss: 0.4872 - val_accuracy: 0.6297 - val_loss: 0.7514\n",
            "Epoch 31/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8152 - loss: 0.4795 - val_accuracy: 0.6156 - val_loss: 0.7734\n",
            "Epoch 32/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8082 - loss: 0.4777 - val_accuracy: 0.6486 - val_loss: 0.7548\n",
            "Epoch 33/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8105 - loss: 0.4700 - val_accuracy: 0.6085 - val_loss: 0.7833\n",
            "Epoch 34/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8105 - loss: 0.4890 - val_accuracy: 0.5967 - val_loss: 0.7875\n",
            "Epoch 35/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8299 - loss: 0.4712 - val_accuracy: 0.5684 - val_loss: 0.8664\n",
            "Epoch 36/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8429 - loss: 0.4396 - val_accuracy: 0.6014 - val_loss: 0.8147\n",
            "Epoch 37/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8320 - loss: 0.4395 - val_accuracy: 0.6509 - val_loss: 0.8077\n",
            "Epoch 38/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8358 - loss: 0.4348 - val_accuracy: 0.5873 - val_loss: 0.8438\n",
            "Epoch 39/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8285 - loss: 0.4490 - val_accuracy: 0.6368 - val_loss: 0.8255\n",
            "Epoch 40/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8514 - loss: 0.4220 - val_accuracy: 0.6250 - val_loss: 0.9066\n",
            "Epoch 41/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.4328 - val_accuracy: 0.6061 - val_loss: 0.8517\n",
            "Epoch 42/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8217 - loss: 0.4350 - val_accuracy: 0.6580 - val_loss: 0.8509\n",
            "Epoch 43/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8619 - loss: 0.3953 - val_accuracy: 0.6038 - val_loss: 0.8532\n",
            "Epoch 44/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8499 - loss: 0.4069 - val_accuracy: 0.5212 - val_loss: 1.0192\n",
            "Epoch 45/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8492 - loss: 0.4132 - val_accuracy: 0.6297 - val_loss: 0.9075\n",
            "Epoch 46/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8507 - loss: 0.3921 - val_accuracy: 0.5708 - val_loss: 0.8934\n",
            "Epoch 47/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8591 - loss: 0.3953 - val_accuracy: 0.5967 - val_loss: 0.9100\n",
            "Epoch 48/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8606 - loss: 0.4029 - val_accuracy: 0.5778 - val_loss: 0.9879\n",
            "Epoch 49/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8687 - loss: 0.3806 - val_accuracy: 0.5542 - val_loss: 0.9894\n",
            "Epoch 50/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8694 - loss: 0.3843 - val_accuracy: 0.5613 - val_loss: 0.9725\n",
            "Epoch 51/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8670 - loss: 0.3805 - val_accuracy: 0.5708 - val_loss: 0.9840\n",
            "Epoch 52/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8817 - loss: 0.3741 - val_accuracy: 0.5943 - val_loss: 0.9413\n",
            "Epoch 53/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8758 - loss: 0.3693 - val_accuracy: 0.6179 - val_loss: 0.9696\n",
            "Epoch 54/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8714 - loss: 0.3545 - val_accuracy: 0.5472 - val_loss: 1.0711\n",
            "Epoch 55/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8860 - loss: 0.3557 - val_accuracy: 0.6297 - val_loss: 0.9886\n",
            "Epoch 56/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8829 - loss: 0.3529 - val_accuracy: 0.5802 - val_loss: 1.0934\n"
          ]
        }
      ],
      "source": [
        "#Model Definition by member 3 (RMSprop variant)\n",
        "def model_david():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(128, input_shape=(X_train.shape[1],), activation=\"relu\",\n",
        "                                   kernel_regularizer=tf.keras.regularizers.l2(0.0005)))\n",
        "  model.add(tf.keras.layers.Dense(64, activation=\"relu\",\n",
        "                                   kernel_regularizer=tf.keras.regularizers.l2(0.0005)))\n",
        "  model.add(tf.keras.layers.Dense(32, activation=\"relu\",\n",
        "                                   kernel_regularizer=tf.keras.regularizers.l2(0.0005)))\n",
        "  model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\",\n",
        "                                   kernel_regularizer=tf.keras.regularizers.l2(0.0005)))\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "                loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "  return model\n",
        "\n",
        "model3 = model_david()\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping_3 = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=50,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history3 = model3.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=300,\n",
        "    batch_size=32,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping_3]\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh4Z094Tl1oJ",
        "outputId": "bde8d2c3-6988-4ccf-d2f2-72b3983c05a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Epoch: 16\n",
            "Train Accuracy at Best Epoch: 0.7314\n",
            "Validation Accuracy at Best Epoch: 0.6934\n"
          ]
        }
      ],
      "source": [
        "# Get best epoch based on validation loss\n",
        "best_epoch = history3.history['val_loss'].index(min(history3.history['val_loss']))\n",
        "\n",
        "# Get train and validation accuracy at best epoch\n",
        "train_acc_at_best = history3.history['accuracy'][best_epoch]\n",
        "val_acc_at_best = history3.history['val_accuracy'][best_epoch]\n",
        "\n",
        "print(f\"Best Epoch: {best_epoch + 1}\")  # +1 for human-readable epoch number\n",
        "print(f\"Train Accuracy at Best Epoch: {train_acc_at_best:.4f}\")\n",
        "print(f\"Validation Accuracy at Best Epoch: {val_acc_at_best:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oczDl65Sl1SH",
        "outputId": "631daac1-8df3-43bb-b2fa-b3bdd6fa54f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Test Loss: 0.6773\n",
            "Test Accuracy: 0.6447\n",
            "Test Precision: 0.5238\n",
            "Test Recall: 0.4204\n",
            "Test AUC: 0.6710\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_probs = model3.predict(X_test).ravel()\n",
        "\n",
        "# Predict binary classes\n",
        "y_pred_classes = (y_pred_probs > 0.5).astype(\"int32\")\n",
        "\n",
        "# Evaluate loss and accuracy\n",
        "test_loss, test_accuracy = model3.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "# Calculate precision, recall, and AUC\n",
        "test_precision = precision_score(y_test, y_pred_classes)\n",
        "test_recall = recall_score(y_test, y_pred_classes)\n",
        "test_auc = roc_auc_score(y_test, y_pred_probs)\n",
        "\n",
        "# Print results\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test AUC: {test_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKoFpxX6_B7D",
        "outputId": "f95d5b6a-a24a-42ad-c3d5-c2b610485240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.72.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Epoch 1/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.4463 - auc: 0.5332 - loss: 1.1428 - precision: 0.3732 - recall: 0.7309 - val_accuracy: 0.6274 - val_auc: 0.4925 - val_loss: 1.0695 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6230 - auc: 0.4940 - loss: 1.0611 - precision: 0.3601 - recall: 0.0689 - val_accuracy: 0.6297 - val_auc: 0.5098 - val_loss: 1.0241 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6345 - auc: 0.5051 - loss: 1.0148 - precision: 0.3592 - recall: 0.0110 - val_accuracy: 0.6297 - val_auc: 0.5214 - val_loss: 0.9831 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6309 - auc: 0.5008 - loss: 0.9795 - precision: 0.4844 - recall: 0.0026 - val_accuracy: 0.6297 - val_auc: 0.5325 - val_loss: 0.9436 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 5/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6331 - auc: 0.5260 - loss: 0.9342 - precision: 0.1250 - recall: 1.7456e-04 - val_accuracy: 0.6297 - val_auc: 0.5339 - val_loss: 0.9055 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 6/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6316 - auc: 0.5272 - loss: 0.8975 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5393 - val_loss: 0.8688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 7/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6519 - auc: 0.5612 - loss: 0.8455 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5392 - val_loss: 0.8346 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 8/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6346 - auc: 0.5408 - loss: 0.8254 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5367 - val_loss: 0.8036 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 9/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6253 - auc: 0.5705 - loss: 0.7946 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5513 - val_loss: 0.7765 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 10/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6183 - auc: 0.5825 - loss: 0.7707 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5511 - val_loss: 0.7532 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 11/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6382 - auc: 0.5677 - loss: 0.7417 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5494 - val_loss: 0.7351 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 12/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6228 - auc: 0.5574 - loss: 0.7344 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5598 - val_loss: 0.7207 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 13/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6250 - auc: 0.5921 - loss: 0.7145 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5509 - val_loss: 0.7103 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 14/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6350 - auc: 0.5876 - loss: 0.6981 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5547 - val_loss: 0.7016 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 15/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6305 - auc: 0.5961 - loss: 0.6956 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5634 - val_loss: 0.6948 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 16/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6310 - auc: 0.5950 - loss: 0.6895 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5690 - val_loss: 0.6887 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 17/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6265 - auc: 0.5831 - loss: 0.6890 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5731 - val_loss: 0.6842 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 18/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6224 - auc: 0.6086 - loss: 0.6814 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5803 - val_loss: 0.6802 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 19/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6330 - auc: 0.5996 - loss: 0.6772 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5833 - val_loss: 0.6775 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 20/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6418 - auc: 0.6377 - loss: 0.6595 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5924 - val_loss: 0.6749 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 21/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6359 - auc: 0.5946 - loss: 0.6729 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5990 - val_loss: 0.6726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 22/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6177 - auc: 0.6170 - loss: 0.6743 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5999 - val_loss: 0.6707 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 23/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6350 - auc: 0.6333 - loss: 0.6601 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5972 - val_loss: 0.6701 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 24/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6158 - auc: 0.6265 - loss: 0.6724 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6043 - val_loss: 0.6686 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 25/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6287 - auc: 0.6515 - loss: 0.6612 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6124 - val_loss: 0.6662 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 26/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6217 - auc: 0.6453 - loss: 0.6671 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6087 - val_loss: 0.6661 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 27/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6222 - auc: 0.6468 - loss: 0.6658 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6134 - val_loss: 0.6644 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 28/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6323 - auc: 0.6581 - loss: 0.6578 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6141 - val_loss: 0.6639 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 29/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6141 - auc: 0.6454 - loss: 0.6670 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6068 - val_loss: 0.6648 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 30/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6125 - auc: 0.6408 - loss: 0.6675 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6051 - val_loss: 0.6636 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 31/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6425 - auc: 0.6467 - loss: 0.6489 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6054 - val_loss: 0.6634 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 32/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6324 - auc: 0.6498 - loss: 0.6533 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6095 - val_loss: 0.6621 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 33/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6256 - auc: 0.6290 - loss: 0.6675 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6087 - val_loss: 0.6621 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 34/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6315 - auc: 0.6404 - loss: 0.6586 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6095 - val_loss: 0.6617 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 35/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6220 - auc: 0.6737 - loss: 0.6550 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6097 - val_loss: 0.6614 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 36/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6264 - auc: 0.6687 - loss: 0.6520 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6206 - val_loss: 0.6592 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 37/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6305 - auc: 0.6652 - loss: 0.6477 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6215 - val_loss: 0.6584 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 38/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6291 - auc: 0.6291 - loss: 0.6634 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6183 - val_loss: 0.6591 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 39/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6378 - auc: 0.6557 - loss: 0.6533 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6204 - val_loss: 0.6581 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 40/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6296 - auc: 0.6358 - loss: 0.6579 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6238 - val_loss: 0.6582 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 41/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6311 - auc: 0.6530 - loss: 0.6538 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6252 - val_loss: 0.6564 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 42/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6353 - auc: 0.6658 - loss: 0.6446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6233 - val_loss: 0.6579 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 43/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6204 - auc: 0.6553 - loss: 0.6635 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6219 - val_loss: 0.6576 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 44/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6215 - auc: 0.6628 - loss: 0.6572 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6277 - val_loss: 0.6568 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 45/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6403 - auc: 0.6598 - loss: 0.6451 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6301 - val_loss: 0.6562 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 46/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6419 - auc: 0.6307 - loss: 0.6548 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6294 - val_loss: 0.6561 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 47/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6423 - auc: 0.6636 - loss: 0.6460 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6306 - val_loss: 0.6553 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 48/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6334 - auc: 0.6261 - loss: 0.6619 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6333 - val_loss: 0.6570 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 49/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6240 - auc: 0.6527 - loss: 0.6590 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6295 - val_loss: 0.6562 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 50/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6389 - auc: 0.6506 - loss: 0.6516 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6348 - val_loss: 0.6560 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 51/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6161 - auc: 0.6520 - loss: 0.6586 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6358 - val_loss: 0.6549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 52/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6308 - auc: 0.6539 - loss: 0.6487 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6273 - val_loss: 0.6568 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 53/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6251 - auc: 0.6528 - loss: 0.6559 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6377 - val_loss: 0.6542 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 54/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6207 - auc: 0.6631 - loss: 0.6524 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6342 - val_loss: 0.6540 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 55/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6390 - auc: 0.6791 - loss: 0.6389 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6301 - val_loss: 0.6565 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 56/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6228 - auc: 0.6620 - loss: 0.6516 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6244 - val_loss: 0.6568 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 57/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6309 - auc: 0.6534 - loss: 0.6533 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6341 - val_loss: 0.6543 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 58/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6183 - auc: 0.6557 - loss: 0.6564 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6351 - val_loss: 0.6539 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 59/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6397 - auc: 0.6637 - loss: 0.6413 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6310 - val_loss: 0.6542 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 60/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6257 - auc: 0.6767 - loss: 0.6505 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6274 - val_loss: 0.6554 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 61/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6372 - auc: 0.6684 - loss: 0.6459 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6293 - val_loss: 0.6549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 62/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6467 - auc: 0.6673 - loss: 0.6411 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6281 - val_loss: 0.6542 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 63/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6306 - auc: 0.6824 - loss: 0.6407 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6323 - val_loss: 0.6545 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 64/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6213 - auc: 0.6726 - loss: 0.6535 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6335 - val_loss: 0.6536 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 65/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6192 - auc: 0.6752 - loss: 0.6457 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6302 - val_loss: 0.6538 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 66/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6194 - auc: 0.6742 - loss: 0.6528 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6318 - val_loss: 0.6545 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 67/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6372 - auc: 0.6769 - loss: 0.6397 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6303 - val_loss: 0.6546 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 68/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6193 - auc: 0.6576 - loss: 0.6561 - precision: 0.5417 - recall: 0.0112 - val_accuracy: 0.6297 - val_auc: 0.6324 - val_loss: 0.6536 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 69/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6559 - auc: 0.6678 - loss: 0.6338 - precision: 0.1268 - recall: 0.0015 - val_accuracy: 0.6297 - val_auc: 0.6271 - val_loss: 0.6559 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 70/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6372 - auc: 0.6548 - loss: 0.6503 - precision: 0.5201 - recall: 0.0368 - val_accuracy: 0.6297 - val_auc: 0.6282 - val_loss: 0.6553 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 71/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6360 - auc: 0.6539 - loss: 0.6495 - precision: 0.5548 - recall: 0.0467 - val_accuracy: 0.6297 - val_auc: 0.6285 - val_loss: 0.6551 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 72/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6347 - auc: 0.6632 - loss: 0.6529 - precision: 0.6491 - recall: 0.0495 - val_accuracy: 0.6297 - val_auc: 0.6332 - val_loss: 0.6543 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 73/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6416 - auc: 0.6685 - loss: 0.6482 - precision: 0.6287 - recall: 0.0601 - val_accuracy: 0.6344 - val_auc: 0.6326 - val_loss: 0.6539 - val_precision: 0.6667 - val_recall: 0.0255\n",
            "Epoch 74/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6425 - auc: 0.6548 - loss: 0.6533 - precision: 0.6257 - recall: 0.0898 - val_accuracy: 0.6297 - val_auc: 0.6294 - val_loss: 0.6537 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 75/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6416 - auc: 0.6370 - loss: 0.6509 - precision: 0.4766 - recall: 0.0302 - val_accuracy: 0.6297 - val_auc: 0.6241 - val_loss: 0.6561 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 76/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6508 - auc: 0.6453 - loss: 0.6559 - precision: 0.7438 - recall: 0.0802 - val_accuracy: 0.6297 - val_auc: 0.6266 - val_loss: 0.6555 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 77/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6408 - auc: 0.6636 - loss: 0.6557 - precision: 0.7694 - recall: 0.0606 - val_accuracy: 0.6297 - val_auc: 0.6321 - val_loss: 0.6537 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 78/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6366 - auc: 0.6601 - loss: 0.6505 - precision: 0.7251 - recall: 0.0238 - val_accuracy: 0.6297 - val_auc: 0.6324 - val_loss: 0.6541 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "#Model Definition by member 4\n",
        "!pip install tensorflow\n",
        "def model_tamanda_kaunda():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(96, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.001)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(48, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.0005)),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Dense(24, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.0005)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(12, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.0001)),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            tf.keras.metrics.Precision(name='precision'),\n",
        "            tf.keras.metrics.Recall(name='recall'),\n",
        "            tf.keras.metrics.AUC(name='auc')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "tamanda_model = model_tamanda_kaunda()\n",
        "\n",
        "early_stopping_4 = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=25,\n",
        "    min_delta=0.001,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = tamanda_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=200,\n",
        "    batch_size=64,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping_4]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBK6hXpY5xre",
        "outputId": "f49bdc35-300d-469e-982e-2f054bf30eec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Epoch: 68\n",
            "Train Accuracy at Best Epoch: 0.6360\n",
            "Val Accuracy at Best Epoch: 0.6297\n"
          ]
        }
      ],
      "source": [
        "best_epoch = np.argmin(history.history['val_loss'])\n",
        "print(f\"Best Epoch: {best_epoch+1}\")\n",
        "print(f\"Train Accuracy at Best Epoch: {history.history['accuracy'][best_epoch]:.4f}\")\n",
        "print(f\"Val Accuracy at Best Epoch: {history.history['val_accuracy'][best_epoch]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5tLv1NT56Xr",
        "outputId": "7558206d-eb00-4ff3-9efa-3f877dcc71cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6436 - auc: 0.6549 - loss: 0.6440 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
            "\n",
            "Test Evaluation Metrics:\n",
            "  Loss      : 0.6459\n",
            "  Accuracy  : 0.6306\n",
            "  Precision : 0.0000\n",
            "  Recall    : 0.0000\n",
            "  AUC       : 0.6799\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_accuracy, test_precision, test_recall, test_auc = tamanda_model.evaluate(X_test, y_test, verbose=1)\n",
        "\n",
        "# Print results with clear formatting\n",
        "print(\"\\nTest Evaluation Metrics:\")\n",
        "print(f\"  Loss      : {test_loss:.4f}\")\n",
        "print(f\"  Accuracy  : {test_accuracy:.4f}\")\n",
        "print(f\"  Precision : {test_precision:.4f}\")\n",
        "print(f\"  Recall    : {test_recall:.4f}\")\n",
        "print(f\"  AUC       : {test_auc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd3m8M3dKcfe",
        "outputId": "e6e7747e-ae3a-4a90-c049-4f3a6d1f1062"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5390 - loss: 0.7547 - val_accuracy: 0.6297 - val_loss: 0.7260\n",
            "Epoch 2/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6241 - loss: 0.7306 - val_accuracy: 0.6297 - val_loss: 0.7253\n",
            "Epoch 3/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6309 - loss: 0.7230 - val_accuracy: 0.6297 - val_loss: 0.7234\n",
            "Epoch 4/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6160 - loss: 0.7268 - val_accuracy: 0.6297 - val_loss: 0.7197\n",
            "Epoch 5/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6444 - loss: 0.7102 - val_accuracy: 0.6297 - val_loss: 0.7181\n",
            "Epoch 6/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6261 - loss: 0.7115 - val_accuracy: 0.6297 - val_loss: 0.7165\n",
            "Epoch 7/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6244 - loss: 0.7229 - val_accuracy: 0.6297 - val_loss: 0.7140\n",
            "Epoch 8/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6271 - loss: 0.7145 - val_accuracy: 0.6297 - val_loss: 0.7113\n",
            "Epoch 9/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6562 - loss: 0.6953 - val_accuracy: 0.6297 - val_loss: 0.7089\n",
            "Epoch 10/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6396 - loss: 0.7078 - val_accuracy: 0.6297 - val_loss: 0.7064\n",
            "Epoch 11/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6554 - loss: 0.6935 - val_accuracy: 0.6368 - val_loss: 0.7038\n",
            "Epoch 12/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6379 - loss: 0.7067 - val_accuracy: 0.6392 - val_loss: 0.6985\n",
            "Epoch 13/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6365 - loss: 0.7024 - val_accuracy: 0.6439 - val_loss: 0.6947\n",
            "Epoch 14/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6327 - loss: 0.7035 - val_accuracy: 0.6533 - val_loss: 0.6926\n",
            "Epoch 15/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6467 - loss: 0.6860 - val_accuracy: 0.6580 - val_loss: 0.6885\n",
            "Epoch 16/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6562 - loss: 0.6772 - val_accuracy: 0.6557 - val_loss: 0.6877\n",
            "Epoch 17/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6682 - loss: 0.6758 - val_accuracy: 0.6439 - val_loss: 0.6840\n",
            "Epoch 18/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6694 - loss: 0.6750 - val_accuracy: 0.6604 - val_loss: 0.6793\n",
            "Epoch 19/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6542 - loss: 0.6825 - val_accuracy: 0.6580 - val_loss: 0.6775\n",
            "Epoch 20/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6367 - loss: 0.6855 - val_accuracy: 0.6627 - val_loss: 0.6764\n",
            "Epoch 21/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6463 - loss: 0.6876 - val_accuracy: 0.6604 - val_loss: 0.6746\n",
            "Epoch 22/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6570 - loss: 0.6770 - val_accuracy: 0.6698 - val_loss: 0.6735\n",
            "Epoch 23/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6688 - loss: 0.6645 - val_accuracy: 0.6651 - val_loss: 0.6749\n",
            "Epoch 24/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6755 - loss: 0.6665 - val_accuracy: 0.6627 - val_loss: 0.6744\n",
            "Epoch 25/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6782 - loss: 0.6681 - val_accuracy: 0.6722 - val_loss: 0.6721\n",
            "Epoch 26/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6677 - loss: 0.6682 - val_accuracy: 0.6769 - val_loss: 0.6728\n",
            "Epoch 27/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6753 - loss: 0.6699 - val_accuracy: 0.6651 - val_loss: 0.6703\n",
            "Epoch 28/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6635 - loss: 0.6631 - val_accuracy: 0.6745 - val_loss: 0.6706\n",
            "Epoch 29/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6646 - loss: 0.6672 - val_accuracy: 0.6651 - val_loss: 0.6695\n",
            "Epoch 30/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6710 - loss: 0.6555 - val_accuracy: 0.6627 - val_loss: 0.6675\n",
            "Epoch 31/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6543 - loss: 0.6723 - val_accuracy: 0.6651 - val_loss: 0.6680\n",
            "Epoch 32/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6794 - loss: 0.6511 - val_accuracy: 0.6722 - val_loss: 0.6659\n",
            "Epoch 33/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6799 - loss: 0.6499 - val_accuracy: 0.6792 - val_loss: 0.6672\n",
            "Epoch 34/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6847 - loss: 0.6487 - val_accuracy: 0.6769 - val_loss: 0.6667\n",
            "Epoch 35/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6677 - loss: 0.6660 - val_accuracy: 0.6698 - val_loss: 0.6668\n",
            "Epoch 36/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6964 - loss: 0.6404 - val_accuracy: 0.6910 - val_loss: 0.6648\n",
            "Epoch 37/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6691 - loss: 0.6658 - val_accuracy: 0.6816 - val_loss: 0.6632\n",
            "Epoch 38/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6705 - loss: 0.6701 - val_accuracy: 0.6863 - val_loss: 0.6634\n",
            "Epoch 39/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6822 - loss: 0.6496 - val_accuracy: 0.6769 - val_loss: 0.6644\n",
            "Epoch 40/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6616 - loss: 0.6549 - val_accuracy: 0.6863 - val_loss: 0.6645\n",
            "Epoch 41/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6715 - loss: 0.6388 - val_accuracy: 0.6840 - val_loss: 0.6641\n",
            "Epoch 42/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6813 - loss: 0.6542 - val_accuracy: 0.6769 - val_loss: 0.6643\n",
            "Epoch 43/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6704 - loss: 0.6529 - val_accuracy: 0.6769 - val_loss: 0.6631\n",
            "Epoch 44/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6793 - loss: 0.6578 - val_accuracy: 0.6863 - val_loss: 0.6650\n",
            "Epoch 45/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7024 - loss: 0.6278 - val_accuracy: 0.6792 - val_loss: 0.6630\n",
            "Epoch 46/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6835 - loss: 0.6534 - val_accuracy: 0.6698 - val_loss: 0.6628\n",
            "Epoch 47/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6997 - loss: 0.6359 - val_accuracy: 0.6792 - val_loss: 0.6609\n",
            "Epoch 48/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6940 - loss: 0.6468 - val_accuracy: 0.6840 - val_loss: 0.6605\n",
            "Epoch 49/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6914 - loss: 0.6404 - val_accuracy: 0.6910 - val_loss: 0.6611\n",
            "Epoch 50/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6935 - loss: 0.6418 - val_accuracy: 0.6887 - val_loss: 0.6591\n",
            "Epoch 51/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6965 - loss: 0.6261 - val_accuracy: 0.6863 - val_loss: 0.6593\n",
            "Epoch 52/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6708 - loss: 0.6489 - val_accuracy: 0.6769 - val_loss: 0.6575\n",
            "Epoch 53/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6839 - loss: 0.6356 - val_accuracy: 0.6769 - val_loss: 0.6583\n",
            "Epoch 54/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6950 - loss: 0.6373 - val_accuracy: 0.6863 - val_loss: 0.6575\n",
            "Epoch 55/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6817 - loss: 0.6377 - val_accuracy: 0.6769 - val_loss: 0.6593\n",
            "Epoch 56/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6735 - loss: 0.6492 - val_accuracy: 0.6745 - val_loss: 0.6571\n",
            "Epoch 57/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6794 - loss: 0.6472 - val_accuracy: 0.6722 - val_loss: 0.6575\n",
            "Epoch 58/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7066 - loss: 0.6291 - val_accuracy: 0.6816 - val_loss: 0.6573\n",
            "Epoch 59/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6973 - loss: 0.6327 - val_accuracy: 0.6769 - val_loss: 0.6594\n",
            "Epoch 60/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6852 - loss: 0.6328 - val_accuracy: 0.6816 - val_loss: 0.6582\n",
            "Epoch 61/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6987 - loss: 0.6298 - val_accuracy: 0.6792 - val_loss: 0.6573\n",
            "Epoch 62/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7099 - loss: 0.6239 - val_accuracy: 0.6769 - val_loss: 0.6560\n",
            "Epoch 63/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6910 - loss: 0.6316 - val_accuracy: 0.6745 - val_loss: 0.6573\n",
            "Epoch 64/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6906 - loss: 0.6211 - val_accuracy: 0.6792 - val_loss: 0.6554\n",
            "Epoch 65/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7073 - loss: 0.6335 - val_accuracy: 0.6769 - val_loss: 0.6548\n",
            "Epoch 66/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6812 - loss: 0.6443 - val_accuracy: 0.6745 - val_loss: 0.6559\n",
            "Epoch 67/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6980 - loss: 0.6233 - val_accuracy: 0.6698 - val_loss: 0.6538\n",
            "Epoch 68/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6978 - loss: 0.6219 - val_accuracy: 0.6675 - val_loss: 0.6519\n",
            "Epoch 69/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7018 - loss: 0.6169 - val_accuracy: 0.6675 - val_loss: 0.6569\n",
            "Epoch 70/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6935 - loss: 0.6282 - val_accuracy: 0.6769 - val_loss: 0.6546\n",
            "Epoch 71/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7058 - loss: 0.6123 - val_accuracy: 0.6816 - val_loss: 0.6560\n",
            "Epoch 72/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6967 - loss: 0.6265 - val_accuracy: 0.6840 - val_loss: 0.6545\n",
            "Epoch 73/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6822 - loss: 0.6378 - val_accuracy: 0.6816 - val_loss: 0.6541\n",
            "Epoch 74/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7104 - loss: 0.6249 - val_accuracy: 0.6863 - val_loss: 0.6537\n",
            "Epoch 75/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6793 - loss: 0.6295 - val_accuracy: 0.6769 - val_loss: 0.6533\n",
            "Epoch 76/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6788 - loss: 0.6385 - val_accuracy: 0.6840 - val_loss: 0.6522\n",
            "Epoch 77/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6825 - loss: 0.6214 - val_accuracy: 0.6698 - val_loss: 0.6548\n",
            "Epoch 78/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6939 - loss: 0.6215 - val_accuracy: 0.6698 - val_loss: 0.6532\n",
            "Epoch 79/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6895 - loss: 0.6346 - val_accuracy: 0.6698 - val_loss: 0.6553\n",
            "Epoch 80/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6769 - loss: 0.6294 - val_accuracy: 0.6722 - val_loss: 0.6541\n",
            "Epoch 81/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7097 - loss: 0.6169 - val_accuracy: 0.6651 - val_loss: 0.6531\n",
            "Epoch 82/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6915 - loss: 0.6342 - val_accuracy: 0.6675 - val_loss: 0.6542\n",
            "Epoch 83/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6731 - loss: 0.6389 - val_accuracy: 0.6675 - val_loss: 0.6527\n",
            "Epoch 84/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7022 - loss: 0.6154 - val_accuracy: 0.6604 - val_loss: 0.6534\n",
            "Epoch 85/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7022 - loss: 0.6096 - val_accuracy: 0.6533 - val_loss: 0.6551\n",
            "Epoch 86/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6931 - loss: 0.6191 - val_accuracy: 0.6627 - val_loss: 0.6527\n",
            "Epoch 87/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7052 - loss: 0.6139 - val_accuracy: 0.6675 - val_loss: 0.6488\n",
            "Epoch 88/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7079 - loss: 0.6043 - val_accuracy: 0.6675 - val_loss: 0.6523\n",
            "Epoch 89/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7055 - loss: 0.6153 - val_accuracy: 0.6604 - val_loss: 0.6556\n",
            "Epoch 90/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7162 - loss: 0.6088 - val_accuracy: 0.6769 - val_loss: 0.6534\n",
            "Epoch 91/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6936 - loss: 0.6191 - val_accuracy: 0.6816 - val_loss: 0.6484\n",
            "Epoch 92/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6988 - loss: 0.6007 - val_accuracy: 0.6769 - val_loss: 0.6508\n",
            "Epoch 93/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7076 - loss: 0.6076 - val_accuracy: 0.6816 - val_loss: 0.6476\n",
            "Epoch 94/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7071 - loss: 0.6143 - val_accuracy: 0.6651 - val_loss: 0.6514\n",
            "Epoch 95/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6895 - loss: 0.6217 - val_accuracy: 0.6604 - val_loss: 0.6540\n",
            "Epoch 96/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6969 - loss: 0.6077 - val_accuracy: 0.6698 - val_loss: 0.6508\n",
            "Epoch 97/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6978 - loss: 0.6263 - val_accuracy: 0.6627 - val_loss: 0.6523\n",
            "Epoch 98/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7108 - loss: 0.6047 - val_accuracy: 0.6698 - val_loss: 0.6510\n",
            "Epoch 99/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7231 - loss: 0.5867 - val_accuracy: 0.6627 - val_loss: 0.6506\n",
            "Epoch 100/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6995 - loss: 0.6201 - val_accuracy: 0.6745 - val_loss: 0.6511\n",
            "Epoch 101/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7123 - loss: 0.6170 - val_accuracy: 0.6840 - val_loss: 0.6496\n",
            "Epoch 102/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7088 - loss: 0.6111 - val_accuracy: 0.6887 - val_loss: 0.6516\n",
            "Epoch 103/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7097 - loss: 0.6088 - val_accuracy: 0.6792 - val_loss: 0.6519\n",
            "Epoch 104/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7130 - loss: 0.6058 - val_accuracy: 0.6769 - val_loss: 0.6545\n",
            "Epoch 105/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7197 - loss: 0.5891 - val_accuracy: 0.6698 - val_loss: 0.6499\n",
            "Epoch 106/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7057 - loss: 0.6020 - val_accuracy: 0.6722 - val_loss: 0.6519\n",
            "Epoch 107/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7141 - loss: 0.6099 - val_accuracy: 0.6486 - val_loss: 0.6525\n",
            "Epoch 108/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7062 - loss: 0.6038 - val_accuracy: 0.6698 - val_loss: 0.6546\n",
            "Epoch 109/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7281 - loss: 0.5984 - val_accuracy: 0.6557 - val_loss: 0.6477\n",
            "Epoch 110/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7302 - loss: 0.5967 - val_accuracy: 0.6675 - val_loss: 0.6480\n",
            "Epoch 111/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7080 - loss: 0.6072 - val_accuracy: 0.6745 - val_loss: 0.6479\n",
            "Epoch 112/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7107 - loss: 0.5928 - val_accuracy: 0.6651 - val_loss: 0.6472\n",
            "Epoch 113/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7113 - loss: 0.5979 - val_accuracy: 0.6792 - val_loss: 0.6495\n",
            "Epoch 114/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7158 - loss: 0.5966 - val_accuracy: 0.6745 - val_loss: 0.6502\n",
            "Epoch 115/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7286 - loss: 0.5853 - val_accuracy: 0.6698 - val_loss: 0.6481\n",
            "Epoch 116/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7112 - loss: 0.5980 - val_accuracy: 0.6651 - val_loss: 0.6461\n",
            "Epoch 117/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7296 - loss: 0.5917 - val_accuracy: 0.6627 - val_loss: 0.6480\n",
            "Epoch 118/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7043 - loss: 0.6127 - val_accuracy: 0.6698 - val_loss: 0.6501\n",
            "Epoch 119/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7412 - loss: 0.5903 - val_accuracy: 0.6698 - val_loss: 0.6464\n",
            "Epoch 120/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7014 - loss: 0.6017 - val_accuracy: 0.6604 - val_loss: 0.6495\n",
            "Epoch 121/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7061 - loss: 0.5977 - val_accuracy: 0.6745 - val_loss: 0.6464\n",
            "Epoch 122/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7150 - loss: 0.5973 - val_accuracy: 0.6698 - val_loss: 0.6478\n",
            "Epoch 123/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7217 - loss: 0.5933 - val_accuracy: 0.6698 - val_loss: 0.6482\n",
            "Epoch 124/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7260 - loss: 0.5908 - val_accuracy: 0.6675 - val_loss: 0.6435\n",
            "Epoch 125/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7121 - loss: 0.6055 - val_accuracy: 0.6698 - val_loss: 0.6444\n",
            "Epoch 126/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7205 - loss: 0.5879 - val_accuracy: 0.6627 - val_loss: 0.6486\n",
            "Epoch 127/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7194 - loss: 0.5896 - val_accuracy: 0.6722 - val_loss: 0.6486\n",
            "Epoch 128/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7334 - loss: 0.5949 - val_accuracy: 0.6675 - val_loss: 0.6501\n",
            "Epoch 129/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7107 - loss: 0.5930 - val_accuracy: 0.6627 - val_loss: 0.6524\n",
            "Epoch 130/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7189 - loss: 0.5951 - val_accuracy: 0.6698 - val_loss: 0.6554\n",
            "Epoch 131/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7305 - loss: 0.5867 - val_accuracy: 0.6533 - val_loss: 0.6516\n",
            "Epoch 132/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7170 - loss: 0.5936 - val_accuracy: 0.6698 - val_loss: 0.6518\n",
            "Epoch 133/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7044 - loss: 0.6057 - val_accuracy: 0.6675 - val_loss: 0.6529\n",
            "Epoch 134/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7306 - loss: 0.5806 - val_accuracy: 0.6745 - val_loss: 0.6474\n",
            "Epoch 135/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7285 - loss: 0.5934 - val_accuracy: 0.6769 - val_loss: 0.6464\n",
            "Epoch 136/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7274 - loss: 0.5973 - val_accuracy: 0.6722 - val_loss: 0.6478\n",
            "Epoch 137/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7124 - loss: 0.5915 - val_accuracy: 0.6651 - val_loss: 0.6472\n",
            "Epoch 138/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7093 - loss: 0.5961 - val_accuracy: 0.6651 - val_loss: 0.6495\n",
            "Epoch 139/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7276 - loss: 0.5921 - val_accuracy: 0.6651 - val_loss: 0.6460\n",
            "Epoch 140/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7420 - loss: 0.5730 - val_accuracy: 0.6557 - val_loss: 0.6484\n",
            "Epoch 141/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7164 - loss: 0.5903 - val_accuracy: 0.6533 - val_loss: 0.6475\n",
            "Epoch 142/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7220 - loss: 0.5797 - val_accuracy: 0.6580 - val_loss: 0.6482\n",
            "Epoch 143/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7351 - loss: 0.5660 - val_accuracy: 0.6580 - val_loss: 0.6507\n",
            "Epoch 144/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7289 - loss: 0.5703 - val_accuracy: 0.6580 - val_loss: 0.6460\n",
            "Epoch 145/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7129 - loss: 0.5909 - val_accuracy: 0.6769 - val_loss: 0.6455\n",
            "Epoch 146/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7170 - loss: 0.5889 - val_accuracy: 0.6627 - val_loss: 0.6495\n",
            "Epoch 147/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7243 - loss: 0.5822 - val_accuracy: 0.6651 - val_loss: 0.6540\n",
            "Epoch 148/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7139 - loss: 0.5871 - val_accuracy: 0.6722 - val_loss: 0.6478\n",
            "Epoch 149/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7218 - loss: 0.5835 - val_accuracy: 0.6557 - val_loss: 0.6463\n",
            "Epoch 150/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7389 - loss: 0.5668 - val_accuracy: 0.6722 - val_loss: 0.6465\n",
            "Epoch 151/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7509 - loss: 0.5559 - val_accuracy: 0.6675 - val_loss: 0.6477\n",
            "Epoch 152/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7321 - loss: 0.5631 - val_accuracy: 0.6627 - val_loss: 0.6456\n",
            "Epoch 153/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7383 - loss: 0.5709 - val_accuracy: 0.6698 - val_loss: 0.6478\n",
            "Epoch 154/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7300 - loss: 0.5759 - val_accuracy: 0.6745 - val_loss: 0.6510\n"
          ]
        }
      ],
      "source": [
        "# Model Definition by member 5\n",
        "def model_rene_ntabana():\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(128, input_shape=(X_train.shape[1],),\n",
        "        activation=\"relu\",\n",
        "        kernel_regularizer=tf.keras.regularizers.l1(0.0001),\n",
        "        name='dense_layer'))\n",
        "    model.add(tf.keras.layers.Dropout(0.4))  # Slightly less dropout\n",
        "    model.add(tf.keras.layers.Dense(64,\n",
        "        activation='relu',\n",
        "        kernel_regularizer=tf.keras.regularizers.l1(0.00005),\n",
        "        name='dense_layer2'))\n",
        "    model.add(tf.keras.layers.Dropout(0.4))\n",
        "    model.add(tf.keras.layers.Dense(32,\n",
        "        activation='relu',\n",
        "        kernel_regularizer=tf.keras.regularizers.l1(0.00005),\n",
        "        name='dense_layer3'))\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "    model.add(tf.keras.layers.Dense(1,\n",
        "        activation='sigmoid',\n",
        "        kernel_regularizer=tf.keras.regularizers.l1(0.00001),\n",
        "        name='output_layer'))\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "model = model_rene_ntabana()\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=30,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=200,\n",
        "    batch_size=32,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GGzrnYYRoMY",
        "outputId": "40742320-26c5-467c-9fea-dc8ec2125f48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Epoch: 124\n",
            "Train Accuracy at Best Epoch: 0.7178\n",
            "Val Accuracy at Best Epoch: 0.6675\n"
          ]
        }
      ],
      "source": [
        "best_epoch = np.argmin(history.history['val_loss'])\n",
        "print(f\"Best Epoch: {best_epoch+1}\")\n",
        "print(f\"Train Accuracy at Best Epoch: {history.history['accuracy'][best_epoch]:.4f}\")\n",
        "print(f\"Val Accuracy at Best Epoch: {history.history['val_accuracy'][best_epoch]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoU6FDapRoMY",
        "outputId": "1853ed74-7599-440e-b629-fe7c121152b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6939 - loss: 0.6297 \n",
            "Test Loss: 0.6403, Test Accuracy: 0.6800\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "BJCqU6C1RoMY",
        "outputId": "4782c932-dd2b-4cb5-a271-8e9a0593460a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7215    0.8022    0.7597       268\n",
            "           1     0.5827    0.4713    0.5211       157\n",
            "\n",
            "    accuracy                         0.6800       425\n",
            "   macro avg     0.6521    0.6368    0.6404       425\n",
            "weighted avg     0.6702    0.6800    0.6716       425\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Classification report and Confusion Matrix\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_probs = model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to binary class predictions (threshold = 0.5)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "# Classification report\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize confusion matrix\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Pred 0\", \"Pred 1\"], yticklabels=[\"True 0\", \"True 1\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDSPmAB9jkrG"
      },
      "source": [
        "# Start the training Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "OWQHapf3jlYH",
        "outputId": "ff09317e-ae97-4661-ac6d-602530c1db74"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'Y' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-fd04eeab69b9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Y' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "#fit model\n",
        "history = model.fit(X, Y, validation_data=(testX, testy), epochs=4000, verbose=0, callbacks=[es])\n",
        "# evaluate the model\n",
        "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
        "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
        "# plot training history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKZ2T8TOIYxL"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMNag3BGIuwZ"
      },
      "outputs": [],
      "source": [
        "#Data Loading and Preprocessing\n",
        "# The coach will never do this!!\n",
        "regularizer = 'l1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsmEC739I4lG"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(32, activation ='relu', kernel_regularizer= regularizer , input_shape = (2224,224)))\n",
        "model.add(Dropout(0.2))\n",
        "#adding Dropout\n",
        "model.add(Dense(64, activation ='relu', kernel_regularizer= regularizer , input_shape = (2224,224)))\n",
        "#adding Dropout\n",
        "model.add(Dense(128, activation ='relu', kernel_regularizer= regularizer , input_shape = (2224,224)))\n",
        "model.add(Dropout(0.2))\n",
        "#adding Dropout\n",
        "model.add(Dense(2, activation = 'sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbyPgkZlLu37"
      },
      "outputs": [],
      "source": [
        "callback =EarlyStopping(monitor='loss',patience=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fw9XQj_ZMWUs"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss= 'rmse', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPhb-1k7LGx8"
      },
      "outputs": [],
      "source": [
        "model.fit(X, Y, epochs=1000, batch_size= 128, callbacks=[callback], verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLlhrOCpJWF5"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
