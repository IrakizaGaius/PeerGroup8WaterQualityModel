{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrXv0rU9sIma"
      },
      "source": [
        "# Excercise - Creating our own custom Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJyZUDbzBTIG"
      },
      "source": [
        "This is a notebook that provides a quick overview of how to create your own custom model. You will be creating a simple model.\n",
        "You will be utilizing Keras and Tensorflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvLegMMvBZYg"
      },
      "source": [
        "## Water Quality Dataset\n",
        "\n",
        "This dataset contains water quality measurements and assessments related to potability, which is the suitability of water for human consumption. The dataset's primary objective is to provide insights into water quality parameters and assist in determining whether the water is potable or not. Each row in the dataset represents a water sample with specific attributes, and the \"Potability\" column indicates whether the water is suitable for consumption.\n",
        "\n",
        "https://www.kaggle.com/datasets/uom190346a/water-quality-and-potability?select=water_potability.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LOAD THE DATA\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"/content/water_potability.csv\")\n",
        "\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "\n",
        "data.head(20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "Qvnx0_dT3JEq",
        "outputId": "7fea3d5d-f91f-4ae5-d4f9-fad617791b12"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           ph    Hardness        Solids  Chloramines     Sulfate  \\\n",
              "0         NaN  204.890455  20791.318981     7.300212  368.516441   \n",
              "1    3.716080  129.422921  18630.057858     6.635246         NaN   \n",
              "2    8.099124  224.236259  19909.541732     9.275884         NaN   \n",
              "3    8.316766  214.373394  22018.417441     8.059332  356.886136   \n",
              "4    9.092223  181.101509  17978.986339     6.546600  310.135738   \n",
              "5    5.584087  188.313324  28748.687739     7.544869  326.678363   \n",
              "6   10.223862  248.071735  28749.716544     7.513408  393.663396   \n",
              "7    8.635849  203.361523  13672.091764     4.563009  303.309771   \n",
              "8         NaN  118.988579  14285.583854     7.804174  268.646941   \n",
              "9   11.180284  227.231469  25484.508491     9.077200  404.041635   \n",
              "10   7.360640  165.520797  32452.614409     7.550701  326.624353   \n",
              "11   7.974522  218.693300  18767.656682     8.110385         NaN   \n",
              "12   7.119824  156.704993  18730.813653     3.606036  282.344050   \n",
              "13        NaN  150.174923  27331.361962     6.838223  299.415781   \n",
              "14   7.496232  205.344982  28388.004887     5.072558         NaN   \n",
              "15   6.347272  186.732881  41065.234765     9.629596  364.487687   \n",
              "16   7.051786  211.049406  30980.600787    10.094796         NaN   \n",
              "17   9.181560  273.813807  24041.326280     6.904990  398.350517   \n",
              "18   8.975464  279.357167  19460.398131     6.204321         NaN   \n",
              "19   7.371050  214.496610  25630.320037     4.432669  335.754439   \n",
              "\n",
              "    Conductivity  Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
              "0     564.308654       10.379783        86.990970   2.963135           0  \n",
              "1     592.885359       15.180013        56.329076   4.500656           0  \n",
              "2     418.606213       16.868637        66.420093   3.055934           0  \n",
              "3     363.266516       18.436524       100.341674   4.628771           0  \n",
              "4     398.410813       11.558279        31.997993   4.075075           0  \n",
              "5     280.467916        8.399735        54.917862   2.559708           0  \n",
              "6     283.651634       13.789695        84.603556   2.672989           0  \n",
              "7     474.607645       12.363817        62.798309   4.401425           0  \n",
              "8     389.375566       12.706049        53.928846   3.595017           0  \n",
              "9     563.885481       17.927806        71.976601   4.370562           0  \n",
              "10    425.383419       15.586810        78.740016   3.662292           0  \n",
              "11    364.098230       14.525746        76.485911   4.011718           0  \n",
              "12    347.715027       15.929536        79.500778   3.445756           0  \n",
              "13    379.761835       19.370807        76.509996   4.413974           0  \n",
              "14    444.645352       13.228311        70.300213   4.777382           0  \n",
              "15    516.743282       11.539781        75.071617   4.376348           0  \n",
              "16    315.141267       20.397022        56.651604   4.268429           0  \n",
              "17    477.974642       13.387341        71.457362   4.503661           0  \n",
              "18    431.443990       12.888759        63.821237   2.436086           0  \n",
              "19    469.914551       12.509164        62.797277   2.560299           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f95ccaec-7dd3-46b4-baea-c2c51975d748\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>204.890455</td>\n",
              "      <td>20791.318981</td>\n",
              "      <td>7.300212</td>\n",
              "      <td>368.516441</td>\n",
              "      <td>564.308654</td>\n",
              "      <td>10.379783</td>\n",
              "      <td>86.990970</td>\n",
              "      <td>2.963135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.716080</td>\n",
              "      <td>129.422921</td>\n",
              "      <td>18630.057858</td>\n",
              "      <td>6.635246</td>\n",
              "      <td>NaN</td>\n",
              "      <td>592.885359</td>\n",
              "      <td>15.180013</td>\n",
              "      <td>56.329076</td>\n",
              "      <td>4.500656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.099124</td>\n",
              "      <td>224.236259</td>\n",
              "      <td>19909.541732</td>\n",
              "      <td>9.275884</td>\n",
              "      <td>NaN</td>\n",
              "      <td>418.606213</td>\n",
              "      <td>16.868637</td>\n",
              "      <td>66.420093</td>\n",
              "      <td>3.055934</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.316766</td>\n",
              "      <td>214.373394</td>\n",
              "      <td>22018.417441</td>\n",
              "      <td>8.059332</td>\n",
              "      <td>356.886136</td>\n",
              "      <td>363.266516</td>\n",
              "      <td>18.436524</td>\n",
              "      <td>100.341674</td>\n",
              "      <td>4.628771</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.092223</td>\n",
              "      <td>181.101509</td>\n",
              "      <td>17978.986339</td>\n",
              "      <td>6.546600</td>\n",
              "      <td>310.135738</td>\n",
              "      <td>398.410813</td>\n",
              "      <td>11.558279</td>\n",
              "      <td>31.997993</td>\n",
              "      <td>4.075075</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.584087</td>\n",
              "      <td>188.313324</td>\n",
              "      <td>28748.687739</td>\n",
              "      <td>7.544869</td>\n",
              "      <td>326.678363</td>\n",
              "      <td>280.467916</td>\n",
              "      <td>8.399735</td>\n",
              "      <td>54.917862</td>\n",
              "      <td>2.559708</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10.223862</td>\n",
              "      <td>248.071735</td>\n",
              "      <td>28749.716544</td>\n",
              "      <td>7.513408</td>\n",
              "      <td>393.663396</td>\n",
              "      <td>283.651634</td>\n",
              "      <td>13.789695</td>\n",
              "      <td>84.603556</td>\n",
              "      <td>2.672989</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8.635849</td>\n",
              "      <td>203.361523</td>\n",
              "      <td>13672.091764</td>\n",
              "      <td>4.563009</td>\n",
              "      <td>303.309771</td>\n",
              "      <td>474.607645</td>\n",
              "      <td>12.363817</td>\n",
              "      <td>62.798309</td>\n",
              "      <td>4.401425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NaN</td>\n",
              "      <td>118.988579</td>\n",
              "      <td>14285.583854</td>\n",
              "      <td>7.804174</td>\n",
              "      <td>268.646941</td>\n",
              "      <td>389.375566</td>\n",
              "      <td>12.706049</td>\n",
              "      <td>53.928846</td>\n",
              "      <td>3.595017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>11.180284</td>\n",
              "      <td>227.231469</td>\n",
              "      <td>25484.508491</td>\n",
              "      <td>9.077200</td>\n",
              "      <td>404.041635</td>\n",
              "      <td>563.885481</td>\n",
              "      <td>17.927806</td>\n",
              "      <td>71.976601</td>\n",
              "      <td>4.370562</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>7.360640</td>\n",
              "      <td>165.520797</td>\n",
              "      <td>32452.614409</td>\n",
              "      <td>7.550701</td>\n",
              "      <td>326.624353</td>\n",
              "      <td>425.383419</td>\n",
              "      <td>15.586810</td>\n",
              "      <td>78.740016</td>\n",
              "      <td>3.662292</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>7.974522</td>\n",
              "      <td>218.693300</td>\n",
              "      <td>18767.656682</td>\n",
              "      <td>8.110385</td>\n",
              "      <td>NaN</td>\n",
              "      <td>364.098230</td>\n",
              "      <td>14.525746</td>\n",
              "      <td>76.485911</td>\n",
              "      <td>4.011718</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>7.119824</td>\n",
              "      <td>156.704993</td>\n",
              "      <td>18730.813653</td>\n",
              "      <td>3.606036</td>\n",
              "      <td>282.344050</td>\n",
              "      <td>347.715027</td>\n",
              "      <td>15.929536</td>\n",
              "      <td>79.500778</td>\n",
              "      <td>3.445756</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>NaN</td>\n",
              "      <td>150.174923</td>\n",
              "      <td>27331.361962</td>\n",
              "      <td>6.838223</td>\n",
              "      <td>299.415781</td>\n",
              "      <td>379.761835</td>\n",
              "      <td>19.370807</td>\n",
              "      <td>76.509996</td>\n",
              "      <td>4.413974</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>7.496232</td>\n",
              "      <td>205.344982</td>\n",
              "      <td>28388.004887</td>\n",
              "      <td>5.072558</td>\n",
              "      <td>NaN</td>\n",
              "      <td>444.645352</td>\n",
              "      <td>13.228311</td>\n",
              "      <td>70.300213</td>\n",
              "      <td>4.777382</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>6.347272</td>\n",
              "      <td>186.732881</td>\n",
              "      <td>41065.234765</td>\n",
              "      <td>9.629596</td>\n",
              "      <td>364.487687</td>\n",
              "      <td>516.743282</td>\n",
              "      <td>11.539781</td>\n",
              "      <td>75.071617</td>\n",
              "      <td>4.376348</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>7.051786</td>\n",
              "      <td>211.049406</td>\n",
              "      <td>30980.600787</td>\n",
              "      <td>10.094796</td>\n",
              "      <td>NaN</td>\n",
              "      <td>315.141267</td>\n",
              "      <td>20.397022</td>\n",
              "      <td>56.651604</td>\n",
              "      <td>4.268429</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>9.181560</td>\n",
              "      <td>273.813807</td>\n",
              "      <td>24041.326280</td>\n",
              "      <td>6.904990</td>\n",
              "      <td>398.350517</td>\n",
              "      <td>477.974642</td>\n",
              "      <td>13.387341</td>\n",
              "      <td>71.457362</td>\n",
              "      <td>4.503661</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>8.975464</td>\n",
              "      <td>279.357167</td>\n",
              "      <td>19460.398131</td>\n",
              "      <td>6.204321</td>\n",
              "      <td>NaN</td>\n",
              "      <td>431.443990</td>\n",
              "      <td>12.888759</td>\n",
              "      <td>63.821237</td>\n",
              "      <td>2.436086</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>7.371050</td>\n",
              "      <td>214.496610</td>\n",
              "      <td>25630.320037</td>\n",
              "      <td>4.432669</td>\n",
              "      <td>335.754439</td>\n",
              "      <td>469.914551</td>\n",
              "      <td>12.509164</td>\n",
              "      <td>62.797277</td>\n",
              "      <td>2.560299</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f95ccaec-7dd3-46b4-baea-c2c51975d748')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f95ccaec-7dd3-46b4-baea-c2c51975d748 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f95ccaec-7dd3-46b4-baea-c2c51975d748');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2ec64655-0dcf-409b-b263-f290b06b70af\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2ec64655-0dcf-409b-b263-f290b06b70af')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2ec64655-0dcf-409b-b263-f290b06b70af button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 3276,\n  \"fields\": [\n    {\n      \"column\": \"ph\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5943195187088104,\n        \"min\": 0.0,\n        \"max\": 13.999999999999998,\n        \"num_unique_values\": 2785,\n        \"samples\": [\n          6.569053876389385,\n          9.271355446767778,\n          8.92790592593881\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hardness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32.879761476294156,\n        \"min\": 47.432,\n        \"max\": 323.124,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          183.5211070261417,\n          188.9135411469536,\n          224.05887682392927\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8768.570827785927,\n        \"min\": 320.942611274359,\n        \"max\": 61227.19600771213,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          20461.252710219946,\n          32873.820021715685,\n          23264.10996772913\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chloramines\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5830848890397096,\n        \"min\": 0.3520000000000003,\n        \"max\": 13.127000000000002,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          7.333212177578906,\n          6.791509363412849,\n          5.92236704115349\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sulfate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 41.416840461672706,\n        \"min\": 129.00000000000003,\n        \"max\": 481.0306423059972,\n        \"num_unique_values\": 2495,\n        \"samples\": [\n          324.64407957923544,\n          370.121384654358,\n          329.12773842254506\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conductivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80.8240640511118,\n        \"min\": 181.483753985146,\n        \"max\": 753.3426195583046,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          356.3690224100897,\n          336.56150104700754,\n          387.971335796834\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Organic_carbon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.308161999126874,\n        \"min\": 2.1999999999999886,\n        \"max\": 28.30000000000001,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          20.179028868493845,\n          14.706810313722087,\n          13.40673745495127\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Trihalomethanes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.175008422218657,\n        \"min\": 0.7379999999999995,\n        \"max\": 124.0,\n        \"num_unique_values\": 3114,\n        \"samples\": [\n          66.163439242252,\n          42.844510851301166,\n          47.06639219544294\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Turbidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7803824084854124,\n        \"min\": 1.45,\n        \"max\": 6.739,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          4.886633785371213,\n          4.562197671215202,\n          2.487968647002356\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Potability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Information on the data\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mn2ks1y4rG2i",
        "outputId": "21f80d64-3628-4ba3-e229-256f8364bb44"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3276 entries, 0 to 3275\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   ph               2785 non-null   float64\n",
            " 1   Hardness         3276 non-null   float64\n",
            " 2   Solids           3276 non-null   float64\n",
            " 3   Chloramines      3276 non-null   float64\n",
            " 4   Sulfate          2495 non-null   float64\n",
            " 5   Conductivity     3276 non-null   float64\n",
            " 6   Organic_carbon   3276 non-null   float64\n",
            " 7   Trihalomethanes  3114 non-null   float64\n",
            " 8   Turbidity        3276 non-null   float64\n",
            " 9   Potability       3276 non-null   int64  \n",
            "dtypes: float64(9), int64(1)\n",
            "memory usage: 256.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Brief overview of the dataset statistics\n",
        "data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "fJvnnIxav4N2",
        "outputId": "ea867eeb-1dc9-4f3a-c043-dfe616ee12b3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                ph     Hardness        Solids  Chloramines      Sulfate  \\\n",
              "count  2785.000000  3276.000000   3276.000000  3276.000000  2495.000000   \n",
              "mean      7.080795   196.369496  22014.092526     7.122277   333.775777   \n",
              "std       1.594320    32.879761   8768.570828     1.583085    41.416840   \n",
              "min       0.000000    47.432000    320.942611     0.352000   129.000000   \n",
              "25%       6.093092   176.850538  15666.690297     6.127421   307.699498   \n",
              "50%       7.036752   196.967627  20927.833607     7.130299   333.073546   \n",
              "75%       8.062066   216.667456  27332.762127     8.114887   359.950170   \n",
              "max      14.000000   323.124000  61227.196008    13.127000   481.030642   \n",
              "\n",
              "       Conductivity  Organic_carbon  Trihalomethanes    Turbidity   Potability  \n",
              "count   3276.000000     3276.000000      3114.000000  3276.000000  3276.000000  \n",
              "mean     426.205111       14.284970        66.396293     3.966786     0.390110  \n",
              "std       80.824064        3.308162        16.175008     0.780382     0.487849  \n",
              "min      181.483754        2.200000         0.738000     1.450000     0.000000  \n",
              "25%      365.734414       12.065801        55.844536     3.439711     0.000000  \n",
              "50%      421.884968       14.218338        66.622485     3.955028     0.000000  \n",
              "75%      481.792304       16.557652        77.337473     4.500320     1.000000  \n",
              "max      753.342620       28.300000       124.000000     6.739000     1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cdc89594-557e-49a3-acef-6d080f3391d2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2785.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>2495.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3114.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.080795</td>\n",
              "      <td>196.369496</td>\n",
              "      <td>22014.092526</td>\n",
              "      <td>7.122277</td>\n",
              "      <td>333.775777</td>\n",
              "      <td>426.205111</td>\n",
              "      <td>14.284970</td>\n",
              "      <td>66.396293</td>\n",
              "      <td>3.966786</td>\n",
              "      <td>0.390110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.594320</td>\n",
              "      <td>32.879761</td>\n",
              "      <td>8768.570828</td>\n",
              "      <td>1.583085</td>\n",
              "      <td>41.416840</td>\n",
              "      <td>80.824064</td>\n",
              "      <td>3.308162</td>\n",
              "      <td>16.175008</td>\n",
              "      <td>0.780382</td>\n",
              "      <td>0.487849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>47.432000</td>\n",
              "      <td>320.942611</td>\n",
              "      <td>0.352000</td>\n",
              "      <td>129.000000</td>\n",
              "      <td>181.483754</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>0.738000</td>\n",
              "      <td>1.450000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6.093092</td>\n",
              "      <td>176.850538</td>\n",
              "      <td>15666.690297</td>\n",
              "      <td>6.127421</td>\n",
              "      <td>307.699498</td>\n",
              "      <td>365.734414</td>\n",
              "      <td>12.065801</td>\n",
              "      <td>55.844536</td>\n",
              "      <td>3.439711</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7.036752</td>\n",
              "      <td>196.967627</td>\n",
              "      <td>20927.833607</td>\n",
              "      <td>7.130299</td>\n",
              "      <td>333.073546</td>\n",
              "      <td>421.884968</td>\n",
              "      <td>14.218338</td>\n",
              "      <td>66.622485</td>\n",
              "      <td>3.955028</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.062066</td>\n",
              "      <td>216.667456</td>\n",
              "      <td>27332.762127</td>\n",
              "      <td>8.114887</td>\n",
              "      <td>359.950170</td>\n",
              "      <td>481.792304</td>\n",
              "      <td>16.557652</td>\n",
              "      <td>77.337473</td>\n",
              "      <td>4.500320</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>14.000000</td>\n",
              "      <td>323.124000</td>\n",
              "      <td>61227.196008</td>\n",
              "      <td>13.127000</td>\n",
              "      <td>481.030642</td>\n",
              "      <td>753.342620</td>\n",
              "      <td>28.300000</td>\n",
              "      <td>124.000000</td>\n",
              "      <td>6.739000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdc89594-557e-49a3-acef-6d080f3391d2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cdc89594-557e-49a3-acef-6d080f3391d2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cdc89594-557e-49a3-acef-6d080f3391d2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e1059738-b240-4928-874e-8f0d4fc89a41\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e1059738-b240-4928-874e-8f0d4fc89a41')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e1059738-b240-4928-874e-8f0d4fc89a41 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"ph\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 982.4396919342113,\n        \"min\": 0.0,\n        \"max\": 2785.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          7.080794504276835,\n          7.036752103833548,\n          2785.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hardness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1102.077573149784,\n        \"min\": 32.879761476294156,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          196.36949601730151,\n          196.96762686363076,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19161.797748474182,\n        \"min\": 320.942611274359,\n        \"max\": 61227.19600771213,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          22014.092526077104,\n          20927.833606520187,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chloramines\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1156.047676013562,\n        \"min\": 0.3520000000000003,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          7.122276793425786,\n          7.130298973883081,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sulfate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 793.8602821876343,\n        \"min\": 41.416840461672706,\n        \"max\": 2495.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          333.7757766108135,\n          333.073545745888,\n          2495.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conductivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1040.8631085884185,\n        \"min\": 80.8240640511118,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          426.20511068255325,\n          421.8849682800544,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Organic_carbon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1153.6765632294614,\n        \"min\": 2.1999999999999886,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          14.284970247677318,\n          14.218337937208588,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Trihalomethanes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1081.0577228535572,\n        \"min\": 0.7379999999999995,\n        \"max\": 3114.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          66.39629294676803,\n          66.62248509808484,\n          3114.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Turbidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1156.9881922638972,\n        \"min\": 0.7803824084854124,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3.966786169791058,\n          3.955027562993039,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Potability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1158.0956231418108,\n        \"min\": 0.0,\n        \"max\": 3276.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3901098901098901,\n          1.0,\n          0.48784916967025516\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop duplicates rows of data\n",
        "\n",
        "data = data.drop_duplicates()"
      ],
      "metadata": {
        "id": "f5Rjjxwg5XnF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# percentage of missingness in the data for each column\n",
        "\n",
        "missing = data.isnull().mean()*100\n",
        "print(missing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjFnkhc35ekL",
        "outputId": "93e360fb-9ca5-431b-95f5-eee8adec0135"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ph                 14.987790\n",
            "Hardness            0.000000\n",
            "Solids              0.000000\n",
            "Chloramines         0.000000\n",
            "Sulfate            23.840049\n",
            "Conductivity        0.000000\n",
            "Organic_carbon      0.000000\n",
            "Trihalomethanes     4.945055\n",
            "Turbidity           0.000000\n",
            "Potability          0.000000\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MICE IMPUTATION to fill the missing data\n",
        "# create the imputer using MICE\n",
        "\n",
        "# separate the target variable from the rest of the data to make sure it is not changed or imputed\n",
        "features = data.drop(columns='Potability')\n",
        "target = data.Potability\n",
        "imputer = IterativeImputer(random_state=0)\n",
        "features_imputed = imputer.fit_transform(features)\n",
        "\n",
        "# convert the data back into a dataframe\n",
        "features_imputed = pd.DataFrame(features_imputed, columns=features.columns)\n",
        "\n",
        "# merge target variable and data\n",
        "data_imputed = pd.concat([features_imputed, target], axis=1)\n",
        "data_imputed.head(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "RlhnFruS2q0X",
        "outputId": "684017f5-dcd8-4ba4-b573-c5de394468fa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
              "0   7.190863  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
              "1   3.716080  129.422921  18630.057858     6.635246  344.836463    592.885359   \n",
              "2   8.099124  224.236259  19909.541732     9.275884  331.981769    418.606213   \n",
              "3   8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
              "4   9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
              "5   5.584087  188.313324  28748.687739     7.544869  326.678363    280.467916   \n",
              "6  10.223862  248.071735  28749.716544     7.513408  393.663396    283.651634   \n",
              "7   8.635849  203.361523  13672.091764     4.563009  303.309771    474.607645   \n",
              "8   6.927779  118.988579  14285.583854     7.804174  268.646941    389.375566   \n",
              "9  11.180284  227.231469  25484.508491     9.077200  404.041635    563.885481   \n",
              "\n",
              "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
              "0       10.379783        86.990970   2.963135           0  \n",
              "1       15.180013        56.329076   4.500656           0  \n",
              "2       16.868637        66.420093   3.055934           0  \n",
              "3       18.436524       100.341674   4.628771           0  \n",
              "4       11.558279        31.997993   4.075075           0  \n",
              "5        8.399735        54.917862   2.559708           0  \n",
              "6       13.789695        84.603556   2.672989           0  \n",
              "7       12.363817        62.798309   4.401425           0  \n",
              "8       12.706049        53.928846   3.595017           0  \n",
              "9       17.927806        71.976601   4.370562           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8dd466d1-7781-4d9f-9c10-ce8e9e2db04e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.190863</td>\n",
              "      <td>204.890455</td>\n",
              "      <td>20791.318981</td>\n",
              "      <td>7.300212</td>\n",
              "      <td>368.516441</td>\n",
              "      <td>564.308654</td>\n",
              "      <td>10.379783</td>\n",
              "      <td>86.990970</td>\n",
              "      <td>2.963135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.716080</td>\n",
              "      <td>129.422921</td>\n",
              "      <td>18630.057858</td>\n",
              "      <td>6.635246</td>\n",
              "      <td>344.836463</td>\n",
              "      <td>592.885359</td>\n",
              "      <td>15.180013</td>\n",
              "      <td>56.329076</td>\n",
              "      <td>4.500656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.099124</td>\n",
              "      <td>224.236259</td>\n",
              "      <td>19909.541732</td>\n",
              "      <td>9.275884</td>\n",
              "      <td>331.981769</td>\n",
              "      <td>418.606213</td>\n",
              "      <td>16.868637</td>\n",
              "      <td>66.420093</td>\n",
              "      <td>3.055934</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.316766</td>\n",
              "      <td>214.373394</td>\n",
              "      <td>22018.417441</td>\n",
              "      <td>8.059332</td>\n",
              "      <td>356.886136</td>\n",
              "      <td>363.266516</td>\n",
              "      <td>18.436524</td>\n",
              "      <td>100.341674</td>\n",
              "      <td>4.628771</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.092223</td>\n",
              "      <td>181.101509</td>\n",
              "      <td>17978.986339</td>\n",
              "      <td>6.546600</td>\n",
              "      <td>310.135738</td>\n",
              "      <td>398.410813</td>\n",
              "      <td>11.558279</td>\n",
              "      <td>31.997993</td>\n",
              "      <td>4.075075</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.584087</td>\n",
              "      <td>188.313324</td>\n",
              "      <td>28748.687739</td>\n",
              "      <td>7.544869</td>\n",
              "      <td>326.678363</td>\n",
              "      <td>280.467916</td>\n",
              "      <td>8.399735</td>\n",
              "      <td>54.917862</td>\n",
              "      <td>2.559708</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10.223862</td>\n",
              "      <td>248.071735</td>\n",
              "      <td>28749.716544</td>\n",
              "      <td>7.513408</td>\n",
              "      <td>393.663396</td>\n",
              "      <td>283.651634</td>\n",
              "      <td>13.789695</td>\n",
              "      <td>84.603556</td>\n",
              "      <td>2.672989</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8.635849</td>\n",
              "      <td>203.361523</td>\n",
              "      <td>13672.091764</td>\n",
              "      <td>4.563009</td>\n",
              "      <td>303.309771</td>\n",
              "      <td>474.607645</td>\n",
              "      <td>12.363817</td>\n",
              "      <td>62.798309</td>\n",
              "      <td>4.401425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6.927779</td>\n",
              "      <td>118.988579</td>\n",
              "      <td>14285.583854</td>\n",
              "      <td>7.804174</td>\n",
              "      <td>268.646941</td>\n",
              "      <td>389.375566</td>\n",
              "      <td>12.706049</td>\n",
              "      <td>53.928846</td>\n",
              "      <td>3.595017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>11.180284</td>\n",
              "      <td>227.231469</td>\n",
              "      <td>25484.508491</td>\n",
              "      <td>9.077200</td>\n",
              "      <td>404.041635</td>\n",
              "      <td>563.885481</td>\n",
              "      <td>17.927806</td>\n",
              "      <td>71.976601</td>\n",
              "      <td>4.370562</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8dd466d1-7781-4d9f-9c10-ce8e9e2db04e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8dd466d1-7781-4d9f-9c10-ce8e9e2db04e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8dd466d1-7781-4d9f-9c10-ce8e9e2db04e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-706ee7e0-06fd-4250-87df-1f786cdf669d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-706ee7e0-06fd-4250-87df-1f786cdf669d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-706ee7e0-06fd-4250-87df-1f786cdf669d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_imputed",
              "summary": "{\n  \"name\": \"data_imputed\",\n  \"rows\": 3276,\n  \"fields\": [\n    {\n      \"column\": \"ph\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.471574062911746,\n        \"min\": 0.0,\n        \"max\": 13.999999999999998,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          7.042483377815478,\n          6.643158712135614,\n          7.846057926337261\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hardness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32.879761476294156,\n        \"min\": 47.432,\n        \"max\": 323.124,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          183.5211070261417,\n          188.9135411469536,\n          224.05887682392927\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8768.570827785927,\n        \"min\": 320.942611274359,\n        \"max\": 61227.19600771213,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          20461.252710219946,\n          32873.820021715685,\n          23264.10996772913\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chloramines\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5830848890397096,\n        \"min\": 0.3520000000000003,\n        \"max\": 13.127000000000002,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          7.333212177578906,\n          6.791509363412849,\n          5.92236704115349\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sulfate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36.3878388853383,\n        \"min\": 129.00000000000003,\n        \"max\": 481.0306423059972,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          333.1194758732444,\n          333.8488418801131,\n          300.40262012672275\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conductivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80.8240640511118,\n        \"min\": 181.483753985146,\n        \"max\": 753.3426195583046,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          356.3690224100897,\n          336.56150104700754,\n          387.971335796834\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Organic_carbon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.308161999126874,\n        \"min\": 2.1999999999999886,\n        \"max\": 28.30000000000001,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          20.179028868493845,\n          14.706810313722087,\n          13.40673745495127\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Trihalomethanes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.769921510590818,\n        \"min\": 0.7379999999999995,\n        \"max\": 124.0,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          67.01990322225635,\n          67.84484886059036,\n          43.07518646611747\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Turbidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7803824084854124,\n        \"min\": 1.45,\n        \"max\": 6.739,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          4.886633785371213,\n          4.562197671215202,\n          2.487968647002356\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Potability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# confirm imputed data\n",
        "data_imputed.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58zqnGV23ZSx",
        "outputId": "c5d2e1ab-2e53-4883-bb9a-b6c2482eb2a4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3276 entries, 0 to 3275\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   ph               3276 non-null   float64\n",
            " 1   Hardness         3276 non-null   float64\n",
            " 2   Solids           3276 non-null   float64\n",
            " 3   Chloramines      3276 non-null   float64\n",
            " 4   Sulfate          3276 non-null   float64\n",
            " 5   Conductivity     3276 non-null   float64\n",
            " 6   Organic_carbon   3276 non-null   float64\n",
            " 7   Trihalomethanes  3276 non-null   float64\n",
            " 8   Turbidity        3276 non-null   float64\n",
            " 9   Potability       3276 non-null   int64  \n",
            "dtypes: float64(9), int64(1)\n",
            "memory usage: 256.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove outliers that may affect the neural network's accuracy using IQR method\n",
        "def remove_outliers_iqr(df, column_name):\n",
        "    Q1 = df[column_name].quantile(0.25)\n",
        "    Q3 = df[column_name].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    # anything above or below this is an outlier\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # place outliers in a data frame\n",
        "    print(f\"{df[column_name]}\")\n",
        "    outliers = df[(df[column_name] < lower_bound) | (df[column_name] > upper_bound)]\n",
        "    print(f\"Number of outliers: {len(outliers)}\")\n",
        "    print(f\"Percentage of outliers: {len(outliers)/len(df)*100:.2f}%\")\n",
        "\n",
        "\n",
        "    # remove outliers\n",
        "\n",
        "    df_clean = df[(df[column_name] >= lower_bound) & (df[column_name] <= upper_bound)]\n",
        "\n",
        "\n",
        "\n",
        "    return df_clean\n",
        "\n",
        "# columns to remove outliers in\n",
        "columns = ['Hardness', 'Solids', 'Sulfate', 'Conductivity', 'Organic_carbon', 'Trihalomethanes', 'Turbidity']\n",
        "\n",
        "data_imputed_copy = data_imputed.copy()\n",
        "\n",
        "for i in columns:\n",
        "  data_imputed_copy = remove_outliers_iqr(data_imputed_copy, i)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIdMxexk47Qa",
        "outputId": "b577a74e-f58d-4729-9fed-d52365e60524"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       204.890455\n",
            "1       129.422921\n",
            "2       224.236259\n",
            "3       214.373394\n",
            "4       181.101509\n",
            "           ...    \n",
            "3271    193.681735\n",
            "3272    193.553212\n",
            "3273    175.762646\n",
            "3274    230.603758\n",
            "3275    195.102299\n",
            "Name: Hardness, Length: 3276, dtype: float64\n",
            "Number of outliers: 83\n",
            "Percentage of outliers: 2.53%\n",
            "0       20791.318981\n",
            "1       18630.057858\n",
            "2       19909.541732\n",
            "3       22018.417441\n",
            "4       17978.986339\n",
            "            ...     \n",
            "3271    47580.991603\n",
            "3272    17329.802160\n",
            "3273    33155.578218\n",
            "3274    11983.869376\n",
            "3275    17404.177061\n",
            "Name: Solids, Length: 3193, dtype: float64\n",
            "Number of outliers: 42\n",
            "Percentage of outliers: 1.32%\n",
            "0       368.516441\n",
            "1       344.836463\n",
            "2       331.981769\n",
            "3       356.886136\n",
            "4       310.135738\n",
            "           ...    \n",
            "3270    345.700257\n",
            "3272    338.612062\n",
            "3273    326.848982\n",
            "3274    336.993878\n",
            "3275    338.025733\n",
            "Name: Sulfate, Length: 3151, dtype: float64\n",
            "Number of outliers: 230\n",
            "Percentage of outliers: 7.30%\n",
            "0       564.308654\n",
            "1       592.885359\n",
            "2       418.606213\n",
            "3       363.266516\n",
            "4       398.410813\n",
            "           ...    \n",
            "3270    415.886955\n",
            "3272    392.449580\n",
            "3273    432.044783\n",
            "3274    402.883113\n",
            "3275    327.459760\n",
            "Name: Conductivity, Length: 2921, dtype: float64\n",
            "Number of outliers: 9\n",
            "Percentage of outliers: 0.31%\n",
            "0       10.379783\n",
            "1       15.180013\n",
            "2       16.868637\n",
            "3       18.436524\n",
            "4       11.558279\n",
            "          ...    \n",
            "3270    12.067620\n",
            "3272    19.903225\n",
            "3273    11.039070\n",
            "3274    11.168946\n",
            "3275    16.140368\n",
            "Name: Organic_carbon, Length: 2912, dtype: float64\n",
            "Number of outliers: 18\n",
            "Percentage of outliers: 0.62%\n",
            "0        86.990970\n",
            "1        56.329076\n",
            "2        66.420093\n",
            "3       100.341674\n",
            "4        31.997993\n",
            "           ...    \n",
            "3270     60.419921\n",
            "3272     66.474992\n",
            "3273     69.845400\n",
            "3274     77.488213\n",
            "3275     78.698446\n",
            "Name: Trihalomethanes, Length: 2894, dtype: float64\n",
            "Number of outliers: 47\n",
            "Percentage of outliers: 1.62%\n",
            "0       2.963135\n",
            "1       4.500656\n",
            "2       3.055934\n",
            "3       4.628771\n",
            "4       4.075075\n",
            "          ...   \n",
            "3270    3.669712\n",
            "3272    2.798243\n",
            "3273    3.298875\n",
            "3274    4.708658\n",
            "3275    2.309149\n",
            "Name: Turbidity, Length: 2847, dtype: float64\n",
            "Number of outliers: 17\n",
            "Percentage of outliers: 0.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the Data Appropriately"
      ],
      "metadata": {
        "id": "2QfR0r8cGVU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# generate 2d classification dataset\n",
        "\n",
        "# X, y = pass\n",
        "\n",
        "# Transforms data to have mean=0 and standard deviation=1\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X = data_imputed_copy.drop(columns='Potability', axis=1)\n",
        "y= data_imputed_copy['Potability']\n",
        "\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# from sklearn.decomposition import PCA\n",
        "# pca = PCA(n_components=2)\n",
        "# X_2d_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "X_scaled.shape\n"
      ],
      "metadata": {
        "id": "PF9lHguSY2vB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4936a724-ced3-4285-cea4-9c3ad050cd0e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2830, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the data into training validation and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3,random_state=42,\n",
        "    stratify=y               # Keep same class distribution in all splits\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5,stratify=y_temp)\n",
        "\n",
        "print(f\"\\n=== FINAL SHAPES ===\")\n",
        "print(f\"X_train: {X_train.shape}\")\n",
        "print(f\"X_val: {X_val.shape}\")\n",
        "print(f\"X_test: {X_test.shape}\")\n",
        "print(f\"y_train: {y_train.shape}\")\n",
        "print(f\"y_val: {y_val.shape}\")\n",
        "print(f\"y_test: {y_test.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "wfSk1lXRYjrh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2178b0a-5d60-4249-a72d-4032b5634678"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== FINAL SHAPES ===\n",
            "X_train: (1981, 9)\n",
            "X_val: (424, 9)\n",
            "X_test: (425, 9)\n",
            "y_train: (1981,)\n",
            "y_val: (424,)\n",
            "y_test: (425,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Each Member Defines their model Here"
      ],
      "metadata": {
        "id": "LvjIHLrcGhzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Definition by member 1\n",
        "def model_jeremiah_agbaje():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(128, input_shape=(X_train.shape[1],), name='dense_layer', activation=\"relu\",kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))  # 50% dropout after first layer\n",
        "  model.add(tf.keras.layers.Dense(64, name='dense_layer2', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))  # 50% dropout after second layer\n",
        "  model.add(tf.keras.layers.Dense(32, name='dense_layer3', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))\n",
        "  model.add(tf.keras.layers.Dense(1, name='output_layer', activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.00001)))\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "model = model_jeremiah_agbaje()\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "      monitor='val_loss',    # Monitor validation loss\n",
        "      patience=50,\n",
        "      restore_best_weights=True  # Restore weights from best epoch\n",
        "  )\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "  X_train, y_train,\n",
        "  validation_data=(X_val, y_val),\n",
        "  epochs=200,\n",
        "  batch_size=32,\n",
        "  verbose=1,\n",
        "  callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "FLwYoJG9jvDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "547927f8-3bf4-41e0-b8e3-7bc86644936e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4477 - loss: 0.7605 - val_accuracy: 0.5495 - val_loss: 0.6945\n",
            "Epoch 2/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4951 - loss: 0.7409 - val_accuracy: 0.6038 - val_loss: 0.6819\n",
            "Epoch 3/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5294 - loss: 0.7122 - val_accuracy: 0.6156 - val_loss: 0.6742\n",
            "Epoch 4/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5048 - loss: 0.7281 - val_accuracy: 0.6274 - val_loss: 0.6715\n",
            "Epoch 5/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5314 - loss: 0.7119 - val_accuracy: 0.6297 - val_loss: 0.6692\n",
            "Epoch 6/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5651 - loss: 0.6875 - val_accuracy: 0.6297 - val_loss: 0.6668\n",
            "Epoch 7/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5863 - loss: 0.6734 - val_accuracy: 0.6297 - val_loss: 0.6654\n",
            "Epoch 8/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5852 - loss: 0.6951 - val_accuracy: 0.6297 - val_loss: 0.6655\n",
            "Epoch 9/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5713 - loss: 0.6982 - val_accuracy: 0.6297 - val_loss: 0.6647\n",
            "Epoch 10/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5783 - loss: 0.6996 - val_accuracy: 0.6297 - val_loss: 0.6643\n",
            "Epoch 11/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5977 - loss: 0.6768 - val_accuracy: 0.6297 - val_loss: 0.6634\n",
            "Epoch 12/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5897 - loss: 0.6890 - val_accuracy: 0.6297 - val_loss: 0.6633\n",
            "Epoch 13/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6238 - loss: 0.6732 - val_accuracy: 0.6297 - val_loss: 0.6633\n",
            "Epoch 14/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6123 - loss: 0.6728 - val_accuracy: 0.6297 - val_loss: 0.6634\n",
            "Epoch 15/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6026 - loss: 0.6736 - val_accuracy: 0.6297 - val_loss: 0.6636\n",
            "Epoch 16/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6111 - loss: 0.6792 - val_accuracy: 0.6297 - val_loss: 0.6636\n",
            "Epoch 17/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5846 - loss: 0.6813 - val_accuracy: 0.6297 - val_loss: 0.6630\n",
            "Epoch 18/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6095 - loss: 0.6785 - val_accuracy: 0.6297 - val_loss: 0.6628\n",
            "Epoch 19/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5832 - loss: 0.6881 - val_accuracy: 0.6297 - val_loss: 0.6631\n",
            "Epoch 20/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6337 - loss: 0.6724 - val_accuracy: 0.6297 - val_loss: 0.6630\n",
            "Epoch 21/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6026 - loss: 0.6755 - val_accuracy: 0.6297 - val_loss: 0.6632\n",
            "Epoch 22/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5818 - loss: 0.6892 - val_accuracy: 0.6297 - val_loss: 0.6634\n",
            "Epoch 23/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6031 - loss: 0.6771 - val_accuracy: 0.6297 - val_loss: 0.6634\n",
            "Epoch 24/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6263 - loss: 0.6691 - val_accuracy: 0.6297 - val_loss: 0.6631\n",
            "Epoch 25/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6349 - loss: 0.6664 - val_accuracy: 0.6297 - val_loss: 0.6628\n",
            "Epoch 26/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6192 - loss: 0.6661 - val_accuracy: 0.6297 - val_loss: 0.6628\n",
            "Epoch 27/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6325 - loss: 0.6635 - val_accuracy: 0.6297 - val_loss: 0.6624\n",
            "Epoch 28/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6149 - loss: 0.6669 - val_accuracy: 0.6297 - val_loss: 0.6620\n",
            "Epoch 29/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6100 - loss: 0.6753 - val_accuracy: 0.6297 - val_loss: 0.6620\n",
            "Epoch 30/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6109 - loss: 0.6774 - val_accuracy: 0.6297 - val_loss: 0.6617\n",
            "Epoch 31/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6226 - loss: 0.6614 - val_accuracy: 0.6297 - val_loss: 0.6611\n",
            "Epoch 32/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6112 - loss: 0.6731 - val_accuracy: 0.6297 - val_loss: 0.6607\n",
            "Epoch 33/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6300 - loss: 0.6606 - val_accuracy: 0.6297 - val_loss: 0.6603\n",
            "Epoch 34/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6229 - loss: 0.6672 - val_accuracy: 0.6297 - val_loss: 0.6607\n",
            "Epoch 35/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6167 - loss: 0.6649 - val_accuracy: 0.6297 - val_loss: 0.6604\n",
            "Epoch 36/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6196 - loss: 0.6650 - val_accuracy: 0.6297 - val_loss: 0.6601\n",
            "Epoch 37/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6378 - loss: 0.6523 - val_accuracy: 0.6297 - val_loss: 0.6596\n",
            "Epoch 38/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6200 - loss: 0.6665 - val_accuracy: 0.6297 - val_loss: 0.6592\n",
            "Epoch 39/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6231 - loss: 0.6690 - val_accuracy: 0.6297 - val_loss: 0.6592\n",
            "Epoch 40/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6178 - loss: 0.6663 - val_accuracy: 0.6297 - val_loss: 0.6590\n",
            "Epoch 41/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6284 - loss: 0.6641 - val_accuracy: 0.6297 - val_loss: 0.6589\n",
            "Epoch 42/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6517 - loss: 0.6522 - val_accuracy: 0.6297 - val_loss: 0.6584\n",
            "Epoch 43/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6532 - loss: 0.6483 - val_accuracy: 0.6297 - val_loss: 0.6578\n",
            "Epoch 44/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6282 - loss: 0.6588 - val_accuracy: 0.6297 - val_loss: 0.6573\n",
            "Epoch 45/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6303 - loss: 0.6657 - val_accuracy: 0.6297 - val_loss: 0.6575\n",
            "Epoch 46/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6160 - loss: 0.6673 - val_accuracy: 0.6297 - val_loss: 0.6572\n",
            "Epoch 47/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6340 - loss: 0.6522 - val_accuracy: 0.6297 - val_loss: 0.6565\n",
            "Epoch 48/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6302 - loss: 0.6549 - val_accuracy: 0.6297 - val_loss: 0.6562\n",
            "Epoch 49/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6223 - loss: 0.6688 - val_accuracy: 0.6297 - val_loss: 0.6562\n",
            "Epoch 50/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6304 - loss: 0.6601 - val_accuracy: 0.6297 - val_loss: 0.6564\n",
            "Epoch 51/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6375 - loss: 0.6572 - val_accuracy: 0.6297 - val_loss: 0.6560\n",
            "Epoch 52/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6369 - loss: 0.6584 - val_accuracy: 0.6297 - val_loss: 0.6559\n",
            "Epoch 53/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6252 - loss: 0.6620 - val_accuracy: 0.6297 - val_loss: 0.6554\n",
            "Epoch 54/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6312 - loss: 0.6523 - val_accuracy: 0.6297 - val_loss: 0.6548\n",
            "Epoch 55/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6338 - loss: 0.6528 - val_accuracy: 0.6297 - val_loss: 0.6544\n",
            "Epoch 56/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6215 - loss: 0.6572 - val_accuracy: 0.6297 - val_loss: 0.6541\n",
            "Epoch 57/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6441 - loss: 0.6477 - val_accuracy: 0.6297 - val_loss: 0.6535\n",
            "Epoch 58/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6221 - loss: 0.6632 - val_accuracy: 0.6297 - val_loss: 0.6536\n",
            "Epoch 59/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6335 - loss: 0.6592 - val_accuracy: 0.6297 - val_loss: 0.6536\n",
            "Epoch 60/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6322 - loss: 0.6656 - val_accuracy: 0.6297 - val_loss: 0.6537\n",
            "Epoch 61/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6494 - loss: 0.6458 - val_accuracy: 0.6297 - val_loss: 0.6534\n",
            "Epoch 62/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6306 - loss: 0.6609 - val_accuracy: 0.6297 - val_loss: 0.6532\n",
            "Epoch 63/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6379 - loss: 0.6527 - val_accuracy: 0.6297 - val_loss: 0.6530\n",
            "Epoch 64/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6246 - loss: 0.6565 - val_accuracy: 0.6297 - val_loss: 0.6528\n",
            "Epoch 65/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6364 - loss: 0.6436 - val_accuracy: 0.6297 - val_loss: 0.6521\n",
            "Epoch 66/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6312 - loss: 0.6463 - val_accuracy: 0.6297 - val_loss: 0.6521\n",
            "Epoch 67/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6275 - loss: 0.6571 - val_accuracy: 0.6297 - val_loss: 0.6524\n",
            "Epoch 68/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6563 - loss: 0.6412 - val_accuracy: 0.6297 - val_loss: 0.6517\n",
            "Epoch 69/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6338 - loss: 0.6589 - val_accuracy: 0.6297 - val_loss: 0.6518\n",
            "Epoch 70/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6283 - loss: 0.6585 - val_accuracy: 0.6297 - val_loss: 0.6514\n",
            "Epoch 71/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6274 - loss: 0.6615 - val_accuracy: 0.6297 - val_loss: 0.6510\n",
            "Epoch 72/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6338 - loss: 0.6484 - val_accuracy: 0.6297 - val_loss: 0.6504\n",
            "Epoch 73/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6338 - loss: 0.6522 - val_accuracy: 0.6297 - val_loss: 0.6498\n",
            "Epoch 74/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6246 - loss: 0.6526 - val_accuracy: 0.6297 - val_loss: 0.6492\n",
            "Epoch 75/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6312 - loss: 0.6662 - val_accuracy: 0.6297 - val_loss: 0.6493\n",
            "Epoch 76/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6363 - loss: 0.6542 - val_accuracy: 0.6297 - val_loss: 0.6492\n",
            "Epoch 77/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6241 - loss: 0.6627 - val_accuracy: 0.6297 - val_loss: 0.6491\n",
            "Epoch 78/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6474 - loss: 0.6503 - val_accuracy: 0.6297 - val_loss: 0.6486\n",
            "Epoch 79/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6425 - loss: 0.6536 - val_accuracy: 0.6297 - val_loss: 0.6481\n",
            "Epoch 80/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6475 - loss: 0.6498 - val_accuracy: 0.6297 - val_loss: 0.6482\n",
            "Epoch 81/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6054 - loss: 0.6594 - val_accuracy: 0.6297 - val_loss: 0.6480\n",
            "Epoch 82/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6290 - loss: 0.6531 - val_accuracy: 0.6297 - val_loss: 0.6477\n",
            "Epoch 83/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6417 - loss: 0.6530 - val_accuracy: 0.6297 - val_loss: 0.6477\n",
            "Epoch 84/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6339 - loss: 0.6463 - val_accuracy: 0.6297 - val_loss: 0.6470\n",
            "Epoch 85/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6191 - loss: 0.6615 - val_accuracy: 0.6297 - val_loss: 0.6466\n",
            "Epoch 86/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6337 - loss: 0.6504 - val_accuracy: 0.6297 - val_loss: 0.6468\n",
            "Epoch 87/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6331 - loss: 0.6461 - val_accuracy: 0.6297 - val_loss: 0.6463\n",
            "Epoch 88/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6465 - loss: 0.6484 - val_accuracy: 0.6297 - val_loss: 0.6461\n",
            "Epoch 89/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6411 - loss: 0.6506 - val_accuracy: 0.6297 - val_loss: 0.6464\n",
            "Epoch 90/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6388 - loss: 0.6419 - val_accuracy: 0.6297 - val_loss: 0.6459\n",
            "Epoch 91/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6381 - loss: 0.6475 - val_accuracy: 0.6297 - val_loss: 0.6457\n",
            "Epoch 92/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6299 - loss: 0.6498 - val_accuracy: 0.6297 - val_loss: 0.6451\n",
            "Epoch 93/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6417 - loss: 0.6416 - val_accuracy: 0.6297 - val_loss: 0.6447\n",
            "Epoch 94/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6192 - loss: 0.6500 - val_accuracy: 0.6297 - val_loss: 0.6443\n",
            "Epoch 95/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6158 - loss: 0.6612 - val_accuracy: 0.6297 - val_loss: 0.6436\n",
            "Epoch 96/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6360 - loss: 0.6413 - val_accuracy: 0.6297 - val_loss: 0.6435\n",
            "Epoch 97/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6184 - loss: 0.6460 - val_accuracy: 0.6297 - val_loss: 0.6430\n",
            "Epoch 98/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6241 - loss: 0.6511 - val_accuracy: 0.6297 - val_loss: 0.6426\n",
            "Epoch 99/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6293 - loss: 0.6513 - val_accuracy: 0.6297 - val_loss: 0.6426\n",
            "Epoch 100/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6485 - loss: 0.6423 - val_accuracy: 0.6297 - val_loss: 0.6425\n",
            "Epoch 101/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6421 - loss: 0.6448 - val_accuracy: 0.6297 - val_loss: 0.6425\n",
            "Epoch 102/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6512 - loss: 0.6386 - val_accuracy: 0.6297 - val_loss: 0.6423\n",
            "Epoch 103/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6302 - loss: 0.6441 - val_accuracy: 0.6297 - val_loss: 0.6417\n",
            "Epoch 104/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6426 - loss: 0.6453 - val_accuracy: 0.6321 - val_loss: 0.6418\n",
            "Epoch 105/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6445 - loss: 0.6327 - val_accuracy: 0.6321 - val_loss: 0.6411\n",
            "Epoch 106/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6215 - loss: 0.6529 - val_accuracy: 0.6344 - val_loss: 0.6414\n",
            "Epoch 107/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6381 - loss: 0.6421 - val_accuracy: 0.6368 - val_loss: 0.6406\n",
            "Epoch 108/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6387 - loss: 0.6475 - val_accuracy: 0.6368 - val_loss: 0.6402\n",
            "Epoch 109/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6441 - loss: 0.6468 - val_accuracy: 0.6368 - val_loss: 0.6404\n",
            "Epoch 110/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6267 - loss: 0.6506 - val_accuracy: 0.6368 - val_loss: 0.6401\n",
            "Epoch 111/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6245 - loss: 0.6505 - val_accuracy: 0.6392 - val_loss: 0.6400\n",
            "Epoch 112/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6485 - loss: 0.6373 - val_accuracy: 0.6392 - val_loss: 0.6395\n",
            "Epoch 113/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6267 - loss: 0.6530 - val_accuracy: 0.6392 - val_loss: 0.6394\n",
            "Epoch 114/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6337 - loss: 0.6335 - val_accuracy: 0.6392 - val_loss: 0.6393\n",
            "Epoch 115/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6416 - loss: 0.6404 - val_accuracy: 0.6415 - val_loss: 0.6392\n",
            "Epoch 116/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6360 - loss: 0.6486 - val_accuracy: 0.6415 - val_loss: 0.6392\n",
            "Epoch 117/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6246 - loss: 0.6492 - val_accuracy: 0.6439 - val_loss: 0.6394\n",
            "Epoch 118/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6342 - loss: 0.6454 - val_accuracy: 0.6439 - val_loss: 0.6390\n",
            "Epoch 119/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6365 - loss: 0.6511 - val_accuracy: 0.6439 - val_loss: 0.6387\n",
            "Epoch 120/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6392 - loss: 0.6528 - val_accuracy: 0.6439 - val_loss: 0.6381\n",
            "Epoch 121/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6597 - loss: 0.6241 - val_accuracy: 0.6462 - val_loss: 0.6374\n",
            "Epoch 122/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6362 - loss: 0.6442 - val_accuracy: 0.6486 - val_loss: 0.6374\n",
            "Epoch 123/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6366 - loss: 0.6436 - val_accuracy: 0.6486 - val_loss: 0.6374\n",
            "Epoch 124/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6503 - loss: 0.6302 - val_accuracy: 0.6462 - val_loss: 0.6369\n",
            "Epoch 125/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6479 - loss: 0.6451 - val_accuracy: 0.6462 - val_loss: 0.6368\n",
            "Epoch 126/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6205 - loss: 0.6456 - val_accuracy: 0.6462 - val_loss: 0.6362\n",
            "Epoch 127/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6412 - loss: 0.6405 - val_accuracy: 0.6486 - val_loss: 0.6362\n",
            "Epoch 128/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6584 - loss: 0.6381 - val_accuracy: 0.6462 - val_loss: 0.6357\n",
            "Epoch 129/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6187 - loss: 0.6560 - val_accuracy: 0.6486 - val_loss: 0.6357\n",
            "Epoch 130/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6587 - loss: 0.6391 - val_accuracy: 0.6486 - val_loss: 0.6352\n",
            "Epoch 131/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6347 - loss: 0.6390 - val_accuracy: 0.6486 - val_loss: 0.6347\n",
            "Epoch 132/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6420 - loss: 0.6392 - val_accuracy: 0.6462 - val_loss: 0.6342\n",
            "Epoch 133/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6322 - loss: 0.6421 - val_accuracy: 0.6509 - val_loss: 0.6339\n",
            "Epoch 134/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6360 - loss: 0.6475 - val_accuracy: 0.6533 - val_loss: 0.6337\n",
            "Epoch 135/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6461 - loss: 0.6278 - val_accuracy: 0.6533 - val_loss: 0.6336\n",
            "Epoch 136/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6360 - loss: 0.6437 - val_accuracy: 0.6557 - val_loss: 0.6336\n",
            "Epoch 137/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6152 - loss: 0.6457 - val_accuracy: 0.6533 - val_loss: 0.6335\n",
            "Epoch 138/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6439 - loss: 0.6436 - val_accuracy: 0.6533 - val_loss: 0.6335\n",
            "Epoch 139/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6456 - loss: 0.6326 - val_accuracy: 0.6533 - val_loss: 0.6331\n",
            "Epoch 140/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6472 - loss: 0.6443 - val_accuracy: 0.6557 - val_loss: 0.6326\n",
            "Epoch 141/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6226 - loss: 0.6506 - val_accuracy: 0.6557 - val_loss: 0.6325\n",
            "Epoch 142/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6637 - loss: 0.6337 - val_accuracy: 0.6557 - val_loss: 0.6323\n",
            "Epoch 143/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6546 - loss: 0.6299 - val_accuracy: 0.6533 - val_loss: 0.6316\n",
            "Epoch 144/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6647 - loss: 0.6249 - val_accuracy: 0.6509 - val_loss: 0.6309\n",
            "Epoch 145/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6439 - loss: 0.6364 - val_accuracy: 0.6509 - val_loss: 0.6304\n",
            "Epoch 146/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6519 - loss: 0.6234 - val_accuracy: 0.6557 - val_loss: 0.6299\n",
            "Epoch 147/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6229 - loss: 0.6488 - val_accuracy: 0.6580 - val_loss: 0.6296\n",
            "Epoch 148/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6439 - loss: 0.6411 - val_accuracy: 0.6580 - val_loss: 0.6296\n",
            "Epoch 149/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6179 - loss: 0.6486 - val_accuracy: 0.6580 - val_loss: 0.6292\n",
            "Epoch 150/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6616 - loss: 0.6230 - val_accuracy: 0.6604 - val_loss: 0.6288\n",
            "Epoch 151/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6722 - loss: 0.6163 - val_accuracy: 0.6627 - val_loss: 0.6280\n",
            "Epoch 152/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6426 - loss: 0.6319 - val_accuracy: 0.6604 - val_loss: 0.6281\n",
            "Epoch 153/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6530 - loss: 0.6267 - val_accuracy: 0.6627 - val_loss: 0.6275\n",
            "Epoch 154/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6593 - loss: 0.6200 - val_accuracy: 0.6604 - val_loss: 0.6270\n",
            "Epoch 155/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6412 - loss: 0.6478 - val_accuracy: 0.6604 - val_loss: 0.6269\n",
            "Epoch 156/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6266 - loss: 0.6425 - val_accuracy: 0.6627 - val_loss: 0.6268\n",
            "Epoch 157/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6535 - loss: 0.6293 - val_accuracy: 0.6627 - val_loss: 0.6264\n",
            "Epoch 158/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6569 - loss: 0.6314 - val_accuracy: 0.6604 - val_loss: 0.6261\n",
            "Epoch 159/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6412 - loss: 0.6278 - val_accuracy: 0.6580 - val_loss: 0.6260\n",
            "Epoch 160/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6649 - loss: 0.6381 - val_accuracy: 0.6604 - val_loss: 0.6263\n",
            "Epoch 161/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6491 - loss: 0.6342 - val_accuracy: 0.6604 - val_loss: 0.6264\n",
            "Epoch 162/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6714 - loss: 0.6161 - val_accuracy: 0.6604 - val_loss: 0.6259\n",
            "Epoch 163/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6260 - loss: 0.6437 - val_accuracy: 0.6604 - val_loss: 0.6262\n",
            "Epoch 164/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6479 - loss: 0.6267 - val_accuracy: 0.6651 - val_loss: 0.6261\n",
            "Epoch 165/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6658 - loss: 0.6254 - val_accuracy: 0.6675 - val_loss: 0.6256\n",
            "Epoch 166/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6390 - loss: 0.6313 - val_accuracy: 0.6651 - val_loss: 0.6254\n",
            "Epoch 167/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6373 - loss: 0.6419 - val_accuracy: 0.6675 - val_loss: 0.6255\n",
            "Epoch 168/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6770 - loss: 0.6155 - val_accuracy: 0.6627 - val_loss: 0.6251\n",
            "Epoch 169/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6273 - loss: 0.6411 - val_accuracy: 0.6627 - val_loss: 0.6250\n",
            "Epoch 170/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6451 - loss: 0.6318 - val_accuracy: 0.6651 - val_loss: 0.6247\n",
            "Epoch 171/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6314 - loss: 0.6405 - val_accuracy: 0.6604 - val_loss: 0.6243\n",
            "Epoch 172/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6454 - loss: 0.6294 - val_accuracy: 0.6627 - val_loss: 0.6242\n",
            "Epoch 173/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6358 - loss: 0.6325 - val_accuracy: 0.6627 - val_loss: 0.6242\n",
            "Epoch 174/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6548 - loss: 0.6312 - val_accuracy: 0.6627 - val_loss: 0.6243\n",
            "Epoch 175/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6343 - loss: 0.6422 - val_accuracy: 0.6627 - val_loss: 0.6243\n",
            "Epoch 176/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6379 - loss: 0.6364 - val_accuracy: 0.6604 - val_loss: 0.6241\n",
            "Epoch 177/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6452 - loss: 0.6163 - val_accuracy: 0.6580 - val_loss: 0.6239\n",
            "Epoch 178/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6584 - loss: 0.6272 - val_accuracy: 0.6580 - val_loss: 0.6237\n",
            "Epoch 179/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6477 - loss: 0.6303 - val_accuracy: 0.6580 - val_loss: 0.6236\n",
            "Epoch 180/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6628 - loss: 0.6143 - val_accuracy: 0.6604 - val_loss: 0.6236\n",
            "Epoch 181/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6429 - loss: 0.6397 - val_accuracy: 0.6627 - val_loss: 0.6238\n",
            "Epoch 182/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6670 - loss: 0.6138 - val_accuracy: 0.6604 - val_loss: 0.6237\n",
            "Epoch 183/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6525 - loss: 0.6145 - val_accuracy: 0.6604 - val_loss: 0.6235\n",
            "Epoch 184/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6498 - loss: 0.6234 - val_accuracy: 0.6580 - val_loss: 0.6233\n",
            "Epoch 185/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6573 - loss: 0.6286 - val_accuracy: 0.6604 - val_loss: 0.6231\n",
            "Epoch 186/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6736 - loss: 0.6291 - val_accuracy: 0.6580 - val_loss: 0.6232\n",
            "Epoch 187/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6706 - loss: 0.6317 - val_accuracy: 0.6604 - val_loss: 0.6230\n",
            "Epoch 188/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6423 - loss: 0.6320 - val_accuracy: 0.6627 - val_loss: 0.6228\n",
            "Epoch 189/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6533 - loss: 0.6210 - val_accuracy: 0.6627 - val_loss: 0.6228\n",
            "Epoch 190/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6605 - loss: 0.6315 - val_accuracy: 0.6604 - val_loss: 0.6226\n",
            "Epoch 191/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6567 - loss: 0.6124 - val_accuracy: 0.6604 - val_loss: 0.6227\n",
            "Epoch 192/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6646 - loss: 0.6174 - val_accuracy: 0.6604 - val_loss: 0.6229\n",
            "Epoch 193/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6734 - loss: 0.6135 - val_accuracy: 0.6580 - val_loss: 0.6224\n",
            "Epoch 194/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6501 - loss: 0.6263 - val_accuracy: 0.6580 - val_loss: 0.6223\n",
            "Epoch 195/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6537 - loss: 0.6289 - val_accuracy: 0.6557 - val_loss: 0.6220\n",
            "Epoch 196/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6478 - loss: 0.6328 - val_accuracy: 0.6557 - val_loss: 0.6220\n",
            "Epoch 197/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6687 - loss: 0.6273 - val_accuracy: 0.6580 - val_loss: 0.6219\n",
            "Epoch 198/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6343 - loss: 0.6415 - val_accuracy: 0.6604 - val_loss: 0.6220\n",
            "Epoch 199/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6714 - loss: 0.6229 - val_accuracy: 0.6604 - val_loss: 0.6220\n",
            "Epoch 200/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6655 - loss: 0.6276 - val_accuracy: 0.6604 - val_loss: 0.6220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_epoch = np.argmin(history.history['val_loss'])\n",
        "print(f\"Best Epoch: {best_epoch+1}\")\n",
        "print(f\"Train Accuracy at Best Epoch: {history.history['accuracy'][best_epoch]:.4f}\")\n",
        "print(f\"Val Accuracy at Best Epoch: {history.history['val_accuracy'][best_epoch]:.4f}\")"
      ],
      "metadata": {
        "id": "1z30otXZnPVI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec5612ab-9f28-47e0-a13d-9d06e1af757d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Epoch: 200\n",
            "Train Accuracy at Best Epoch: 0.6588\n",
            "Val Accuracy at Best Epoch: 0.6509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}, Test Loss: {test_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8-xUOoyJk5_",
        "outputId": "2c35d7c3-cd92-4b60-fa22-e0abc22e7ea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6745 - loss: 0.6114 \n",
            "Test Accuracy: 0.6682, Test Loss: 0.6180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_gaius_irakiza():\n",
        "    model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Nadam(learning_rate=0.0001)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            tf.keras.metrics.Precision(name='precision'),\n",
        "            tf.keras.metrics.Recall(name='recall'),\n",
        "            tf.keras.metrics.AUC(name='auc')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "gaius_model = model_gaius_irakiza()\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=30,\n",
        "    min_delta=0.0001,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "history = gaius_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=300,\n",
        "    batch_size=32,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "hmWIUNw0-l0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac043d6-afe3-4907-e9d4-ac33988912cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.5743 - auc: 0.5435 - loss: 0.6844 - precision: 0.4177 - recall: 0.3650 - val_accuracy: 0.5330 - val_auc: 0.5028 - val_loss: 0.6892 - val_precision: 0.3815 - val_recall: 0.4204\n",
            "Epoch 2/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5440 - auc: 0.4892 - loss: 0.7024 - precision: 0.3417 - recall: 0.2853 - val_accuracy: 0.4953 - val_auc: 0.4990 - val_loss: 0.6924 - val_precision: 0.3662 - val_recall: 0.4968\n",
            "Epoch 3/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5692 - auc: 0.4871 - loss: 0.7011 - precision: 0.3785 - recall: 0.2747 - val_accuracy: 0.5212 - val_auc: 0.5064 - val_loss: 0.6898 - val_precision: 0.3814 - val_recall: 0.4713\n",
            "Epoch 4/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5814 - auc: 0.4988 - loss: 0.6880 - precision: 0.3755 - recall: 0.2337 - val_accuracy: 0.5259 - val_auc: 0.5081 - val_loss: 0.6870 - val_precision: 0.3706 - val_recall: 0.4013\n",
            "Epoch 5/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5719 - auc: 0.4812 - loss: 0.6910 - precision: 0.3373 - recall: 0.1806 - val_accuracy: 0.5519 - val_auc: 0.5132 - val_loss: 0.6818 - val_precision: 0.3636 - val_recall: 0.2803\n",
            "Epoch 6/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6031 - auc: 0.4877 - loss: 0.6853 - precision: 0.3873 - recall: 0.1899 - val_accuracy: 0.5991 - val_auc: 0.5251 - val_loss: 0.6766 - val_precision: 0.4270 - val_recall: 0.2420\n",
            "Epoch 7/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5922 - auc: 0.5110 - loss: 0.6790 - precision: 0.3716 - recall: 0.1484 - val_accuracy: 0.5991 - val_auc: 0.5272 - val_loss: 0.6737 - val_precision: 0.4133 - val_recall: 0.1975\n",
            "Epoch 8/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5826 - auc: 0.4709 - loss: 0.6901 - precision: 0.3005 - recall: 0.1028 - val_accuracy: 0.6179 - val_auc: 0.5365 - val_loss: 0.6697 - val_precision: 0.4510 - val_recall: 0.1465\n",
            "Epoch 9/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5903 - auc: 0.5210 - loss: 0.6796 - precision: 0.4036 - recall: 0.1537 - val_accuracy: 0.6203 - val_auc: 0.5421 - val_loss: 0.6661 - val_precision: 0.4500 - val_recall: 0.1146\n",
            "Epoch 10/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6218 - auc: 0.5248 - loss: 0.6659 - precision: 0.4192 - recall: 0.1491 - val_accuracy: 0.6274 - val_auc: 0.5441 - val_loss: 0.6635 - val_precision: 0.4848 - val_recall: 0.1019\n",
            "Epoch 11/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6020 - auc: 0.5290 - loss: 0.6764 - precision: 0.4472 - recall: 0.1592 - val_accuracy: 0.6226 - val_auc: 0.5545 - val_loss: 0.6608 - val_precision: 0.4444 - val_recall: 0.0764\n",
            "Epoch 12/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6110 - auc: 0.5624 - loss: 0.6546 - precision: 0.3835 - recall: 0.0981 - val_accuracy: 0.6203 - val_auc: 0.5595 - val_loss: 0.6591 - val_precision: 0.4091 - val_recall: 0.0573\n",
            "Epoch 13/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5976 - auc: 0.5097 - loss: 0.6764 - precision: 0.3770 - recall: 0.1170 - val_accuracy: 0.6226 - val_auc: 0.5629 - val_loss: 0.6583 - val_precision: 0.4348 - val_recall: 0.0637\n",
            "Epoch 14/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6242 - auc: 0.5435 - loss: 0.6616 - precision: 0.4352 - recall: 0.1251 - val_accuracy: 0.6179 - val_auc: 0.5638 - val_loss: 0.6574 - val_precision: 0.3684 - val_recall: 0.0446\n",
            "Epoch 15/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6231 - auc: 0.5309 - loss: 0.6708 - precision: 0.5059 - recall: 0.1180 - val_accuracy: 0.6156 - val_auc: 0.5592 - val_loss: 0.6580 - val_precision: 0.3500 - val_recall: 0.0446\n",
            "Epoch 16/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6138 - auc: 0.5525 - loss: 0.6610 - precision: 0.3961 - recall: 0.0928 - val_accuracy: 0.6203 - val_auc: 0.5643 - val_loss: 0.6564 - val_precision: 0.3750 - val_recall: 0.0382\n",
            "Epoch 17/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6234 - auc: 0.5365 - loss: 0.6633 - precision: 0.4061 - recall: 0.1275 - val_accuracy: 0.6203 - val_auc: 0.5699 - val_loss: 0.6552 - val_precision: 0.3333 - val_recall: 0.0255\n",
            "Epoch 18/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6097 - auc: 0.5302 - loss: 0.6678 - precision: 0.3609 - recall: 0.0898 - val_accuracy: 0.6179 - val_auc: 0.5743 - val_loss: 0.6534 - val_precision: 0.2727 - val_recall: 0.0191\n",
            "Epoch 19/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6156 - auc: 0.5294 - loss: 0.6661 - precision: 0.3919 - recall: 0.0634 - val_accuracy: 0.6179 - val_auc: 0.5764 - val_loss: 0.6524 - val_precision: 0.2727 - val_recall: 0.0191\n",
            "Epoch 20/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6354 - auc: 0.5764 - loss: 0.6475 - precision: 0.4688 - recall: 0.1189 - val_accuracy: 0.6250 - val_auc: 0.5773 - val_loss: 0.6518 - val_precision: 0.3750 - val_recall: 0.0191\n",
            "Epoch 21/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6353 - auc: 0.5628 - loss: 0.6537 - precision: 0.4911 - recall: 0.0919 - val_accuracy: 0.6250 - val_auc: 0.5771 - val_loss: 0.6515 - val_precision: 0.3750 - val_recall: 0.0191\n",
            "Epoch 22/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6326 - auc: 0.5412 - loss: 0.6546 - precision: 0.4356 - recall: 0.0926 - val_accuracy: 0.6226 - val_auc: 0.5785 - val_loss: 0.6503 - val_precision: 0.3333 - val_recall: 0.0191\n",
            "Epoch 23/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6249 - auc: 0.5561 - loss: 0.6564 - precision: 0.4308 - recall: 0.0776 - val_accuracy: 0.6226 - val_auc: 0.5821 - val_loss: 0.6497 - val_precision: 0.2857 - val_recall: 0.0127\n",
            "Epoch 24/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6319 - auc: 0.5818 - loss: 0.6432 - precision: 0.4219 - recall: 0.0765 - val_accuracy: 0.6226 - val_auc: 0.5816 - val_loss: 0.6498 - val_precision: 0.2857 - val_recall: 0.0127\n",
            "Epoch 25/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6192 - auc: 0.5629 - loss: 0.6544 - precision: 0.4105 - recall: 0.0780 - val_accuracy: 0.6250 - val_auc: 0.5817 - val_loss: 0.6491 - val_precision: 0.3333 - val_recall: 0.0127\n",
            "Epoch 26/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6039 - auc: 0.5596 - loss: 0.6628 - precision: 0.4045 - recall: 0.0715 - val_accuracy: 0.6226 - val_auc: 0.5822 - val_loss: 0.6487 - val_precision: 0.2857 - val_recall: 0.0127\n",
            "Epoch 27/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6149 - auc: 0.6000 - loss: 0.6460 - precision: 0.3760 - recall: 0.0601 - val_accuracy: 0.6274 - val_auc: 0.5851 - val_loss: 0.6477 - val_precision: 0.4000 - val_recall: 0.0127\n",
            "Epoch 28/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6446 - auc: 0.5412 - loss: 0.6482 - precision: 0.4174 - recall: 0.0699 - val_accuracy: 0.6297 - val_auc: 0.5836 - val_loss: 0.6473 - val_precision: 0.5000 - val_recall: 0.0191\n",
            "Epoch 29/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6396 - auc: 0.5444 - loss: 0.6502 - precision: 0.3894 - recall: 0.0737 - val_accuracy: 0.6274 - val_auc: 0.5880 - val_loss: 0.6465 - val_precision: 0.4000 - val_recall: 0.0127\n",
            "Epoch 30/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6501 - auc: 0.5495 - loss: 0.6547 - precision: 0.5984 - recall: 0.0963 - val_accuracy: 0.6297 - val_auc: 0.5864 - val_loss: 0.6460 - val_precision: 0.5000 - val_recall: 0.0191\n",
            "Epoch 31/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6165 - auc: 0.5628 - loss: 0.6568 - precision: 0.4007 - recall: 0.0701 - val_accuracy: 0.6274 - val_auc: 0.5882 - val_loss: 0.6457 - val_precision: 0.4000 - val_recall: 0.0127\n",
            "Epoch 32/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6202 - auc: 0.5495 - loss: 0.6679 - precision: 0.5134 - recall: 0.0870 - val_accuracy: 0.6274 - val_auc: 0.5914 - val_loss: 0.6448 - val_precision: 0.4000 - val_recall: 0.0127\n",
            "Epoch 33/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6083 - auc: 0.5540 - loss: 0.6598 - precision: 0.3420 - recall: 0.0522 - val_accuracy: 0.6297 - val_auc: 0.5960 - val_loss: 0.6439 - val_precision: 0.5000 - val_recall: 0.0191\n",
            "Epoch 34/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6177 - auc: 0.5785 - loss: 0.6506 - precision: 0.4184 - recall: 0.0730 - val_accuracy: 0.6321 - val_auc: 0.5968 - val_loss: 0.6435 - val_precision: 0.6000 - val_recall: 0.0191\n",
            "Epoch 35/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6296 - auc: 0.5329 - loss: 0.6529 - precision: 0.3674 - recall: 0.0557 - val_accuracy: 0.6274 - val_auc: 0.5984 - val_loss: 0.6428 - val_precision: 0.4286 - val_recall: 0.0191\n",
            "Epoch 36/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6277 - auc: 0.5429 - loss: 0.6581 - precision: 0.4316 - recall: 0.0608 - val_accuracy: 0.6297 - val_auc: 0.5992 - val_loss: 0.6422 - val_precision: 0.5000 - val_recall: 0.0255\n",
            "Epoch 37/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6509 - auc: 0.5892 - loss: 0.6429 - precision: 0.5835 - recall: 0.0858 - val_accuracy: 0.6344 - val_auc: 0.5991 - val_loss: 0.6420 - val_precision: 0.6667 - val_recall: 0.0255\n",
            "Epoch 38/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6320 - auc: 0.5862 - loss: 0.6485 - precision: 0.5545 - recall: 0.0717 - val_accuracy: 0.6297 - val_auc: 0.5965 - val_loss: 0.6419 - val_precision: 0.5000 - val_recall: 0.0255\n",
            "Epoch 39/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6308 - auc: 0.5881 - loss: 0.6457 - precision: 0.5103 - recall: 0.0839 - val_accuracy: 0.6321 - val_auc: 0.5990 - val_loss: 0.6413 - val_precision: 0.5714 - val_recall: 0.0255\n",
            "Epoch 40/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6298 - auc: 0.5708 - loss: 0.6503 - precision: 0.4642 - recall: 0.0841 - val_accuracy: 0.6321 - val_auc: 0.6030 - val_loss: 0.6404 - val_precision: 0.5714 - val_recall: 0.0255\n",
            "Epoch 41/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6327 - auc: 0.5839 - loss: 0.6370 - precision: 0.3452 - recall: 0.0613 - val_accuracy: 0.6297 - val_auc: 0.6053 - val_loss: 0.6402 - val_precision: 0.5000 - val_recall: 0.0255\n",
            "Epoch 42/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6314 - auc: 0.5685 - loss: 0.6486 - precision: 0.3352 - recall: 0.0386 - val_accuracy: 0.6321 - val_auc: 0.6021 - val_loss: 0.6405 - val_precision: 0.5556 - val_recall: 0.0318\n",
            "Epoch 43/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6201 - auc: 0.5947 - loss: 0.6535 - precision: 0.5908 - recall: 0.0650 - val_accuracy: 0.6321 - val_auc: 0.6034 - val_loss: 0.6405 - val_precision: 0.5556 - val_recall: 0.0318\n",
            "Epoch 44/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6221 - auc: 0.5899 - loss: 0.6456 - precision: 0.4263 - recall: 0.0592 - val_accuracy: 0.6368 - val_auc: 0.6087 - val_loss: 0.6388 - val_precision: 0.6667 - val_recall: 0.0382\n",
            "Epoch 45/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6209 - auc: 0.5667 - loss: 0.6558 - precision: 0.4285 - recall: 0.0664 - val_accuracy: 0.6321 - val_auc: 0.6049 - val_loss: 0.6391 - val_precision: 0.5455 - val_recall: 0.0382\n",
            "Epoch 46/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6374 - auc: 0.5987 - loss: 0.6397 - precision: 0.4840 - recall: 0.0694 - val_accuracy: 0.6321 - val_auc: 0.6038 - val_loss: 0.6389 - val_precision: 0.5455 - val_recall: 0.0382\n",
            "Epoch 47/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6219 - auc: 0.6085 - loss: 0.6467 - precision: 0.5149 - recall: 0.0919 - val_accuracy: 0.6321 - val_auc: 0.6041 - val_loss: 0.6393 - val_precision: 0.5455 - val_recall: 0.0382\n",
            "Epoch 48/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6291 - auc: 0.5709 - loss: 0.6502 - precision: 0.4189 - recall: 0.0602 - val_accuracy: 0.6392 - val_auc: 0.6058 - val_loss: 0.6384 - val_precision: 0.7000 - val_recall: 0.0446\n",
            "Epoch 49/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6479 - auc: 0.6036 - loss: 0.6377 - precision: 0.5610 - recall: 0.0905 - val_accuracy: 0.6368 - val_auc: 0.6082 - val_loss: 0.6372 - val_precision: 0.6667 - val_recall: 0.0382\n",
            "Epoch 50/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6198 - auc: 0.5907 - loss: 0.6534 - precision: 0.5189 - recall: 0.0838 - val_accuracy: 0.6415 - val_auc: 0.6084 - val_loss: 0.6368 - val_precision: 0.7273 - val_recall: 0.0510\n",
            "Epoch 51/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6308 - auc: 0.6167 - loss: 0.6343 - precision: 0.4581 - recall: 0.0758 - val_accuracy: 0.6392 - val_auc: 0.6114 - val_loss: 0.6365 - val_precision: 0.7000 - val_recall: 0.0446\n",
            "Epoch 52/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6484 - auc: 0.6384 - loss: 0.6304 - precision: 0.6441 - recall: 0.1095 - val_accuracy: 0.6439 - val_auc: 0.6092 - val_loss: 0.6357 - val_precision: 0.7500 - val_recall: 0.0573\n",
            "Epoch 53/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6441 - auc: 0.5874 - loss: 0.6455 - precision: 0.6077 - recall: 0.0904 - val_accuracy: 0.6415 - val_auc: 0.6115 - val_loss: 0.6354 - val_precision: 0.7273 - val_recall: 0.0510\n",
            "Epoch 54/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6515 - auc: 0.6109 - loss: 0.6336 - precision: 0.5688 - recall: 0.1098 - val_accuracy: 0.6415 - val_auc: 0.6092 - val_loss: 0.6360 - val_precision: 0.6923 - val_recall: 0.0573\n",
            "Epoch 55/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6370 - auc: 0.5882 - loss: 0.6461 - precision: 0.5296 - recall: 0.0903 - val_accuracy: 0.6392 - val_auc: 0.6094 - val_loss: 0.6360 - val_precision: 0.6429 - val_recall: 0.0573\n",
            "Epoch 56/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6474 - auc: 0.6024 - loss: 0.6437 - precision: 0.6350 - recall: 0.1080 - val_accuracy: 0.6392 - val_auc: 0.6054 - val_loss: 0.6369 - val_precision: 0.6429 - val_recall: 0.0573\n",
            "Epoch 57/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6538 - auc: 0.6008 - loss: 0.6320 - precision: 0.4680 - recall: 0.0738 - val_accuracy: 0.6392 - val_auc: 0.6039 - val_loss: 0.6370 - val_precision: 0.6429 - val_recall: 0.0573\n",
            "Epoch 58/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6448 - auc: 0.6027 - loss: 0.6450 - precision: 0.5829 - recall: 0.1123 - val_accuracy: 0.6439 - val_auc: 0.6064 - val_loss: 0.6366 - val_precision: 0.6875 - val_recall: 0.0701\n",
            "Epoch 59/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6404 - auc: 0.6179 - loss: 0.6333 - precision: 0.5035 - recall: 0.1036 - val_accuracy: 0.6439 - val_auc: 0.6044 - val_loss: 0.6366 - val_precision: 0.6875 - val_recall: 0.0701\n",
            "Epoch 60/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6318 - auc: 0.6069 - loss: 0.6401 - precision: 0.4877 - recall: 0.0969 - val_accuracy: 0.6415 - val_auc: 0.6086 - val_loss: 0.6355 - val_precision: 0.6667 - val_recall: 0.0637\n",
            "Epoch 61/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6232 - auc: 0.6066 - loss: 0.6452 - precision: 0.5348 - recall: 0.1145 - val_accuracy: 0.6462 - val_auc: 0.6052 - val_loss: 0.6359 - val_precision: 0.7059 - val_recall: 0.0764\n",
            "Epoch 62/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6663 - auc: 0.6229 - loss: 0.6224 - precision: 0.5680 - recall: 0.1033 - val_accuracy: 0.6415 - val_auc: 0.6060 - val_loss: 0.6353 - val_precision: 0.6471 - val_recall: 0.0701\n",
            "Epoch 63/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6471 - auc: 0.6228 - loss: 0.6364 - precision: 0.5940 - recall: 0.1207 - val_accuracy: 0.6439 - val_auc: 0.6074 - val_loss: 0.6350 - val_precision: 0.6875 - val_recall: 0.0701\n",
            "Epoch 64/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6455 - auc: 0.6225 - loss: 0.6347 - precision: 0.5586 - recall: 0.1176 - val_accuracy: 0.6509 - val_auc: 0.6122 - val_loss: 0.6335 - val_precision: 0.7143 - val_recall: 0.0955\n",
            "Epoch 65/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6365 - auc: 0.6172 - loss: 0.6354 - precision: 0.5207 - recall: 0.1176 - val_accuracy: 0.6462 - val_auc: 0.6117 - val_loss: 0.6335 - val_precision: 0.6667 - val_recall: 0.0892\n",
            "Epoch 66/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6306 - auc: 0.6218 - loss: 0.6435 - precision: 0.5736 - recall: 0.1278 - val_accuracy: 0.6462 - val_auc: 0.6166 - val_loss: 0.6325 - val_precision: 0.6667 - val_recall: 0.0892\n",
            "Epoch 67/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6292 - auc: 0.5936 - loss: 0.6459 - precision: 0.5075 - recall: 0.1236 - val_accuracy: 0.6486 - val_auc: 0.6169 - val_loss: 0.6323 - val_precision: 0.6818 - val_recall: 0.0955\n",
            "Epoch 68/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6286 - auc: 0.6211 - loss: 0.6460 - precision: 0.5598 - recall: 0.1367 - val_accuracy: 0.6509 - val_auc: 0.6176 - val_loss: 0.6319 - val_precision: 0.6957 - val_recall: 0.1019\n",
            "Epoch 69/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6473 - auc: 0.6184 - loss: 0.6374 - precision: 0.6075 - recall: 0.1537 - val_accuracy: 0.6486 - val_auc: 0.6177 - val_loss: 0.6315 - val_precision: 0.6538 - val_recall: 0.1083\n",
            "Epoch 70/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6428 - auc: 0.6354 - loss: 0.6244 - precision: 0.5010 - recall: 0.1437 - val_accuracy: 0.6486 - val_auc: 0.6172 - val_loss: 0.6312 - val_precision: 0.6538 - val_recall: 0.1083\n",
            "Epoch 71/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6235 - auc: 0.6200 - loss: 0.6410 - precision: 0.5043 - recall: 0.1325 - val_accuracy: 0.6415 - val_auc: 0.6204 - val_loss: 0.6305 - val_precision: 0.5806 - val_recall: 0.1146\n",
            "Epoch 72/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6470 - auc: 0.6047 - loss: 0.6336 - precision: 0.5021 - recall: 0.1555 - val_accuracy: 0.6462 - val_auc: 0.6208 - val_loss: 0.6302 - val_precision: 0.6207 - val_recall: 0.1146\n",
            "Epoch 73/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6273 - auc: 0.6054 - loss: 0.6493 - precision: 0.5397 - recall: 0.1706 - val_accuracy: 0.6439 - val_auc: 0.6227 - val_loss: 0.6298 - val_precision: 0.6000 - val_recall: 0.1146\n",
            "Epoch 74/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6405 - auc: 0.6375 - loss: 0.6309 - precision: 0.5506 - recall: 0.1412 - val_accuracy: 0.6462 - val_auc: 0.6233 - val_loss: 0.6298 - val_precision: 0.6207 - val_recall: 0.1146\n",
            "Epoch 75/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6531 - auc: 0.6411 - loss: 0.6281 - precision: 0.6023 - recall: 0.1774 - val_accuracy: 0.6557 - val_auc: 0.6212 - val_loss: 0.6298 - val_precision: 0.6774 - val_recall: 0.1338\n",
            "Epoch 76/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6379 - auc: 0.6086 - loss: 0.6394 - precision: 0.5322 - recall: 0.1765 - val_accuracy: 0.6557 - val_auc: 0.6243 - val_loss: 0.6293 - val_precision: 0.6667 - val_recall: 0.1401\n",
            "Epoch 77/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6435 - auc: 0.6226 - loss: 0.6399 - precision: 0.5984 - recall: 0.1857 - val_accuracy: 0.6580 - val_auc: 0.6266 - val_loss: 0.6288 - val_precision: 0.6667 - val_recall: 0.1529\n",
            "Epoch 78/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6406 - auc: 0.6104 - loss: 0.6383 - precision: 0.5349 - recall: 0.1647 - val_accuracy: 0.6533 - val_auc: 0.6290 - val_loss: 0.6279 - val_precision: 0.6316 - val_recall: 0.1529\n",
            "Epoch 79/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6635 - auc: 0.6279 - loss: 0.6203 - precision: 0.5524 - recall: 0.2107 - val_accuracy: 0.6651 - val_auc: 0.6311 - val_loss: 0.6270 - val_precision: 0.6829 - val_recall: 0.1783\n",
            "Epoch 80/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6495 - auc: 0.6632 - loss: 0.6160 - precision: 0.5764 - recall: 0.1962 - val_accuracy: 0.6627 - val_auc: 0.6318 - val_loss: 0.6266 - val_precision: 0.6522 - val_recall: 0.1911\n",
            "Epoch 81/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6519 - auc: 0.6243 - loss: 0.6347 - precision: 0.5483 - recall: 0.1921 - val_accuracy: 0.6627 - val_auc: 0.6310 - val_loss: 0.6268 - val_precision: 0.6522 - val_recall: 0.1911\n",
            "Epoch 82/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6438 - auc: 0.6332 - loss: 0.6310 - precision: 0.5456 - recall: 0.1969 - val_accuracy: 0.6651 - val_auc: 0.6323 - val_loss: 0.6264 - val_precision: 0.6531 - val_recall: 0.2038\n",
            "Epoch 83/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6635 - auc: 0.6570 - loss: 0.6101 - precision: 0.5599 - recall: 0.2016 - val_accuracy: 0.6745 - val_auc: 0.6329 - val_loss: 0.6262 - val_precision: 0.6939 - val_recall: 0.2166\n",
            "Epoch 84/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6561 - auc: 0.6607 - loss: 0.6281 - precision: 0.6526 - recall: 0.2222 - val_accuracy: 0.6722 - val_auc: 0.6354 - val_loss: 0.6248 - val_precision: 0.6800 - val_recall: 0.2166\n",
            "Epoch 85/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6603 - auc: 0.6597 - loss: 0.6268 - precision: 0.6565 - recall: 0.2283 - val_accuracy: 0.6698 - val_auc: 0.6362 - val_loss: 0.6250 - val_precision: 0.6809 - val_recall: 0.2038\n",
            "Epoch 86/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6446 - auc: 0.6288 - loss: 0.6426 - precision: 0.6210 - recall: 0.2279 - val_accuracy: 0.6698 - val_auc: 0.6365 - val_loss: 0.6250 - val_precision: 0.6735 - val_recall: 0.2102\n",
            "Epoch 87/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6273 - auc: 0.6418 - loss: 0.6338 - precision: 0.5282 - recall: 0.1827 - val_accuracy: 0.6698 - val_auc: 0.6342 - val_loss: 0.6256 - val_precision: 0.6809 - val_recall: 0.2038\n",
            "Epoch 88/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6477 - auc: 0.6656 - loss: 0.6178 - precision: 0.5767 - recall: 0.1971 - val_accuracy: 0.6769 - val_auc: 0.6358 - val_loss: 0.6249 - val_precision: 0.7083 - val_recall: 0.2166\n",
            "Epoch 89/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6727 - auc: 0.6515 - loss: 0.6133 - precision: 0.5671 - recall: 0.2270 - val_accuracy: 0.6816 - val_auc: 0.6357 - val_loss: 0.6252 - val_precision: 0.7292 - val_recall: 0.2229\n",
            "Epoch 90/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6724 - auc: 0.6633 - loss: 0.6077 - precision: 0.6003 - recall: 0.2399 - val_accuracy: 0.6816 - val_auc: 0.6368 - val_loss: 0.6249 - val_precision: 0.7200 - val_recall: 0.2293\n",
            "Epoch 91/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6521 - auc: 0.6352 - loss: 0.6334 - precision: 0.5671 - recall: 0.2223 - val_accuracy: 0.6769 - val_auc: 0.6348 - val_loss: 0.6261 - val_precision: 0.7000 - val_recall: 0.2229\n",
            "Epoch 92/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6391 - auc: 0.6729 - loss: 0.6185 - precision: 0.5779 - recall: 0.2402 - val_accuracy: 0.6769 - val_auc: 0.6334 - val_loss: 0.6264 - val_precision: 0.6852 - val_recall: 0.2357\n",
            "Epoch 93/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6451 - auc: 0.6369 - loss: 0.6274 - precision: 0.5334 - recall: 0.2153 - val_accuracy: 0.6792 - val_auc: 0.6352 - val_loss: 0.6249 - val_precision: 0.6981 - val_recall: 0.2357\n",
            "Epoch 94/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6500 - auc: 0.6462 - loss: 0.6174 - precision: 0.5097 - recall: 0.2305 - val_accuracy: 0.6769 - val_auc: 0.6346 - val_loss: 0.6252 - val_precision: 0.6852 - val_recall: 0.2357\n",
            "Epoch 95/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6520 - auc: 0.6638 - loss: 0.6147 - precision: 0.5609 - recall: 0.2340 - val_accuracy: 0.6745 - val_auc: 0.6359 - val_loss: 0.6242 - val_precision: 0.6727 - val_recall: 0.2357\n",
            "Epoch 96/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6457 - auc: 0.6459 - loss: 0.6324 - precision: 0.5532 - recall: 0.2470 - val_accuracy: 0.6769 - val_auc: 0.6383 - val_loss: 0.6234 - val_precision: 0.6852 - val_recall: 0.2357\n",
            "Epoch 97/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6740 - auc: 0.6653 - loss: 0.6104 - precision: 0.6050 - recall: 0.2849 - val_accuracy: 0.6698 - val_auc: 0.6362 - val_loss: 0.6252 - val_precision: 0.6491 - val_recall: 0.2357\n",
            "Epoch 98/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6410 - auc: 0.6411 - loss: 0.6303 - precision: 0.5502 - recall: 0.2194 - val_accuracy: 0.6769 - val_auc: 0.6326 - val_loss: 0.6268 - val_precision: 0.6667 - val_recall: 0.2548\n",
            "Epoch 99/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6178 - auc: 0.6409 - loss: 0.6401 - precision: 0.5099 - recall: 0.2183 - val_accuracy: 0.6722 - val_auc: 0.6330 - val_loss: 0.6263 - val_precision: 0.6500 - val_recall: 0.2484\n",
            "Epoch 100/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6345 - auc: 0.6344 - loss: 0.6323 - precision: 0.5278 - recall: 0.2316 - val_accuracy: 0.6722 - val_auc: 0.6325 - val_loss: 0.6270 - val_precision: 0.6500 - val_recall: 0.2484\n",
            "Epoch 101/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6614 - auc: 0.6678 - loss: 0.6137 - precision: 0.5447 - recall: 0.2629 - val_accuracy: 0.6745 - val_auc: 0.6333 - val_loss: 0.6271 - val_precision: 0.6610 - val_recall: 0.2484\n",
            "Epoch 102/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6792 - auc: 0.6827 - loss: 0.6142 - precision: 0.6462 - recall: 0.2991 - val_accuracy: 0.6745 - val_auc: 0.6329 - val_loss: 0.6275 - val_precision: 0.6557 - val_recall: 0.2548\n",
            "Epoch 103/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6586 - auc: 0.6935 - loss: 0.6074 - precision: 0.6070 - recall: 0.2828 - val_accuracy: 0.6792 - val_auc: 0.6330 - val_loss: 0.6279 - val_precision: 0.6721 - val_recall: 0.2611\n",
            "Epoch 104/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6439 - auc: 0.6665 - loss: 0.6204 - precision: 0.5608 - recall: 0.2456 - val_accuracy: 0.6840 - val_auc: 0.6339 - val_loss: 0.6276 - val_precision: 0.6949 - val_recall: 0.2611\n",
            "Epoch 105/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6582 - auc: 0.6640 - loss: 0.6165 - precision: 0.5753 - recall: 0.2691 - val_accuracy: 0.6792 - val_auc: 0.6354 - val_loss: 0.6271 - val_precision: 0.6667 - val_recall: 0.2675\n",
            "Epoch 106/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6348 - auc: 0.6637 - loss: 0.6190 - precision: 0.5249 - recall: 0.2330 - val_accuracy: 0.6769 - val_auc: 0.6365 - val_loss: 0.6263 - val_precision: 0.6613 - val_recall: 0.2611\n",
            "Epoch 107/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6674 - auc: 0.6616 - loss: 0.6198 - precision: 0.6310 - recall: 0.2711 - val_accuracy: 0.6816 - val_auc: 0.6381 - val_loss: 0.6256 - val_precision: 0.6774 - val_recall: 0.2675\n",
            "Epoch 108/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6499 - auc: 0.6614 - loss: 0.6213 - precision: 0.5512 - recall: 0.2493 - val_accuracy: 0.6722 - val_auc: 0.6365 - val_loss: 0.6258 - val_precision: 0.6364 - val_recall: 0.2675\n",
            "Epoch 109/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6623 - auc: 0.6601 - loss: 0.6192 - precision: 0.5949 - recall: 0.2670 - val_accuracy: 0.6769 - val_auc: 0.6384 - val_loss: 0.6252 - val_precision: 0.6562 - val_recall: 0.2675\n",
            "Epoch 110/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6830 - auc: 0.6877 - loss: 0.6001 - precision: 0.6136 - recall: 0.2913 - val_accuracy: 0.6604 - val_auc: 0.6390 - val_loss: 0.6246 - val_precision: 0.5915 - val_recall: 0.2675\n",
            "Epoch 111/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6587 - auc: 0.6765 - loss: 0.6097 - precision: 0.5624 - recall: 0.2791 - val_accuracy: 0.6651 - val_auc: 0.6374 - val_loss: 0.6248 - val_precision: 0.6056 - val_recall: 0.2739\n",
            "Epoch 112/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6734 - auc: 0.6709 - loss: 0.6064 - precision: 0.5713 - recall: 0.2860 - val_accuracy: 0.6675 - val_auc: 0.6401 - val_loss: 0.6235 - val_precision: 0.6143 - val_recall: 0.2739\n",
            "Epoch 113/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6491 - auc: 0.6585 - loss: 0.6233 - precision: 0.5604 - recall: 0.2646 - val_accuracy: 0.6675 - val_auc: 0.6393 - val_loss: 0.6249 - val_precision: 0.6143 - val_recall: 0.2739\n",
            "Epoch 114/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6670 - auc: 0.6694 - loss: 0.6239 - precision: 0.6661 - recall: 0.2876 - val_accuracy: 0.6792 - val_auc: 0.6407 - val_loss: 0.6244 - val_precision: 0.6615 - val_recall: 0.2739\n",
            "Epoch 115/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6539 - auc: 0.6492 - loss: 0.6274 - precision: 0.5863 - recall: 0.2613 - val_accuracy: 0.6769 - val_auc: 0.6421 - val_loss: 0.6239 - val_precision: 0.6515 - val_recall: 0.2739\n",
            "Epoch 116/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6438 - auc: 0.6788 - loss: 0.6142 - precision: 0.5589 - recall: 0.2591 - val_accuracy: 0.6698 - val_auc: 0.6419 - val_loss: 0.6243 - val_precision: 0.6232 - val_recall: 0.2739\n",
            "Epoch 117/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6620 - auc: 0.6906 - loss: 0.6070 - precision: 0.6104 - recall: 0.2659 - val_accuracy: 0.6651 - val_auc: 0.6459 - val_loss: 0.6229 - val_precision: 0.6056 - val_recall: 0.2739\n",
            "Epoch 118/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6454 - auc: 0.6681 - loss: 0.6194 - precision: 0.5729 - recall: 0.2625 - val_accuracy: 0.6627 - val_auc: 0.6441 - val_loss: 0.6238 - val_precision: 0.5972 - val_recall: 0.2739\n",
            "Epoch 119/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6613 - auc: 0.6692 - loss: 0.6148 - precision: 0.5822 - recall: 0.2933 - val_accuracy: 0.6651 - val_auc: 0.6459 - val_loss: 0.6234 - val_precision: 0.6027 - val_recall: 0.2803\n",
            "Epoch 120/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6370 - auc: 0.6510 - loss: 0.6284 - precision: 0.5535 - recall: 0.2435 - val_accuracy: 0.6745 - val_auc: 0.6466 - val_loss: 0.6232 - val_precision: 0.6377 - val_recall: 0.2803\n",
            "Epoch 121/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6634 - auc: 0.6890 - loss: 0.6063 - precision: 0.6084 - recall: 0.2862 - val_accuracy: 0.6698 - val_auc: 0.6469 - val_loss: 0.6228 - val_precision: 0.6232 - val_recall: 0.2739\n",
            "Epoch 122/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6635 - auc: 0.6891 - loss: 0.6018 - precision: 0.5747 - recall: 0.2879 - val_accuracy: 0.6698 - val_auc: 0.6450 - val_loss: 0.6245 - val_precision: 0.6197 - val_recall: 0.2803\n",
            "Epoch 123/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6740 - auc: 0.6586 - loss: 0.6213 - precision: 0.5936 - recall: 0.3144 - val_accuracy: 0.6651 - val_auc: 0.6466 - val_loss: 0.6236 - val_precision: 0.6027 - val_recall: 0.2803\n",
            "Epoch 124/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6648 - auc: 0.6656 - loss: 0.6176 - precision: 0.6081 - recall: 0.2930 - val_accuracy: 0.6698 - val_auc: 0.6464 - val_loss: 0.6238 - val_precision: 0.6164 - val_recall: 0.2866\n",
            "Epoch 125/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6644 - auc: 0.6928 - loss: 0.6121 - precision: 0.6516 - recall: 0.2869 - val_accuracy: 0.6651 - val_auc: 0.6446 - val_loss: 0.6246 - val_precision: 0.6027 - val_recall: 0.2803\n",
            "Epoch 126/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6600 - auc: 0.6647 - loss: 0.6128 - precision: 0.5714 - recall: 0.2714 - val_accuracy: 0.6651 - val_auc: 0.6438 - val_loss: 0.6248 - val_precision: 0.6000 - val_recall: 0.2866\n",
            "Epoch 127/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6799 - auc: 0.6836 - loss: 0.6069 - precision: 0.6316 - recall: 0.3041 - val_accuracy: 0.6792 - val_auc: 0.6444 - val_loss: 0.6245 - val_precision: 0.6438 - val_recall: 0.2994\n",
            "Epoch 128/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6577 - auc: 0.6691 - loss: 0.6141 - precision: 0.5839 - recall: 0.2775 - val_accuracy: 0.6745 - val_auc: 0.6426 - val_loss: 0.6250 - val_precision: 0.6267 - val_recall: 0.2994\n",
            "Epoch 129/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6514 - auc: 0.6737 - loss: 0.6164 - precision: 0.5802 - recall: 0.2608 - val_accuracy: 0.6698 - val_auc: 0.6423 - val_loss: 0.6249 - val_precision: 0.6104 - val_recall: 0.2994\n",
            "Epoch 130/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6635 - auc: 0.6807 - loss: 0.6117 - precision: 0.6153 - recall: 0.2886 - val_accuracy: 0.6651 - val_auc: 0.6413 - val_loss: 0.6254 - val_precision: 0.6000 - val_recall: 0.2866\n",
            "Epoch 131/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6749 - auc: 0.6671 - loss: 0.6096 - precision: 0.5964 - recall: 0.2932 - val_accuracy: 0.6627 - val_auc: 0.6398 - val_loss: 0.6257 - val_precision: 0.5897 - val_recall: 0.2930\n",
            "Epoch 132/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6649 - auc: 0.6656 - loss: 0.6123 - precision: 0.5917 - recall: 0.2780 - val_accuracy: 0.6651 - val_auc: 0.6399 - val_loss: 0.6260 - val_precision: 0.5949 - val_recall: 0.2994\n",
            "Epoch 133/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6739 - auc: 0.7114 - loss: 0.5928 - precision: 0.6132 - recall: 0.3225 - val_accuracy: 0.6627 - val_auc: 0.6435 - val_loss: 0.6249 - val_precision: 0.5897 - val_recall: 0.2930\n",
            "Epoch 134/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6481 - auc: 0.6650 - loss: 0.6206 - precision: 0.5876 - recall: 0.2632 - val_accuracy: 0.6627 - val_auc: 0.6449 - val_loss: 0.6238 - val_precision: 0.5875 - val_recall: 0.2994\n",
            "Epoch 135/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6594 - auc: 0.6658 - loss: 0.6231 - precision: 0.5900 - recall: 0.2970 - val_accuracy: 0.6604 - val_auc: 0.6456 - val_loss: 0.6235 - val_precision: 0.5823 - val_recall: 0.2930\n",
            "Epoch 136/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6531 - auc: 0.6790 - loss: 0.6156 - precision: 0.6039 - recall: 0.3015 - val_accuracy: 0.6627 - val_auc: 0.6472 - val_loss: 0.6233 - val_precision: 0.5897 - val_recall: 0.2930\n",
            "Epoch 137/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6724 - auc: 0.6870 - loss: 0.6027 - precision: 0.6059 - recall: 0.3191 - val_accuracy: 0.6580 - val_auc: 0.6464 - val_loss: 0.6240 - val_precision: 0.5750 - val_recall: 0.2930\n",
            "Epoch 138/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6869 - auc: 0.7071 - loss: 0.5904 - precision: 0.6184 - recall: 0.3161 - val_accuracy: 0.6533 - val_auc: 0.6459 - val_loss: 0.6234 - val_precision: 0.5595 - val_recall: 0.2994\n",
            "Epoch 139/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6820 - auc: 0.6968 - loss: 0.6045 - precision: 0.6331 - recall: 0.3351 - val_accuracy: 0.6557 - val_auc: 0.6430 - val_loss: 0.6245 - val_precision: 0.5663 - val_recall: 0.2994\n",
            "Epoch 140/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6645 - auc: 0.6694 - loss: 0.6084 - precision: 0.5540 - recall: 0.3049 - val_accuracy: 0.6604 - val_auc: 0.6453 - val_loss: 0.6233 - val_precision: 0.5802 - val_recall: 0.2994\n",
            "Epoch 141/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6850 - auc: 0.6900 - loss: 0.6015 - precision: 0.6467 - recall: 0.3193 - val_accuracy: 0.6580 - val_auc: 0.6424 - val_loss: 0.6248 - val_precision: 0.5750 - val_recall: 0.2930\n",
            "Epoch 142/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6597 - auc: 0.6748 - loss: 0.6136 - precision: 0.5843 - recall: 0.3087 - val_accuracy: 0.6533 - val_auc: 0.6430 - val_loss: 0.6250 - val_precision: 0.5610 - val_recall: 0.2930\n",
            "Epoch 143/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6668 - auc: 0.6741 - loss: 0.6095 - precision: 0.6117 - recall: 0.3161 - val_accuracy: 0.6557 - val_auc: 0.6440 - val_loss: 0.6249 - val_precision: 0.5679 - val_recall: 0.2930\n",
            "Epoch 144/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6740 - auc: 0.6607 - loss: 0.6135 - precision: 0.6092 - recall: 0.3084 - val_accuracy: 0.6533 - val_auc: 0.6425 - val_loss: 0.6257 - val_precision: 0.5610 - val_recall: 0.2930\n",
            "Epoch 145/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6704 - auc: 0.6856 - loss: 0.6000 - precision: 0.5900 - recall: 0.2990 - val_accuracy: 0.6462 - val_auc: 0.6425 - val_loss: 0.6254 - val_precision: 0.5412 - val_recall: 0.2930\n",
            "Epoch 146/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6481 - auc: 0.6691 - loss: 0.6217 - precision: 0.5607 - recall: 0.2747 - val_accuracy: 0.6392 - val_auc: 0.6437 - val_loss: 0.6250 - val_precision: 0.5233 - val_recall: 0.2866\n",
            "Epoch 147/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6837 - auc: 0.6963 - loss: 0.5983 - precision: 0.6263 - recall: 0.3179 - val_accuracy: 0.6439 - val_auc: 0.6455 - val_loss: 0.6247 - val_precision: 0.5357 - val_recall: 0.2866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_epoch = np.argmin(history.history['val_loss'])\n",
        "print(f\"Best Epoch: {best_epoch+1}\")\n",
        "print(f\"Train Accuracy at Best Epoch: {history.history['accuracy'][best_epoch]:.4f}\")\n",
        "print(f\"Val Accuracy at Best Epoch: {history.history['val_accuracy'][best_epoch]:.4f}\")"
      ],
      "metadata": {
        "id": "nIQiApSSMZR8",
        "outputId": "974af313-a129-4da2-f189-5182c0cfaeb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Epoch: 267\n",
            "Train Accuracy at Best Epoch: 0.7017\n",
            "Val Accuracy at Best Epoch: 0.6863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy, test_precision, test_recall, test_auc = gaius_model.evaluate(X_test, y_test, verbose=1)\n",
        "\n",
        "# Print results with clear formatting\n",
        "print(\"\\nTest Evaluation Metrics:\")\n",
        "print(f\"  Loss      : {test_loss:.4f}\")\n",
        "print(f\"  Accuracy  : {test_accuracy:.4f}\")\n",
        "print(f\"  Precision : {test_precision:.4f}\")\n",
        "print(f\"  Recall    : {test_recall:.4f}\")\n",
        "print(f\"  AUC       : {test_auc:.4f}\")\n"
      ],
      "metadata": {
        "id": "FaanMjPsMpYH",
        "outputId": "01b244ac-fbe9-429f-9862-f42cf01ecec9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6774 - auc: 0.6722 - loss: 0.6024 - precision: 0.6296 - recall: 0.2362 \n",
            "\n",
            "Test Evaluation Metrics:\n",
            "  Loss      : 0.6084\n",
            "  Accuracy  : 0.6706\n",
            "  Precision : 0.6491\n",
            "  Recall    : 0.2357\n",
            "  AUC       : 0.6794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Definition by member 3 (RMSprop variant)\n",
        "def model_david():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(128, input_shape=(X_train.shape[1],), activation=\"relu\",\n",
        "                                   kernel_regularizer=tf.keras.regularizers.l2(0.0005)))\n",
        "  model.add(tf.keras.layers.Dense(64, activation=\"relu\",\n",
        "                                   kernel_regularizer=tf.keras.regularizers.l2(0.0005)))\n",
        "  model.add(tf.keras.layers.Dense(32, activation=\"relu\",\n",
        "                                   kernel_regularizer=tf.keras.regularizers.l2(0.0005)))\n",
        "  model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\",\n",
        "                                   kernel_regularizer=tf.keras.regularizers.l2(0.0005)))\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "                loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "  return model\n",
        "\n",
        "model3 = model_david()\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping_3 = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=50,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history3 = model3.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=300,\n",
        "    batch_size=32,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping_3]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "0R8q1MuJ-mJd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec70c1af-61b9-4070-8d24-33b83221736d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6406 - loss: 0.7338 - val_accuracy: 0.6321 - val_loss: 0.7122\n",
            "Epoch 2/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6311 - loss: 0.7081 - val_accuracy: 0.6344 - val_loss: 0.6951\n",
            "Epoch 3/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6729 - loss: 0.6631 - val_accuracy: 0.6439 - val_loss: 0.6850\n",
            "Epoch 4/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6774 - loss: 0.6631 - val_accuracy: 0.6533 - val_loss: 0.6786\n",
            "Epoch 5/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6874 - loss: 0.6464 - val_accuracy: 0.6462 - val_loss: 0.6752\n",
            "Epoch 6/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6850 - loss: 0.6381 - val_accuracy: 0.6533 - val_loss: 0.6671\n",
            "Epoch 7/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6927 - loss: 0.6384 - val_accuracy: 0.6533 - val_loss: 0.6712\n",
            "Epoch 8/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7044 - loss: 0.6256 - val_accuracy: 0.6557 - val_loss: 0.6732\n",
            "Epoch 9/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7039 - loss: 0.6230 - val_accuracy: 0.6627 - val_loss: 0.6727\n",
            "Epoch 10/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7088 - loss: 0.6178 - val_accuracy: 0.6604 - val_loss: 0.6743\n",
            "Epoch 11/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7219 - loss: 0.6029 - val_accuracy: 0.6462 - val_loss: 0.6713\n",
            "Epoch 12/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7166 - loss: 0.6015 - val_accuracy: 0.6509 - val_loss: 0.6727\n",
            "Epoch 13/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7170 - loss: 0.5997 - val_accuracy: 0.6392 - val_loss: 0.6888\n",
            "Epoch 14/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7244 - loss: 0.5910 - val_accuracy: 0.6462 - val_loss: 0.6853\n",
            "Epoch 15/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7243 - loss: 0.5945 - val_accuracy: 0.6179 - val_loss: 0.6847\n",
            "Epoch 16/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7578 - loss: 0.5670 - val_accuracy: 0.6392 - val_loss: 0.6786\n",
            "Epoch 17/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7427 - loss: 0.5679 - val_accuracy: 0.6392 - val_loss: 0.6947\n",
            "Epoch 18/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7325 - loss: 0.5774 - val_accuracy: 0.6297 - val_loss: 0.6976\n",
            "Epoch 19/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7319 - loss: 0.5691 - val_accuracy: 0.6509 - val_loss: 0.7088\n",
            "Epoch 20/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7340 - loss: 0.5707 - val_accuracy: 0.6085 - val_loss: 0.7160\n",
            "Epoch 21/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7684 - loss: 0.5518 - val_accuracy: 0.6321 - val_loss: 0.7163\n",
            "Epoch 22/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7625 - loss: 0.5487 - val_accuracy: 0.5849 - val_loss: 0.7235\n",
            "Epoch 23/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7788 - loss: 0.5301 - val_accuracy: 0.6108 - val_loss: 0.7179\n",
            "Epoch 24/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7634 - loss: 0.5349 - val_accuracy: 0.6368 - val_loss: 0.7088\n",
            "Epoch 25/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7874 - loss: 0.5174 - val_accuracy: 0.6061 - val_loss: 0.7135\n",
            "Epoch 26/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8019 - loss: 0.5081 - val_accuracy: 0.5943 - val_loss: 0.7313\n",
            "Epoch 27/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7943 - loss: 0.5082 - val_accuracy: 0.6392 - val_loss: 0.7315\n",
            "Epoch 28/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7968 - loss: 0.5081 - val_accuracy: 0.6321 - val_loss: 0.7443\n",
            "Epoch 29/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8052 - loss: 0.4921 - val_accuracy: 0.6321 - val_loss: 0.7536\n",
            "Epoch 30/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8003 - loss: 0.4872 - val_accuracy: 0.6297 - val_loss: 0.7514\n",
            "Epoch 31/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8152 - loss: 0.4795 - val_accuracy: 0.6156 - val_loss: 0.7734\n",
            "Epoch 32/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8082 - loss: 0.4777 - val_accuracy: 0.6486 - val_loss: 0.7548\n",
            "Epoch 33/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8105 - loss: 0.4700 - val_accuracy: 0.6085 - val_loss: 0.7833\n",
            "Epoch 34/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8105 - loss: 0.4890 - val_accuracy: 0.5967 - val_loss: 0.7875\n",
            "Epoch 35/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8299 - loss: 0.4712 - val_accuracy: 0.5684 - val_loss: 0.8664\n",
            "Epoch 36/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8429 - loss: 0.4396 - val_accuracy: 0.6014 - val_loss: 0.8147\n",
            "Epoch 37/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8320 - loss: 0.4395 - val_accuracy: 0.6509 - val_loss: 0.8077\n",
            "Epoch 38/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8358 - loss: 0.4348 - val_accuracy: 0.5873 - val_loss: 0.8438\n",
            "Epoch 39/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8285 - loss: 0.4490 - val_accuracy: 0.6368 - val_loss: 0.8255\n",
            "Epoch 40/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8514 - loss: 0.4220 - val_accuracy: 0.6250 - val_loss: 0.9066\n",
            "Epoch 41/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.4328 - val_accuracy: 0.6061 - val_loss: 0.8517\n",
            "Epoch 42/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8217 - loss: 0.4350 - val_accuracy: 0.6580 - val_loss: 0.8509\n",
            "Epoch 43/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8619 - loss: 0.3953 - val_accuracy: 0.6038 - val_loss: 0.8532\n",
            "Epoch 44/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8499 - loss: 0.4069 - val_accuracy: 0.5212 - val_loss: 1.0192\n",
            "Epoch 45/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8492 - loss: 0.4132 - val_accuracy: 0.6297 - val_loss: 0.9075\n",
            "Epoch 46/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8507 - loss: 0.3921 - val_accuracy: 0.5708 - val_loss: 0.8934\n",
            "Epoch 47/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8591 - loss: 0.3953 - val_accuracy: 0.5967 - val_loss: 0.9100\n",
            "Epoch 48/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8606 - loss: 0.4029 - val_accuracy: 0.5778 - val_loss: 0.9879\n",
            "Epoch 49/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8687 - loss: 0.3806 - val_accuracy: 0.5542 - val_loss: 0.9894\n",
            "Epoch 50/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8694 - loss: 0.3843 - val_accuracy: 0.5613 - val_loss: 0.9725\n",
            "Epoch 51/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8670 - loss: 0.3805 - val_accuracy: 0.5708 - val_loss: 0.9840\n",
            "Epoch 52/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8817 - loss: 0.3741 - val_accuracy: 0.5943 - val_loss: 0.9413\n",
            "Epoch 53/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8758 - loss: 0.3693 - val_accuracy: 0.6179 - val_loss: 0.9696\n",
            "Epoch 54/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8714 - loss: 0.3545 - val_accuracy: 0.5472 - val_loss: 1.0711\n",
            "Epoch 55/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8860 - loss: 0.3557 - val_accuracy: 0.6297 - val_loss: 0.9886\n",
            "Epoch 56/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8829 - loss: 0.3529 - val_accuracy: 0.5802 - val_loss: 1.0934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get best epoch based on validation loss\n",
        "best_epoch = history3.history['val_loss'].index(min(history3.history['val_loss']))\n",
        "\n",
        "# Get train and validation accuracy at best epoch\n",
        "train_acc_at_best = history3.history['accuracy'][best_epoch]\n",
        "val_acc_at_best = history3.history['val_accuracy'][best_epoch]\n",
        "\n",
        "print(f\"Best Epoch: {best_epoch + 1}\")  # +1 for human-readable epoch number\n",
        "print(f\"Train Accuracy at Best Epoch: {train_acc_at_best:.4f}\")\n",
        "print(f\"Validation Accuracy at Best Epoch: {val_acc_at_best:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh4Z094Tl1oJ",
        "outputId": "bde8d2c3-6988-4ccf-d2f2-72b3983c05a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Epoch: 16\n",
            "Train Accuracy at Best Epoch: 0.7314\n",
            "Validation Accuracy at Best Epoch: 0.6934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_probs = model3.predict(X_test).ravel()\n",
        "\n",
        "# Predict binary classes\n",
        "y_pred_classes = (y_pred_probs > 0.5).astype(\"int32\")\n",
        "\n",
        "# Evaluate loss and accuracy\n",
        "test_loss, test_accuracy = model3.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "# Calculate precision, recall, and AUC\n",
        "test_precision = precision_score(y_test, y_pred_classes)\n",
        "test_recall = recall_score(y_test, y_pred_classes)\n",
        "test_auc = roc_auc_score(y_test, y_pred_probs)\n",
        "\n",
        "# Print results\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test AUC: {test_auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oczDl65Sl1SH",
        "outputId": "631daac1-8df3-43bb-b2fa-b3bdd6fa54f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Test Loss: 0.6773\n",
            "Test Accuracy: 0.6447\n",
            "Test Precision: 0.5238\n",
            "Test Recall: 0.4204\n",
            "Test AUC: 0.6710\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Definition by member 4\n",
        "!pip install tensorflow\n",
        "def model_tamanda_kaunda():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(96, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.001)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(48, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.0005)),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Dense(24, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.0005)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(12, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.0001)),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            tf.keras.metrics.Precision(name='precision'),\n",
        "            tf.keras.metrics.Recall(name='recall'),\n",
        "            tf.keras.metrics.AUC(name='auc')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "tamanda_model = model_tamanda_kaunda()\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=25,\n",
        "    min_delta=0.001,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = tamanda_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=200,\n",
        "    batch_size=64,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "TKoFpxX6_B7D",
        "outputId": "f95d5b6a-a24a-42ad-c3d5-c2b610485240",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.72.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Epoch 1/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.4463 - auc: 0.5332 - loss: 1.1428 - precision: 0.3732 - recall: 0.7309 - val_accuracy: 0.6274 - val_auc: 0.4925 - val_loss: 1.0695 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6230 - auc: 0.4940 - loss: 1.0611 - precision: 0.3601 - recall: 0.0689 - val_accuracy: 0.6297 - val_auc: 0.5098 - val_loss: 1.0241 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6345 - auc: 0.5051 - loss: 1.0148 - precision: 0.3592 - recall: 0.0110 - val_accuracy: 0.6297 - val_auc: 0.5214 - val_loss: 0.9831 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6309 - auc: 0.5008 - loss: 0.9795 - precision: 0.4844 - recall: 0.0026 - val_accuracy: 0.6297 - val_auc: 0.5325 - val_loss: 0.9436 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 5/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6331 - auc: 0.5260 - loss: 0.9342 - precision: 0.1250 - recall: 1.7456e-04 - val_accuracy: 0.6297 - val_auc: 0.5339 - val_loss: 0.9055 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 6/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6316 - auc: 0.5272 - loss: 0.8975 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5393 - val_loss: 0.8688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 7/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6519 - auc: 0.5612 - loss: 0.8455 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5392 - val_loss: 0.8346 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 8/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6346 - auc: 0.5408 - loss: 0.8254 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5367 - val_loss: 0.8036 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 9/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6253 - auc: 0.5705 - loss: 0.7946 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5513 - val_loss: 0.7765 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 10/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6183 - auc: 0.5825 - loss: 0.7707 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5511 - val_loss: 0.7532 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 11/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6382 - auc: 0.5677 - loss: 0.7417 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5494 - val_loss: 0.7351 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 12/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6228 - auc: 0.5574 - loss: 0.7344 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5598 - val_loss: 0.7207 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 13/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6250 - auc: 0.5921 - loss: 0.7145 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5509 - val_loss: 0.7103 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 14/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6350 - auc: 0.5876 - loss: 0.6981 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5547 - val_loss: 0.7016 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 15/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6305 - auc: 0.5961 - loss: 0.6956 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5634 - val_loss: 0.6948 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 16/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6310 - auc: 0.5950 - loss: 0.6895 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5690 - val_loss: 0.6887 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 17/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6265 - auc: 0.5831 - loss: 0.6890 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5731 - val_loss: 0.6842 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 18/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6224 - auc: 0.6086 - loss: 0.6814 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5803 - val_loss: 0.6802 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 19/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6330 - auc: 0.5996 - loss: 0.6772 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5833 - val_loss: 0.6775 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 20/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6418 - auc: 0.6377 - loss: 0.6595 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5924 - val_loss: 0.6749 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 21/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6359 - auc: 0.5946 - loss: 0.6729 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5990 - val_loss: 0.6726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 22/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6177 - auc: 0.6170 - loss: 0.6743 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5999 - val_loss: 0.6707 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 23/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6350 - auc: 0.6333 - loss: 0.6601 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5972 - val_loss: 0.6701 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 24/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6158 - auc: 0.6265 - loss: 0.6724 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6043 - val_loss: 0.6686 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 25/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6287 - auc: 0.6515 - loss: 0.6612 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6124 - val_loss: 0.6662 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 26/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6217 - auc: 0.6453 - loss: 0.6671 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6087 - val_loss: 0.6661 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 27/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6222 - auc: 0.6468 - loss: 0.6658 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6134 - val_loss: 0.6644 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 28/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6323 - auc: 0.6581 - loss: 0.6578 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6141 - val_loss: 0.6639 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 29/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6141 - auc: 0.6454 - loss: 0.6670 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6068 - val_loss: 0.6648 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 30/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6125 - auc: 0.6408 - loss: 0.6675 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6051 - val_loss: 0.6636 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 31/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6425 - auc: 0.6467 - loss: 0.6489 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6054 - val_loss: 0.6634 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 32/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6324 - auc: 0.6498 - loss: 0.6533 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6095 - val_loss: 0.6621 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 33/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6256 - auc: 0.6290 - loss: 0.6675 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6087 - val_loss: 0.6621 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 34/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6315 - auc: 0.6404 - loss: 0.6586 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6095 - val_loss: 0.6617 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 35/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6220 - auc: 0.6737 - loss: 0.6550 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6097 - val_loss: 0.6614 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 36/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6264 - auc: 0.6687 - loss: 0.6520 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6206 - val_loss: 0.6592 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 37/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6305 - auc: 0.6652 - loss: 0.6477 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6215 - val_loss: 0.6584 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 38/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6291 - auc: 0.6291 - loss: 0.6634 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6183 - val_loss: 0.6591 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 39/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6378 - auc: 0.6557 - loss: 0.6533 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6204 - val_loss: 0.6581 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 40/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6296 - auc: 0.6358 - loss: 0.6579 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6238 - val_loss: 0.6582 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 41/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6311 - auc: 0.6530 - loss: 0.6538 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6252 - val_loss: 0.6564 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 42/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6353 - auc: 0.6658 - loss: 0.6446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6233 - val_loss: 0.6579 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 43/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6204 - auc: 0.6553 - loss: 0.6635 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6219 - val_loss: 0.6576 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 44/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6215 - auc: 0.6628 - loss: 0.6572 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6277 - val_loss: 0.6568 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 45/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6403 - auc: 0.6598 - loss: 0.6451 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6301 - val_loss: 0.6562 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 46/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6419 - auc: 0.6307 - loss: 0.6548 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6294 - val_loss: 0.6561 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 47/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6423 - auc: 0.6636 - loss: 0.6460 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6306 - val_loss: 0.6553 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 48/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6334 - auc: 0.6261 - loss: 0.6619 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6333 - val_loss: 0.6570 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 49/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6240 - auc: 0.6527 - loss: 0.6590 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6295 - val_loss: 0.6562 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 50/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6389 - auc: 0.6506 - loss: 0.6516 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6348 - val_loss: 0.6560 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 51/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6161 - auc: 0.6520 - loss: 0.6586 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6358 - val_loss: 0.6549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 52/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6308 - auc: 0.6539 - loss: 0.6487 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6273 - val_loss: 0.6568 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 53/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6251 - auc: 0.6528 - loss: 0.6559 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6377 - val_loss: 0.6542 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 54/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6207 - auc: 0.6631 - loss: 0.6524 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6342 - val_loss: 0.6540 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 55/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6390 - auc: 0.6791 - loss: 0.6389 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6301 - val_loss: 0.6565 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 56/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6228 - auc: 0.6620 - loss: 0.6516 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6244 - val_loss: 0.6568 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 57/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6309 - auc: 0.6534 - loss: 0.6533 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6341 - val_loss: 0.6543 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 58/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6183 - auc: 0.6557 - loss: 0.6564 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6351 - val_loss: 0.6539 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 59/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6397 - auc: 0.6637 - loss: 0.6413 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6310 - val_loss: 0.6542 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 60/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6257 - auc: 0.6767 - loss: 0.6505 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6274 - val_loss: 0.6554 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 61/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6372 - auc: 0.6684 - loss: 0.6459 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6293 - val_loss: 0.6549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 62/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6467 - auc: 0.6673 - loss: 0.6411 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6281 - val_loss: 0.6542 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 63/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6306 - auc: 0.6824 - loss: 0.6407 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6323 - val_loss: 0.6545 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 64/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6213 - auc: 0.6726 - loss: 0.6535 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6335 - val_loss: 0.6536 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 65/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6192 - auc: 0.6752 - loss: 0.6457 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6302 - val_loss: 0.6538 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 66/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6194 - auc: 0.6742 - loss: 0.6528 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6318 - val_loss: 0.6545 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 67/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6372 - auc: 0.6769 - loss: 0.6397 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6303 - val_loss: 0.6546 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 68/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6193 - auc: 0.6576 - loss: 0.6561 - precision: 0.5417 - recall: 0.0112 - val_accuracy: 0.6297 - val_auc: 0.6324 - val_loss: 0.6536 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 69/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6559 - auc: 0.6678 - loss: 0.6338 - precision: 0.1268 - recall: 0.0015 - val_accuracy: 0.6297 - val_auc: 0.6271 - val_loss: 0.6559 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 70/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6372 - auc: 0.6548 - loss: 0.6503 - precision: 0.5201 - recall: 0.0368 - val_accuracy: 0.6297 - val_auc: 0.6282 - val_loss: 0.6553 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 71/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6360 - auc: 0.6539 - loss: 0.6495 - precision: 0.5548 - recall: 0.0467 - val_accuracy: 0.6297 - val_auc: 0.6285 - val_loss: 0.6551 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 72/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6347 - auc: 0.6632 - loss: 0.6529 - precision: 0.6491 - recall: 0.0495 - val_accuracy: 0.6297 - val_auc: 0.6332 - val_loss: 0.6543 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 73/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6416 - auc: 0.6685 - loss: 0.6482 - precision: 0.6287 - recall: 0.0601 - val_accuracy: 0.6344 - val_auc: 0.6326 - val_loss: 0.6539 - val_precision: 0.6667 - val_recall: 0.0255\n",
            "Epoch 74/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6425 - auc: 0.6548 - loss: 0.6533 - precision: 0.6257 - recall: 0.0898 - val_accuracy: 0.6297 - val_auc: 0.6294 - val_loss: 0.6537 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 75/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6416 - auc: 0.6370 - loss: 0.6509 - precision: 0.4766 - recall: 0.0302 - val_accuracy: 0.6297 - val_auc: 0.6241 - val_loss: 0.6561 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 76/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6508 - auc: 0.6453 - loss: 0.6559 - precision: 0.7438 - recall: 0.0802 - val_accuracy: 0.6297 - val_auc: 0.6266 - val_loss: 0.6555 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 77/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6408 - auc: 0.6636 - loss: 0.6557 - precision: 0.7694 - recall: 0.0606 - val_accuracy: 0.6297 - val_auc: 0.6321 - val_loss: 0.6537 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 78/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6366 - auc: 0.6601 - loss: 0.6505 - precision: 0.7251 - recall: 0.0238 - val_accuracy: 0.6297 - val_auc: 0.6324 - val_loss: 0.6541 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_epoch = np.argmin(history.history['val_loss'])\n",
        "print(f\"Best Epoch: {best_epoch+1}\")\n",
        "print(f\"Train Accuracy at Best Epoch: {history.history['accuracy'][best_epoch]:.4f}\")\n",
        "print(f\"Val Accuracy at Best Epoch: {history.history['val_accuracy'][best_epoch]:.4f}\")"
      ],
      "metadata": {
        "id": "UBK6hXpY5xre",
        "outputId": "f49bdc35-300d-469e-982e-2f054bf30eec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Epoch: 68\n",
            "Train Accuracy at Best Epoch: 0.6360\n",
            "Val Accuracy at Best Epoch: 0.6297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy, test_precision, test_recall, test_auc = tamanda_model.evaluate(X_test, y_test, verbose=1)\n",
        "\n",
        "# Print results with clear formatting\n",
        "print(\"\\nTest Evaluation Metrics:\")\n",
        "print(f\"  Loss      : {test_loss:.4f}\")\n",
        "print(f\"  Accuracy  : {test_accuracy:.4f}\")\n",
        "print(f\"  Precision : {test_precision:.4f}\")\n",
        "print(f\"  Recall    : {test_recall:.4f}\")\n",
        "print(f\"  AUC       : {test_auc:.4f}\")"
      ],
      "metadata": {
        "id": "_5tLv1NT56Xr",
        "outputId": "7558206d-eb00-4ff3-9efa-3f877dcc71cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6436 - auc: 0.6549 - loss: 0.6440 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
            "\n",
            "Test Evaluation Metrics:\n",
            "  Loss      : 0.6459\n",
            "  Accuracy  : 0.6306\n",
            "  Precision : 0.0000\n",
            "  Recall    : 0.0000\n",
            "  AUC       : 0.6799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Definition by member 5\n",
        "def model_rene_ntabana():\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(128, input_shape=(X_train.shape[1],),\n",
        "                                     activation=\"relu\",\n",
        "                                     kernel_regularizer=tf.keras.regularizers.l1(0.0001),\n",
        "                                     name='dense_layer'))\n",
        "    model.add(tf.keras.layers.Dropout(0.4))  # Slightly less dropout\n",
        "    model.add(tf.keras.layers.Dense(64,\n",
        "                                     activation='relu',\n",
        "                                     kernel_regularizer=tf.keras.regularizers.l1(0.00005),\n",
        "                                     name='dense_layer2'))\n",
        "    model.add(tf.keras.layers.Dropout(0.4))\n",
        "    model.add(tf.keras.layers.Dense(32,\n",
        "                                     activation='relu',\n",
        "                                     kernel_regularizer=tf.keras.regularizers.l1(0.00005),\n",
        "                                     name='dense_layer3'))\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "    model.add(tf.keras.layers.Dense(1,\n",
        "                                     activation='sigmoid',\n",
        "                                     kernel_regularizer=tf.keras.regularizers.l1(0.00001),\n",
        "                                     name='output_layer'))\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "model = model_rene_ntabana()\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=30,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=200,\n",
        "    batch_size=32,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping]\n",
        ")\n"
      ],
      "metadata": {
        "id": "Dd3m8M3dKcfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76ca4776-ef76-4fb2-b48e-b08825ffe5c7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5109 - loss: 0.7801 - val_accuracy: 0.6297 - val_loss: 0.7208\n",
            "Epoch 2/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6196 - loss: 0.7306 - val_accuracy: 0.6297 - val_loss: 0.7153\n",
            "Epoch 3/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6268 - loss: 0.7253 - val_accuracy: 0.6297 - val_loss: 0.7131\n",
            "Epoch 4/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6344 - loss: 0.7198 - val_accuracy: 0.6297 - val_loss: 0.7134\n",
            "Epoch 5/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6146 - loss: 0.7177 - val_accuracy: 0.6297 - val_loss: 0.7091\n",
            "Epoch 6/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6322 - loss: 0.7211 - val_accuracy: 0.6297 - val_loss: 0.7076\n",
            "Epoch 7/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6220 - loss: 0.7198 - val_accuracy: 0.6297 - val_loss: 0.7027\n",
            "Epoch 8/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6154 - loss: 0.7173 - val_accuracy: 0.6321 - val_loss: 0.7014\n",
            "Epoch 9/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6257 - loss: 0.7181 - val_accuracy: 0.6368 - val_loss: 0.6994\n",
            "Epoch 10/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6530 - loss: 0.6988 - val_accuracy: 0.6439 - val_loss: 0.6940\n",
            "Epoch 11/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6425 - loss: 0.6943 - val_accuracy: 0.6486 - val_loss: 0.6917\n",
            "Epoch 12/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6406 - loss: 0.6945 - val_accuracy: 0.6486 - val_loss: 0.6884\n",
            "Epoch 13/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6620 - loss: 0.6803 - val_accuracy: 0.6580 - val_loss: 0.6857\n",
            "Epoch 14/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6292 - loss: 0.6974 - val_accuracy: 0.6486 - val_loss: 0.6839\n",
            "Epoch 15/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6576 - loss: 0.6779 - val_accuracy: 0.6557 - val_loss: 0.6830\n",
            "Epoch 16/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6602 - loss: 0.6819 - val_accuracy: 0.6580 - val_loss: 0.6806\n",
            "Epoch 17/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6439 - loss: 0.6820 - val_accuracy: 0.6651 - val_loss: 0.6766\n",
            "Epoch 18/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6675 - loss: 0.6774 - val_accuracy: 0.6627 - val_loss: 0.6772\n",
            "Epoch 19/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6626 - loss: 0.6822 - val_accuracy: 0.6580 - val_loss: 0.6748\n",
            "Epoch 20/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6602 - loss: 0.6751 - val_accuracy: 0.6627 - val_loss: 0.6725\n",
            "Epoch 21/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6630 - loss: 0.6843 - val_accuracy: 0.6580 - val_loss: 0.6707\n",
            "Epoch 22/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6618 - loss: 0.6658 - val_accuracy: 0.6604 - val_loss: 0.6702\n",
            "Epoch 23/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6517 - loss: 0.6758 - val_accuracy: 0.6533 - val_loss: 0.6701\n",
            "Epoch 24/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6681 - loss: 0.6622 - val_accuracy: 0.6557 - val_loss: 0.6664\n",
            "Epoch 25/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6627 - loss: 0.6724 - val_accuracy: 0.6627 - val_loss: 0.6680\n",
            "Epoch 26/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6751 - loss: 0.6592 - val_accuracy: 0.6627 - val_loss: 0.6662\n",
            "Epoch 27/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6710 - loss: 0.6805 - val_accuracy: 0.6675 - val_loss: 0.6662\n",
            "Epoch 28/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6597 - loss: 0.6539 - val_accuracy: 0.6722 - val_loss: 0.6661\n",
            "Epoch 29/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6680 - loss: 0.6625 - val_accuracy: 0.6769 - val_loss: 0.6622\n",
            "Epoch 30/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6912 - loss: 0.6537 - val_accuracy: 0.6722 - val_loss: 0.6606\n",
            "Epoch 31/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6610 - loss: 0.6689 - val_accuracy: 0.6698 - val_loss: 0.6633\n",
            "Epoch 32/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6613 - loss: 0.6720 - val_accuracy: 0.6698 - val_loss: 0.6647\n",
            "Epoch 33/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6870 - loss: 0.6488 - val_accuracy: 0.6651 - val_loss: 0.6615\n",
            "Epoch 34/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6799 - loss: 0.6647 - val_accuracy: 0.6651 - val_loss: 0.6639\n",
            "Epoch 35/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6815 - loss: 0.6540 - val_accuracy: 0.6604 - val_loss: 0.6632\n",
            "Epoch 36/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6844 - loss: 0.6439 - val_accuracy: 0.6675 - val_loss: 0.6625\n",
            "Epoch 37/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6586 - loss: 0.6618 - val_accuracy: 0.6627 - val_loss: 0.6622\n",
            "Epoch 38/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6695 - loss: 0.6517 - val_accuracy: 0.6604 - val_loss: 0.6632\n",
            "Epoch 39/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6752 - loss: 0.6547 - val_accuracy: 0.6627 - val_loss: 0.6641\n",
            "Epoch 40/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6705 - loss: 0.6592 - val_accuracy: 0.6698 - val_loss: 0.6619\n",
            "Epoch 41/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6636 - loss: 0.6551 - val_accuracy: 0.6722 - val_loss: 0.6595\n",
            "Epoch 42/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6835 - loss: 0.6498 - val_accuracy: 0.6792 - val_loss: 0.6575\n",
            "Epoch 43/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6796 - loss: 0.6524 - val_accuracy: 0.6816 - val_loss: 0.6578\n",
            "Epoch 44/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6833 - loss: 0.6594 - val_accuracy: 0.6745 - val_loss: 0.6566\n",
            "Epoch 45/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6880 - loss: 0.6401 - val_accuracy: 0.6675 - val_loss: 0.6563\n",
            "Epoch 46/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6825 - loss: 0.6398 - val_accuracy: 0.6745 - val_loss: 0.6552\n",
            "Epoch 47/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6903 - loss: 0.6335 - val_accuracy: 0.6722 - val_loss: 0.6551\n",
            "Epoch 48/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6783 - loss: 0.6355 - val_accuracy: 0.6698 - val_loss: 0.6587\n",
            "Epoch 49/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6939 - loss: 0.6428 - val_accuracy: 0.6769 - val_loss: 0.6566\n",
            "Epoch 50/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6829 - loss: 0.6358 - val_accuracy: 0.6745 - val_loss: 0.6558\n",
            "Epoch 51/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6614 - loss: 0.6503 - val_accuracy: 0.6840 - val_loss: 0.6540\n",
            "Epoch 52/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6729 - loss: 0.6608 - val_accuracy: 0.6840 - val_loss: 0.6542\n",
            "Epoch 53/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6739 - loss: 0.6488 - val_accuracy: 0.6769 - val_loss: 0.6550\n",
            "Epoch 54/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6993 - loss: 0.6297 - val_accuracy: 0.6651 - val_loss: 0.6565\n",
            "Epoch 55/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6893 - loss: 0.6442 - val_accuracy: 0.6745 - val_loss: 0.6571\n",
            "Epoch 56/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6647 - loss: 0.6459 - val_accuracy: 0.6745 - val_loss: 0.6592\n",
            "Epoch 57/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6819 - loss: 0.6440 - val_accuracy: 0.6675 - val_loss: 0.6569\n",
            "Epoch 58/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6679 - loss: 0.6485 - val_accuracy: 0.6675 - val_loss: 0.6550\n",
            "Epoch 59/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6835 - loss: 0.6427 - val_accuracy: 0.6792 - val_loss: 0.6536\n",
            "Epoch 60/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6743 - loss: 0.6440 - val_accuracy: 0.6604 - val_loss: 0.6546\n",
            "Epoch 61/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6760 - loss: 0.6341 - val_accuracy: 0.6816 - val_loss: 0.6551\n",
            "Epoch 62/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6799 - loss: 0.6369 - val_accuracy: 0.6557 - val_loss: 0.6544\n",
            "Epoch 63/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7078 - loss: 0.6262 - val_accuracy: 0.6722 - val_loss: 0.6517\n",
            "Epoch 64/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6814 - loss: 0.6342 - val_accuracy: 0.6745 - val_loss: 0.6539\n",
            "Epoch 65/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7012 - loss: 0.6133 - val_accuracy: 0.6722 - val_loss: 0.6527\n",
            "Epoch 66/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6750 - loss: 0.6382 - val_accuracy: 0.6698 - val_loss: 0.6515\n",
            "Epoch 67/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6786 - loss: 0.6475 - val_accuracy: 0.6604 - val_loss: 0.6521\n",
            "Epoch 68/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6775 - loss: 0.6400 - val_accuracy: 0.6604 - val_loss: 0.6496\n",
            "Epoch 69/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6786 - loss: 0.6230 - val_accuracy: 0.6722 - val_loss: 0.6518\n",
            "Epoch 70/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6945 - loss: 0.6257 - val_accuracy: 0.6627 - val_loss: 0.6500\n",
            "Epoch 71/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6929 - loss: 0.6255 - val_accuracy: 0.6627 - val_loss: 0.6527\n",
            "Epoch 72/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6919 - loss: 0.6237 - val_accuracy: 0.6675 - val_loss: 0.6506\n",
            "Epoch 73/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6845 - loss: 0.6324 - val_accuracy: 0.6580 - val_loss: 0.6473\n",
            "Epoch 74/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6951 - loss: 0.6142 - val_accuracy: 0.6627 - val_loss: 0.6459\n",
            "Epoch 75/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7065 - loss: 0.6095 - val_accuracy: 0.6557 - val_loss: 0.6468\n",
            "Epoch 76/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6836 - loss: 0.6266 - val_accuracy: 0.6580 - val_loss: 0.6479\n",
            "Epoch 77/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6804 - loss: 0.6279 - val_accuracy: 0.6604 - val_loss: 0.6475\n",
            "Epoch 78/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6880 - loss: 0.6437 - val_accuracy: 0.6533 - val_loss: 0.6464\n",
            "Epoch 79/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6987 - loss: 0.6245 - val_accuracy: 0.6627 - val_loss: 0.6457\n",
            "Epoch 80/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6905 - loss: 0.6307 - val_accuracy: 0.6557 - val_loss: 0.6475\n",
            "Epoch 81/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6870 - loss: 0.6296 - val_accuracy: 0.6486 - val_loss: 0.6513\n",
            "Epoch 82/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6935 - loss: 0.6169 - val_accuracy: 0.6439 - val_loss: 0.6519\n",
            "Epoch 83/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6998 - loss: 0.6134 - val_accuracy: 0.6462 - val_loss: 0.6536\n",
            "Epoch 84/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6975 - loss: 0.6148 - val_accuracy: 0.6509 - val_loss: 0.6537\n",
            "Epoch 85/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7157 - loss: 0.6134 - val_accuracy: 0.6533 - val_loss: 0.6521\n",
            "Epoch 86/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6972 - loss: 0.6225 - val_accuracy: 0.6557 - val_loss: 0.6512\n",
            "Epoch 87/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6894 - loss: 0.6245 - val_accuracy: 0.6557 - val_loss: 0.6503\n",
            "Epoch 88/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6988 - loss: 0.6186 - val_accuracy: 0.6557 - val_loss: 0.6504\n",
            "Epoch 89/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6952 - loss: 0.6111 - val_accuracy: 0.6604 - val_loss: 0.6514\n",
            "Epoch 90/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7215 - loss: 0.5999 - val_accuracy: 0.6509 - val_loss: 0.6514\n",
            "Epoch 91/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7092 - loss: 0.6122 - val_accuracy: 0.6486 - val_loss: 0.6526\n",
            "Epoch 92/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7016 - loss: 0.6066 - val_accuracy: 0.6415 - val_loss: 0.6551\n",
            "Epoch 93/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6938 - loss: 0.6081 - val_accuracy: 0.6462 - val_loss: 0.6520\n",
            "Epoch 94/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6990 - loss: 0.6237 - val_accuracy: 0.6509 - val_loss: 0.6490\n",
            "Epoch 95/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7013 - loss: 0.6203 - val_accuracy: 0.6486 - val_loss: 0.6499\n",
            "Epoch 96/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7026 - loss: 0.6107 - val_accuracy: 0.6486 - val_loss: 0.6513\n",
            "Epoch 97/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6879 - loss: 0.6288 - val_accuracy: 0.6486 - val_loss: 0.6495\n",
            "Epoch 98/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7148 - loss: 0.5917 - val_accuracy: 0.6533 - val_loss: 0.6470\n",
            "Epoch 99/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7161 - loss: 0.5985 - val_accuracy: 0.6509 - val_loss: 0.6503\n",
            "Epoch 100/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7026 - loss: 0.6055 - val_accuracy: 0.6580 - val_loss: 0.6482\n",
            "Epoch 101/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7257 - loss: 0.5997 - val_accuracy: 0.6439 - val_loss: 0.6516\n",
            "Epoch 102/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6953 - loss: 0.6221 - val_accuracy: 0.6557 - val_loss: 0.6531\n",
            "Epoch 103/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7119 - loss: 0.6159 - val_accuracy: 0.6509 - val_loss: 0.6514\n",
            "Epoch 104/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7368 - loss: 0.5888 - val_accuracy: 0.6580 - val_loss: 0.6519\n",
            "Epoch 105/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7115 - loss: 0.6001 - val_accuracy: 0.6439 - val_loss: 0.6519\n",
            "Epoch 106/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6989 - loss: 0.6150 - val_accuracy: 0.6486 - val_loss: 0.6484\n",
            "Epoch 107/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6978 - loss: 0.5953 - val_accuracy: 0.6509 - val_loss: 0.6484\n",
            "Epoch 108/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7276 - loss: 0.5900 - val_accuracy: 0.6321 - val_loss: 0.6490\n",
            "Epoch 109/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7384 - loss: 0.5862 - val_accuracy: 0.6486 - val_loss: 0.6492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_epoch = np.argmin(history.history['val_loss'])\n",
        "print(f\"Best Epoch: {best_epoch+1}\")\n",
        "print(f\"Train Accuracy at Best Epoch: {history.history['accuracy'][best_epoch]:.4f}\")\n",
        "print(f\"Val Accuracy at Best Epoch: {history.history['val_accuracy'][best_epoch]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwhNaHTQDB5p",
        "outputId": "9d99f303-9443-4225-e870-4878ed3465b5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Epoch: 79\n",
            "Train Accuracy at Best Epoch: 0.6966\n",
            "Val Accuracy at Best Epoch: 0.6627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7ZHFQ1KDJJ9",
        "outputId": "fa5665f7-e45f-4f26-f40d-3bb602a9e643"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6721 - loss: 0.6790 \n",
            "Test Loss: 0.6428, Test Accuracy: 0.6918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Classification report and Confusion Matrix\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_probs = model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to binary class predictions (threshold = 0.5)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "# Classification report\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize confusion matrix\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Pred 0\", \"Pred 1\"], yticklabels=[\"True 0\", \"True 1\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "0dGqgFKyDMkM",
        "outputId": "c169ba6d-c782-492b-b3eb-c7c219916d16"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6930    0.9179    0.7897       268\n",
            "           1     0.6857    0.3057    0.4229       157\n",
            "\n",
            "    accuracy                         0.6918       425\n",
            "   macro avg     0.6893    0.6118    0.6063       425\n",
            "weighted avg     0.6903    0.6918    0.6542       425\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start the training Process"
      ],
      "metadata": {
        "id": "hDSPmAB9jkrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#fit model\n",
        "history = model.fit(X, Y, validation_data=(testX, testy), epochs=4000, verbose=0, callbacks=[es])\n",
        "# evaluate the model\n",
        "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
        "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
        "# plot training history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "OWQHapf3jlYH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "ff09317e-ae97-4661-ac6d-602530c1db74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Y' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-fd04eeab69b9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Y' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy"
      ],
      "metadata": {
        "id": "dKZ2T8TOIYxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Loading and Preprocessing\n",
        "# The coach will never do this!!\n",
        "regularizer = 'l1'"
      ],
      "metadata": {
        "id": "qMNag3BGIuwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(32, activation ='relu', kernel_regularizer= regularizer , input_shape = (2224,224)))\n",
        "model.add(Dropout(0.2))\n",
        "#adding Dropout\n",
        "model.add(Dense(64, activation ='relu', kernel_regularizer= regularizer , input_shape = (2224,224)))\n",
        "#adding Dropout\n",
        "model.add(Dense(128, activation ='relu', kernel_regularizer= regularizer , input_shape = (2224,224)))\n",
        "model.add(Dropout(0.2))\n",
        "#adding Dropout\n",
        "model.add(Dense(2, activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "fsmEC739I4lG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback =EarlyStopping(monitor='loss',patience=3)"
      ],
      "metadata": {
        "id": "BbyPgkZlLu37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss= 'rmse', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "Fw9XQj_ZMWUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, Y, epochs=1000, batch_size= 128, callbacks=[callback], verbose=0)"
      ],
      "metadata": {
        "id": "GPhb-1k7LGx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "wLlhrOCpJWF5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}