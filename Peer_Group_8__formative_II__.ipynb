{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrXv0rU9sIma"
      },
      "source": [
        "# Excercise - Creating our own custom Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJyZUDbzBTIG"
      },
      "source": [
        "This is a notebook that provides a quick overview of how to create your own custom model. You will be creating a simple model.\n",
        "You will be utilizing Keras and Tensorflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvLegMMvBZYg"
      },
      "source": [
        "## Water Quality Dataset\n",
        "\n",
        "This dataset contains water quality measurements and assessments related to potability, which is the suitability of water for human consumption. The dataset's primary objective is to provide insights into water quality parameters and assist in determining whether the water is potable or not. Each row in the dataset represents a water sample with specific attributes, and the \"Potability\" column indicates whether the water is suitable for consumption.\n",
        "\n",
        "https://www.kaggle.com/datasets/uom190346a/water-quality-and-potability?select=water_potability.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LOAD THE DATA\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"/content/water_potability.csv\")\n",
        "\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "\n",
        "data.head(20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "id": "Qvnx0_dT3JEq",
        "outputId": "3d13cea4-79d7-4082-b16d-d2596521ad3c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           ph    Hardness        Solids  Chloramines     Sulfate  \\\n",
              "0         NaN  204.890455  20791.318981     7.300212  368.516441   \n",
              "1    3.716080  129.422921  18630.057858     6.635246         NaN   \n",
              "2    8.099124  224.236259  19909.541732     9.275884         NaN   \n",
              "3    8.316766  214.373394  22018.417441     8.059332  356.886136   \n",
              "4    9.092223  181.101509  17978.986339     6.546600  310.135738   \n",
              "5    5.584087  188.313324  28748.687739     7.544869  326.678363   \n",
              "6   10.223862  248.071735  28749.716544     7.513408  393.663396   \n",
              "7    8.635849  203.361523  13672.091764     4.563009  303.309771   \n",
              "8         NaN  118.988579  14285.583854     7.804174  268.646941   \n",
              "9   11.180284  227.231469  25484.508491     9.077200  404.041635   \n",
              "10   7.360640  165.520797  32452.614409     7.550701  326.624353   \n",
              "11   7.974522  218.693300  18767.656682     8.110385         NaN   \n",
              "12   7.119824  156.704993  18730.813653     3.606036  282.344050   \n",
              "13        NaN  150.174923  27331.361962     6.838223  299.415781   \n",
              "14   7.496232  205.344982  28388.004887     5.072558         NaN   \n",
              "15   6.347272  186.732881  41065.234765     9.629596  364.487687   \n",
              "16   7.051786  211.049406  30980.600787    10.094796         NaN   \n",
              "17   9.181560  273.813807  24041.326280     6.904990  398.350517   \n",
              "18   8.975464  279.357167  19460.398131     6.204321         NaN   \n",
              "19   7.371050  214.496610  25630.320037     4.432669  335.754439   \n",
              "\n",
              "    Conductivity  Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
              "0     564.308654       10.379783        86.990970   2.963135           0  \n",
              "1     592.885359       15.180013        56.329076   4.500656           0  \n",
              "2     418.606213       16.868637        66.420093   3.055934           0  \n",
              "3     363.266516       18.436524       100.341674   4.628771           0  \n",
              "4     398.410813       11.558279        31.997993   4.075075           0  \n",
              "5     280.467916        8.399735        54.917862   2.559708           0  \n",
              "6     283.651634       13.789695        84.603556   2.672989           0  \n",
              "7     474.607645       12.363817        62.798309   4.401425           0  \n",
              "8     389.375566       12.706049        53.928846   3.595017           0  \n",
              "9     563.885481       17.927806        71.976601   4.370562           0  \n",
              "10    425.383419       15.586810        78.740016   3.662292           0  \n",
              "11    364.098230       14.525746        76.485911   4.011718           0  \n",
              "12    347.715027       15.929536        79.500778   3.445756           0  \n",
              "13    379.761835       19.370807        76.509996   4.413974           0  \n",
              "14    444.645352       13.228311        70.300213   4.777382           0  \n",
              "15    516.743282       11.539781        75.071617   4.376348           0  \n",
              "16    315.141267       20.397022        56.651604   4.268429           0  \n",
              "17    477.974642       13.387341        71.457362   4.503661           0  \n",
              "18    431.443990       12.888759        63.821237   2.436086           0  \n",
              "19    469.914551       12.509164        62.797277   2.560299           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d2b8da8-18f2-43b0-9f0a-232d033678b9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>204.890455</td>\n",
              "      <td>20791.318981</td>\n",
              "      <td>7.300212</td>\n",
              "      <td>368.516441</td>\n",
              "      <td>564.308654</td>\n",
              "      <td>10.379783</td>\n",
              "      <td>86.990970</td>\n",
              "      <td>2.963135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.716080</td>\n",
              "      <td>129.422921</td>\n",
              "      <td>18630.057858</td>\n",
              "      <td>6.635246</td>\n",
              "      <td>NaN</td>\n",
              "      <td>592.885359</td>\n",
              "      <td>15.180013</td>\n",
              "      <td>56.329076</td>\n",
              "      <td>4.500656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.099124</td>\n",
              "      <td>224.236259</td>\n",
              "      <td>19909.541732</td>\n",
              "      <td>9.275884</td>\n",
              "      <td>NaN</td>\n",
              "      <td>418.606213</td>\n",
              "      <td>16.868637</td>\n",
              "      <td>66.420093</td>\n",
              "      <td>3.055934</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.316766</td>\n",
              "      <td>214.373394</td>\n",
              "      <td>22018.417441</td>\n",
              "      <td>8.059332</td>\n",
              "      <td>356.886136</td>\n",
              "      <td>363.266516</td>\n",
              "      <td>18.436524</td>\n",
              "      <td>100.341674</td>\n",
              "      <td>4.628771</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.092223</td>\n",
              "      <td>181.101509</td>\n",
              "      <td>17978.986339</td>\n",
              "      <td>6.546600</td>\n",
              "      <td>310.135738</td>\n",
              "      <td>398.410813</td>\n",
              "      <td>11.558279</td>\n",
              "      <td>31.997993</td>\n",
              "      <td>4.075075</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.584087</td>\n",
              "      <td>188.313324</td>\n",
              "      <td>28748.687739</td>\n",
              "      <td>7.544869</td>\n",
              "      <td>326.678363</td>\n",
              "      <td>280.467916</td>\n",
              "      <td>8.399735</td>\n",
              "      <td>54.917862</td>\n",
              "      <td>2.559708</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10.223862</td>\n",
              "      <td>248.071735</td>\n",
              "      <td>28749.716544</td>\n",
              "      <td>7.513408</td>\n",
              "      <td>393.663396</td>\n",
              "      <td>283.651634</td>\n",
              "      <td>13.789695</td>\n",
              "      <td>84.603556</td>\n",
              "      <td>2.672989</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8.635849</td>\n",
              "      <td>203.361523</td>\n",
              "      <td>13672.091764</td>\n",
              "      <td>4.563009</td>\n",
              "      <td>303.309771</td>\n",
              "      <td>474.607645</td>\n",
              "      <td>12.363817</td>\n",
              "      <td>62.798309</td>\n",
              "      <td>4.401425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NaN</td>\n",
              "      <td>118.988579</td>\n",
              "      <td>14285.583854</td>\n",
              "      <td>7.804174</td>\n",
              "      <td>268.646941</td>\n",
              "      <td>389.375566</td>\n",
              "      <td>12.706049</td>\n",
              "      <td>53.928846</td>\n",
              "      <td>3.595017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>11.180284</td>\n",
              "      <td>227.231469</td>\n",
              "      <td>25484.508491</td>\n",
              "      <td>9.077200</td>\n",
              "      <td>404.041635</td>\n",
              "      <td>563.885481</td>\n",
              "      <td>17.927806</td>\n",
              "      <td>71.976601</td>\n",
              "      <td>4.370562</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>7.360640</td>\n",
              "      <td>165.520797</td>\n",
              "      <td>32452.614409</td>\n",
              "      <td>7.550701</td>\n",
              "      <td>326.624353</td>\n",
              "      <td>425.383419</td>\n",
              "      <td>15.586810</td>\n",
              "      <td>78.740016</td>\n",
              "      <td>3.662292</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>7.974522</td>\n",
              "      <td>218.693300</td>\n",
              "      <td>18767.656682</td>\n",
              "      <td>8.110385</td>\n",
              "      <td>NaN</td>\n",
              "      <td>364.098230</td>\n",
              "      <td>14.525746</td>\n",
              "      <td>76.485911</td>\n",
              "      <td>4.011718</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>7.119824</td>\n",
              "      <td>156.704993</td>\n",
              "      <td>18730.813653</td>\n",
              "      <td>3.606036</td>\n",
              "      <td>282.344050</td>\n",
              "      <td>347.715027</td>\n",
              "      <td>15.929536</td>\n",
              "      <td>79.500778</td>\n",
              "      <td>3.445756</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>NaN</td>\n",
              "      <td>150.174923</td>\n",
              "      <td>27331.361962</td>\n",
              "      <td>6.838223</td>\n",
              "      <td>299.415781</td>\n",
              "      <td>379.761835</td>\n",
              "      <td>19.370807</td>\n",
              "      <td>76.509996</td>\n",
              "      <td>4.413974</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>7.496232</td>\n",
              "      <td>205.344982</td>\n",
              "      <td>28388.004887</td>\n",
              "      <td>5.072558</td>\n",
              "      <td>NaN</td>\n",
              "      <td>444.645352</td>\n",
              "      <td>13.228311</td>\n",
              "      <td>70.300213</td>\n",
              "      <td>4.777382</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>6.347272</td>\n",
              "      <td>186.732881</td>\n",
              "      <td>41065.234765</td>\n",
              "      <td>9.629596</td>\n",
              "      <td>364.487687</td>\n",
              "      <td>516.743282</td>\n",
              "      <td>11.539781</td>\n",
              "      <td>75.071617</td>\n",
              "      <td>4.376348</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>7.051786</td>\n",
              "      <td>211.049406</td>\n",
              "      <td>30980.600787</td>\n",
              "      <td>10.094796</td>\n",
              "      <td>NaN</td>\n",
              "      <td>315.141267</td>\n",
              "      <td>20.397022</td>\n",
              "      <td>56.651604</td>\n",
              "      <td>4.268429</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>9.181560</td>\n",
              "      <td>273.813807</td>\n",
              "      <td>24041.326280</td>\n",
              "      <td>6.904990</td>\n",
              "      <td>398.350517</td>\n",
              "      <td>477.974642</td>\n",
              "      <td>13.387341</td>\n",
              "      <td>71.457362</td>\n",
              "      <td>4.503661</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>8.975464</td>\n",
              "      <td>279.357167</td>\n",
              "      <td>19460.398131</td>\n",
              "      <td>6.204321</td>\n",
              "      <td>NaN</td>\n",
              "      <td>431.443990</td>\n",
              "      <td>12.888759</td>\n",
              "      <td>63.821237</td>\n",
              "      <td>2.436086</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>7.371050</td>\n",
              "      <td>214.496610</td>\n",
              "      <td>25630.320037</td>\n",
              "      <td>4.432669</td>\n",
              "      <td>335.754439</td>\n",
              "      <td>469.914551</td>\n",
              "      <td>12.509164</td>\n",
              "      <td>62.797277</td>\n",
              "      <td>2.560299</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d2b8da8-18f2-43b0-9f0a-232d033678b9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4d2b8da8-18f2-43b0-9f0a-232d033678b9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4d2b8da8-18f2-43b0-9f0a-232d033678b9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-836adeb4-c466-40fe-bc2b-f8dbdb8f5716\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-836adeb4-c466-40fe-bc2b-f8dbdb8f5716')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-836adeb4-c466-40fe-bc2b-f8dbdb8f5716 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 3276,\n  \"fields\": [\n    {\n      \"column\": \"ph\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5943195187088104,\n        \"min\": 0.0,\n        \"max\": 13.999999999999998,\n        \"num_unique_values\": 2785,\n        \"samples\": [\n          6.569053876389385,\n          9.271355446767778,\n          8.92790592593881\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hardness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32.879761476294156,\n        \"min\": 47.432,\n        \"max\": 323.124,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          183.5211070261417,\n          188.9135411469536,\n          224.05887682392927\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8768.570827785927,\n        \"min\": 320.942611274359,\n        \"max\": 61227.19600771213,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          20461.252710219946,\n          32873.820021715685,\n          23264.10996772913\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chloramines\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5830848890397096,\n        \"min\": 0.3520000000000003,\n        \"max\": 13.127000000000002,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          7.333212177578906,\n          6.791509363412849,\n          5.92236704115349\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sulfate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 41.416840461672706,\n        \"min\": 129.00000000000003,\n        \"max\": 481.0306423059972,\n        \"num_unique_values\": 2495,\n        \"samples\": [\n          324.64407957923544,\n          370.121384654358,\n          329.12773842254506\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conductivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80.8240640511118,\n        \"min\": 181.483753985146,\n        \"max\": 753.3426195583046,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          356.3690224100897,\n          336.56150104700754,\n          387.971335796834\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Organic_carbon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.308161999126874,\n        \"min\": 2.1999999999999886,\n        \"max\": 28.30000000000001,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          20.179028868493845,\n          14.706810313722087,\n          13.40673745495127\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Trihalomethanes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.175008422218657,\n        \"min\": 0.7379999999999995,\n        \"max\": 124.0,\n        \"num_unique_values\": 3114,\n        \"samples\": [\n          66.163439242252,\n          42.844510851301166,\n          47.06639219544294\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Turbidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7803824084854124,\n        \"min\": 1.45,\n        \"max\": 6.739,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          4.886633785371213,\n          4.562197671215202,\n          2.487968647002356\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Potability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Information on the data\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mn2ks1y4rG2i",
        "outputId": "48a2307d-aa4f-4689-bd89-912dc3d043b3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3276 entries, 0 to 3275\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   ph               2785 non-null   float64\n",
            " 1   Hardness         3276 non-null   float64\n",
            " 2   Solids           3276 non-null   float64\n",
            " 3   Chloramines      3276 non-null   float64\n",
            " 4   Sulfate          2495 non-null   float64\n",
            " 5   Conductivity     3276 non-null   float64\n",
            " 6   Organic_carbon   3276 non-null   float64\n",
            " 7   Trihalomethanes  3114 non-null   float64\n",
            " 8   Turbidity        3276 non-null   float64\n",
            " 9   Potability       3276 non-null   int64  \n",
            "dtypes: float64(9), int64(1)\n",
            "memory usage: 256.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Brief overview of the dataset statistics\n",
        "data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "fJvnnIxav4N2",
        "outputId": "c1e7c415-2134-41ec-8949-4f918d0c466a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                ph     Hardness        Solids  Chloramines      Sulfate  \\\n",
              "count  2785.000000  3276.000000   3276.000000  3276.000000  2495.000000   \n",
              "mean      7.080795   196.369496  22014.092526     7.122277   333.775777   \n",
              "std       1.594320    32.879761   8768.570828     1.583085    41.416840   \n",
              "min       0.000000    47.432000    320.942611     0.352000   129.000000   \n",
              "25%       6.093092   176.850538  15666.690297     6.127421   307.699498   \n",
              "50%       7.036752   196.967627  20927.833607     7.130299   333.073546   \n",
              "75%       8.062066   216.667456  27332.762127     8.114887   359.950170   \n",
              "max      14.000000   323.124000  61227.196008    13.127000   481.030642   \n",
              "\n",
              "       Conductivity  Organic_carbon  Trihalomethanes    Turbidity   Potability  \n",
              "count   3276.000000     3276.000000      3114.000000  3276.000000  3276.000000  \n",
              "mean     426.205111       14.284970        66.396293     3.966786     0.390110  \n",
              "std       80.824064        3.308162        16.175008     0.780382     0.487849  \n",
              "min      181.483754        2.200000         0.738000     1.450000     0.000000  \n",
              "25%      365.734414       12.065801        55.844536     3.439711     0.000000  \n",
              "50%      421.884968       14.218338        66.622485     3.955028     0.000000  \n",
              "75%      481.792304       16.557652        77.337473     4.500320     1.000000  \n",
              "max      753.342620       28.300000       124.000000     6.739000     1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c55292d-18bb-4e1f-9faf-c0c8a340e78c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2785.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>2495.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3114.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.080795</td>\n",
              "      <td>196.369496</td>\n",
              "      <td>22014.092526</td>\n",
              "      <td>7.122277</td>\n",
              "      <td>333.775777</td>\n",
              "      <td>426.205111</td>\n",
              "      <td>14.284970</td>\n",
              "      <td>66.396293</td>\n",
              "      <td>3.966786</td>\n",
              "      <td>0.390110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.594320</td>\n",
              "      <td>32.879761</td>\n",
              "      <td>8768.570828</td>\n",
              "      <td>1.583085</td>\n",
              "      <td>41.416840</td>\n",
              "      <td>80.824064</td>\n",
              "      <td>3.308162</td>\n",
              "      <td>16.175008</td>\n",
              "      <td>0.780382</td>\n",
              "      <td>0.487849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>47.432000</td>\n",
              "      <td>320.942611</td>\n",
              "      <td>0.352000</td>\n",
              "      <td>129.000000</td>\n",
              "      <td>181.483754</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>0.738000</td>\n",
              "      <td>1.450000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6.093092</td>\n",
              "      <td>176.850538</td>\n",
              "      <td>15666.690297</td>\n",
              "      <td>6.127421</td>\n",
              "      <td>307.699498</td>\n",
              "      <td>365.734414</td>\n",
              "      <td>12.065801</td>\n",
              "      <td>55.844536</td>\n",
              "      <td>3.439711</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7.036752</td>\n",
              "      <td>196.967627</td>\n",
              "      <td>20927.833607</td>\n",
              "      <td>7.130299</td>\n",
              "      <td>333.073546</td>\n",
              "      <td>421.884968</td>\n",
              "      <td>14.218338</td>\n",
              "      <td>66.622485</td>\n",
              "      <td>3.955028</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.062066</td>\n",
              "      <td>216.667456</td>\n",
              "      <td>27332.762127</td>\n",
              "      <td>8.114887</td>\n",
              "      <td>359.950170</td>\n",
              "      <td>481.792304</td>\n",
              "      <td>16.557652</td>\n",
              "      <td>77.337473</td>\n",
              "      <td>4.500320</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>14.000000</td>\n",
              "      <td>323.124000</td>\n",
              "      <td>61227.196008</td>\n",
              "      <td>13.127000</td>\n",
              "      <td>481.030642</td>\n",
              "      <td>753.342620</td>\n",
              "      <td>28.300000</td>\n",
              "      <td>124.000000</td>\n",
              "      <td>6.739000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c55292d-18bb-4e1f-9faf-c0c8a340e78c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5c55292d-18bb-4e1f-9faf-c0c8a340e78c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5c55292d-18bb-4e1f-9faf-c0c8a340e78c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8e55c642-37a8-49de-8747-f325ef2fe7ab\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8e55c642-37a8-49de-8747-f325ef2fe7ab')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8e55c642-37a8-49de-8747-f325ef2fe7ab button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"ph\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 982.4396919342113,\n        \"min\": 0.0,\n        \"max\": 2785.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          7.080794504276835,\n          7.036752103833548,\n          2785.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hardness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1102.077573149784,\n        \"min\": 32.879761476294156,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          196.36949601730151,\n          196.96762686363076,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19161.797748474182,\n        \"min\": 320.942611274359,\n        \"max\": 61227.19600771213,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          22014.092526077104,\n          20927.833606520187,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chloramines\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1156.047676013562,\n        \"min\": 0.3520000000000003,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          7.122276793425786,\n          7.130298973883081,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sulfate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 793.8602821876343,\n        \"min\": 41.416840461672706,\n        \"max\": 2495.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          333.7757766108135,\n          333.073545745888,\n          2495.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conductivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1040.8631085884185,\n        \"min\": 80.8240640511118,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          426.20511068255325,\n          421.8849682800544,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Organic_carbon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1153.6765632294614,\n        \"min\": 2.1999999999999886,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          14.284970247677318,\n          14.218337937208588,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Trihalomethanes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1081.0577228535572,\n        \"min\": 0.7379999999999995,\n        \"max\": 3114.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          66.39629294676803,\n          66.62248509808484,\n          3114.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Turbidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1156.9881922638972,\n        \"min\": 0.7803824084854124,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3.966786169791058,\n          3.955027562993039,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Potability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1158.0956231418108,\n        \"min\": 0.0,\n        \"max\": 3276.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3901098901098901,\n          1.0,\n          0.48784916967025516\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop duplicates rows of data\n",
        "\n",
        "data = data.drop_duplicates()"
      ],
      "metadata": {
        "id": "f5Rjjxwg5XnF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# percentage of missingness in the data for each column\n",
        "\n",
        "missing = data.isnull().mean()*100\n",
        "print(missing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjFnkhc35ekL",
        "outputId": "4513c72c-f078-44f5-d4bd-986eea1764c9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ph                 14.987790\n",
            "Hardness            0.000000\n",
            "Solids              0.000000\n",
            "Chloramines         0.000000\n",
            "Sulfate            23.840049\n",
            "Conductivity        0.000000\n",
            "Organic_carbon      0.000000\n",
            "Trihalomethanes     4.945055\n",
            "Turbidity           0.000000\n",
            "Potability          0.000000\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MICE IMPUTATION to fill the missing data\n",
        "# create the imputer using MICE\n",
        "\n",
        "# separate the target variable from the rest of the data to make sure it is not changed or imputed\n",
        "features = data.drop(columns='Potability')\n",
        "target = data.Potability\n",
        "imputer = IterativeImputer(random_state=0)\n",
        "features_imputed = imputer.fit_transform(features)\n",
        "\n",
        "# convert the data back into a dataframe\n",
        "features_imputed = pd.DataFrame(features_imputed, columns=features.columns)\n",
        "\n",
        "# merge target variable and data\n",
        "data_imputed = pd.concat([features_imputed, target], axis=1)\n",
        "data_imputed.head(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "RlhnFruS2q0X",
        "outputId": "0f880742-e359-4383-82b9-5e93e39bd719"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
              "0   7.190863  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
              "1   3.716080  129.422921  18630.057858     6.635246  344.836463    592.885359   \n",
              "2   8.099124  224.236259  19909.541732     9.275884  331.981769    418.606213   \n",
              "3   8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
              "4   9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
              "5   5.584087  188.313324  28748.687739     7.544869  326.678363    280.467916   \n",
              "6  10.223862  248.071735  28749.716544     7.513408  393.663396    283.651634   \n",
              "7   8.635849  203.361523  13672.091764     4.563009  303.309771    474.607645   \n",
              "8   6.927779  118.988579  14285.583854     7.804174  268.646941    389.375566   \n",
              "9  11.180284  227.231469  25484.508491     9.077200  404.041635    563.885481   \n",
              "\n",
              "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
              "0       10.379783        86.990970   2.963135           0  \n",
              "1       15.180013        56.329076   4.500656           0  \n",
              "2       16.868637        66.420093   3.055934           0  \n",
              "3       18.436524       100.341674   4.628771           0  \n",
              "4       11.558279        31.997993   4.075075           0  \n",
              "5        8.399735        54.917862   2.559708           0  \n",
              "6       13.789695        84.603556   2.672989           0  \n",
              "7       12.363817        62.798309   4.401425           0  \n",
              "8       12.706049        53.928846   3.595017           0  \n",
              "9       17.927806        71.976601   4.370562           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae11636c-859c-4156-9b01-48d8a552c833\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.190863</td>\n",
              "      <td>204.890455</td>\n",
              "      <td>20791.318981</td>\n",
              "      <td>7.300212</td>\n",
              "      <td>368.516441</td>\n",
              "      <td>564.308654</td>\n",
              "      <td>10.379783</td>\n",
              "      <td>86.990970</td>\n",
              "      <td>2.963135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.716080</td>\n",
              "      <td>129.422921</td>\n",
              "      <td>18630.057858</td>\n",
              "      <td>6.635246</td>\n",
              "      <td>344.836463</td>\n",
              "      <td>592.885359</td>\n",
              "      <td>15.180013</td>\n",
              "      <td>56.329076</td>\n",
              "      <td>4.500656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.099124</td>\n",
              "      <td>224.236259</td>\n",
              "      <td>19909.541732</td>\n",
              "      <td>9.275884</td>\n",
              "      <td>331.981769</td>\n",
              "      <td>418.606213</td>\n",
              "      <td>16.868637</td>\n",
              "      <td>66.420093</td>\n",
              "      <td>3.055934</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.316766</td>\n",
              "      <td>214.373394</td>\n",
              "      <td>22018.417441</td>\n",
              "      <td>8.059332</td>\n",
              "      <td>356.886136</td>\n",
              "      <td>363.266516</td>\n",
              "      <td>18.436524</td>\n",
              "      <td>100.341674</td>\n",
              "      <td>4.628771</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.092223</td>\n",
              "      <td>181.101509</td>\n",
              "      <td>17978.986339</td>\n",
              "      <td>6.546600</td>\n",
              "      <td>310.135738</td>\n",
              "      <td>398.410813</td>\n",
              "      <td>11.558279</td>\n",
              "      <td>31.997993</td>\n",
              "      <td>4.075075</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.584087</td>\n",
              "      <td>188.313324</td>\n",
              "      <td>28748.687739</td>\n",
              "      <td>7.544869</td>\n",
              "      <td>326.678363</td>\n",
              "      <td>280.467916</td>\n",
              "      <td>8.399735</td>\n",
              "      <td>54.917862</td>\n",
              "      <td>2.559708</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10.223862</td>\n",
              "      <td>248.071735</td>\n",
              "      <td>28749.716544</td>\n",
              "      <td>7.513408</td>\n",
              "      <td>393.663396</td>\n",
              "      <td>283.651634</td>\n",
              "      <td>13.789695</td>\n",
              "      <td>84.603556</td>\n",
              "      <td>2.672989</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8.635849</td>\n",
              "      <td>203.361523</td>\n",
              "      <td>13672.091764</td>\n",
              "      <td>4.563009</td>\n",
              "      <td>303.309771</td>\n",
              "      <td>474.607645</td>\n",
              "      <td>12.363817</td>\n",
              "      <td>62.798309</td>\n",
              "      <td>4.401425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6.927779</td>\n",
              "      <td>118.988579</td>\n",
              "      <td>14285.583854</td>\n",
              "      <td>7.804174</td>\n",
              "      <td>268.646941</td>\n",
              "      <td>389.375566</td>\n",
              "      <td>12.706049</td>\n",
              "      <td>53.928846</td>\n",
              "      <td>3.595017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>11.180284</td>\n",
              "      <td>227.231469</td>\n",
              "      <td>25484.508491</td>\n",
              "      <td>9.077200</td>\n",
              "      <td>404.041635</td>\n",
              "      <td>563.885481</td>\n",
              "      <td>17.927806</td>\n",
              "      <td>71.976601</td>\n",
              "      <td>4.370562</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae11636c-859c-4156-9b01-48d8a552c833')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ae11636c-859c-4156-9b01-48d8a552c833 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ae11636c-859c-4156-9b01-48d8a552c833');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-66a7f73a-6478-4b43-930e-156df007f349\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-66a7f73a-6478-4b43-930e-156df007f349')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-66a7f73a-6478-4b43-930e-156df007f349 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_imputed",
              "summary": "{\n  \"name\": \"data_imputed\",\n  \"rows\": 3276,\n  \"fields\": [\n    {\n      \"column\": \"ph\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.471574062911746,\n        \"min\": 0.0,\n        \"max\": 13.999999999999998,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          7.042483377815478,\n          6.643158712135614,\n          7.846057926337261\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hardness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32.879761476294156,\n        \"min\": 47.432,\n        \"max\": 323.124,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          183.5211070261417,\n          188.9135411469536,\n          224.05887682392927\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8768.570827785927,\n        \"min\": 320.942611274359,\n        \"max\": 61227.19600771213,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          20461.252710219946,\n          32873.820021715685,\n          23264.10996772913\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chloramines\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5830848890397096,\n        \"min\": 0.3520000000000003,\n        \"max\": 13.127000000000002,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          7.333212177578906,\n          6.791509363412849,\n          5.92236704115349\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sulfate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36.3878388853383,\n        \"min\": 129.00000000000003,\n        \"max\": 481.0306423059972,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          333.1194758732444,\n          333.8488418801131,\n          300.40262012672275\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conductivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80.8240640511118,\n        \"min\": 181.483753985146,\n        \"max\": 753.3426195583046,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          356.3690224100897,\n          336.56150104700754,\n          387.971335796834\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Organic_carbon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.308161999126874,\n        \"min\": 2.1999999999999886,\n        \"max\": 28.30000000000001,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          20.179028868493845,\n          14.706810313722087,\n          13.40673745495127\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Trihalomethanes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.769921510590818,\n        \"min\": 0.7379999999999995,\n        \"max\": 124.0,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          67.01990322225635,\n          67.84484886059036,\n          43.07518646611747\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Turbidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7803824084854124,\n        \"min\": 1.45,\n        \"max\": 6.739,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          4.886633785371213,\n          4.562197671215202,\n          2.487968647002356\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Potability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# confirm imputed data\n",
        "data_imputed.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58zqnGV23ZSx",
        "outputId": "e38d1bd4-f204-4839-eabe-3ba11c5a6dff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3276 entries, 0 to 3275\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   ph               3276 non-null   float64\n",
            " 1   Hardness         3276 non-null   float64\n",
            " 2   Solids           3276 non-null   float64\n",
            " 3   Chloramines      3276 non-null   float64\n",
            " 4   Sulfate          3276 non-null   float64\n",
            " 5   Conductivity     3276 non-null   float64\n",
            " 6   Organic_carbon   3276 non-null   float64\n",
            " 7   Trihalomethanes  3276 non-null   float64\n",
            " 8   Turbidity        3276 non-null   float64\n",
            " 9   Potability       3276 non-null   int64  \n",
            "dtypes: float64(9), int64(1)\n",
            "memory usage: 256.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove outliers that may affect the neural network's accuracy using IQR method\n",
        "def remove_outliers_iqr(df, column_name):\n",
        "    Q1 = df[column_name].quantile(0.25)\n",
        "    Q3 = df[column_name].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    # anything above or below this is an outlier\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # place outliers in a data frame\n",
        "    print(f\"{df[column_name]}\")\n",
        "    outliers = df[(df[column_name] < lower_bound) | (df[column_name] > upper_bound)]\n",
        "    print(f\"Number of outliers: {len(outliers)}\")\n",
        "    print(f\"Percentage of outliers: {len(outliers)/len(df)*100:.2f}%\")\n",
        "\n",
        "\n",
        "    # remove outliers\n",
        "\n",
        "    df_clean = df[(df[column_name] >= lower_bound) & (df[column_name] <= upper_bound)]\n",
        "\n",
        "\n",
        "\n",
        "    return df_clean\n",
        "\n",
        "# columns to remove outliers in\n",
        "columns = ['Hardness', 'Solids', 'Sulfate', 'Conductivity', 'Organic_carbon', 'Trihalomethanes', 'Turbidity']\n",
        "\n",
        "data_imputed_copy = data_imputed.copy()\n",
        "\n",
        "for i in columns:\n",
        "  data_imputed_copy = remove_outliers_iqr(data_imputed_copy, i)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIdMxexk47Qa",
        "outputId": "8823b2ec-e1a9-4878-ce6b-8f2f9cfcfcd6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       204.890455\n",
            "1       129.422921\n",
            "2       224.236259\n",
            "3       214.373394\n",
            "4       181.101509\n",
            "           ...    \n",
            "3271    193.681735\n",
            "3272    193.553212\n",
            "3273    175.762646\n",
            "3274    230.603758\n",
            "3275    195.102299\n",
            "Name: Hardness, Length: 3276, dtype: float64\n",
            "Number of outliers: 83\n",
            "Percentage of outliers: 2.53%\n",
            "0       20791.318981\n",
            "1       18630.057858\n",
            "2       19909.541732\n",
            "3       22018.417441\n",
            "4       17978.986339\n",
            "            ...     \n",
            "3271    47580.991603\n",
            "3272    17329.802160\n",
            "3273    33155.578218\n",
            "3274    11983.869376\n",
            "3275    17404.177061\n",
            "Name: Solids, Length: 3193, dtype: float64\n",
            "Number of outliers: 42\n",
            "Percentage of outliers: 1.32%\n",
            "0       368.516441\n",
            "1       344.836463\n",
            "2       331.981769\n",
            "3       356.886136\n",
            "4       310.135738\n",
            "           ...    \n",
            "3270    345.700257\n",
            "3272    338.612062\n",
            "3273    326.848982\n",
            "3274    336.993878\n",
            "3275    338.025733\n",
            "Name: Sulfate, Length: 3151, dtype: float64\n",
            "Number of outliers: 230\n",
            "Percentage of outliers: 7.30%\n",
            "0       564.308654\n",
            "1       592.885359\n",
            "2       418.606213\n",
            "3       363.266516\n",
            "4       398.410813\n",
            "           ...    \n",
            "3270    415.886955\n",
            "3272    392.449580\n",
            "3273    432.044783\n",
            "3274    402.883113\n",
            "3275    327.459760\n",
            "Name: Conductivity, Length: 2921, dtype: float64\n",
            "Number of outliers: 9\n",
            "Percentage of outliers: 0.31%\n",
            "0       10.379783\n",
            "1       15.180013\n",
            "2       16.868637\n",
            "3       18.436524\n",
            "4       11.558279\n",
            "          ...    \n",
            "3270    12.067620\n",
            "3272    19.903225\n",
            "3273    11.039070\n",
            "3274    11.168946\n",
            "3275    16.140368\n",
            "Name: Organic_carbon, Length: 2912, dtype: float64\n",
            "Number of outliers: 18\n",
            "Percentage of outliers: 0.62%\n",
            "0        86.990970\n",
            "1        56.329076\n",
            "2        66.420093\n",
            "3       100.341674\n",
            "4        31.997993\n",
            "           ...    \n",
            "3270     60.419921\n",
            "3272     66.474992\n",
            "3273     69.845400\n",
            "3274     77.488213\n",
            "3275     78.698446\n",
            "Name: Trihalomethanes, Length: 2894, dtype: float64\n",
            "Number of outliers: 47\n",
            "Percentage of outliers: 1.62%\n",
            "0       2.963135\n",
            "1       4.500656\n",
            "2       3.055934\n",
            "3       4.628771\n",
            "4       4.075075\n",
            "          ...   \n",
            "3270    3.669712\n",
            "3272    2.798243\n",
            "3273    3.298875\n",
            "3274    4.708658\n",
            "3275    2.309149\n",
            "Name: Turbidity, Length: 2847, dtype: float64\n",
            "Number of outliers: 17\n",
            "Percentage of outliers: 0.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the Data Appropriately"
      ],
      "metadata": {
        "id": "2QfR0r8cGVU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# generate 2d classification dataset\n",
        "\n",
        "# X, y = pass\n",
        "\n",
        "# Transforms data to have mean=0 and standard deviation=1\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X = data_imputed_copy.drop(columns='Potability', axis=1)\n",
        "y= data_imputed_copy['Potability']\n",
        "\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# from sklearn.decomposition import PCA\n",
        "# pca = PCA(n_components=2)\n",
        "# X_2d_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "X_scaled.shape\n"
      ],
      "metadata": {
        "id": "PF9lHguSY2vB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6d29828-8f82-473f-a6cd-97288a171416"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2830, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the data into training validation and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3,random_state=42,\n",
        "    stratify=y               # Keep same class distribution in all splits\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5,stratify=y_temp)\n",
        "\n",
        "print(f\"\\n=== FINAL SHAPES ===\")\n",
        "print(f\"X_train: {X_train.shape}\")\n",
        "print(f\"X_val: {X_val.shape}\")\n",
        "print(f\"X_test: {X_test.shape}\")\n",
        "print(f\"y_train: {y_train.shape}\")\n",
        "print(f\"y_val: {y_val.shape}\")\n",
        "print(f\"y_test: {y_test.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "wfSk1lXRYjrh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aea43068-b555-4faa-c9c5-90bd60b71a37"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== FINAL SHAPES ===\n",
            "X_train: (1981, 9)\n",
            "X_val: (424, 9)\n",
            "X_test: (425, 9)\n",
            "y_train: (1981,)\n",
            "y_val: (424,)\n",
            "y_test: (425,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Each Member Defines their model Here"
      ],
      "metadata": {
        "id": "LvjIHLrcGhzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Definition by member 1\n",
        "def model_jeremiah_agbaje():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(128, input_shape=(X_train.shape[1],), name='dense_layer', activation=\"relu\",kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))  # 50% dropout after first layer\n",
        "  model.add(tf.keras.layers.Dense(64, name='dense_layer2', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))  # 50% dropout after second layer\n",
        "  model.add(tf.keras.layers.Dense(32, name='dense_layer3', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))\n",
        "  model.add(tf.keras.layers.Dense(1, name='output_layer', activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.00001)))\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "model = model_jeremiah_agbaje()\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "      monitor='val_loss',    # Monitor validation loss\n",
        "      patience=50,\n",
        "      restore_best_weights=True  # Restore weights from best epoch\n",
        "  )\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "  X_train, y_train,\n",
        "  validation_data=(X_val, y_val),\n",
        "  epochs=200,\n",
        "  batch_size=32,\n",
        "  verbose=1,\n",
        "  callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "FLwYoJG9jvDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cb840a4-7282-4c03-cfd9-5f5bf15aeb85"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5683 - loss: 0.7008 - val_accuracy: 0.5991 - val_loss: 0.6862\n",
            "Epoch 2/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5801 - loss: 0.6968 - val_accuracy: 0.6038 - val_loss: 0.6840\n",
            "Epoch 3/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5859 - loss: 0.6924 - val_accuracy: 0.6108 - val_loss: 0.6822\n",
            "Epoch 4/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5747 - loss: 0.6921 - val_accuracy: 0.6203 - val_loss: 0.6811\n",
            "Epoch 5/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5715 - loss: 0.6985 - val_accuracy: 0.6250 - val_loss: 0.6796\n",
            "Epoch 6/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5954 - loss: 0.6965 - val_accuracy: 0.6297 - val_loss: 0.6792\n",
            "Epoch 7/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5990 - loss: 0.6879 - val_accuracy: 0.6297 - val_loss: 0.6783\n",
            "Epoch 8/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5893 - loss: 0.6918 - val_accuracy: 0.6297 - val_loss: 0.6776\n",
            "Epoch 9/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6038 - loss: 0.6803 - val_accuracy: 0.6297 - val_loss: 0.6766\n",
            "Epoch 10/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6016 - loss: 0.6852 - val_accuracy: 0.6297 - val_loss: 0.6761\n",
            "Epoch 11/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6179 - loss: 0.6681 - val_accuracy: 0.6297 - val_loss: 0.6757\n",
            "Epoch 12/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6151 - loss: 0.6852 - val_accuracy: 0.6297 - val_loss: 0.6758\n",
            "Epoch 13/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6020 - loss: 0.6897 - val_accuracy: 0.6297 - val_loss: 0.6752\n",
            "Epoch 14/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6060 - loss: 0.6872 - val_accuracy: 0.6297 - val_loss: 0.6749\n",
            "Epoch 15/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6193 - loss: 0.6731 - val_accuracy: 0.6297 - val_loss: 0.6748\n",
            "Epoch 16/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6149 - loss: 0.6691 - val_accuracy: 0.6297 - val_loss: 0.6742\n",
            "Epoch 17/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6255 - loss: 0.6716 - val_accuracy: 0.6297 - val_loss: 0.6740\n",
            "Epoch 18/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6126 - loss: 0.6806 - val_accuracy: 0.6297 - val_loss: 0.6734\n",
            "Epoch 19/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6146 - loss: 0.6887 - val_accuracy: 0.6297 - val_loss: 0.6735\n",
            "Epoch 20/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6017 - loss: 0.6880 - val_accuracy: 0.6297 - val_loss: 0.6736\n",
            "Epoch 21/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6239 - loss: 0.6689 - val_accuracy: 0.6297 - val_loss: 0.6737\n",
            "Epoch 22/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6193 - loss: 0.6715 - val_accuracy: 0.6297 - val_loss: 0.6733\n",
            "Epoch 23/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6580 - loss: 0.6539 - val_accuracy: 0.6297 - val_loss: 0.6729\n",
            "Epoch 24/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6152 - loss: 0.6779 - val_accuracy: 0.6297 - val_loss: 0.6726\n",
            "Epoch 25/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6327 - loss: 0.6666 - val_accuracy: 0.6297 - val_loss: 0.6717\n",
            "Epoch 26/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6107 - loss: 0.6731 - val_accuracy: 0.6297 - val_loss: 0.6717\n",
            "Epoch 27/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6415 - loss: 0.6587 - val_accuracy: 0.6297 - val_loss: 0.6716\n",
            "Epoch 28/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6085 - loss: 0.6704 - val_accuracy: 0.6297 - val_loss: 0.6717\n",
            "Epoch 29/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6246 - loss: 0.6779 - val_accuracy: 0.6297 - val_loss: 0.6713\n",
            "Epoch 30/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6257 - loss: 0.6751 - val_accuracy: 0.6297 - val_loss: 0.6715\n",
            "Epoch 31/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6159 - loss: 0.6741 - val_accuracy: 0.6297 - val_loss: 0.6713\n",
            "Epoch 32/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6488 - loss: 0.6567 - val_accuracy: 0.6297 - val_loss: 0.6711\n",
            "Epoch 33/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6412 - loss: 0.6659 - val_accuracy: 0.6297 - val_loss: 0.6709\n",
            "Epoch 34/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6271 - loss: 0.6734 - val_accuracy: 0.6297 - val_loss: 0.6710\n",
            "Epoch 35/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6320 - loss: 0.6650 - val_accuracy: 0.6297 - val_loss: 0.6705\n",
            "Epoch 36/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6106 - loss: 0.6689 - val_accuracy: 0.6297 - val_loss: 0.6702\n",
            "Epoch 37/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6450 - loss: 0.6547 - val_accuracy: 0.6297 - val_loss: 0.6695\n",
            "Epoch 38/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6271 - loss: 0.6615 - val_accuracy: 0.6297 - val_loss: 0.6692\n",
            "Epoch 39/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6219 - loss: 0.6725 - val_accuracy: 0.6297 - val_loss: 0.6690\n",
            "Epoch 40/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6065 - loss: 0.6701 - val_accuracy: 0.6297 - val_loss: 0.6692\n",
            "Epoch 41/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6341 - loss: 0.6618 - val_accuracy: 0.6297 - val_loss: 0.6690\n",
            "Epoch 42/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6257 - loss: 0.6644 - val_accuracy: 0.6297 - val_loss: 0.6688\n",
            "Epoch 43/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6351 - loss: 0.6671 - val_accuracy: 0.6297 - val_loss: 0.6684\n",
            "Epoch 44/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6282 - loss: 0.6648 - val_accuracy: 0.6297 - val_loss: 0.6681\n",
            "Epoch 45/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6304 - loss: 0.6648 - val_accuracy: 0.6297 - val_loss: 0.6678\n",
            "Epoch 46/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6385 - loss: 0.6595 - val_accuracy: 0.6297 - val_loss: 0.6675\n",
            "Epoch 47/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6309 - loss: 0.6648 - val_accuracy: 0.6297 - val_loss: 0.6673\n",
            "Epoch 48/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6356 - loss: 0.6542 - val_accuracy: 0.6297 - val_loss: 0.6672\n",
            "Epoch 49/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6137 - loss: 0.6680 - val_accuracy: 0.6297 - val_loss: 0.6669\n",
            "Epoch 50/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6314 - loss: 0.6631 - val_accuracy: 0.6297 - val_loss: 0.6664\n",
            "Epoch 51/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6376 - loss: 0.6566 - val_accuracy: 0.6297 - val_loss: 0.6661\n",
            "Epoch 52/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6316 - loss: 0.6641 - val_accuracy: 0.6297 - val_loss: 0.6656\n",
            "Epoch 53/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6466 - loss: 0.6586 - val_accuracy: 0.6297 - val_loss: 0.6656\n",
            "Epoch 54/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6258 - loss: 0.6629 - val_accuracy: 0.6297 - val_loss: 0.6649\n",
            "Epoch 55/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6213 - loss: 0.6689 - val_accuracy: 0.6297 - val_loss: 0.6652\n",
            "Epoch 56/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6314 - loss: 0.6702 - val_accuracy: 0.6297 - val_loss: 0.6648\n",
            "Epoch 57/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6270 - loss: 0.6615 - val_accuracy: 0.6297 - val_loss: 0.6645\n",
            "Epoch 58/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6475 - loss: 0.6498 - val_accuracy: 0.6297 - val_loss: 0.6640\n",
            "Epoch 59/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6386 - loss: 0.6609 - val_accuracy: 0.6297 - val_loss: 0.6640\n",
            "Epoch 60/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6286 - loss: 0.6689 - val_accuracy: 0.6297 - val_loss: 0.6638\n",
            "Epoch 61/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6129 - loss: 0.6697 - val_accuracy: 0.6297 - val_loss: 0.6637\n",
            "Epoch 62/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6387 - loss: 0.6611 - val_accuracy: 0.6297 - val_loss: 0.6634\n",
            "Epoch 63/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6211 - loss: 0.6604 - val_accuracy: 0.6297 - val_loss: 0.6634\n",
            "Epoch 64/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6146 - loss: 0.6647 - val_accuracy: 0.6297 - val_loss: 0.6631\n",
            "Epoch 65/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6344 - loss: 0.6571 - val_accuracy: 0.6297 - val_loss: 0.6629\n",
            "Epoch 66/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6403 - loss: 0.6497 - val_accuracy: 0.6297 - val_loss: 0.6624\n",
            "Epoch 67/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6342 - loss: 0.6569 - val_accuracy: 0.6297 - val_loss: 0.6624\n",
            "Epoch 68/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6179 - loss: 0.6574 - val_accuracy: 0.6297 - val_loss: 0.6617\n",
            "Epoch 69/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6357 - loss: 0.6534 - val_accuracy: 0.6297 - val_loss: 0.6614\n",
            "Epoch 70/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6327 - loss: 0.6600 - val_accuracy: 0.6297 - val_loss: 0.6616\n",
            "Epoch 71/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6166 - loss: 0.6700 - val_accuracy: 0.6297 - val_loss: 0.6612\n",
            "Epoch 72/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6410 - loss: 0.6399 - val_accuracy: 0.6297 - val_loss: 0.6601\n",
            "Epoch 73/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6400 - loss: 0.6477 - val_accuracy: 0.6297 - val_loss: 0.6596\n",
            "Epoch 74/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6135 - loss: 0.6592 - val_accuracy: 0.6297 - val_loss: 0.6597\n",
            "Epoch 75/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6227 - loss: 0.6619 - val_accuracy: 0.6297 - val_loss: 0.6594\n",
            "Epoch 76/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6160 - loss: 0.6618 - val_accuracy: 0.6297 - val_loss: 0.6593\n",
            "Epoch 77/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6256 - loss: 0.6627 - val_accuracy: 0.6297 - val_loss: 0.6591\n",
            "Epoch 78/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6207 - loss: 0.6607 - val_accuracy: 0.6297 - val_loss: 0.6589\n",
            "Epoch 79/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6325 - loss: 0.6551 - val_accuracy: 0.6297 - val_loss: 0.6586\n",
            "Epoch 80/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6306 - loss: 0.6589 - val_accuracy: 0.6297 - val_loss: 0.6589\n",
            "Epoch 81/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6163 - loss: 0.6647 - val_accuracy: 0.6297 - val_loss: 0.6587\n",
            "Epoch 82/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6378 - loss: 0.6471 - val_accuracy: 0.6297 - val_loss: 0.6581\n",
            "Epoch 83/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6284 - loss: 0.6560 - val_accuracy: 0.6297 - val_loss: 0.6577\n",
            "Epoch 84/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6133 - loss: 0.6572 - val_accuracy: 0.6297 - val_loss: 0.6574\n",
            "Epoch 85/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6331 - loss: 0.6503 - val_accuracy: 0.6297 - val_loss: 0.6569\n",
            "Epoch 86/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6285 - loss: 0.6555 - val_accuracy: 0.6297 - val_loss: 0.6566\n",
            "Epoch 87/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6361 - loss: 0.6588 - val_accuracy: 0.6297 - val_loss: 0.6569\n",
            "Epoch 88/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6313 - loss: 0.6536 - val_accuracy: 0.6297 - val_loss: 0.6560\n",
            "Epoch 89/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6231 - loss: 0.6540 - val_accuracy: 0.6297 - val_loss: 0.6558\n",
            "Epoch 90/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6229 - loss: 0.6600 - val_accuracy: 0.6297 - val_loss: 0.6557\n",
            "Epoch 91/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6418 - loss: 0.6531 - val_accuracy: 0.6297 - val_loss: 0.6555\n",
            "Epoch 92/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6307 - loss: 0.6543 - val_accuracy: 0.6297 - val_loss: 0.6548\n",
            "Epoch 93/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6278 - loss: 0.6540 - val_accuracy: 0.6297 - val_loss: 0.6545\n",
            "Epoch 94/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6336 - loss: 0.6569 - val_accuracy: 0.6297 - val_loss: 0.6542\n",
            "Epoch 95/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6257 - loss: 0.6529 - val_accuracy: 0.6297 - val_loss: 0.6538\n",
            "Epoch 96/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6057 - loss: 0.6529 - val_accuracy: 0.6297 - val_loss: 0.6538\n",
            "Epoch 97/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6219 - loss: 0.6663 - val_accuracy: 0.6297 - val_loss: 0.6535\n",
            "Epoch 98/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6269 - loss: 0.6528 - val_accuracy: 0.6297 - val_loss: 0.6535\n",
            "Epoch 99/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6162 - loss: 0.6588 - val_accuracy: 0.6297 - val_loss: 0.6530\n",
            "Epoch 100/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6392 - loss: 0.6488 - val_accuracy: 0.6297 - val_loss: 0.6528\n",
            "Epoch 101/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6341 - loss: 0.6568 - val_accuracy: 0.6297 - val_loss: 0.6527\n",
            "Epoch 102/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6383 - loss: 0.6436 - val_accuracy: 0.6297 - val_loss: 0.6523\n",
            "Epoch 103/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6498 - loss: 0.6441 - val_accuracy: 0.6297 - val_loss: 0.6521\n",
            "Epoch 104/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6447 - loss: 0.6441 - val_accuracy: 0.6297 - val_loss: 0.6526\n",
            "Epoch 105/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6535 - loss: 0.6383 - val_accuracy: 0.6297 - val_loss: 0.6524\n",
            "Epoch 106/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6352 - loss: 0.6511 - val_accuracy: 0.6297 - val_loss: 0.6523\n",
            "Epoch 107/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6385 - loss: 0.6411 - val_accuracy: 0.6297 - val_loss: 0.6516\n",
            "Epoch 108/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6437 - loss: 0.6365 - val_accuracy: 0.6297 - val_loss: 0.6510\n",
            "Epoch 109/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6129 - loss: 0.6557 - val_accuracy: 0.6297 - val_loss: 0.6510\n",
            "Epoch 110/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6356 - loss: 0.6476 - val_accuracy: 0.6297 - val_loss: 0.6508\n",
            "Epoch 111/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6346 - loss: 0.6481 - val_accuracy: 0.6297 - val_loss: 0.6508\n",
            "Epoch 112/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6174 - loss: 0.6621 - val_accuracy: 0.6297 - val_loss: 0.6509\n",
            "Epoch 113/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6326 - loss: 0.6488 - val_accuracy: 0.6297 - val_loss: 0.6505\n",
            "Epoch 114/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6325 - loss: 0.6473 - val_accuracy: 0.6297 - val_loss: 0.6504\n",
            "Epoch 115/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6301 - loss: 0.6504 - val_accuracy: 0.6321 - val_loss: 0.6500\n",
            "Epoch 116/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6320 - loss: 0.6504 - val_accuracy: 0.6321 - val_loss: 0.6499\n",
            "Epoch 117/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6168 - loss: 0.6564 - val_accuracy: 0.6321 - val_loss: 0.6497\n",
            "Epoch 118/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6270 - loss: 0.6491 - val_accuracy: 0.6321 - val_loss: 0.6492\n",
            "Epoch 119/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6411 - loss: 0.6398 - val_accuracy: 0.6344 - val_loss: 0.6488\n",
            "Epoch 120/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6298 - loss: 0.6424 - val_accuracy: 0.6344 - val_loss: 0.6488\n",
            "Epoch 121/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6338 - loss: 0.6436 - val_accuracy: 0.6344 - val_loss: 0.6487\n",
            "Epoch 122/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6420 - loss: 0.6423 - val_accuracy: 0.6344 - val_loss: 0.6491\n",
            "Epoch 123/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6423 - loss: 0.6336 - val_accuracy: 0.6344 - val_loss: 0.6489\n",
            "Epoch 124/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6353 - loss: 0.6507 - val_accuracy: 0.6344 - val_loss: 0.6485\n",
            "Epoch 125/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6383 - loss: 0.6312 - val_accuracy: 0.6344 - val_loss: 0.6480\n",
            "Epoch 126/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6367 - loss: 0.6431 - val_accuracy: 0.6368 - val_loss: 0.6482\n",
            "Epoch 127/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6546 - loss: 0.6431 - val_accuracy: 0.6368 - val_loss: 0.6480\n",
            "Epoch 128/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6176 - loss: 0.6532 - val_accuracy: 0.6368 - val_loss: 0.6474\n",
            "Epoch 129/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6524 - loss: 0.6396 - val_accuracy: 0.6344 - val_loss: 0.6470\n",
            "Epoch 130/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6379 - loss: 0.6433 - val_accuracy: 0.6368 - val_loss: 0.6461\n",
            "Epoch 131/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6526 - loss: 0.6332 - val_accuracy: 0.6368 - val_loss: 0.6461\n",
            "Epoch 132/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6340 - loss: 0.6383 - val_accuracy: 0.6392 - val_loss: 0.6458\n",
            "Epoch 133/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6437 - loss: 0.6346 - val_accuracy: 0.6368 - val_loss: 0.6455\n",
            "Epoch 134/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6386 - loss: 0.6419 - val_accuracy: 0.6368 - val_loss: 0.6453\n",
            "Epoch 135/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6233 - loss: 0.6537 - val_accuracy: 0.6344 - val_loss: 0.6456\n",
            "Epoch 136/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6286 - loss: 0.6510 - val_accuracy: 0.6368 - val_loss: 0.6459\n",
            "Epoch 137/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6382 - loss: 0.6458 - val_accuracy: 0.6368 - val_loss: 0.6455\n",
            "Epoch 138/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6297 - loss: 0.6530 - val_accuracy: 0.6321 - val_loss: 0.6454\n",
            "Epoch 139/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6240 - loss: 0.6515 - val_accuracy: 0.6321 - val_loss: 0.6451\n",
            "Epoch 140/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6193 - loss: 0.6569 - val_accuracy: 0.6321 - val_loss: 0.6447\n",
            "Epoch 141/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6247 - loss: 0.6474 - val_accuracy: 0.6344 - val_loss: 0.6446\n",
            "Epoch 142/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6327 - loss: 0.6475 - val_accuracy: 0.6321 - val_loss: 0.6446\n",
            "Epoch 143/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6178 - loss: 0.6427 - val_accuracy: 0.6344 - val_loss: 0.6444\n",
            "Epoch 144/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6269 - loss: 0.6466 - val_accuracy: 0.6344 - val_loss: 0.6445\n",
            "Epoch 145/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6230 - loss: 0.6413 - val_accuracy: 0.6344 - val_loss: 0.6440\n",
            "Epoch 146/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6512 - loss: 0.6336 - val_accuracy: 0.6392 - val_loss: 0.6440\n",
            "Epoch 147/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6437 - loss: 0.6403 - val_accuracy: 0.6415 - val_loss: 0.6439\n",
            "Epoch 148/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6409 - loss: 0.6441 - val_accuracy: 0.6439 - val_loss: 0.6436\n",
            "Epoch 149/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6292 - loss: 0.6567 - val_accuracy: 0.6439 - val_loss: 0.6434\n",
            "Epoch 150/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6483 - loss: 0.6384 - val_accuracy: 0.6415 - val_loss: 0.6432\n",
            "Epoch 151/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6372 - loss: 0.6364 - val_accuracy: 0.6415 - val_loss: 0.6426\n",
            "Epoch 152/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6334 - loss: 0.6411 - val_accuracy: 0.6415 - val_loss: 0.6423\n",
            "Epoch 153/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6225 - loss: 0.6498 - val_accuracy: 0.6392 - val_loss: 0.6427\n",
            "Epoch 154/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6477 - loss: 0.6308 - val_accuracy: 0.6392 - val_loss: 0.6427\n",
            "Epoch 155/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6431 - loss: 0.6435 - val_accuracy: 0.6392 - val_loss: 0.6426\n",
            "Epoch 156/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6285 - loss: 0.6427 - val_accuracy: 0.6415 - val_loss: 0.6423\n",
            "Epoch 157/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6290 - loss: 0.6470 - val_accuracy: 0.6415 - val_loss: 0.6419\n",
            "Epoch 158/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6309 - loss: 0.6400 - val_accuracy: 0.6415 - val_loss: 0.6414\n",
            "Epoch 159/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6381 - loss: 0.6342 - val_accuracy: 0.6392 - val_loss: 0.6408\n",
            "Epoch 160/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6342 - loss: 0.6423 - val_accuracy: 0.6415 - val_loss: 0.6409\n",
            "Epoch 161/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6383 - loss: 0.6354 - val_accuracy: 0.6415 - val_loss: 0.6405\n",
            "Epoch 162/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6391 - loss: 0.6351 - val_accuracy: 0.6392 - val_loss: 0.6404\n",
            "Epoch 163/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6374 - loss: 0.6315 - val_accuracy: 0.6392 - val_loss: 0.6404\n",
            "Epoch 164/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6326 - loss: 0.6453 - val_accuracy: 0.6392 - val_loss: 0.6404\n",
            "Epoch 165/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6320 - loss: 0.6471 - val_accuracy: 0.6392 - val_loss: 0.6404\n",
            "Epoch 166/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6355 - loss: 0.6366 - val_accuracy: 0.6415 - val_loss: 0.6400\n",
            "Epoch 167/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6480 - loss: 0.6296 - val_accuracy: 0.6415 - val_loss: 0.6399\n",
            "Epoch 168/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6529 - loss: 0.6316 - val_accuracy: 0.6415 - val_loss: 0.6400\n",
            "Epoch 169/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6361 - loss: 0.6438 - val_accuracy: 0.6462 - val_loss: 0.6401\n",
            "Epoch 170/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6493 - loss: 0.6340 - val_accuracy: 0.6415 - val_loss: 0.6399\n",
            "Epoch 171/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6370 - loss: 0.6341 - val_accuracy: 0.6415 - val_loss: 0.6400\n",
            "Epoch 172/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6478 - loss: 0.6287 - val_accuracy: 0.6415 - val_loss: 0.6399\n",
            "Epoch 173/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6463 - loss: 0.6382 - val_accuracy: 0.6415 - val_loss: 0.6398\n",
            "Epoch 174/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6407 - loss: 0.6412 - val_accuracy: 0.6439 - val_loss: 0.6397\n",
            "Epoch 175/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6406 - loss: 0.6372 - val_accuracy: 0.6462 - val_loss: 0.6398\n",
            "Epoch 176/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6357 - loss: 0.6399 - val_accuracy: 0.6415 - val_loss: 0.6395\n",
            "Epoch 177/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6508 - loss: 0.6378 - val_accuracy: 0.6392 - val_loss: 0.6393\n",
            "Epoch 178/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6514 - loss: 0.6249 - val_accuracy: 0.6439 - val_loss: 0.6392\n",
            "Epoch 179/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6739 - loss: 0.6126 - val_accuracy: 0.6415 - val_loss: 0.6387\n",
            "Epoch 180/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6336 - loss: 0.6432 - val_accuracy: 0.6439 - val_loss: 0.6388\n",
            "Epoch 181/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6620 - loss: 0.6303 - val_accuracy: 0.6439 - val_loss: 0.6384\n",
            "Epoch 182/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6474 - loss: 0.6435 - val_accuracy: 0.6392 - val_loss: 0.6384\n",
            "Epoch 183/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6480 - loss: 0.6393 - val_accuracy: 0.6392 - val_loss: 0.6380\n",
            "Epoch 184/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6529 - loss: 0.6325 - val_accuracy: 0.6392 - val_loss: 0.6380\n",
            "Epoch 185/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6686 - loss: 0.6222 - val_accuracy: 0.6439 - val_loss: 0.6377\n",
            "Epoch 186/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6393 - loss: 0.6312 - val_accuracy: 0.6439 - val_loss: 0.6375\n",
            "Epoch 187/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6437 - loss: 0.6296 - val_accuracy: 0.6415 - val_loss: 0.6370\n",
            "Epoch 188/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6501 - loss: 0.6347 - val_accuracy: 0.6439 - val_loss: 0.6368\n",
            "Epoch 189/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6752 - loss: 0.6257 - val_accuracy: 0.6509 - val_loss: 0.6361\n",
            "Epoch 190/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6604 - loss: 0.6293 - val_accuracy: 0.6509 - val_loss: 0.6360\n",
            "Epoch 191/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6679 - loss: 0.6145 - val_accuracy: 0.6509 - val_loss: 0.6358\n",
            "Epoch 192/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6481 - loss: 0.6310 - val_accuracy: 0.6486 - val_loss: 0.6360\n",
            "Epoch 193/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6839 - loss: 0.6213 - val_accuracy: 0.6462 - val_loss: 0.6357\n",
            "Epoch 194/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6515 - loss: 0.6284 - val_accuracy: 0.6462 - val_loss: 0.6357\n",
            "Epoch 195/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6406 - loss: 0.6370 - val_accuracy: 0.6439 - val_loss: 0.6356\n",
            "Epoch 196/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6659 - loss: 0.6154 - val_accuracy: 0.6509 - val_loss: 0.6349\n",
            "Epoch 197/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6552 - loss: 0.6265 - val_accuracy: 0.6557 - val_loss: 0.6350\n",
            "Epoch 198/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6684 - loss: 0.6229 - val_accuracy: 0.6533 - val_loss: 0.6346\n",
            "Epoch 199/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6637 - loss: 0.6170 - val_accuracy: 0.6486 - val_loss: 0.6345\n",
            "Epoch 200/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6495 - loss: 0.6256 - val_accuracy: 0.6509 - val_loss: 0.6339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_epoch = np.argmin(history.history['val_loss'])\n",
        "print(f\"Best Epoch: {best_epoch+1}\")\n",
        "print(f\"Train Accuracy at Best Epoch: {history.history['accuracy'][best_epoch]:.4f}\")\n",
        "print(f\"Val Accuracy at Best Epoch: {history.history['val_accuracy'][best_epoch]:.4f}\")"
      ],
      "metadata": {
        "id": "1z30otXZnPVI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec5612ab-9f28-47e0-a13d-9d06e1af757d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Epoch: 200\n",
            "Train Accuracy at Best Epoch: 0.6588\n",
            "Val Accuracy at Best Epoch: 0.6509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}, Test Loss: {test_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8-xUOoyJk5_",
        "outputId": "2c35d7c3-cd92-4b60-fa22-e0abc22e7ea8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6745 - loss: 0.6114 \n",
            "Test Accuracy: 0.6682, Test Loss: 0.6180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_gaius_irakiza():\n",
        "    model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Nadam(learning_rate=0.0001)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            tf.keras.metrics.Precision(name='precision'),\n",
        "            tf.keras.metrics.Recall(name='recall'),\n",
        "            tf.keras.metrics.AUC(name='auc')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "gaius_model = model_gaius_irakiza()\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=30,\n",
        "    min_delta=0.0001,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "history = gaius_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=300,\n",
        "    batch_size=32,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "hmWIUNw0-l0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac043d6-afe3-4907-e9d4-ac33988912cf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.5743 - auc: 0.5435 - loss: 0.6844 - precision: 0.4177 - recall: 0.3650 - val_accuracy: 0.5330 - val_auc: 0.5028 - val_loss: 0.6892 - val_precision: 0.3815 - val_recall: 0.4204\n",
            "Epoch 2/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5440 - auc: 0.4892 - loss: 0.7024 - precision: 0.3417 - recall: 0.2853 - val_accuracy: 0.4953 - val_auc: 0.4990 - val_loss: 0.6924 - val_precision: 0.3662 - val_recall: 0.4968\n",
            "Epoch 3/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5692 - auc: 0.4871 - loss: 0.7011 - precision: 0.3785 - recall: 0.2747 - val_accuracy: 0.5212 - val_auc: 0.5064 - val_loss: 0.6898 - val_precision: 0.3814 - val_recall: 0.4713\n",
            "Epoch 4/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5814 - auc: 0.4988 - loss: 0.6880 - precision: 0.3755 - recall: 0.2337 - val_accuracy: 0.5259 - val_auc: 0.5081 - val_loss: 0.6870 - val_precision: 0.3706 - val_recall: 0.4013\n",
            "Epoch 5/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5719 - auc: 0.4812 - loss: 0.6910 - precision: 0.3373 - recall: 0.1806 - val_accuracy: 0.5519 - val_auc: 0.5132 - val_loss: 0.6818 - val_precision: 0.3636 - val_recall: 0.2803\n",
            "Epoch 6/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6031 - auc: 0.4877 - loss: 0.6853 - precision: 0.3873 - recall: 0.1899 - val_accuracy: 0.5991 - val_auc: 0.5251 - val_loss: 0.6766 - val_precision: 0.4270 - val_recall: 0.2420\n",
            "Epoch 7/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5922 - auc: 0.5110 - loss: 0.6790 - precision: 0.3716 - recall: 0.1484 - val_accuracy: 0.5991 - val_auc: 0.5272 - val_loss: 0.6737 - val_precision: 0.4133 - val_recall: 0.1975\n",
            "Epoch 8/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5826 - auc: 0.4709 - loss: 0.6901 - precision: 0.3005 - recall: 0.1028 - val_accuracy: 0.6179 - val_auc: 0.5365 - val_loss: 0.6697 - val_precision: 0.4510 - val_recall: 0.1465\n",
            "Epoch 9/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5903 - auc: 0.5210 - loss: 0.6796 - precision: 0.4036 - recall: 0.1537 - val_accuracy: 0.6203 - val_auc: 0.5421 - val_loss: 0.6661 - val_precision: 0.4500 - val_recall: 0.1146\n",
            "Epoch 10/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6218 - auc: 0.5248 - loss: 0.6659 - precision: 0.4192 - recall: 0.1491 - val_accuracy: 0.6274 - val_auc: 0.5441 - val_loss: 0.6635 - val_precision: 0.4848 - val_recall: 0.1019\n",
            "Epoch 11/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6020 - auc: 0.5290 - loss: 0.6764 - precision: 0.4472 - recall: 0.1592 - val_accuracy: 0.6226 - val_auc: 0.5545 - val_loss: 0.6608 - val_precision: 0.4444 - val_recall: 0.0764\n",
            "Epoch 12/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6110 - auc: 0.5624 - loss: 0.6546 - precision: 0.3835 - recall: 0.0981 - val_accuracy: 0.6203 - val_auc: 0.5595 - val_loss: 0.6591 - val_precision: 0.4091 - val_recall: 0.0573\n",
            "Epoch 13/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5976 - auc: 0.5097 - loss: 0.6764 - precision: 0.3770 - recall: 0.1170 - val_accuracy: 0.6226 - val_auc: 0.5629 - val_loss: 0.6583 - val_precision: 0.4348 - val_recall: 0.0637\n",
            "Epoch 14/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6242 - auc: 0.5435 - loss: 0.6616 - precision: 0.4352 - recall: 0.1251 - val_accuracy: 0.6179 - val_auc: 0.5638 - val_loss: 0.6574 - val_precision: 0.3684 - val_recall: 0.0446\n",
            "Epoch 15/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6231 - auc: 0.5309 - loss: 0.6708 - precision: 0.5059 - recall: 0.1180 - val_accuracy: 0.6156 - val_auc: 0.5592 - val_loss: 0.6580 - val_precision: 0.3500 - val_recall: 0.0446\n",
            "Epoch 16/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6138 - auc: 0.5525 - loss: 0.6610 - precision: 0.3961 - recall: 0.0928 - val_accuracy: 0.6203 - val_auc: 0.5643 - val_loss: 0.6564 - val_precision: 0.3750 - val_recall: 0.0382\n",
            "Epoch 17/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6234 - auc: 0.5365 - loss: 0.6633 - precision: 0.4061 - recall: 0.1275 - val_accuracy: 0.6203 - val_auc: 0.5699 - val_loss: 0.6552 - val_precision: 0.3333 - val_recall: 0.0255\n",
            "Epoch 18/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6097 - auc: 0.5302 - loss: 0.6678 - precision: 0.3609 - recall: 0.0898 - val_accuracy: 0.6179 - val_auc: 0.5743 - val_loss: 0.6534 - val_precision: 0.2727 - val_recall: 0.0191\n",
            "Epoch 19/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6156 - auc: 0.5294 - loss: 0.6661 - precision: 0.3919 - recall: 0.0634 - val_accuracy: 0.6179 - val_auc: 0.5764 - val_loss: 0.6524 - val_precision: 0.2727 - val_recall: 0.0191\n",
            "Epoch 20/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6354 - auc: 0.5764 - loss: 0.6475 - precision: 0.4688 - recall: 0.1189 - val_accuracy: 0.6250 - val_auc: 0.5773 - val_loss: 0.6518 - val_precision: 0.3750 - val_recall: 0.0191\n",
            "Epoch 21/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6353 - auc: 0.5628 - loss: 0.6537 - precision: 0.4911 - recall: 0.0919 - val_accuracy: 0.6250 - val_auc: 0.5771 - val_loss: 0.6515 - val_precision: 0.3750 - val_recall: 0.0191\n",
            "Epoch 22/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6326 - auc: 0.5412 - loss: 0.6546 - precision: 0.4356 - recall: 0.0926 - val_accuracy: 0.6226 - val_auc: 0.5785 - val_loss: 0.6503 - val_precision: 0.3333 - val_recall: 0.0191\n",
            "Epoch 23/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6249 - auc: 0.5561 - loss: 0.6564 - precision: 0.4308 - recall: 0.0776 - val_accuracy: 0.6226 - val_auc: 0.5821 - val_loss: 0.6497 - val_precision: 0.2857 - val_recall: 0.0127\n",
            "Epoch 24/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6319 - auc: 0.5818 - loss: 0.6432 - precision: 0.4219 - recall: 0.0765 - val_accuracy: 0.6226 - val_auc: 0.5816 - val_loss: 0.6498 - val_precision: 0.2857 - val_recall: 0.0127\n",
            "Epoch 25/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6192 - auc: 0.5629 - loss: 0.6544 - precision: 0.4105 - recall: 0.0780 - val_accuracy: 0.6250 - val_auc: 0.5817 - val_loss: 0.6491 - val_precision: 0.3333 - val_recall: 0.0127\n",
            "Epoch 26/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6039 - auc: 0.5596 - loss: 0.6628 - precision: 0.4045 - recall: 0.0715 - val_accuracy: 0.6226 - val_auc: 0.5822 - val_loss: 0.6487 - val_precision: 0.2857 - val_recall: 0.0127\n",
            "Epoch 27/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6149 - auc: 0.6000 - loss: 0.6460 - precision: 0.3760 - recall: 0.0601 - val_accuracy: 0.6274 - val_auc: 0.5851 - val_loss: 0.6477 - val_precision: 0.4000 - val_recall: 0.0127\n",
            "Epoch 28/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6446 - auc: 0.5412 - loss: 0.6482 - precision: 0.4174 - recall: 0.0699 - val_accuracy: 0.6297 - val_auc: 0.5836 - val_loss: 0.6473 - val_precision: 0.5000 - val_recall: 0.0191\n",
            "Epoch 29/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6396 - auc: 0.5444 - loss: 0.6502 - precision: 0.3894 - recall: 0.0737 - val_accuracy: 0.6274 - val_auc: 0.5880 - val_loss: 0.6465 - val_precision: 0.4000 - val_recall: 0.0127\n",
            "Epoch 30/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6501 - auc: 0.5495 - loss: 0.6547 - precision: 0.5984 - recall: 0.0963 - val_accuracy: 0.6297 - val_auc: 0.5864 - val_loss: 0.6460 - val_precision: 0.5000 - val_recall: 0.0191\n",
            "Epoch 31/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6165 - auc: 0.5628 - loss: 0.6568 - precision: 0.4007 - recall: 0.0701 - val_accuracy: 0.6274 - val_auc: 0.5882 - val_loss: 0.6457 - val_precision: 0.4000 - val_recall: 0.0127\n",
            "Epoch 32/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6202 - auc: 0.5495 - loss: 0.6679 - precision: 0.5134 - recall: 0.0870 - val_accuracy: 0.6274 - val_auc: 0.5914 - val_loss: 0.6448 - val_precision: 0.4000 - val_recall: 0.0127\n",
            "Epoch 33/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6083 - auc: 0.5540 - loss: 0.6598 - precision: 0.3420 - recall: 0.0522 - val_accuracy: 0.6297 - val_auc: 0.5960 - val_loss: 0.6439 - val_precision: 0.5000 - val_recall: 0.0191\n",
            "Epoch 34/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6177 - auc: 0.5785 - loss: 0.6506 - precision: 0.4184 - recall: 0.0730 - val_accuracy: 0.6321 - val_auc: 0.5968 - val_loss: 0.6435 - val_precision: 0.6000 - val_recall: 0.0191\n",
            "Epoch 35/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6296 - auc: 0.5329 - loss: 0.6529 - precision: 0.3674 - recall: 0.0557 - val_accuracy: 0.6274 - val_auc: 0.5984 - val_loss: 0.6428 - val_precision: 0.4286 - val_recall: 0.0191\n",
            "Epoch 36/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6277 - auc: 0.5429 - loss: 0.6581 - precision: 0.4316 - recall: 0.0608 - val_accuracy: 0.6297 - val_auc: 0.5992 - val_loss: 0.6422 - val_precision: 0.5000 - val_recall: 0.0255\n",
            "Epoch 37/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6509 - auc: 0.5892 - loss: 0.6429 - precision: 0.5835 - recall: 0.0858 - val_accuracy: 0.6344 - val_auc: 0.5991 - val_loss: 0.6420 - val_precision: 0.6667 - val_recall: 0.0255\n",
            "Epoch 38/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6320 - auc: 0.5862 - loss: 0.6485 - precision: 0.5545 - recall: 0.0717 - val_accuracy: 0.6297 - val_auc: 0.5965 - val_loss: 0.6419 - val_precision: 0.5000 - val_recall: 0.0255\n",
            "Epoch 39/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6308 - auc: 0.5881 - loss: 0.6457 - precision: 0.5103 - recall: 0.0839 - val_accuracy: 0.6321 - val_auc: 0.5990 - val_loss: 0.6413 - val_precision: 0.5714 - val_recall: 0.0255\n",
            "Epoch 40/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6298 - auc: 0.5708 - loss: 0.6503 - precision: 0.4642 - recall: 0.0841 - val_accuracy: 0.6321 - val_auc: 0.6030 - val_loss: 0.6404 - val_precision: 0.5714 - val_recall: 0.0255\n",
            "Epoch 41/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6327 - auc: 0.5839 - loss: 0.6370 - precision: 0.3452 - recall: 0.0613 - val_accuracy: 0.6297 - val_auc: 0.6053 - val_loss: 0.6402 - val_precision: 0.5000 - val_recall: 0.0255\n",
            "Epoch 42/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6314 - auc: 0.5685 - loss: 0.6486 - precision: 0.3352 - recall: 0.0386 - val_accuracy: 0.6321 - val_auc: 0.6021 - val_loss: 0.6405 - val_precision: 0.5556 - val_recall: 0.0318\n",
            "Epoch 43/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6201 - auc: 0.5947 - loss: 0.6535 - precision: 0.5908 - recall: 0.0650 - val_accuracy: 0.6321 - val_auc: 0.6034 - val_loss: 0.6405 - val_precision: 0.5556 - val_recall: 0.0318\n",
            "Epoch 44/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6221 - auc: 0.5899 - loss: 0.6456 - precision: 0.4263 - recall: 0.0592 - val_accuracy: 0.6368 - val_auc: 0.6087 - val_loss: 0.6388 - val_precision: 0.6667 - val_recall: 0.0382\n",
            "Epoch 45/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6209 - auc: 0.5667 - loss: 0.6558 - precision: 0.4285 - recall: 0.0664 - val_accuracy: 0.6321 - val_auc: 0.6049 - val_loss: 0.6391 - val_precision: 0.5455 - val_recall: 0.0382\n",
            "Epoch 46/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6374 - auc: 0.5987 - loss: 0.6397 - precision: 0.4840 - recall: 0.0694 - val_accuracy: 0.6321 - val_auc: 0.6038 - val_loss: 0.6389 - val_precision: 0.5455 - val_recall: 0.0382\n",
            "Epoch 47/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6219 - auc: 0.6085 - loss: 0.6467 - precision: 0.5149 - recall: 0.0919 - val_accuracy: 0.6321 - val_auc: 0.6041 - val_loss: 0.6393 - val_precision: 0.5455 - val_recall: 0.0382\n",
            "Epoch 48/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6291 - auc: 0.5709 - loss: 0.6502 - precision: 0.4189 - recall: 0.0602 - val_accuracy: 0.6392 - val_auc: 0.6058 - val_loss: 0.6384 - val_precision: 0.7000 - val_recall: 0.0446\n",
            "Epoch 49/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6479 - auc: 0.6036 - loss: 0.6377 - precision: 0.5610 - recall: 0.0905 - val_accuracy: 0.6368 - val_auc: 0.6082 - val_loss: 0.6372 - val_precision: 0.6667 - val_recall: 0.0382\n",
            "Epoch 50/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6198 - auc: 0.5907 - loss: 0.6534 - precision: 0.5189 - recall: 0.0838 - val_accuracy: 0.6415 - val_auc: 0.6084 - val_loss: 0.6368 - val_precision: 0.7273 - val_recall: 0.0510\n",
            "Epoch 51/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6308 - auc: 0.6167 - loss: 0.6343 - precision: 0.4581 - recall: 0.0758 - val_accuracy: 0.6392 - val_auc: 0.6114 - val_loss: 0.6365 - val_precision: 0.7000 - val_recall: 0.0446\n",
            "Epoch 52/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6484 - auc: 0.6384 - loss: 0.6304 - precision: 0.6441 - recall: 0.1095 - val_accuracy: 0.6439 - val_auc: 0.6092 - val_loss: 0.6357 - val_precision: 0.7500 - val_recall: 0.0573\n",
            "Epoch 53/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6441 - auc: 0.5874 - loss: 0.6455 - precision: 0.6077 - recall: 0.0904 - val_accuracy: 0.6415 - val_auc: 0.6115 - val_loss: 0.6354 - val_precision: 0.7273 - val_recall: 0.0510\n",
            "Epoch 54/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6515 - auc: 0.6109 - loss: 0.6336 - precision: 0.5688 - recall: 0.1098 - val_accuracy: 0.6415 - val_auc: 0.6092 - val_loss: 0.6360 - val_precision: 0.6923 - val_recall: 0.0573\n",
            "Epoch 55/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6370 - auc: 0.5882 - loss: 0.6461 - precision: 0.5296 - recall: 0.0903 - val_accuracy: 0.6392 - val_auc: 0.6094 - val_loss: 0.6360 - val_precision: 0.6429 - val_recall: 0.0573\n",
            "Epoch 56/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6474 - auc: 0.6024 - loss: 0.6437 - precision: 0.6350 - recall: 0.1080 - val_accuracy: 0.6392 - val_auc: 0.6054 - val_loss: 0.6369 - val_precision: 0.6429 - val_recall: 0.0573\n",
            "Epoch 57/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6538 - auc: 0.6008 - loss: 0.6320 - precision: 0.4680 - recall: 0.0738 - val_accuracy: 0.6392 - val_auc: 0.6039 - val_loss: 0.6370 - val_precision: 0.6429 - val_recall: 0.0573\n",
            "Epoch 58/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6448 - auc: 0.6027 - loss: 0.6450 - precision: 0.5829 - recall: 0.1123 - val_accuracy: 0.6439 - val_auc: 0.6064 - val_loss: 0.6366 - val_precision: 0.6875 - val_recall: 0.0701\n",
            "Epoch 59/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6404 - auc: 0.6179 - loss: 0.6333 - precision: 0.5035 - recall: 0.1036 - val_accuracy: 0.6439 - val_auc: 0.6044 - val_loss: 0.6366 - val_precision: 0.6875 - val_recall: 0.0701\n",
            "Epoch 60/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6318 - auc: 0.6069 - loss: 0.6401 - precision: 0.4877 - recall: 0.0969 - val_accuracy: 0.6415 - val_auc: 0.6086 - val_loss: 0.6355 - val_precision: 0.6667 - val_recall: 0.0637\n",
            "Epoch 61/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6232 - auc: 0.6066 - loss: 0.6452 - precision: 0.5348 - recall: 0.1145 - val_accuracy: 0.6462 - val_auc: 0.6052 - val_loss: 0.6359 - val_precision: 0.7059 - val_recall: 0.0764\n",
            "Epoch 62/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6663 - auc: 0.6229 - loss: 0.6224 - precision: 0.5680 - recall: 0.1033 - val_accuracy: 0.6415 - val_auc: 0.6060 - val_loss: 0.6353 - val_precision: 0.6471 - val_recall: 0.0701\n",
            "Epoch 63/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6471 - auc: 0.6228 - loss: 0.6364 - precision: 0.5940 - recall: 0.1207 - val_accuracy: 0.6439 - val_auc: 0.6074 - val_loss: 0.6350 - val_precision: 0.6875 - val_recall: 0.0701\n",
            "Epoch 64/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6455 - auc: 0.6225 - loss: 0.6347 - precision: 0.5586 - recall: 0.1176 - val_accuracy: 0.6509 - val_auc: 0.6122 - val_loss: 0.6335 - val_precision: 0.7143 - val_recall: 0.0955\n",
            "Epoch 65/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6365 - auc: 0.6172 - loss: 0.6354 - precision: 0.5207 - recall: 0.1176 - val_accuracy: 0.6462 - val_auc: 0.6117 - val_loss: 0.6335 - val_precision: 0.6667 - val_recall: 0.0892\n",
            "Epoch 66/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6306 - auc: 0.6218 - loss: 0.6435 - precision: 0.5736 - recall: 0.1278 - val_accuracy: 0.6462 - val_auc: 0.6166 - val_loss: 0.6325 - val_precision: 0.6667 - val_recall: 0.0892\n",
            "Epoch 67/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6292 - auc: 0.5936 - loss: 0.6459 - precision: 0.5075 - recall: 0.1236 - val_accuracy: 0.6486 - val_auc: 0.6169 - val_loss: 0.6323 - val_precision: 0.6818 - val_recall: 0.0955\n",
            "Epoch 68/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6286 - auc: 0.6211 - loss: 0.6460 - precision: 0.5598 - recall: 0.1367 - val_accuracy: 0.6509 - val_auc: 0.6176 - val_loss: 0.6319 - val_precision: 0.6957 - val_recall: 0.1019\n",
            "Epoch 69/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6473 - auc: 0.6184 - loss: 0.6374 - precision: 0.6075 - recall: 0.1537 - val_accuracy: 0.6486 - val_auc: 0.6177 - val_loss: 0.6315 - val_precision: 0.6538 - val_recall: 0.1083\n",
            "Epoch 70/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6428 - auc: 0.6354 - loss: 0.6244 - precision: 0.5010 - recall: 0.1437 - val_accuracy: 0.6486 - val_auc: 0.6172 - val_loss: 0.6312 - val_precision: 0.6538 - val_recall: 0.1083\n",
            "Epoch 71/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6235 - auc: 0.6200 - loss: 0.6410 - precision: 0.5043 - recall: 0.1325 - val_accuracy: 0.6415 - val_auc: 0.6204 - val_loss: 0.6305 - val_precision: 0.5806 - val_recall: 0.1146\n",
            "Epoch 72/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6470 - auc: 0.6047 - loss: 0.6336 - precision: 0.5021 - recall: 0.1555 - val_accuracy: 0.6462 - val_auc: 0.6208 - val_loss: 0.6302 - val_precision: 0.6207 - val_recall: 0.1146\n",
            "Epoch 73/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6273 - auc: 0.6054 - loss: 0.6493 - precision: 0.5397 - recall: 0.1706 - val_accuracy: 0.6439 - val_auc: 0.6227 - val_loss: 0.6298 - val_precision: 0.6000 - val_recall: 0.1146\n",
            "Epoch 74/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6405 - auc: 0.6375 - loss: 0.6309 - precision: 0.5506 - recall: 0.1412 - val_accuracy: 0.6462 - val_auc: 0.6233 - val_loss: 0.6298 - val_precision: 0.6207 - val_recall: 0.1146\n",
            "Epoch 75/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6531 - auc: 0.6411 - loss: 0.6281 - precision: 0.6023 - recall: 0.1774 - val_accuracy: 0.6557 - val_auc: 0.6212 - val_loss: 0.6298 - val_precision: 0.6774 - val_recall: 0.1338\n",
            "Epoch 76/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6379 - auc: 0.6086 - loss: 0.6394 - precision: 0.5322 - recall: 0.1765 - val_accuracy: 0.6557 - val_auc: 0.6243 - val_loss: 0.6293 - val_precision: 0.6667 - val_recall: 0.1401\n",
            "Epoch 77/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6435 - auc: 0.6226 - loss: 0.6399 - precision: 0.5984 - recall: 0.1857 - val_accuracy: 0.6580 - val_auc: 0.6266 - val_loss: 0.6288 - val_precision: 0.6667 - val_recall: 0.1529\n",
            "Epoch 78/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6406 - auc: 0.6104 - loss: 0.6383 - precision: 0.5349 - recall: 0.1647 - val_accuracy: 0.6533 - val_auc: 0.6290 - val_loss: 0.6279 - val_precision: 0.6316 - val_recall: 0.1529\n",
            "Epoch 79/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6635 - auc: 0.6279 - loss: 0.6203 - precision: 0.5524 - recall: 0.2107 - val_accuracy: 0.6651 - val_auc: 0.6311 - val_loss: 0.6270 - val_precision: 0.6829 - val_recall: 0.1783\n",
            "Epoch 80/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6495 - auc: 0.6632 - loss: 0.6160 - precision: 0.5764 - recall: 0.1962 - val_accuracy: 0.6627 - val_auc: 0.6318 - val_loss: 0.6266 - val_precision: 0.6522 - val_recall: 0.1911\n",
            "Epoch 81/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6519 - auc: 0.6243 - loss: 0.6347 - precision: 0.5483 - recall: 0.1921 - val_accuracy: 0.6627 - val_auc: 0.6310 - val_loss: 0.6268 - val_precision: 0.6522 - val_recall: 0.1911\n",
            "Epoch 82/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6438 - auc: 0.6332 - loss: 0.6310 - precision: 0.5456 - recall: 0.1969 - val_accuracy: 0.6651 - val_auc: 0.6323 - val_loss: 0.6264 - val_precision: 0.6531 - val_recall: 0.2038\n",
            "Epoch 83/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6635 - auc: 0.6570 - loss: 0.6101 - precision: 0.5599 - recall: 0.2016 - val_accuracy: 0.6745 - val_auc: 0.6329 - val_loss: 0.6262 - val_precision: 0.6939 - val_recall: 0.2166\n",
            "Epoch 84/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6561 - auc: 0.6607 - loss: 0.6281 - precision: 0.6526 - recall: 0.2222 - val_accuracy: 0.6722 - val_auc: 0.6354 - val_loss: 0.6248 - val_precision: 0.6800 - val_recall: 0.2166\n",
            "Epoch 85/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6603 - auc: 0.6597 - loss: 0.6268 - precision: 0.6565 - recall: 0.2283 - val_accuracy: 0.6698 - val_auc: 0.6362 - val_loss: 0.6250 - val_precision: 0.6809 - val_recall: 0.2038\n",
            "Epoch 86/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6446 - auc: 0.6288 - loss: 0.6426 - precision: 0.6210 - recall: 0.2279 - val_accuracy: 0.6698 - val_auc: 0.6365 - val_loss: 0.6250 - val_precision: 0.6735 - val_recall: 0.2102\n",
            "Epoch 87/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6273 - auc: 0.6418 - loss: 0.6338 - precision: 0.5282 - recall: 0.1827 - val_accuracy: 0.6698 - val_auc: 0.6342 - val_loss: 0.6256 - val_precision: 0.6809 - val_recall: 0.2038\n",
            "Epoch 88/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6477 - auc: 0.6656 - loss: 0.6178 - precision: 0.5767 - recall: 0.1971 - val_accuracy: 0.6769 - val_auc: 0.6358 - val_loss: 0.6249 - val_precision: 0.7083 - val_recall: 0.2166\n",
            "Epoch 89/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6727 - auc: 0.6515 - loss: 0.6133 - precision: 0.5671 - recall: 0.2270 - val_accuracy: 0.6816 - val_auc: 0.6357 - val_loss: 0.6252 - val_precision: 0.7292 - val_recall: 0.2229\n",
            "Epoch 90/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6724 - auc: 0.6633 - loss: 0.6077 - precision: 0.6003 - recall: 0.2399 - val_accuracy: 0.6816 - val_auc: 0.6368 - val_loss: 0.6249 - val_precision: 0.7200 - val_recall: 0.2293\n",
            "Epoch 91/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6521 - auc: 0.6352 - loss: 0.6334 - precision: 0.5671 - recall: 0.2223 - val_accuracy: 0.6769 - val_auc: 0.6348 - val_loss: 0.6261 - val_precision: 0.7000 - val_recall: 0.2229\n",
            "Epoch 92/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6391 - auc: 0.6729 - loss: 0.6185 - precision: 0.5779 - recall: 0.2402 - val_accuracy: 0.6769 - val_auc: 0.6334 - val_loss: 0.6264 - val_precision: 0.6852 - val_recall: 0.2357\n",
            "Epoch 93/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6451 - auc: 0.6369 - loss: 0.6274 - precision: 0.5334 - recall: 0.2153 - val_accuracy: 0.6792 - val_auc: 0.6352 - val_loss: 0.6249 - val_precision: 0.6981 - val_recall: 0.2357\n",
            "Epoch 94/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6500 - auc: 0.6462 - loss: 0.6174 - precision: 0.5097 - recall: 0.2305 - val_accuracy: 0.6769 - val_auc: 0.6346 - val_loss: 0.6252 - val_precision: 0.6852 - val_recall: 0.2357\n",
            "Epoch 95/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6520 - auc: 0.6638 - loss: 0.6147 - precision: 0.5609 - recall: 0.2340 - val_accuracy: 0.6745 - val_auc: 0.6359 - val_loss: 0.6242 - val_precision: 0.6727 - val_recall: 0.2357\n",
            "Epoch 96/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6457 - auc: 0.6459 - loss: 0.6324 - precision: 0.5532 - recall: 0.2470 - val_accuracy: 0.6769 - val_auc: 0.6383 - val_loss: 0.6234 - val_precision: 0.6852 - val_recall: 0.2357\n",
            "Epoch 97/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6740 - auc: 0.6653 - loss: 0.6104 - precision: 0.6050 - recall: 0.2849 - val_accuracy: 0.6698 - val_auc: 0.6362 - val_loss: 0.6252 - val_precision: 0.6491 - val_recall: 0.2357\n",
            "Epoch 98/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6410 - auc: 0.6411 - loss: 0.6303 - precision: 0.5502 - recall: 0.2194 - val_accuracy: 0.6769 - val_auc: 0.6326 - val_loss: 0.6268 - val_precision: 0.6667 - val_recall: 0.2548\n",
            "Epoch 99/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6178 - auc: 0.6409 - loss: 0.6401 - precision: 0.5099 - recall: 0.2183 - val_accuracy: 0.6722 - val_auc: 0.6330 - val_loss: 0.6263 - val_precision: 0.6500 - val_recall: 0.2484\n",
            "Epoch 100/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6345 - auc: 0.6344 - loss: 0.6323 - precision: 0.5278 - recall: 0.2316 - val_accuracy: 0.6722 - val_auc: 0.6325 - val_loss: 0.6270 - val_precision: 0.6500 - val_recall: 0.2484\n",
            "Epoch 101/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6614 - auc: 0.6678 - loss: 0.6137 - precision: 0.5447 - recall: 0.2629 - val_accuracy: 0.6745 - val_auc: 0.6333 - val_loss: 0.6271 - val_precision: 0.6610 - val_recall: 0.2484\n",
            "Epoch 102/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6792 - auc: 0.6827 - loss: 0.6142 - precision: 0.6462 - recall: 0.2991 - val_accuracy: 0.6745 - val_auc: 0.6329 - val_loss: 0.6275 - val_precision: 0.6557 - val_recall: 0.2548\n",
            "Epoch 103/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6586 - auc: 0.6935 - loss: 0.6074 - precision: 0.6070 - recall: 0.2828 - val_accuracy: 0.6792 - val_auc: 0.6330 - val_loss: 0.6279 - val_precision: 0.6721 - val_recall: 0.2611\n",
            "Epoch 104/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6439 - auc: 0.6665 - loss: 0.6204 - precision: 0.5608 - recall: 0.2456 - val_accuracy: 0.6840 - val_auc: 0.6339 - val_loss: 0.6276 - val_precision: 0.6949 - val_recall: 0.2611\n",
            "Epoch 105/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6582 - auc: 0.6640 - loss: 0.6165 - precision: 0.5753 - recall: 0.2691 - val_accuracy: 0.6792 - val_auc: 0.6354 - val_loss: 0.6271 - val_precision: 0.6667 - val_recall: 0.2675\n",
            "Epoch 106/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6348 - auc: 0.6637 - loss: 0.6190 - precision: 0.5249 - recall: 0.2330 - val_accuracy: 0.6769 - val_auc: 0.6365 - val_loss: 0.6263 - val_precision: 0.6613 - val_recall: 0.2611\n",
            "Epoch 107/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6674 - auc: 0.6616 - loss: 0.6198 - precision: 0.6310 - recall: 0.2711 - val_accuracy: 0.6816 - val_auc: 0.6381 - val_loss: 0.6256 - val_precision: 0.6774 - val_recall: 0.2675\n",
            "Epoch 108/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6499 - auc: 0.6614 - loss: 0.6213 - precision: 0.5512 - recall: 0.2493 - val_accuracy: 0.6722 - val_auc: 0.6365 - val_loss: 0.6258 - val_precision: 0.6364 - val_recall: 0.2675\n",
            "Epoch 109/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6623 - auc: 0.6601 - loss: 0.6192 - precision: 0.5949 - recall: 0.2670 - val_accuracy: 0.6769 - val_auc: 0.6384 - val_loss: 0.6252 - val_precision: 0.6562 - val_recall: 0.2675\n",
            "Epoch 110/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6830 - auc: 0.6877 - loss: 0.6001 - precision: 0.6136 - recall: 0.2913 - val_accuracy: 0.6604 - val_auc: 0.6390 - val_loss: 0.6246 - val_precision: 0.5915 - val_recall: 0.2675\n",
            "Epoch 111/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6587 - auc: 0.6765 - loss: 0.6097 - precision: 0.5624 - recall: 0.2791 - val_accuracy: 0.6651 - val_auc: 0.6374 - val_loss: 0.6248 - val_precision: 0.6056 - val_recall: 0.2739\n",
            "Epoch 112/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6734 - auc: 0.6709 - loss: 0.6064 - precision: 0.5713 - recall: 0.2860 - val_accuracy: 0.6675 - val_auc: 0.6401 - val_loss: 0.6235 - val_precision: 0.6143 - val_recall: 0.2739\n",
            "Epoch 113/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6491 - auc: 0.6585 - loss: 0.6233 - precision: 0.5604 - recall: 0.2646 - val_accuracy: 0.6675 - val_auc: 0.6393 - val_loss: 0.6249 - val_precision: 0.6143 - val_recall: 0.2739\n",
            "Epoch 114/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6670 - auc: 0.6694 - loss: 0.6239 - precision: 0.6661 - recall: 0.2876 - val_accuracy: 0.6792 - val_auc: 0.6407 - val_loss: 0.6244 - val_precision: 0.6615 - val_recall: 0.2739\n",
            "Epoch 115/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6539 - auc: 0.6492 - loss: 0.6274 - precision: 0.5863 - recall: 0.2613 - val_accuracy: 0.6769 - val_auc: 0.6421 - val_loss: 0.6239 - val_precision: 0.6515 - val_recall: 0.2739\n",
            "Epoch 116/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6438 - auc: 0.6788 - loss: 0.6142 - precision: 0.5589 - recall: 0.2591 - val_accuracy: 0.6698 - val_auc: 0.6419 - val_loss: 0.6243 - val_precision: 0.6232 - val_recall: 0.2739\n",
            "Epoch 117/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6620 - auc: 0.6906 - loss: 0.6070 - precision: 0.6104 - recall: 0.2659 - val_accuracy: 0.6651 - val_auc: 0.6459 - val_loss: 0.6229 - val_precision: 0.6056 - val_recall: 0.2739\n",
            "Epoch 118/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6454 - auc: 0.6681 - loss: 0.6194 - precision: 0.5729 - recall: 0.2625 - val_accuracy: 0.6627 - val_auc: 0.6441 - val_loss: 0.6238 - val_precision: 0.5972 - val_recall: 0.2739\n",
            "Epoch 119/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6613 - auc: 0.6692 - loss: 0.6148 - precision: 0.5822 - recall: 0.2933 - val_accuracy: 0.6651 - val_auc: 0.6459 - val_loss: 0.6234 - val_precision: 0.6027 - val_recall: 0.2803\n",
            "Epoch 120/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6370 - auc: 0.6510 - loss: 0.6284 - precision: 0.5535 - recall: 0.2435 - val_accuracy: 0.6745 - val_auc: 0.6466 - val_loss: 0.6232 - val_precision: 0.6377 - val_recall: 0.2803\n",
            "Epoch 121/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6634 - auc: 0.6890 - loss: 0.6063 - precision: 0.6084 - recall: 0.2862 - val_accuracy: 0.6698 - val_auc: 0.6469 - val_loss: 0.6228 - val_precision: 0.6232 - val_recall: 0.2739\n",
            "Epoch 122/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6635 - auc: 0.6891 - loss: 0.6018 - precision: 0.5747 - recall: 0.2879 - val_accuracy: 0.6698 - val_auc: 0.6450 - val_loss: 0.6245 - val_precision: 0.6197 - val_recall: 0.2803\n",
            "Epoch 123/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6740 - auc: 0.6586 - loss: 0.6213 - precision: 0.5936 - recall: 0.3144 - val_accuracy: 0.6651 - val_auc: 0.6466 - val_loss: 0.6236 - val_precision: 0.6027 - val_recall: 0.2803\n",
            "Epoch 124/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6648 - auc: 0.6656 - loss: 0.6176 - precision: 0.6081 - recall: 0.2930 - val_accuracy: 0.6698 - val_auc: 0.6464 - val_loss: 0.6238 - val_precision: 0.6164 - val_recall: 0.2866\n",
            "Epoch 125/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6644 - auc: 0.6928 - loss: 0.6121 - precision: 0.6516 - recall: 0.2869 - val_accuracy: 0.6651 - val_auc: 0.6446 - val_loss: 0.6246 - val_precision: 0.6027 - val_recall: 0.2803\n",
            "Epoch 126/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6600 - auc: 0.6647 - loss: 0.6128 - precision: 0.5714 - recall: 0.2714 - val_accuracy: 0.6651 - val_auc: 0.6438 - val_loss: 0.6248 - val_precision: 0.6000 - val_recall: 0.2866\n",
            "Epoch 127/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6799 - auc: 0.6836 - loss: 0.6069 - precision: 0.6316 - recall: 0.3041 - val_accuracy: 0.6792 - val_auc: 0.6444 - val_loss: 0.6245 - val_precision: 0.6438 - val_recall: 0.2994\n",
            "Epoch 128/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6577 - auc: 0.6691 - loss: 0.6141 - precision: 0.5839 - recall: 0.2775 - val_accuracy: 0.6745 - val_auc: 0.6426 - val_loss: 0.6250 - val_precision: 0.6267 - val_recall: 0.2994\n",
            "Epoch 129/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6514 - auc: 0.6737 - loss: 0.6164 - precision: 0.5802 - recall: 0.2608 - val_accuracy: 0.6698 - val_auc: 0.6423 - val_loss: 0.6249 - val_precision: 0.6104 - val_recall: 0.2994\n",
            "Epoch 130/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6635 - auc: 0.6807 - loss: 0.6117 - precision: 0.6153 - recall: 0.2886 - val_accuracy: 0.6651 - val_auc: 0.6413 - val_loss: 0.6254 - val_precision: 0.6000 - val_recall: 0.2866\n",
            "Epoch 131/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6749 - auc: 0.6671 - loss: 0.6096 - precision: 0.5964 - recall: 0.2932 - val_accuracy: 0.6627 - val_auc: 0.6398 - val_loss: 0.6257 - val_precision: 0.5897 - val_recall: 0.2930\n",
            "Epoch 132/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6649 - auc: 0.6656 - loss: 0.6123 - precision: 0.5917 - recall: 0.2780 - val_accuracy: 0.6651 - val_auc: 0.6399 - val_loss: 0.6260 - val_precision: 0.5949 - val_recall: 0.2994\n",
            "Epoch 133/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6739 - auc: 0.7114 - loss: 0.5928 - precision: 0.6132 - recall: 0.3225 - val_accuracy: 0.6627 - val_auc: 0.6435 - val_loss: 0.6249 - val_precision: 0.5897 - val_recall: 0.2930\n",
            "Epoch 134/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6481 - auc: 0.6650 - loss: 0.6206 - precision: 0.5876 - recall: 0.2632 - val_accuracy: 0.6627 - val_auc: 0.6449 - val_loss: 0.6238 - val_precision: 0.5875 - val_recall: 0.2994\n",
            "Epoch 135/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6594 - auc: 0.6658 - loss: 0.6231 - precision: 0.5900 - recall: 0.2970 - val_accuracy: 0.6604 - val_auc: 0.6456 - val_loss: 0.6235 - val_precision: 0.5823 - val_recall: 0.2930\n",
            "Epoch 136/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6531 - auc: 0.6790 - loss: 0.6156 - precision: 0.6039 - recall: 0.3015 - val_accuracy: 0.6627 - val_auc: 0.6472 - val_loss: 0.6233 - val_precision: 0.5897 - val_recall: 0.2930\n",
            "Epoch 137/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6724 - auc: 0.6870 - loss: 0.6027 - precision: 0.6059 - recall: 0.3191 - val_accuracy: 0.6580 - val_auc: 0.6464 - val_loss: 0.6240 - val_precision: 0.5750 - val_recall: 0.2930\n",
            "Epoch 138/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6869 - auc: 0.7071 - loss: 0.5904 - precision: 0.6184 - recall: 0.3161 - val_accuracy: 0.6533 - val_auc: 0.6459 - val_loss: 0.6234 - val_precision: 0.5595 - val_recall: 0.2994\n",
            "Epoch 139/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6820 - auc: 0.6968 - loss: 0.6045 - precision: 0.6331 - recall: 0.3351 - val_accuracy: 0.6557 - val_auc: 0.6430 - val_loss: 0.6245 - val_precision: 0.5663 - val_recall: 0.2994\n",
            "Epoch 140/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6645 - auc: 0.6694 - loss: 0.6084 - precision: 0.5540 - recall: 0.3049 - val_accuracy: 0.6604 - val_auc: 0.6453 - val_loss: 0.6233 - val_precision: 0.5802 - val_recall: 0.2994\n",
            "Epoch 141/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6850 - auc: 0.6900 - loss: 0.6015 - precision: 0.6467 - recall: 0.3193 - val_accuracy: 0.6580 - val_auc: 0.6424 - val_loss: 0.6248 - val_precision: 0.5750 - val_recall: 0.2930\n",
            "Epoch 142/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6597 - auc: 0.6748 - loss: 0.6136 - precision: 0.5843 - recall: 0.3087 - val_accuracy: 0.6533 - val_auc: 0.6430 - val_loss: 0.6250 - val_precision: 0.5610 - val_recall: 0.2930\n",
            "Epoch 143/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6668 - auc: 0.6741 - loss: 0.6095 - precision: 0.6117 - recall: 0.3161 - val_accuracy: 0.6557 - val_auc: 0.6440 - val_loss: 0.6249 - val_precision: 0.5679 - val_recall: 0.2930\n",
            "Epoch 144/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6740 - auc: 0.6607 - loss: 0.6135 - precision: 0.6092 - recall: 0.3084 - val_accuracy: 0.6533 - val_auc: 0.6425 - val_loss: 0.6257 - val_precision: 0.5610 - val_recall: 0.2930\n",
            "Epoch 145/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6704 - auc: 0.6856 - loss: 0.6000 - precision: 0.5900 - recall: 0.2990 - val_accuracy: 0.6462 - val_auc: 0.6425 - val_loss: 0.6254 - val_precision: 0.5412 - val_recall: 0.2930\n",
            "Epoch 146/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6481 - auc: 0.6691 - loss: 0.6217 - precision: 0.5607 - recall: 0.2747 - val_accuracy: 0.6392 - val_auc: 0.6437 - val_loss: 0.6250 - val_precision: 0.5233 - val_recall: 0.2866\n",
            "Epoch 147/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6837 - auc: 0.6963 - loss: 0.5983 - precision: 0.6263 - recall: 0.3179 - val_accuracy: 0.6439 - val_auc: 0.6455 - val_loss: 0.6247 - val_precision: 0.5357 - val_recall: 0.2866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_epoch = np.argmin(history.history['val_loss'])\n",
        "print(f\"Best Epoch: {best_epoch+1}\")\n",
        "print(f\"Train Accuracy at Best Epoch: {history.history['accuracy'][best_epoch]:.4f}\")\n",
        "print(f\"Val Accuracy at Best Epoch: {history.history['val_accuracy'][best_epoch]:.4f}\")"
      ],
      "metadata": {
        "id": "nIQiApSSMZR8",
        "outputId": "974af313-a129-4da2-f189-5182c0cfaeb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Epoch: 267\n",
            "Train Accuracy at Best Epoch: 0.7017\n",
            "Val Accuracy at Best Epoch: 0.6863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy, test_precision, test_recall, test_auc = gaius_model.evaluate(X_test, y_test, verbose=1)\n",
        "\n",
        "# Print results with clear formatting\n",
        "print(\"\\nTest Evaluation Metrics:\")\n",
        "print(f\"  Loss      : {test_loss:.4f}\")\n",
        "print(f\"  Accuracy  : {test_accuracy:.4f}\")\n",
        "print(f\"  Precision : {test_precision:.4f}\")\n",
        "print(f\"  Recall    : {test_recall:.4f}\")\n",
        "print(f\"  AUC       : {test_auc:.4f}\")\n"
      ],
      "metadata": {
        "id": "FaanMjPsMpYH",
        "outputId": "01b244ac-fbe9-429f-9862-f42cf01ecec9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6774 - auc: 0.6722 - loss: 0.6024 - precision: 0.6296 - recall: 0.2362 \n",
            "\n",
            "Test Evaluation Metrics:\n",
            "  Loss      : 0.6084\n",
            "  Accuracy  : 0.6706\n",
            "  Precision : 0.6491\n",
            "  Recall    : 0.2357\n",
            "  AUC       : 0.6794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Definition by member 3 (RMSprop variant)\n",
        "def model_david():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(128, input_shape=(X_train.shape[1],), activation=\"relu\",\n",
        "                                   kernel_regularizer=tf.keras.regularizers.l2(0.0005)))\n",
        "  model.add(tf.keras.layers.Dense(64, activation=\"relu\",\n",
        "                                   kernel_regularizer=tf.keras.regularizers.l2(0.0005)))\n",
        "  model.add(tf.keras.layers.Dense(32, activation=\"relu\",\n",
        "                                   kernel_regularizer=tf.keras.regularizers.l2(0.0005)))\n",
        "  model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\",\n",
        "                                   kernel_regularizer=tf.keras.regularizers.l2(0.0005)))\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "                loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "  return model\n",
        "\n",
        "model3 = model_david()\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping_3 = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=50,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history3 = model3.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=300,\n",
        "    batch_size=32,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping_3]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "0R8q1MuJ-mJd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec70c1af-61b9-4070-8d24-33b83221736d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6406 - loss: 0.7338 - val_accuracy: 0.6321 - val_loss: 0.7122\n",
            "Epoch 2/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6311 - loss: 0.7081 - val_accuracy: 0.6344 - val_loss: 0.6951\n",
            "Epoch 3/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6729 - loss: 0.6631 - val_accuracy: 0.6439 - val_loss: 0.6850\n",
            "Epoch 4/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6774 - loss: 0.6631 - val_accuracy: 0.6533 - val_loss: 0.6786\n",
            "Epoch 5/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6874 - loss: 0.6464 - val_accuracy: 0.6462 - val_loss: 0.6752\n",
            "Epoch 6/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6850 - loss: 0.6381 - val_accuracy: 0.6533 - val_loss: 0.6671\n",
            "Epoch 7/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6927 - loss: 0.6384 - val_accuracy: 0.6533 - val_loss: 0.6712\n",
            "Epoch 8/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7044 - loss: 0.6256 - val_accuracy: 0.6557 - val_loss: 0.6732\n",
            "Epoch 9/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7039 - loss: 0.6230 - val_accuracy: 0.6627 - val_loss: 0.6727\n",
            "Epoch 10/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7088 - loss: 0.6178 - val_accuracy: 0.6604 - val_loss: 0.6743\n",
            "Epoch 11/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7219 - loss: 0.6029 - val_accuracy: 0.6462 - val_loss: 0.6713\n",
            "Epoch 12/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7166 - loss: 0.6015 - val_accuracy: 0.6509 - val_loss: 0.6727\n",
            "Epoch 13/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7170 - loss: 0.5997 - val_accuracy: 0.6392 - val_loss: 0.6888\n",
            "Epoch 14/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7244 - loss: 0.5910 - val_accuracy: 0.6462 - val_loss: 0.6853\n",
            "Epoch 15/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7243 - loss: 0.5945 - val_accuracy: 0.6179 - val_loss: 0.6847\n",
            "Epoch 16/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7578 - loss: 0.5670 - val_accuracy: 0.6392 - val_loss: 0.6786\n",
            "Epoch 17/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7427 - loss: 0.5679 - val_accuracy: 0.6392 - val_loss: 0.6947\n",
            "Epoch 18/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7325 - loss: 0.5774 - val_accuracy: 0.6297 - val_loss: 0.6976\n",
            "Epoch 19/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7319 - loss: 0.5691 - val_accuracy: 0.6509 - val_loss: 0.7088\n",
            "Epoch 20/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7340 - loss: 0.5707 - val_accuracy: 0.6085 - val_loss: 0.7160\n",
            "Epoch 21/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7684 - loss: 0.5518 - val_accuracy: 0.6321 - val_loss: 0.7163\n",
            "Epoch 22/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7625 - loss: 0.5487 - val_accuracy: 0.5849 - val_loss: 0.7235\n",
            "Epoch 23/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7788 - loss: 0.5301 - val_accuracy: 0.6108 - val_loss: 0.7179\n",
            "Epoch 24/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7634 - loss: 0.5349 - val_accuracy: 0.6368 - val_loss: 0.7088\n",
            "Epoch 25/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7874 - loss: 0.5174 - val_accuracy: 0.6061 - val_loss: 0.7135\n",
            "Epoch 26/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8019 - loss: 0.5081 - val_accuracy: 0.5943 - val_loss: 0.7313\n",
            "Epoch 27/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7943 - loss: 0.5082 - val_accuracy: 0.6392 - val_loss: 0.7315\n",
            "Epoch 28/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7968 - loss: 0.5081 - val_accuracy: 0.6321 - val_loss: 0.7443\n",
            "Epoch 29/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8052 - loss: 0.4921 - val_accuracy: 0.6321 - val_loss: 0.7536\n",
            "Epoch 30/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8003 - loss: 0.4872 - val_accuracy: 0.6297 - val_loss: 0.7514\n",
            "Epoch 31/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8152 - loss: 0.4795 - val_accuracy: 0.6156 - val_loss: 0.7734\n",
            "Epoch 32/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8082 - loss: 0.4777 - val_accuracy: 0.6486 - val_loss: 0.7548\n",
            "Epoch 33/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8105 - loss: 0.4700 - val_accuracy: 0.6085 - val_loss: 0.7833\n",
            "Epoch 34/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8105 - loss: 0.4890 - val_accuracy: 0.5967 - val_loss: 0.7875\n",
            "Epoch 35/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8299 - loss: 0.4712 - val_accuracy: 0.5684 - val_loss: 0.8664\n",
            "Epoch 36/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8429 - loss: 0.4396 - val_accuracy: 0.6014 - val_loss: 0.8147\n",
            "Epoch 37/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8320 - loss: 0.4395 - val_accuracy: 0.6509 - val_loss: 0.8077\n",
            "Epoch 38/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8358 - loss: 0.4348 - val_accuracy: 0.5873 - val_loss: 0.8438\n",
            "Epoch 39/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8285 - loss: 0.4490 - val_accuracy: 0.6368 - val_loss: 0.8255\n",
            "Epoch 40/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8514 - loss: 0.4220 - val_accuracy: 0.6250 - val_loss: 0.9066\n",
            "Epoch 41/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.4328 - val_accuracy: 0.6061 - val_loss: 0.8517\n",
            "Epoch 42/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8217 - loss: 0.4350 - val_accuracy: 0.6580 - val_loss: 0.8509\n",
            "Epoch 43/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8619 - loss: 0.3953 - val_accuracy: 0.6038 - val_loss: 0.8532\n",
            "Epoch 44/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8499 - loss: 0.4069 - val_accuracy: 0.5212 - val_loss: 1.0192\n",
            "Epoch 45/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8492 - loss: 0.4132 - val_accuracy: 0.6297 - val_loss: 0.9075\n",
            "Epoch 46/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8507 - loss: 0.3921 - val_accuracy: 0.5708 - val_loss: 0.8934\n",
            "Epoch 47/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8591 - loss: 0.3953 - val_accuracy: 0.5967 - val_loss: 0.9100\n",
            "Epoch 48/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8606 - loss: 0.4029 - val_accuracy: 0.5778 - val_loss: 0.9879\n",
            "Epoch 49/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8687 - loss: 0.3806 - val_accuracy: 0.5542 - val_loss: 0.9894\n",
            "Epoch 50/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8694 - loss: 0.3843 - val_accuracy: 0.5613 - val_loss: 0.9725\n",
            "Epoch 51/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8670 - loss: 0.3805 - val_accuracy: 0.5708 - val_loss: 0.9840\n",
            "Epoch 52/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8817 - loss: 0.3741 - val_accuracy: 0.5943 - val_loss: 0.9413\n",
            "Epoch 53/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8758 - loss: 0.3693 - val_accuracy: 0.6179 - val_loss: 0.9696\n",
            "Epoch 54/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8714 - loss: 0.3545 - val_accuracy: 0.5472 - val_loss: 1.0711\n",
            "Epoch 55/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8860 - loss: 0.3557 - val_accuracy: 0.6297 - val_loss: 0.9886\n",
            "Epoch 56/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8829 - loss: 0.3529 - val_accuracy: 0.5802 - val_loss: 1.0934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get best epoch based on validation loss\n",
        "best_epoch = history3.history['val_loss'].index(min(history3.history['val_loss']))\n",
        "\n",
        "# Get train and validation accuracy at best epoch\n",
        "train_acc_at_best = history3.history['accuracy'][best_epoch]\n",
        "val_acc_at_best = history3.history['val_accuracy'][best_epoch]\n",
        "\n",
        "print(f\"Best Epoch: {best_epoch + 1}\")  # +1 for human-readable epoch number\n",
        "print(f\"Train Accuracy at Best Epoch: {train_acc_at_best:.4f}\")\n",
        "print(f\"Validation Accuracy at Best Epoch: {val_acc_at_best:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh4Z094Tl1oJ",
        "outputId": "bde8d2c3-6988-4ccf-d2f2-72b3983c05a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Epoch: 16\n",
            "Train Accuracy at Best Epoch: 0.7314\n",
            "Validation Accuracy at Best Epoch: 0.6934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_probs = model3.predict(X_test).ravel()\n",
        "\n",
        "# Predict binary classes\n",
        "y_pred_classes = (y_pred_probs > 0.5).astype(\"int32\")\n",
        "\n",
        "# Evaluate loss and accuracy\n",
        "test_loss, test_accuracy = model3.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "# Calculate precision, recall, and AUC\n",
        "test_precision = precision_score(y_test, y_pred_classes)\n",
        "test_recall = recall_score(y_test, y_pred_classes)\n",
        "test_auc = roc_auc_score(y_test, y_pred_probs)\n",
        "\n",
        "# Print results\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test AUC: {test_auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oczDl65Sl1SH",
        "outputId": "631daac1-8df3-43bb-b2fa-b3bdd6fa54f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Test Loss: 0.6773\n",
            "Test Accuracy: 0.6447\n",
            "Test Precision: 0.5238\n",
            "Test Recall: 0.4204\n",
            "Test AUC: 0.6710\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Definition by member 4\n",
        "!pip install tensorflow\n",
        "def model_tamanda_kaunda():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(96, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.001)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(48, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.0005)),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Dense(24, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.0005)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(12, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.0001)),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            tf.keras.metrics.Precision(name='precision'),\n",
        "            tf.keras.metrics.Recall(name='recall'),\n",
        "            tf.keras.metrics.AUC(name='auc')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "tamanda_model = model_tamanda_kaunda()\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=25,\n",
        "    min_delta=0.001,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = tamanda_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=200,\n",
        "    batch_size=64,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "TKoFpxX6_B7D",
        "outputId": "f95d5b6a-a24a-42ad-c3d5-c2b610485240",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.72.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Epoch 1/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.4463 - auc: 0.5332 - loss: 1.1428 - precision: 0.3732 - recall: 0.7309 - val_accuracy: 0.6274 - val_auc: 0.4925 - val_loss: 1.0695 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6230 - auc: 0.4940 - loss: 1.0611 - precision: 0.3601 - recall: 0.0689 - val_accuracy: 0.6297 - val_auc: 0.5098 - val_loss: 1.0241 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6345 - auc: 0.5051 - loss: 1.0148 - precision: 0.3592 - recall: 0.0110 - val_accuracy: 0.6297 - val_auc: 0.5214 - val_loss: 0.9831 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6309 - auc: 0.5008 - loss: 0.9795 - precision: 0.4844 - recall: 0.0026 - val_accuracy: 0.6297 - val_auc: 0.5325 - val_loss: 0.9436 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 5/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6331 - auc: 0.5260 - loss: 0.9342 - precision: 0.1250 - recall: 1.7456e-04 - val_accuracy: 0.6297 - val_auc: 0.5339 - val_loss: 0.9055 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 6/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6316 - auc: 0.5272 - loss: 0.8975 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5393 - val_loss: 0.8688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 7/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6519 - auc: 0.5612 - loss: 0.8455 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5392 - val_loss: 0.8346 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 8/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6346 - auc: 0.5408 - loss: 0.8254 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5367 - val_loss: 0.8036 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 9/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6253 - auc: 0.5705 - loss: 0.7946 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5513 - val_loss: 0.7765 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 10/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6183 - auc: 0.5825 - loss: 0.7707 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5511 - val_loss: 0.7532 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 11/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6382 - auc: 0.5677 - loss: 0.7417 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5494 - val_loss: 0.7351 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 12/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6228 - auc: 0.5574 - loss: 0.7344 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5598 - val_loss: 0.7207 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 13/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6250 - auc: 0.5921 - loss: 0.7145 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5509 - val_loss: 0.7103 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 14/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6350 - auc: 0.5876 - loss: 0.6981 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5547 - val_loss: 0.7016 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 15/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6305 - auc: 0.5961 - loss: 0.6956 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5634 - val_loss: 0.6948 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 16/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6310 - auc: 0.5950 - loss: 0.6895 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5690 - val_loss: 0.6887 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 17/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6265 - auc: 0.5831 - loss: 0.6890 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5731 - val_loss: 0.6842 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 18/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6224 - auc: 0.6086 - loss: 0.6814 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5803 - val_loss: 0.6802 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 19/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6330 - auc: 0.5996 - loss: 0.6772 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5833 - val_loss: 0.6775 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 20/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6418 - auc: 0.6377 - loss: 0.6595 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5924 - val_loss: 0.6749 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 21/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6359 - auc: 0.5946 - loss: 0.6729 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5990 - val_loss: 0.6726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 22/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6177 - auc: 0.6170 - loss: 0.6743 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5999 - val_loss: 0.6707 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 23/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6350 - auc: 0.6333 - loss: 0.6601 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5972 - val_loss: 0.6701 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 24/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6158 - auc: 0.6265 - loss: 0.6724 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6043 - val_loss: 0.6686 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 25/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6287 - auc: 0.6515 - loss: 0.6612 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6124 - val_loss: 0.6662 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 26/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6217 - auc: 0.6453 - loss: 0.6671 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6087 - val_loss: 0.6661 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 27/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6222 - auc: 0.6468 - loss: 0.6658 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6134 - val_loss: 0.6644 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 28/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6323 - auc: 0.6581 - loss: 0.6578 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6141 - val_loss: 0.6639 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 29/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6141 - auc: 0.6454 - loss: 0.6670 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6068 - val_loss: 0.6648 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 30/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6125 - auc: 0.6408 - loss: 0.6675 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6051 - val_loss: 0.6636 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 31/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6425 - auc: 0.6467 - loss: 0.6489 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6054 - val_loss: 0.6634 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 32/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6324 - auc: 0.6498 - loss: 0.6533 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6095 - val_loss: 0.6621 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 33/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6256 - auc: 0.6290 - loss: 0.6675 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6087 - val_loss: 0.6621 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 34/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6315 - auc: 0.6404 - loss: 0.6586 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6095 - val_loss: 0.6617 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 35/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6220 - auc: 0.6737 - loss: 0.6550 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6097 - val_loss: 0.6614 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 36/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6264 - auc: 0.6687 - loss: 0.6520 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6206 - val_loss: 0.6592 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 37/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6305 - auc: 0.6652 - loss: 0.6477 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6215 - val_loss: 0.6584 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 38/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6291 - auc: 0.6291 - loss: 0.6634 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6183 - val_loss: 0.6591 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 39/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6378 - auc: 0.6557 - loss: 0.6533 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6204 - val_loss: 0.6581 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 40/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6296 - auc: 0.6358 - loss: 0.6579 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6238 - val_loss: 0.6582 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 41/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6311 - auc: 0.6530 - loss: 0.6538 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6252 - val_loss: 0.6564 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 42/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6353 - auc: 0.6658 - loss: 0.6446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6233 - val_loss: 0.6579 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 43/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6204 - auc: 0.6553 - loss: 0.6635 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6219 - val_loss: 0.6576 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 44/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6215 - auc: 0.6628 - loss: 0.6572 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6277 - val_loss: 0.6568 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 45/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6403 - auc: 0.6598 - loss: 0.6451 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6301 - val_loss: 0.6562 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 46/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6419 - auc: 0.6307 - loss: 0.6548 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6294 - val_loss: 0.6561 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 47/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6423 - auc: 0.6636 - loss: 0.6460 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6306 - val_loss: 0.6553 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 48/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6334 - auc: 0.6261 - loss: 0.6619 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6333 - val_loss: 0.6570 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 49/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6240 - auc: 0.6527 - loss: 0.6590 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6295 - val_loss: 0.6562 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 50/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6389 - auc: 0.6506 - loss: 0.6516 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6348 - val_loss: 0.6560 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 51/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6161 - auc: 0.6520 - loss: 0.6586 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6358 - val_loss: 0.6549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 52/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6308 - auc: 0.6539 - loss: 0.6487 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6273 - val_loss: 0.6568 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 53/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6251 - auc: 0.6528 - loss: 0.6559 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6377 - val_loss: 0.6542 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 54/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6207 - auc: 0.6631 - loss: 0.6524 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6342 - val_loss: 0.6540 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 55/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6390 - auc: 0.6791 - loss: 0.6389 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6301 - val_loss: 0.6565 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 56/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6228 - auc: 0.6620 - loss: 0.6516 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6244 - val_loss: 0.6568 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 57/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6309 - auc: 0.6534 - loss: 0.6533 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6341 - val_loss: 0.6543 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 58/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6183 - auc: 0.6557 - loss: 0.6564 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6351 - val_loss: 0.6539 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 59/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6397 - auc: 0.6637 - loss: 0.6413 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6310 - val_loss: 0.6542 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 60/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6257 - auc: 0.6767 - loss: 0.6505 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6274 - val_loss: 0.6554 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 61/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6372 - auc: 0.6684 - loss: 0.6459 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6293 - val_loss: 0.6549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 62/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6467 - auc: 0.6673 - loss: 0.6411 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6281 - val_loss: 0.6542 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 63/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6306 - auc: 0.6824 - loss: 0.6407 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6323 - val_loss: 0.6545 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 64/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6213 - auc: 0.6726 - loss: 0.6535 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6335 - val_loss: 0.6536 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 65/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6192 - auc: 0.6752 - loss: 0.6457 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6302 - val_loss: 0.6538 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 66/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6194 - auc: 0.6742 - loss: 0.6528 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6318 - val_loss: 0.6545 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 67/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6372 - auc: 0.6769 - loss: 0.6397 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6303 - val_loss: 0.6546 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 68/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6193 - auc: 0.6576 - loss: 0.6561 - precision: 0.5417 - recall: 0.0112 - val_accuracy: 0.6297 - val_auc: 0.6324 - val_loss: 0.6536 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 69/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6559 - auc: 0.6678 - loss: 0.6338 - precision: 0.1268 - recall: 0.0015 - val_accuracy: 0.6297 - val_auc: 0.6271 - val_loss: 0.6559 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 70/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6372 - auc: 0.6548 - loss: 0.6503 - precision: 0.5201 - recall: 0.0368 - val_accuracy: 0.6297 - val_auc: 0.6282 - val_loss: 0.6553 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 71/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6360 - auc: 0.6539 - loss: 0.6495 - precision: 0.5548 - recall: 0.0467 - val_accuracy: 0.6297 - val_auc: 0.6285 - val_loss: 0.6551 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 72/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6347 - auc: 0.6632 - loss: 0.6529 - precision: 0.6491 - recall: 0.0495 - val_accuracy: 0.6297 - val_auc: 0.6332 - val_loss: 0.6543 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 73/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6416 - auc: 0.6685 - loss: 0.6482 - precision: 0.6287 - recall: 0.0601 - val_accuracy: 0.6344 - val_auc: 0.6326 - val_loss: 0.6539 - val_precision: 0.6667 - val_recall: 0.0255\n",
            "Epoch 74/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6425 - auc: 0.6548 - loss: 0.6533 - precision: 0.6257 - recall: 0.0898 - val_accuracy: 0.6297 - val_auc: 0.6294 - val_loss: 0.6537 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 75/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6416 - auc: 0.6370 - loss: 0.6509 - precision: 0.4766 - recall: 0.0302 - val_accuracy: 0.6297 - val_auc: 0.6241 - val_loss: 0.6561 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 76/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6508 - auc: 0.6453 - loss: 0.6559 - precision: 0.7438 - recall: 0.0802 - val_accuracy: 0.6297 - val_auc: 0.6266 - val_loss: 0.6555 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 77/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6408 - auc: 0.6636 - loss: 0.6557 - precision: 0.7694 - recall: 0.0606 - val_accuracy: 0.6297 - val_auc: 0.6321 - val_loss: 0.6537 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 78/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6366 - auc: 0.6601 - loss: 0.6505 - precision: 0.7251 - recall: 0.0238 - val_accuracy: 0.6297 - val_auc: 0.6324 - val_loss: 0.6541 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_epoch = np.argmin(history.history['val_loss'])\n",
        "print(f\"Best Epoch: {best_epoch+1}\")\n",
        "print(f\"Train Accuracy at Best Epoch: {history.history['accuracy'][best_epoch]:.4f}\")\n",
        "print(f\"Val Accuracy at Best Epoch: {history.history['val_accuracy'][best_epoch]:.4f}\")"
      ],
      "metadata": {
        "id": "UBK6hXpY5xre",
        "outputId": "f49bdc35-300d-469e-982e-2f054bf30eec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Epoch: 68\n",
            "Train Accuracy at Best Epoch: 0.6360\n",
            "Val Accuracy at Best Epoch: 0.6297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy, test_precision, test_recall, test_auc = tamanda_model.evaluate(X_test, y_test, verbose=1)\n",
        "\n",
        "# Print results with clear formatting\n",
        "print(\"\\nTest Evaluation Metrics:\")\n",
        "print(f\"  Loss      : {test_loss:.4f}\")\n",
        "print(f\"  Accuracy  : {test_accuracy:.4f}\")\n",
        "print(f\"  Precision : {test_precision:.4f}\")\n",
        "print(f\"  Recall    : {test_recall:.4f}\")\n",
        "print(f\"  AUC       : {test_auc:.4f}\")"
      ],
      "metadata": {
        "id": "_5tLv1NT56Xr",
        "outputId": "7558206d-eb00-4ff3-9efa-3f877dcc71cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6436 - auc: 0.6549 - loss: 0.6440 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
            "\n",
            "Test Evaluation Metrics:\n",
            "  Loss      : 0.6459\n",
            "  Accuracy  : 0.6306\n",
            "  Precision : 0.0000\n",
            "  Recall    : 0.0000\n",
            "  AUC       : 0.6799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Definition by member 5\n",
        "def model_name_of_student():\n",
        "\n",
        "  return"
      ],
      "metadata": {
        "id": "Dd3m8M3dKcfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start the training Process"
      ],
      "metadata": {
        "id": "hDSPmAB9jkrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#fit model\n",
        "history = model.fit(X, Y, validation_data=(testX, testy), epochs=4000, verbose=0, callbacks=[es])\n",
        "# evaluate the model\n",
        "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
        "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
        "# plot training history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "OWQHapf3jlYH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "ff09317e-ae97-4661-ac6d-602530c1db74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Y' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-fd04eeab69b9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Y' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy"
      ],
      "metadata": {
        "id": "dKZ2T8TOIYxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Loading and Preprocessing\n",
        "# The coach will never do this!!\n",
        "regularizer = 'l1'"
      ],
      "metadata": {
        "id": "qMNag3BGIuwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(32, activation ='relu', kernel_regularizer= regularizer , input_shape = (2224,224)))\n",
        "model.add(Dropout(0.2))\n",
        "#adding Dropout\n",
        "model.add(Dense(64, activation ='relu', kernel_regularizer= regularizer , input_shape = (2224,224)))\n",
        "#adding Dropout\n",
        "model.add(Dense(128, activation ='relu', kernel_regularizer= regularizer , input_shape = (2224,224)))\n",
        "model.add(Dropout(0.2))\n",
        "#adding Dropout\n",
        "model.add(Dense(2, activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "fsmEC739I4lG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback =EarlyStopping(monitor='loss',patience=3)"
      ],
      "metadata": {
        "id": "BbyPgkZlLu37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss= 'rmse', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "Fw9XQj_ZMWUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, Y, epochs=1000, batch_size= 128, callbacks=[callback], verbose=0)"
      ],
      "metadata": {
        "id": "GPhb-1k7LGx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "wLlhrOCpJWF5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}