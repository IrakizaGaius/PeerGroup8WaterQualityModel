{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrXv0rU9sIma"
      },
      "source": [
        "# Excercise - Creating our own custom Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJyZUDbzBTIG"
      },
      "source": [
        "This is a notebook that provides a quick overview of how to create your own custom model. You will be creating a simple model.\n",
        "You will be utilizing Keras and Tensorflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvLegMMvBZYg"
      },
      "source": [
        "## Water Quality Dataset\n",
        "\n",
        "This dataset contains water quality measurements and assessments related to potability, which is the suitability of water for human consumption. The dataset's primary objective is to provide insights into water quality parameters and assist in determining whether the water is potable or not. Each row in the dataset represents a water sample with specific attributes, and the \"Potability\" column indicates whether the water is suitable for consumption.\n",
        "\n",
        "https://www.kaggle.com/datasets/uom190346a/water-quality-and-potability?select=water_potability.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LOAD THE DATA\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"/content/water_potability.csv\")\n",
        "\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "\n",
        "data.head(20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "Qvnx0_dT3JEq",
        "outputId": "8b2a752d-4289-495f-c21d-5341ae23bdf9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           ph    Hardness        Solids  Chloramines     Sulfate  \\\n",
              "0         NaN  204.890455  20791.318981     7.300212  368.516441   \n",
              "1    3.716080  129.422921  18630.057858     6.635246         NaN   \n",
              "2    8.099124  224.236259  19909.541732     9.275884         NaN   \n",
              "3    8.316766  214.373394  22018.417441     8.059332  356.886136   \n",
              "4    9.092223  181.101509  17978.986339     6.546600  310.135738   \n",
              "5    5.584087  188.313324  28748.687739     7.544869  326.678363   \n",
              "6   10.223862  248.071735  28749.716544     7.513408  393.663396   \n",
              "7    8.635849  203.361523  13672.091764     4.563009  303.309771   \n",
              "8         NaN  118.988579  14285.583854     7.804174  268.646941   \n",
              "9   11.180284  227.231469  25484.508491     9.077200  404.041635   \n",
              "10   7.360640  165.520797  32452.614409     7.550701  326.624353   \n",
              "11   7.974522  218.693300  18767.656682     8.110385         NaN   \n",
              "12   7.119824  156.704993  18730.813653     3.606036  282.344050   \n",
              "13        NaN  150.174923  27331.361962     6.838223  299.415781   \n",
              "14   7.496232  205.344982  28388.004887     5.072558         NaN   \n",
              "15   6.347272  186.732881  41065.234765     9.629596  364.487687   \n",
              "16   7.051786  211.049406  30980.600787    10.094796         NaN   \n",
              "17   9.181560  273.813807  24041.326280     6.904990  398.350517   \n",
              "18   8.975464  279.357167  19460.398131     6.204321         NaN   \n",
              "19   7.371050  214.496610  25630.320037     4.432669  335.754439   \n",
              "\n",
              "    Conductivity  Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
              "0     564.308654       10.379783        86.990970   2.963135           0  \n",
              "1     592.885359       15.180013        56.329076   4.500656           0  \n",
              "2     418.606213       16.868637        66.420093   3.055934           0  \n",
              "3     363.266516       18.436524       100.341674   4.628771           0  \n",
              "4     398.410813       11.558279        31.997993   4.075075           0  \n",
              "5     280.467916        8.399735        54.917862   2.559708           0  \n",
              "6     283.651634       13.789695        84.603556   2.672989           0  \n",
              "7     474.607645       12.363817        62.798309   4.401425           0  \n",
              "8     389.375566       12.706049        53.928846   3.595017           0  \n",
              "9     563.885481       17.927806        71.976601   4.370562           0  \n",
              "10    425.383419       15.586810        78.740016   3.662292           0  \n",
              "11    364.098230       14.525746        76.485911   4.011718           0  \n",
              "12    347.715027       15.929536        79.500778   3.445756           0  \n",
              "13    379.761835       19.370807        76.509996   4.413974           0  \n",
              "14    444.645352       13.228311        70.300213   4.777382           0  \n",
              "15    516.743282       11.539781        75.071617   4.376348           0  \n",
              "16    315.141267       20.397022        56.651604   4.268429           0  \n",
              "17    477.974642       13.387341        71.457362   4.503661           0  \n",
              "18    431.443990       12.888759        63.821237   2.436086           0  \n",
              "19    469.914551       12.509164        62.797277   2.560299           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10e4644f-f0eb-415d-a6d7-57d24f37c3f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>204.890455</td>\n",
              "      <td>20791.318981</td>\n",
              "      <td>7.300212</td>\n",
              "      <td>368.516441</td>\n",
              "      <td>564.308654</td>\n",
              "      <td>10.379783</td>\n",
              "      <td>86.990970</td>\n",
              "      <td>2.963135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.716080</td>\n",
              "      <td>129.422921</td>\n",
              "      <td>18630.057858</td>\n",
              "      <td>6.635246</td>\n",
              "      <td>NaN</td>\n",
              "      <td>592.885359</td>\n",
              "      <td>15.180013</td>\n",
              "      <td>56.329076</td>\n",
              "      <td>4.500656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.099124</td>\n",
              "      <td>224.236259</td>\n",
              "      <td>19909.541732</td>\n",
              "      <td>9.275884</td>\n",
              "      <td>NaN</td>\n",
              "      <td>418.606213</td>\n",
              "      <td>16.868637</td>\n",
              "      <td>66.420093</td>\n",
              "      <td>3.055934</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.316766</td>\n",
              "      <td>214.373394</td>\n",
              "      <td>22018.417441</td>\n",
              "      <td>8.059332</td>\n",
              "      <td>356.886136</td>\n",
              "      <td>363.266516</td>\n",
              "      <td>18.436524</td>\n",
              "      <td>100.341674</td>\n",
              "      <td>4.628771</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.092223</td>\n",
              "      <td>181.101509</td>\n",
              "      <td>17978.986339</td>\n",
              "      <td>6.546600</td>\n",
              "      <td>310.135738</td>\n",
              "      <td>398.410813</td>\n",
              "      <td>11.558279</td>\n",
              "      <td>31.997993</td>\n",
              "      <td>4.075075</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.584087</td>\n",
              "      <td>188.313324</td>\n",
              "      <td>28748.687739</td>\n",
              "      <td>7.544869</td>\n",
              "      <td>326.678363</td>\n",
              "      <td>280.467916</td>\n",
              "      <td>8.399735</td>\n",
              "      <td>54.917862</td>\n",
              "      <td>2.559708</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10.223862</td>\n",
              "      <td>248.071735</td>\n",
              "      <td>28749.716544</td>\n",
              "      <td>7.513408</td>\n",
              "      <td>393.663396</td>\n",
              "      <td>283.651634</td>\n",
              "      <td>13.789695</td>\n",
              "      <td>84.603556</td>\n",
              "      <td>2.672989</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8.635849</td>\n",
              "      <td>203.361523</td>\n",
              "      <td>13672.091764</td>\n",
              "      <td>4.563009</td>\n",
              "      <td>303.309771</td>\n",
              "      <td>474.607645</td>\n",
              "      <td>12.363817</td>\n",
              "      <td>62.798309</td>\n",
              "      <td>4.401425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NaN</td>\n",
              "      <td>118.988579</td>\n",
              "      <td>14285.583854</td>\n",
              "      <td>7.804174</td>\n",
              "      <td>268.646941</td>\n",
              "      <td>389.375566</td>\n",
              "      <td>12.706049</td>\n",
              "      <td>53.928846</td>\n",
              "      <td>3.595017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>11.180284</td>\n",
              "      <td>227.231469</td>\n",
              "      <td>25484.508491</td>\n",
              "      <td>9.077200</td>\n",
              "      <td>404.041635</td>\n",
              "      <td>563.885481</td>\n",
              "      <td>17.927806</td>\n",
              "      <td>71.976601</td>\n",
              "      <td>4.370562</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>7.360640</td>\n",
              "      <td>165.520797</td>\n",
              "      <td>32452.614409</td>\n",
              "      <td>7.550701</td>\n",
              "      <td>326.624353</td>\n",
              "      <td>425.383419</td>\n",
              "      <td>15.586810</td>\n",
              "      <td>78.740016</td>\n",
              "      <td>3.662292</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>7.974522</td>\n",
              "      <td>218.693300</td>\n",
              "      <td>18767.656682</td>\n",
              "      <td>8.110385</td>\n",
              "      <td>NaN</td>\n",
              "      <td>364.098230</td>\n",
              "      <td>14.525746</td>\n",
              "      <td>76.485911</td>\n",
              "      <td>4.011718</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>7.119824</td>\n",
              "      <td>156.704993</td>\n",
              "      <td>18730.813653</td>\n",
              "      <td>3.606036</td>\n",
              "      <td>282.344050</td>\n",
              "      <td>347.715027</td>\n",
              "      <td>15.929536</td>\n",
              "      <td>79.500778</td>\n",
              "      <td>3.445756</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>NaN</td>\n",
              "      <td>150.174923</td>\n",
              "      <td>27331.361962</td>\n",
              "      <td>6.838223</td>\n",
              "      <td>299.415781</td>\n",
              "      <td>379.761835</td>\n",
              "      <td>19.370807</td>\n",
              "      <td>76.509996</td>\n",
              "      <td>4.413974</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>7.496232</td>\n",
              "      <td>205.344982</td>\n",
              "      <td>28388.004887</td>\n",
              "      <td>5.072558</td>\n",
              "      <td>NaN</td>\n",
              "      <td>444.645352</td>\n",
              "      <td>13.228311</td>\n",
              "      <td>70.300213</td>\n",
              "      <td>4.777382</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>6.347272</td>\n",
              "      <td>186.732881</td>\n",
              "      <td>41065.234765</td>\n",
              "      <td>9.629596</td>\n",
              "      <td>364.487687</td>\n",
              "      <td>516.743282</td>\n",
              "      <td>11.539781</td>\n",
              "      <td>75.071617</td>\n",
              "      <td>4.376348</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>7.051786</td>\n",
              "      <td>211.049406</td>\n",
              "      <td>30980.600787</td>\n",
              "      <td>10.094796</td>\n",
              "      <td>NaN</td>\n",
              "      <td>315.141267</td>\n",
              "      <td>20.397022</td>\n",
              "      <td>56.651604</td>\n",
              "      <td>4.268429</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>9.181560</td>\n",
              "      <td>273.813807</td>\n",
              "      <td>24041.326280</td>\n",
              "      <td>6.904990</td>\n",
              "      <td>398.350517</td>\n",
              "      <td>477.974642</td>\n",
              "      <td>13.387341</td>\n",
              "      <td>71.457362</td>\n",
              "      <td>4.503661</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>8.975464</td>\n",
              "      <td>279.357167</td>\n",
              "      <td>19460.398131</td>\n",
              "      <td>6.204321</td>\n",
              "      <td>NaN</td>\n",
              "      <td>431.443990</td>\n",
              "      <td>12.888759</td>\n",
              "      <td>63.821237</td>\n",
              "      <td>2.436086</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>7.371050</td>\n",
              "      <td>214.496610</td>\n",
              "      <td>25630.320037</td>\n",
              "      <td>4.432669</td>\n",
              "      <td>335.754439</td>\n",
              "      <td>469.914551</td>\n",
              "      <td>12.509164</td>\n",
              "      <td>62.797277</td>\n",
              "      <td>2.560299</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10e4644f-f0eb-415d-a6d7-57d24f37c3f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-10e4644f-f0eb-415d-a6d7-57d24f37c3f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-10e4644f-f0eb-415d-a6d7-57d24f37c3f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b197431e-96bd-4341-b73f-9dab33774175\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b197431e-96bd-4341-b73f-9dab33774175')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b197431e-96bd-4341-b73f-9dab33774175 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 3276,\n  \"fields\": [\n    {\n      \"column\": \"ph\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5943195187088117,\n        \"min\": 0.0,\n        \"max\": 13.999999999999998,\n        \"num_unique_values\": 2785,\n        \"samples\": [\n          6.569053876389385,\n          9.271355446767778,\n          8.92790592593881\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hardness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32.879761476294185,\n        \"min\": 47.432,\n        \"max\": 323.124,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          183.5211070261417,\n          188.9135411469536,\n          224.05887682392927\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8768.570827785932,\n        \"min\": 320.942611274359,\n        \"max\": 61227.19600771213,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          20461.252710219946,\n          32873.820021715685,\n          23264.10996772913\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chloramines\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.58308488903971,\n        \"min\": 0.3520000000000003,\n        \"max\": 13.127000000000002,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          7.333212177578906,\n          6.791509363412849,\n          5.92236704115349\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sulfate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 41.416840461672685,\n        \"min\": 129.00000000000003,\n        \"max\": 481.0306423059972,\n        \"num_unique_values\": 2495,\n        \"samples\": [\n          324.64407957923544,\n          370.121384654358,\n          329.12773842254506\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conductivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80.82406405111182,\n        \"min\": 181.483753985146,\n        \"max\": 753.3426195583046,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          356.3690224100897,\n          336.56150104700754,\n          387.971335796834\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Organic_carbon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.308161999126868,\n        \"min\": 2.1999999999999886,\n        \"max\": 28.30000000000001,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          20.179028868493845,\n          14.706810313722087,\n          13.40673745495127\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Trihalomethanes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.17500842221865,\n        \"min\": 0.7379999999999995,\n        \"max\": 124.0,\n        \"num_unique_values\": 3114,\n        \"samples\": [\n          66.163439242252,\n          42.844510851301166,\n          47.06639219544294\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Turbidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7803824084854116,\n        \"min\": 1.45,\n        \"max\": 6.739,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          4.886633785371213,\n          4.562197671215202,\n          2.487968647002356\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Potability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Information on the data\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mn2ks1y4rG2i",
        "outputId": "9d2a2f00-eb86-454f-ee65-559ef4eac74f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3276 entries, 0 to 3275\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   ph               2785 non-null   float64\n",
            " 1   Hardness         3276 non-null   float64\n",
            " 2   Solids           3276 non-null   float64\n",
            " 3   Chloramines      3276 non-null   float64\n",
            " 4   Sulfate          2495 non-null   float64\n",
            " 5   Conductivity     3276 non-null   float64\n",
            " 6   Organic_carbon   3276 non-null   float64\n",
            " 7   Trihalomethanes  3114 non-null   float64\n",
            " 8   Turbidity        3276 non-null   float64\n",
            " 9   Potability       3276 non-null   int64  \n",
            "dtypes: float64(9), int64(1)\n",
            "memory usage: 256.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Brief overview of the dataset statistics\n",
        "data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "fJvnnIxav4N2",
        "outputId": "b2f17ca8-86be-4087-8da0-a155d69f0c68"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                ph     Hardness        Solids  Chloramines      Sulfate  \\\n",
              "count  2785.000000  3276.000000   3276.000000  3276.000000  2495.000000   \n",
              "mean      7.080795   196.369496  22014.092526     7.122277   333.775777   \n",
              "std       1.594320    32.879761   8768.570828     1.583085    41.416840   \n",
              "min       0.000000    47.432000    320.942611     0.352000   129.000000   \n",
              "25%       6.093092   176.850538  15666.690297     6.127421   307.699498   \n",
              "50%       7.036752   196.967627  20927.833607     7.130299   333.073546   \n",
              "75%       8.062066   216.667456  27332.762127     8.114887   359.950170   \n",
              "max      14.000000   323.124000  61227.196008    13.127000   481.030642   \n",
              "\n",
              "       Conductivity  Organic_carbon  Trihalomethanes    Turbidity   Potability  \n",
              "count   3276.000000     3276.000000      3114.000000  3276.000000  3276.000000  \n",
              "mean     426.205111       14.284970        66.396293     3.966786     0.390110  \n",
              "std       80.824064        3.308162        16.175008     0.780382     0.487849  \n",
              "min      181.483754        2.200000         0.738000     1.450000     0.000000  \n",
              "25%      365.734414       12.065801        55.844536     3.439711     0.000000  \n",
              "50%      421.884968       14.218338        66.622485     3.955028     0.000000  \n",
              "75%      481.792304       16.557652        77.337473     4.500320     1.000000  \n",
              "max      753.342620       28.300000       124.000000     6.739000     1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-813ca16d-f3bc-46d4-bff7-5b60afd9117f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2785.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>2495.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3114.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.080795</td>\n",
              "      <td>196.369496</td>\n",
              "      <td>22014.092526</td>\n",
              "      <td>7.122277</td>\n",
              "      <td>333.775777</td>\n",
              "      <td>426.205111</td>\n",
              "      <td>14.284970</td>\n",
              "      <td>66.396293</td>\n",
              "      <td>3.966786</td>\n",
              "      <td>0.390110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.594320</td>\n",
              "      <td>32.879761</td>\n",
              "      <td>8768.570828</td>\n",
              "      <td>1.583085</td>\n",
              "      <td>41.416840</td>\n",
              "      <td>80.824064</td>\n",
              "      <td>3.308162</td>\n",
              "      <td>16.175008</td>\n",
              "      <td>0.780382</td>\n",
              "      <td>0.487849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>47.432000</td>\n",
              "      <td>320.942611</td>\n",
              "      <td>0.352000</td>\n",
              "      <td>129.000000</td>\n",
              "      <td>181.483754</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>0.738000</td>\n",
              "      <td>1.450000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6.093092</td>\n",
              "      <td>176.850538</td>\n",
              "      <td>15666.690297</td>\n",
              "      <td>6.127421</td>\n",
              "      <td>307.699498</td>\n",
              "      <td>365.734414</td>\n",
              "      <td>12.065801</td>\n",
              "      <td>55.844536</td>\n",
              "      <td>3.439711</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7.036752</td>\n",
              "      <td>196.967627</td>\n",
              "      <td>20927.833607</td>\n",
              "      <td>7.130299</td>\n",
              "      <td>333.073546</td>\n",
              "      <td>421.884968</td>\n",
              "      <td>14.218338</td>\n",
              "      <td>66.622485</td>\n",
              "      <td>3.955028</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.062066</td>\n",
              "      <td>216.667456</td>\n",
              "      <td>27332.762127</td>\n",
              "      <td>8.114887</td>\n",
              "      <td>359.950170</td>\n",
              "      <td>481.792304</td>\n",
              "      <td>16.557652</td>\n",
              "      <td>77.337473</td>\n",
              "      <td>4.500320</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>14.000000</td>\n",
              "      <td>323.124000</td>\n",
              "      <td>61227.196008</td>\n",
              "      <td>13.127000</td>\n",
              "      <td>481.030642</td>\n",
              "      <td>753.342620</td>\n",
              "      <td>28.300000</td>\n",
              "      <td>124.000000</td>\n",
              "      <td>6.739000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-813ca16d-f3bc-46d4-bff7-5b60afd9117f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-813ca16d-f3bc-46d4-bff7-5b60afd9117f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-813ca16d-f3bc-46d4-bff7-5b60afd9117f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4ed38250-1eef-4321-a6be-de18c3aac896\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4ed38250-1eef-4321-a6be-de18c3aac896')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4ed38250-1eef-4321-a6be-de18c3aac896 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"ph\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 982.4396919342113,\n        \"min\": 0.0,\n        \"max\": 2785.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          7.080794504276835,\n          7.036752103833548,\n          2785.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hardness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1102.077573149784,\n        \"min\": 32.879761476294185,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          196.36949601730151,\n          196.96762686363076,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19161.79774847418,\n        \"min\": 320.942611274359,\n        \"max\": 61227.19600771213,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          22014.092526077104,\n          20927.833606520187,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chloramines\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1156.0476760135623,\n        \"min\": 0.3520000000000003,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          7.122276793425786,\n          7.130298973883081,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sulfate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 793.8602821876343,\n        \"min\": 41.416840461672685,\n        \"max\": 2495.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          333.7757766108135,\n          333.073545745888,\n          2495.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conductivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1040.8631085884185,\n        \"min\": 80.82406405111182,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          426.20511068255325,\n          421.8849682800544,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Organic_carbon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1153.6765632294614,\n        \"min\": 2.1999999999999886,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          14.284970247677318,\n          14.218337937208588,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Trihalomethanes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1081.0577228535572,\n        \"min\": 0.7379999999999995,\n        \"max\": 3114.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          66.39629294676803,\n          66.62248509808484,\n          3114.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Turbidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1156.9881922638967,\n        \"min\": 0.7803824084854116,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3.966786169791058,\n          3.955027562993039,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Potability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1158.0956231418108,\n        \"min\": 0.0,\n        \"max\": 3276.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3901098901098901,\n          1.0,\n          0.4878491696702489\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop duplicates rows of data\n",
        "\n",
        "data = data.drop_duplicates()"
      ],
      "metadata": {
        "id": "f5Rjjxwg5XnF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# percentage of missingness in the data for each column\n",
        "\n",
        "missing = data.isnull().mean()*100\n",
        "print(missing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjFnkhc35ekL",
        "outputId": "09145d35-398d-43b3-9d1a-dfc191399bbe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ph                 14.987790\n",
            "Hardness            0.000000\n",
            "Solids              0.000000\n",
            "Chloramines         0.000000\n",
            "Sulfate            23.840049\n",
            "Conductivity        0.000000\n",
            "Organic_carbon      0.000000\n",
            "Trihalomethanes     4.945055\n",
            "Turbidity           0.000000\n",
            "Potability          0.000000\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MICE IMPUTATION to fill the missing data\n",
        "# create the imputer using MICE\n",
        "\n",
        "# separate the target variable from the rest of the data to make sure it is not changed or imputed\n",
        "features = data.drop(columns='Potability')\n",
        "target = data.Potability\n",
        "imputer = IterativeImputer(random_state=0)\n",
        "features_imputed = imputer.fit_transform(features)\n",
        "\n",
        "# convert the data back into a dataframe\n",
        "features_imputed = pd.DataFrame(features_imputed, columns=features.columns)\n",
        "\n",
        "# merge target variable and data\n",
        "data_imputed = pd.concat([features_imputed, target], axis=1)\n",
        "data_imputed.head(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "RlhnFruS2q0X",
        "outputId": "cf4d76e5-c2c4-4d06-bba3-0cf17f7db1f4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
              "0   7.190863  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
              "1   3.716080  129.422921  18630.057858     6.635246  344.836463    592.885359   \n",
              "2   8.099124  224.236259  19909.541732     9.275884  331.981769    418.606213   \n",
              "3   8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
              "4   9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
              "5   5.584087  188.313324  28748.687739     7.544869  326.678363    280.467916   \n",
              "6  10.223862  248.071735  28749.716544     7.513408  393.663396    283.651634   \n",
              "7   8.635849  203.361523  13672.091764     4.563009  303.309771    474.607645   \n",
              "8   6.927779  118.988579  14285.583854     7.804174  268.646941    389.375566   \n",
              "9  11.180284  227.231469  25484.508491     9.077200  404.041635    563.885481   \n",
              "\n",
              "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
              "0       10.379783        86.990970   2.963135           0  \n",
              "1       15.180013        56.329076   4.500656           0  \n",
              "2       16.868637        66.420093   3.055934           0  \n",
              "3       18.436524       100.341674   4.628771           0  \n",
              "4       11.558279        31.997993   4.075075           0  \n",
              "5        8.399735        54.917862   2.559708           0  \n",
              "6       13.789695        84.603556   2.672989           0  \n",
              "7       12.363817        62.798309   4.401425           0  \n",
              "8       12.706049        53.928846   3.595017           0  \n",
              "9       17.927806        71.976601   4.370562           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d2a5d030-f102-464f-9f4c-eb2f2798bf7d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.190863</td>\n",
              "      <td>204.890455</td>\n",
              "      <td>20791.318981</td>\n",
              "      <td>7.300212</td>\n",
              "      <td>368.516441</td>\n",
              "      <td>564.308654</td>\n",
              "      <td>10.379783</td>\n",
              "      <td>86.990970</td>\n",
              "      <td>2.963135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.716080</td>\n",
              "      <td>129.422921</td>\n",
              "      <td>18630.057858</td>\n",
              "      <td>6.635246</td>\n",
              "      <td>344.836463</td>\n",
              "      <td>592.885359</td>\n",
              "      <td>15.180013</td>\n",
              "      <td>56.329076</td>\n",
              "      <td>4.500656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.099124</td>\n",
              "      <td>224.236259</td>\n",
              "      <td>19909.541732</td>\n",
              "      <td>9.275884</td>\n",
              "      <td>331.981769</td>\n",
              "      <td>418.606213</td>\n",
              "      <td>16.868637</td>\n",
              "      <td>66.420093</td>\n",
              "      <td>3.055934</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.316766</td>\n",
              "      <td>214.373394</td>\n",
              "      <td>22018.417441</td>\n",
              "      <td>8.059332</td>\n",
              "      <td>356.886136</td>\n",
              "      <td>363.266516</td>\n",
              "      <td>18.436524</td>\n",
              "      <td>100.341674</td>\n",
              "      <td>4.628771</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.092223</td>\n",
              "      <td>181.101509</td>\n",
              "      <td>17978.986339</td>\n",
              "      <td>6.546600</td>\n",
              "      <td>310.135738</td>\n",
              "      <td>398.410813</td>\n",
              "      <td>11.558279</td>\n",
              "      <td>31.997993</td>\n",
              "      <td>4.075075</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.584087</td>\n",
              "      <td>188.313324</td>\n",
              "      <td>28748.687739</td>\n",
              "      <td>7.544869</td>\n",
              "      <td>326.678363</td>\n",
              "      <td>280.467916</td>\n",
              "      <td>8.399735</td>\n",
              "      <td>54.917862</td>\n",
              "      <td>2.559708</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10.223862</td>\n",
              "      <td>248.071735</td>\n",
              "      <td>28749.716544</td>\n",
              "      <td>7.513408</td>\n",
              "      <td>393.663396</td>\n",
              "      <td>283.651634</td>\n",
              "      <td>13.789695</td>\n",
              "      <td>84.603556</td>\n",
              "      <td>2.672989</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8.635849</td>\n",
              "      <td>203.361523</td>\n",
              "      <td>13672.091764</td>\n",
              "      <td>4.563009</td>\n",
              "      <td>303.309771</td>\n",
              "      <td>474.607645</td>\n",
              "      <td>12.363817</td>\n",
              "      <td>62.798309</td>\n",
              "      <td>4.401425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6.927779</td>\n",
              "      <td>118.988579</td>\n",
              "      <td>14285.583854</td>\n",
              "      <td>7.804174</td>\n",
              "      <td>268.646941</td>\n",
              "      <td>389.375566</td>\n",
              "      <td>12.706049</td>\n",
              "      <td>53.928846</td>\n",
              "      <td>3.595017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>11.180284</td>\n",
              "      <td>227.231469</td>\n",
              "      <td>25484.508491</td>\n",
              "      <td>9.077200</td>\n",
              "      <td>404.041635</td>\n",
              "      <td>563.885481</td>\n",
              "      <td>17.927806</td>\n",
              "      <td>71.976601</td>\n",
              "      <td>4.370562</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2a5d030-f102-464f-9f4c-eb2f2798bf7d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d2a5d030-f102-464f-9f4c-eb2f2798bf7d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d2a5d030-f102-464f-9f4c-eb2f2798bf7d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c949e3e6-4b78-435d-916f-f48395761cc1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c949e3e6-4b78-435d-916f-f48395761cc1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c949e3e6-4b78-435d-916f-f48395761cc1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_imputed",
              "summary": "{\n  \"name\": \"data_imputed\",\n  \"rows\": 3276,\n  \"fields\": [\n    {\n      \"column\": \"ph\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4715740629117464,\n        \"min\": 0.0,\n        \"max\": 13.999999999999998,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          7.042483377815478,\n          6.643158712135614,\n          7.846057926337261\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hardness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32.879761476294185,\n        \"min\": 47.432,\n        \"max\": 323.124,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          183.5211070261417,\n          188.9135411469536,\n          224.05887682392927\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8768.570827785932,\n        \"min\": 320.942611274359,\n        \"max\": 61227.19600771213,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          20461.252710219946,\n          32873.820021715685,\n          23264.10996772913\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chloramines\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.58308488903971,\n        \"min\": 0.3520000000000003,\n        \"max\": 13.127000000000002,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          7.333212177578906,\n          6.791509363412849,\n          5.92236704115349\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sulfate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36.38783888533828,\n        \"min\": 129.00000000000003,\n        \"max\": 481.0306423059972,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          333.1194758732444,\n          333.8488418801131,\n          300.40262012672275\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conductivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80.82406405111182,\n        \"min\": 181.483753985146,\n        \"max\": 753.3426195583046,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          356.3690224100897,\n          336.56150104700754,\n          387.971335796834\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Organic_carbon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.308161999126868,\n        \"min\": 2.1999999999999886,\n        \"max\": 28.30000000000001,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          20.179028868493845,\n          14.706810313722087,\n          13.40673745495127\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Trihalomethanes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.769921510590814,\n        \"min\": 0.7379999999999995,\n        \"max\": 124.0,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          67.01990322225635,\n          67.84484886059036,\n          43.07518646611747\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Turbidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7803824084854116,\n        \"min\": 1.45,\n        \"max\": 6.739,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          4.886633785371213,\n          4.562197671215202,\n          2.487968647002356\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Potability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# confirm imputed data\n",
        "data_imputed.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58zqnGV23ZSx",
        "outputId": "d687ed0d-f3fa-4024-f45e-37934e7471b6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3276 entries, 0 to 3275\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   ph               3276 non-null   float64\n",
            " 1   Hardness         3276 non-null   float64\n",
            " 2   Solids           3276 non-null   float64\n",
            " 3   Chloramines      3276 non-null   float64\n",
            " 4   Sulfate          3276 non-null   float64\n",
            " 5   Conductivity     3276 non-null   float64\n",
            " 6   Organic_carbon   3276 non-null   float64\n",
            " 7   Trihalomethanes  3276 non-null   float64\n",
            " 8   Turbidity        3276 non-null   float64\n",
            " 9   Potability       3276 non-null   int64  \n",
            "dtypes: float64(9), int64(1)\n",
            "memory usage: 256.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove outliers that may affect the neural network's accuracy using IQR method\n",
        "def remove_outliers_iqr(df, column_name):\n",
        "    Q1 = df[column_name].quantile(0.25)\n",
        "    Q3 = df[column_name].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    # anything above or below this is an outlier\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # place outliers in a data frame\n",
        "    print(f\"{df[column_name]}\")\n",
        "    outliers = df[(df[column_name] < lower_bound) | (df[column_name] > upper_bound)]\n",
        "    print(f\"Number of outliers: {len(outliers)}\")\n",
        "    print(f\"Percentage of outliers: {len(outliers)/len(df)*100:.2f}%\")\n",
        "\n",
        "\n",
        "    # remove outliers\n",
        "\n",
        "    df_clean = df[(df[column_name] >= lower_bound) & (df[column_name] <= upper_bound)]\n",
        "\n",
        "\n",
        "\n",
        "    return df_clean\n",
        "\n",
        "# columns to remove outliers in\n",
        "columns = ['Hardness', 'Solids', 'Sulfate', 'Conductivity', 'Organic_carbon', 'Trihalomethanes', 'Turbidity']\n",
        "\n",
        "data_imputed_copy = data_imputed.copy()\n",
        "\n",
        "for i in columns:\n",
        "  data_imputed_copy = remove_outliers_iqr(data_imputed_copy, i)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIdMxexk47Qa",
        "outputId": "ecad0760-297a-4ff3-8473-88437eb44a91"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       204.890455\n",
            "1       129.422921\n",
            "2       224.236259\n",
            "3       214.373394\n",
            "4       181.101509\n",
            "           ...    \n",
            "3271    193.681735\n",
            "3272    193.553212\n",
            "3273    175.762646\n",
            "3274    230.603758\n",
            "3275    195.102299\n",
            "Name: Hardness, Length: 3276, dtype: float64\n",
            "Number of outliers: 83\n",
            "Percentage of outliers: 2.53%\n",
            "0       20791.318981\n",
            "1       18630.057858\n",
            "2       19909.541732\n",
            "3       22018.417441\n",
            "4       17978.986339\n",
            "            ...     \n",
            "3271    47580.991603\n",
            "3272    17329.802160\n",
            "3273    33155.578218\n",
            "3274    11983.869376\n",
            "3275    17404.177061\n",
            "Name: Solids, Length: 3193, dtype: float64\n",
            "Number of outliers: 42\n",
            "Percentage of outliers: 1.32%\n",
            "0       368.516441\n",
            "1       344.836463\n",
            "2       331.981769\n",
            "3       356.886136\n",
            "4       310.135738\n",
            "           ...    \n",
            "3270    345.700257\n",
            "3272    338.612062\n",
            "3273    326.848982\n",
            "3274    336.993878\n",
            "3275    338.025733\n",
            "Name: Sulfate, Length: 3151, dtype: float64\n",
            "Number of outliers: 230\n",
            "Percentage of outliers: 7.30%\n",
            "0       564.308654\n",
            "1       592.885359\n",
            "2       418.606213\n",
            "3       363.266516\n",
            "4       398.410813\n",
            "           ...    \n",
            "3270    415.886955\n",
            "3272    392.449580\n",
            "3273    432.044783\n",
            "3274    402.883113\n",
            "3275    327.459760\n",
            "Name: Conductivity, Length: 2921, dtype: float64\n",
            "Number of outliers: 9\n",
            "Percentage of outliers: 0.31%\n",
            "0       10.379783\n",
            "1       15.180013\n",
            "2       16.868637\n",
            "3       18.436524\n",
            "4       11.558279\n",
            "          ...    \n",
            "3270    12.067620\n",
            "3272    19.903225\n",
            "3273    11.039070\n",
            "3274    11.168946\n",
            "3275    16.140368\n",
            "Name: Organic_carbon, Length: 2912, dtype: float64\n",
            "Number of outliers: 18\n",
            "Percentage of outliers: 0.62%\n",
            "0        86.990970\n",
            "1        56.329076\n",
            "2        66.420093\n",
            "3       100.341674\n",
            "4        31.997993\n",
            "           ...    \n",
            "3270     60.419921\n",
            "3272     66.474992\n",
            "3273     69.845400\n",
            "3274     77.488213\n",
            "3275     78.698446\n",
            "Name: Trihalomethanes, Length: 2894, dtype: float64\n",
            "Number of outliers: 47\n",
            "Percentage of outliers: 1.62%\n",
            "0       2.963135\n",
            "1       4.500656\n",
            "2       3.055934\n",
            "3       4.628771\n",
            "4       4.075075\n",
            "          ...   \n",
            "3270    3.669712\n",
            "3272    2.798243\n",
            "3273    3.298875\n",
            "3274    4.708658\n",
            "3275    2.309149\n",
            "Name: Turbidity, Length: 2847, dtype: float64\n",
            "Number of outliers: 17\n",
            "Percentage of outliers: 0.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the Data Appropriately"
      ],
      "metadata": {
        "id": "2QfR0r8cGVU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# generate 2d classification dataset\n",
        "\n",
        "# X, y = pass\n",
        "\n",
        "# Transforms data to have mean=0 and standard deviation=1\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X = data_imputed_copy.drop(columns='Potability', axis=1)\n",
        "y= data_imputed_copy['Potability']\n",
        "\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# from sklearn.decomposition import PCA\n",
        "# pca = PCA(n_components=2)\n",
        "# X_2d_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "X_scaled.shape\n"
      ],
      "metadata": {
        "id": "PF9lHguSY2vB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e14eb36-0201-4faa-b500-8cfbb2189328"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2830, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the data into training validation and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3,random_state=42,\n",
        "    stratify=y               # Keep same class distribution in all splits\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5,stratify=y_temp)\n",
        "\n",
        "print(f\"\\n=== FINAL SHAPES ===\")\n",
        "print(f\"X_train: {X_train.shape}\")\n",
        "print(f\"X_val: {X_val.shape}\")\n",
        "print(f\"X_test: {X_test.shape}\")\n",
        "print(f\"y_train: {y_train.shape}\")\n",
        "print(f\"y_val: {y_val.shape}\")\n",
        "print(f\"y_test: {y_test.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "wfSk1lXRYjrh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e47a2f72-07cb-47c6-e028-bda111d43fe0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== FINAL SHAPES ===\n",
            "X_train: (1981, 9)\n",
            "X_val: (424, 9)\n",
            "X_test: (425, 9)\n",
            "y_train: (1981,)\n",
            "y_val: (424,)\n",
            "y_test: (425,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Each Member Defines their model Here"
      ],
      "metadata": {
        "id": "LvjIHLrcGhzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Definition by member 1\n",
        "def model_jeremiah_agbaje():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(128, input_shape=(X_train.shape[1],), name='dense_layer', activation=\"relu\",kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))  # 50% dropout after first layer\n",
        "  model.add(tf.keras.layers.Dense(64, name='dense_layer2', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))  # 50% dropout after second layer\n",
        "  model.add(tf.keras.layers.Dense(32, name='dense_layer3', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))\n",
        "  model.add(tf.keras.layers.Dense(1, name='output_layer', activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.00001)))\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "model = model_jeremiah_agbaje()\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "      monitor='val_loss',    # Monitor validation loss\n",
        "      patience=50,\n",
        "      restore_best_weights=True  # Restore weights from best epoch\n",
        "  )\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "  X_train, y_train,\n",
        "  validation_data=(X_val, y_val),\n",
        "  epochs=200,\n",
        "  batch_size=32,\n",
        "  verbose=1,\n",
        "  callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "FLwYoJG9jvDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df1c7f0f-93b3-4b5b-bacd-570fcfc5b481"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5851 - loss: 0.6943 - val_accuracy: 0.5967 - val_loss: 0.6762\n",
            "Epoch 2/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5579 - loss: 0.7148 - val_accuracy: 0.5991 - val_loss: 0.6742\n",
            "Epoch 3/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5761 - loss: 0.7050 - val_accuracy: 0.6061 - val_loss: 0.6729\n",
            "Epoch 4/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5791 - loss: 0.6886 - val_accuracy: 0.6156 - val_loss: 0.6718\n",
            "Epoch 5/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5954 - loss: 0.6854 - val_accuracy: 0.6250 - val_loss: 0.6709\n",
            "Epoch 6/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5974 - loss: 0.6951 - val_accuracy: 0.6274 - val_loss: 0.6713\n",
            "Epoch 7/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5771 - loss: 0.7070 - val_accuracy: 0.6274 - val_loss: 0.6713\n",
            "Epoch 8/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5902 - loss: 0.6939 - val_accuracy: 0.6274 - val_loss: 0.6712\n",
            "Epoch 9/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5842 - loss: 0.6880 - val_accuracy: 0.6297 - val_loss: 0.6706\n",
            "Epoch 10/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6095 - loss: 0.6854 - val_accuracy: 0.6297 - val_loss: 0.6702\n",
            "Epoch 11/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5874 - loss: 0.6787 - val_accuracy: 0.6297 - val_loss: 0.6694\n",
            "Epoch 12/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6100 - loss: 0.6688 - val_accuracy: 0.6297 - val_loss: 0.6690\n",
            "Epoch 13/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6074 - loss: 0.6747 - val_accuracy: 0.6297 - val_loss: 0.6697\n",
            "Epoch 14/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6006 - loss: 0.6817 - val_accuracy: 0.6297 - val_loss: 0.6698\n",
            "Epoch 15/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6177 - loss: 0.6870 - val_accuracy: 0.6297 - val_loss: 0.6694\n",
            "Epoch 16/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6242 - loss: 0.6678 - val_accuracy: 0.6297 - val_loss: 0.6685\n",
            "Epoch 17/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5965 - loss: 0.6883 - val_accuracy: 0.6297 - val_loss: 0.6687\n",
            "Epoch 18/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6284 - loss: 0.6652 - val_accuracy: 0.6297 - val_loss: 0.6680\n",
            "Epoch 19/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6147 - loss: 0.6681 - val_accuracy: 0.6297 - val_loss: 0.6679\n",
            "Epoch 20/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6181 - loss: 0.6771 - val_accuracy: 0.6297 - val_loss: 0.6677\n",
            "Epoch 21/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6187 - loss: 0.6771 - val_accuracy: 0.6297 - val_loss: 0.6674\n",
            "Epoch 22/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6156 - loss: 0.6846 - val_accuracy: 0.6297 - val_loss: 0.6675\n",
            "Epoch 23/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6222 - loss: 0.6742 - val_accuracy: 0.6297 - val_loss: 0.6673\n",
            "Epoch 24/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6121 - loss: 0.6698 - val_accuracy: 0.6297 - val_loss: 0.6668\n",
            "Epoch 25/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6129 - loss: 0.6706 - val_accuracy: 0.6297 - val_loss: 0.6663\n",
            "Epoch 26/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6313 - loss: 0.6689 - val_accuracy: 0.6297 - val_loss: 0.6661\n",
            "Epoch 27/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6178 - loss: 0.6630 - val_accuracy: 0.6297 - val_loss: 0.6654\n",
            "Epoch 28/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6248 - loss: 0.6695 - val_accuracy: 0.6297 - val_loss: 0.6651\n",
            "Epoch 29/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6323 - loss: 0.6654 - val_accuracy: 0.6297 - val_loss: 0.6651\n",
            "Epoch 30/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6010 - loss: 0.6740 - val_accuracy: 0.6297 - val_loss: 0.6651\n",
            "Epoch 31/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6229 - loss: 0.6624 - val_accuracy: 0.6297 - val_loss: 0.6641\n",
            "Epoch 32/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6110 - loss: 0.6704 - val_accuracy: 0.6297 - val_loss: 0.6635\n",
            "Epoch 33/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6439 - loss: 0.6533 - val_accuracy: 0.6297 - val_loss: 0.6634\n",
            "Epoch 34/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6163 - loss: 0.6680 - val_accuracy: 0.6297 - val_loss: 0.6634\n",
            "Epoch 35/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6258 - loss: 0.6661 - val_accuracy: 0.6297 - val_loss: 0.6629\n",
            "Epoch 36/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6262 - loss: 0.6620 - val_accuracy: 0.6297 - val_loss: 0.6633\n",
            "Epoch 37/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6164 - loss: 0.6639 - val_accuracy: 0.6297 - val_loss: 0.6628\n",
            "Epoch 38/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6176 - loss: 0.6682 - val_accuracy: 0.6297 - val_loss: 0.6625\n",
            "Epoch 39/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6191 - loss: 0.6662 - val_accuracy: 0.6297 - val_loss: 0.6621\n",
            "Epoch 40/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6450 - loss: 0.6594 - val_accuracy: 0.6297 - val_loss: 0.6624\n",
            "Epoch 41/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6277 - loss: 0.6632 - val_accuracy: 0.6297 - val_loss: 0.6615\n",
            "Epoch 42/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6364 - loss: 0.6681 - val_accuracy: 0.6297 - val_loss: 0.6615\n",
            "Epoch 43/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6378 - loss: 0.6638 - val_accuracy: 0.6297 - val_loss: 0.6613\n",
            "Epoch 44/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6365 - loss: 0.6565 - val_accuracy: 0.6297 - val_loss: 0.6608\n",
            "Epoch 45/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6393 - loss: 0.6625 - val_accuracy: 0.6297 - val_loss: 0.6605\n",
            "Epoch 46/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6318 - loss: 0.6606 - val_accuracy: 0.6297 - val_loss: 0.6603\n",
            "Epoch 47/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6260 - loss: 0.6602 - val_accuracy: 0.6297 - val_loss: 0.6601\n",
            "Epoch 48/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6275 - loss: 0.6625 - val_accuracy: 0.6297 - val_loss: 0.6596\n",
            "Epoch 49/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5991 - loss: 0.6779 - val_accuracy: 0.6297 - val_loss: 0.6592\n",
            "Epoch 50/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6260 - loss: 0.6626 - val_accuracy: 0.6297 - val_loss: 0.6591\n",
            "Epoch 51/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6079 - loss: 0.6749 - val_accuracy: 0.6297 - val_loss: 0.6590\n",
            "Epoch 52/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6311 - loss: 0.6661 - val_accuracy: 0.6297 - val_loss: 0.6589\n",
            "Epoch 53/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6238 - loss: 0.6576 - val_accuracy: 0.6297 - val_loss: 0.6581\n",
            "Epoch 54/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6548 - loss: 0.6429 - val_accuracy: 0.6297 - val_loss: 0.6581\n",
            "Epoch 55/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6434 - loss: 0.6520 - val_accuracy: 0.6297 - val_loss: 0.6577\n",
            "Epoch 56/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6345 - loss: 0.6524 - val_accuracy: 0.6297 - val_loss: 0.6574\n",
            "Epoch 57/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6413 - loss: 0.6530 - val_accuracy: 0.6297 - val_loss: 0.6567\n",
            "Epoch 58/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6552 - loss: 0.6493 - val_accuracy: 0.6297 - val_loss: 0.6568\n",
            "Epoch 59/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6456 - loss: 0.6564 - val_accuracy: 0.6297 - val_loss: 0.6566\n",
            "Epoch 60/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6198 - loss: 0.6545 - val_accuracy: 0.6297 - val_loss: 0.6563\n",
            "Epoch 61/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6284 - loss: 0.6572 - val_accuracy: 0.6297 - val_loss: 0.6558\n",
            "Epoch 62/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6327 - loss: 0.6567 - val_accuracy: 0.6297 - val_loss: 0.6557\n",
            "Epoch 63/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6169 - loss: 0.6654 - val_accuracy: 0.6297 - val_loss: 0.6551\n",
            "Epoch 64/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6234 - loss: 0.6555 - val_accuracy: 0.6297 - val_loss: 0.6545\n",
            "Epoch 65/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6213 - loss: 0.6571 - val_accuracy: 0.6297 - val_loss: 0.6538\n",
            "Epoch 66/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6096 - loss: 0.6626 - val_accuracy: 0.6297 - val_loss: 0.6534\n",
            "Epoch 67/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6218 - loss: 0.6523 - val_accuracy: 0.6297 - val_loss: 0.6532\n",
            "Epoch 68/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6393 - loss: 0.6484 - val_accuracy: 0.6297 - val_loss: 0.6531\n",
            "Epoch 69/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6468 - loss: 0.6439 - val_accuracy: 0.6297 - val_loss: 0.6527\n",
            "Epoch 70/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6162 - loss: 0.6651 - val_accuracy: 0.6297 - val_loss: 0.6531\n",
            "Epoch 71/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6336 - loss: 0.6434 - val_accuracy: 0.6297 - val_loss: 0.6526\n",
            "Epoch 72/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6387 - loss: 0.6469 - val_accuracy: 0.6297 - val_loss: 0.6523\n",
            "Epoch 73/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6219 - loss: 0.6506 - val_accuracy: 0.6297 - val_loss: 0.6520\n",
            "Epoch 74/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6200 - loss: 0.6571 - val_accuracy: 0.6297 - val_loss: 0.6517\n",
            "Epoch 75/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6375 - loss: 0.6479 - val_accuracy: 0.6297 - val_loss: 0.6514\n",
            "Epoch 76/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6205 - loss: 0.6599 - val_accuracy: 0.6297 - val_loss: 0.6512\n",
            "Epoch 77/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6172 - loss: 0.6619 - val_accuracy: 0.6297 - val_loss: 0.6507\n",
            "Epoch 78/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6417 - loss: 0.6480 - val_accuracy: 0.6297 - val_loss: 0.6507\n",
            "Epoch 79/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6204 - loss: 0.6539 - val_accuracy: 0.6297 - val_loss: 0.6511\n",
            "Epoch 80/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6434 - loss: 0.6429 - val_accuracy: 0.6297 - val_loss: 0.6507\n",
            "Epoch 81/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6457 - loss: 0.6485 - val_accuracy: 0.6297 - val_loss: 0.6503\n",
            "Epoch 82/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6391 - loss: 0.6432 - val_accuracy: 0.6297 - val_loss: 0.6502\n",
            "Epoch 83/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6345 - loss: 0.6447 - val_accuracy: 0.6297 - val_loss: 0.6497\n",
            "Epoch 84/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6396 - loss: 0.6499 - val_accuracy: 0.6297 - val_loss: 0.6493\n",
            "Epoch 85/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6312 - loss: 0.6545 - val_accuracy: 0.6297 - val_loss: 0.6493\n",
            "Epoch 86/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6150 - loss: 0.6594 - val_accuracy: 0.6297 - val_loss: 0.6490\n",
            "Epoch 87/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6341 - loss: 0.6471 - val_accuracy: 0.6297 - val_loss: 0.6488\n",
            "Epoch 88/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6420 - loss: 0.6422 - val_accuracy: 0.6297 - val_loss: 0.6481\n",
            "Epoch 89/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6258 - loss: 0.6476 - val_accuracy: 0.6297 - val_loss: 0.6482\n",
            "Epoch 90/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6407 - loss: 0.6336 - val_accuracy: 0.6297 - val_loss: 0.6475\n",
            "Epoch 91/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6233 - loss: 0.6513 - val_accuracy: 0.6297 - val_loss: 0.6473\n",
            "Epoch 92/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6321 - loss: 0.6545 - val_accuracy: 0.6297 - val_loss: 0.6472\n",
            "Epoch 93/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6223 - loss: 0.6551 - val_accuracy: 0.6321 - val_loss: 0.6476\n",
            "Epoch 94/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6344 - loss: 0.6489 - val_accuracy: 0.6321 - val_loss: 0.6476\n",
            "Epoch 95/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6209 - loss: 0.6524 - val_accuracy: 0.6321 - val_loss: 0.6474\n",
            "Epoch 96/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6197 - loss: 0.6566 - val_accuracy: 0.6321 - val_loss: 0.6470\n",
            "Epoch 97/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6169 - loss: 0.6611 - val_accuracy: 0.6321 - val_loss: 0.6475\n",
            "Epoch 98/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6478 - loss: 0.6372 - val_accuracy: 0.6321 - val_loss: 0.6471\n",
            "Epoch 99/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6184 - loss: 0.6611 - val_accuracy: 0.6321 - val_loss: 0.6478\n",
            "Epoch 100/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6314 - loss: 0.6450 - val_accuracy: 0.6321 - val_loss: 0.6476\n",
            "Epoch 101/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6372 - loss: 0.6474 - val_accuracy: 0.6321 - val_loss: 0.6472\n",
            "Epoch 102/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6537 - loss: 0.6374 - val_accuracy: 0.6321 - val_loss: 0.6465\n",
            "Epoch 103/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6462 - loss: 0.6364 - val_accuracy: 0.6321 - val_loss: 0.6458\n",
            "Epoch 104/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6402 - loss: 0.6410 - val_accuracy: 0.6321 - val_loss: 0.6455\n",
            "Epoch 105/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6247 - loss: 0.6538 - val_accuracy: 0.6321 - val_loss: 0.6458\n",
            "Epoch 106/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6276 - loss: 0.6461 - val_accuracy: 0.6321 - val_loss: 0.6455\n",
            "Epoch 107/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6298 - loss: 0.6461 - val_accuracy: 0.6321 - val_loss: 0.6451\n",
            "Epoch 108/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6166 - loss: 0.6545 - val_accuracy: 0.6321 - val_loss: 0.6450\n",
            "Epoch 109/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6272 - loss: 0.6562 - val_accuracy: 0.6321 - val_loss: 0.6450\n",
            "Epoch 110/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6501 - loss: 0.6375 - val_accuracy: 0.6321 - val_loss: 0.6445\n",
            "Epoch 111/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6460 - loss: 0.6482 - val_accuracy: 0.6321 - val_loss: 0.6444\n",
            "Epoch 112/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6375 - loss: 0.6449 - val_accuracy: 0.6321 - val_loss: 0.6444\n",
            "Epoch 113/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6411 - loss: 0.6425 - val_accuracy: 0.6344 - val_loss: 0.6445\n",
            "Epoch 114/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6479 - loss: 0.6334 - val_accuracy: 0.6344 - val_loss: 0.6436\n",
            "Epoch 115/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6309 - loss: 0.6376 - val_accuracy: 0.6321 - val_loss: 0.6434\n",
            "Epoch 116/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6612 - loss: 0.6250 - val_accuracy: 0.6321 - val_loss: 0.6428\n",
            "Epoch 117/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6425 - loss: 0.6335 - val_accuracy: 0.6321 - val_loss: 0.6426\n",
            "Epoch 118/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6547 - loss: 0.6372 - val_accuracy: 0.6321 - val_loss: 0.6426\n",
            "Epoch 119/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6486 - loss: 0.6328 - val_accuracy: 0.6321 - val_loss: 0.6419\n",
            "Epoch 120/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6362 - loss: 0.6560 - val_accuracy: 0.6321 - val_loss: 0.6418\n",
            "Epoch 121/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6572 - loss: 0.6214 - val_accuracy: 0.6368 - val_loss: 0.6411\n",
            "Epoch 122/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6436 - loss: 0.6303 - val_accuracy: 0.6415 - val_loss: 0.6409\n",
            "Epoch 123/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6403 - loss: 0.6374 - val_accuracy: 0.6415 - val_loss: 0.6405\n",
            "Epoch 124/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6240 - loss: 0.6482 - val_accuracy: 0.6415 - val_loss: 0.6404\n",
            "Epoch 125/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6533 - loss: 0.6348 - val_accuracy: 0.6439 - val_loss: 0.6400\n",
            "Epoch 126/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6305 - loss: 0.6463 - val_accuracy: 0.6462 - val_loss: 0.6399\n",
            "Epoch 127/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6338 - loss: 0.6330 - val_accuracy: 0.6462 - val_loss: 0.6393\n",
            "Epoch 128/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6537 - loss: 0.6369 - val_accuracy: 0.6462 - val_loss: 0.6392\n",
            "Epoch 129/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6503 - loss: 0.6228 - val_accuracy: 0.6462 - val_loss: 0.6387\n",
            "Epoch 130/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6268 - loss: 0.6501 - val_accuracy: 0.6462 - val_loss: 0.6395\n",
            "Epoch 131/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6478 - loss: 0.6357 - val_accuracy: 0.6462 - val_loss: 0.6396\n",
            "Epoch 132/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6208 - loss: 0.6491 - val_accuracy: 0.6486 - val_loss: 0.6396\n",
            "Epoch 133/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6442 - loss: 0.6265 - val_accuracy: 0.6439 - val_loss: 0.6387\n",
            "Epoch 134/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6721 - loss: 0.6284 - val_accuracy: 0.6462 - val_loss: 0.6383\n",
            "Epoch 135/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6368 - loss: 0.6387 - val_accuracy: 0.6462 - val_loss: 0.6378\n",
            "Epoch 136/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6475 - loss: 0.6349 - val_accuracy: 0.6462 - val_loss: 0.6374\n",
            "Epoch 137/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6346 - loss: 0.6372 - val_accuracy: 0.6462 - val_loss: 0.6371\n",
            "Epoch 138/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6384 - loss: 0.6442 - val_accuracy: 0.6486 - val_loss: 0.6367\n",
            "Epoch 139/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6472 - loss: 0.6268 - val_accuracy: 0.6486 - val_loss: 0.6369\n",
            "Epoch 140/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6419 - loss: 0.6230 - val_accuracy: 0.6486 - val_loss: 0.6370\n",
            "Epoch 141/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6478 - loss: 0.6170 - val_accuracy: 0.6486 - val_loss: 0.6360\n",
            "Epoch 142/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6309 - loss: 0.6287 - val_accuracy: 0.6486 - val_loss: 0.6364\n",
            "Epoch 143/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6626 - loss: 0.6193 - val_accuracy: 0.6486 - val_loss: 0.6361\n",
            "Epoch 144/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6364 - loss: 0.6392 - val_accuracy: 0.6486 - val_loss: 0.6359\n",
            "Epoch 145/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6374 - loss: 0.6346 - val_accuracy: 0.6486 - val_loss: 0.6356\n",
            "Epoch 146/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6558 - loss: 0.6230 - val_accuracy: 0.6462 - val_loss: 0.6351\n",
            "Epoch 147/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6395 - loss: 0.6351 - val_accuracy: 0.6462 - val_loss: 0.6346\n",
            "Epoch 148/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6571 - loss: 0.6294 - val_accuracy: 0.6462 - val_loss: 0.6341\n",
            "Epoch 149/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6394 - loss: 0.6377 - val_accuracy: 0.6462 - val_loss: 0.6339\n",
            "Epoch 150/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6186 - loss: 0.6462 - val_accuracy: 0.6462 - val_loss: 0.6337\n",
            "Epoch 151/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6402 - loss: 0.6274 - val_accuracy: 0.6462 - val_loss: 0.6333\n",
            "Epoch 152/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6469 - loss: 0.6271 - val_accuracy: 0.6462 - val_loss: 0.6329\n",
            "Epoch 153/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6439 - loss: 0.6281 - val_accuracy: 0.6462 - val_loss: 0.6326\n",
            "Epoch 154/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6349 - loss: 0.6376 - val_accuracy: 0.6486 - val_loss: 0.6323\n",
            "Epoch 155/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6568 - loss: 0.6330 - val_accuracy: 0.6509 - val_loss: 0.6323\n",
            "Epoch 156/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6460 - loss: 0.6185 - val_accuracy: 0.6509 - val_loss: 0.6319\n",
            "Epoch 157/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6371 - loss: 0.6461 - val_accuracy: 0.6486 - val_loss: 0.6320\n",
            "Epoch 158/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6611 - loss: 0.6335 - val_accuracy: 0.6486 - val_loss: 0.6316\n",
            "Epoch 159/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6385 - loss: 0.6523 - val_accuracy: 0.6509 - val_loss: 0.6319\n",
            "Epoch 160/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6567 - loss: 0.6304 - val_accuracy: 0.6533 - val_loss: 0.6322\n",
            "Epoch 161/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6421 - loss: 0.6292 - val_accuracy: 0.6486 - val_loss: 0.6314\n",
            "Epoch 162/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6506 - loss: 0.6298 - val_accuracy: 0.6486 - val_loss: 0.6315\n",
            "Epoch 163/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6566 - loss: 0.6247 - val_accuracy: 0.6486 - val_loss: 0.6312\n",
            "Epoch 164/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6295 - loss: 0.6340 - val_accuracy: 0.6486 - val_loss: 0.6310\n",
            "Epoch 165/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6294 - loss: 0.6391 - val_accuracy: 0.6486 - val_loss: 0.6306\n",
            "Epoch 166/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6384 - loss: 0.6369 - val_accuracy: 0.6486 - val_loss: 0.6305\n",
            "Epoch 167/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6476 - loss: 0.6380 - val_accuracy: 0.6462 - val_loss: 0.6302\n",
            "Epoch 168/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6340 - loss: 0.6407 - val_accuracy: 0.6486 - val_loss: 0.6305\n",
            "Epoch 169/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6520 - loss: 0.6275 - val_accuracy: 0.6486 - val_loss: 0.6302\n",
            "Epoch 170/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6437 - loss: 0.6285 - val_accuracy: 0.6509 - val_loss: 0.6297\n",
            "Epoch 171/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6553 - loss: 0.6266 - val_accuracy: 0.6486 - val_loss: 0.6292\n",
            "Epoch 172/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6574 - loss: 0.6207 - val_accuracy: 0.6509 - val_loss: 0.6290\n",
            "Epoch 173/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6677 - loss: 0.6202 - val_accuracy: 0.6509 - val_loss: 0.6289\n",
            "Epoch 174/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6395 - loss: 0.6325 - val_accuracy: 0.6533 - val_loss: 0.6290\n",
            "Epoch 175/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6611 - loss: 0.6253 - val_accuracy: 0.6533 - val_loss: 0.6284\n",
            "Epoch 176/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6485 - loss: 0.6366 - val_accuracy: 0.6533 - val_loss: 0.6287\n",
            "Epoch 177/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6555 - loss: 0.6275 - val_accuracy: 0.6533 - val_loss: 0.6290\n",
            "Epoch 178/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6644 - loss: 0.6169 - val_accuracy: 0.6533 - val_loss: 0.6286\n",
            "Epoch 179/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6468 - loss: 0.6228 - val_accuracy: 0.6509 - val_loss: 0.6286\n",
            "Epoch 180/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6491 - loss: 0.6198 - val_accuracy: 0.6533 - val_loss: 0.6283\n",
            "Epoch 181/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6723 - loss: 0.6324 - val_accuracy: 0.6533 - val_loss: 0.6281\n",
            "Epoch 182/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6296 - loss: 0.6426 - val_accuracy: 0.6509 - val_loss: 0.6281\n",
            "Epoch 183/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6346 - loss: 0.6358 - val_accuracy: 0.6509 - val_loss: 0.6277\n",
            "Epoch 184/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6598 - loss: 0.6202 - val_accuracy: 0.6533 - val_loss: 0.6276\n",
            "Epoch 185/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6551 - loss: 0.6339 - val_accuracy: 0.6580 - val_loss: 0.6277\n",
            "Epoch 186/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6434 - loss: 0.6297 - val_accuracy: 0.6580 - val_loss: 0.6275\n",
            "Epoch 187/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6527 - loss: 0.6202 - val_accuracy: 0.6557 - val_loss: 0.6268\n",
            "Epoch 188/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6728 - loss: 0.6253 - val_accuracy: 0.6580 - val_loss: 0.6266\n",
            "Epoch 189/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6462 - loss: 0.6213 - val_accuracy: 0.6580 - val_loss: 0.6262\n",
            "Epoch 190/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6732 - loss: 0.6257 - val_accuracy: 0.6557 - val_loss: 0.6262\n",
            "Epoch 191/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6423 - loss: 0.6343 - val_accuracy: 0.6580 - val_loss: 0.6264\n",
            "Epoch 192/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6528 - loss: 0.6182 - val_accuracy: 0.6604 - val_loss: 0.6261\n",
            "Epoch 193/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6521 - loss: 0.6207 - val_accuracy: 0.6604 - val_loss: 0.6259\n",
            "Epoch 194/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6723 - loss: 0.6120 - val_accuracy: 0.6604 - val_loss: 0.6261\n",
            "Epoch 195/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6613 - loss: 0.6215 - val_accuracy: 0.6675 - val_loss: 0.6257\n",
            "Epoch 196/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6445 - loss: 0.6365 - val_accuracy: 0.6627 - val_loss: 0.6255\n",
            "Epoch 197/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6681 - loss: 0.6194 - val_accuracy: 0.6627 - val_loss: 0.6250\n",
            "Epoch 198/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6579 - loss: 0.6237 - val_accuracy: 0.6627 - val_loss: 0.6247\n",
            "Epoch 199/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6631 - loss: 0.6034 - val_accuracy: 0.6604 - val_loss: 0.6241\n",
            "Epoch 200/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6513 - loss: 0.6123 - val_accuracy: 0.6651 - val_loss: 0.6238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_epoch = np.argmin(history.history['val_loss'])\n",
        "print(f\"Best Epoch: {best_epoch+1}\")\n",
        "print(f\"Train Accuracy at Best Epoch: {history.history['accuracy'][best_epoch]:.4f}\")\n",
        "print(f\"Val Accuracy at Best Epoch: {history.history['val_accuracy'][best_epoch]:.4f}\")"
      ],
      "metadata": {
        "id": "1z30otXZnPVI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b374338-9fbf-4127-b486-2536fa0482e1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Epoch: 200\n",
            "Train Accuracy at Best Epoch: 0.6552\n",
            "Val Accuracy at Best Epoch: 0.6651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}, Test Loss: {test_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8-xUOoyJk5_",
        "outputId": "18417755-5744-4628-cb8e-833444425375"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6636 - loss: 0.6264 \n",
            "Test Accuracy: 0.6635, Test Loss: 0.6215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_gaius_irakiza():\n",
        "    model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Nadam(learning_rate=0.0001)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            tf.keras.metrics.Precision(name='precision'),\n",
        "            tf.keras.metrics.Recall(name='recall'),\n",
        "            tf.keras.metrics.AUC(name='auc')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "gaius_model = model_gaius_irakiza()\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=30,\n",
        "    min_delta=0.0001,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "history = gaius_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=300,\n",
        "    batch_size=32,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "hmWIUNw0-l0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5dfddda-4cff-4517-dc75-4a00af02636b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.3941 - auc: 0.4899 - loss: 0.8508 - precision: 0.3483 - recall: 0.8024 - val_accuracy: 0.3868 - val_auc: 0.5019 - val_loss: 0.7080 - val_precision: 0.3676 - val_recall: 0.9108\n",
            "Epoch 2/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.4289 - auc: 0.5030 - loss: 0.7942 - precision: 0.3474 - recall: 0.7110 - val_accuracy: 0.4033 - val_auc: 0.4884 - val_loss: 0.7065 - val_precision: 0.3629 - val_recall: 0.8089\n",
            "Epoch 3/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4597 - auc: 0.4978 - loss: 0.7576 - precision: 0.3620 - recall: 0.5768 - val_accuracy: 0.5000 - val_auc: 0.4875 - val_loss: 0.6948 - val_precision: 0.3575 - val_recall: 0.4395\n",
            "Epoch 4/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5051 - auc: 0.4990 - loss: 0.7288 - precision: 0.3696 - recall: 0.4765 - val_accuracy: 0.5613 - val_auc: 0.4920 - val_loss: 0.6812 - val_precision: 0.3505 - val_recall: 0.2166\n",
            "Epoch 5/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5144 - auc: 0.4939 - loss: 0.7177 - precision: 0.3810 - recall: 0.4100 - val_accuracy: 0.5920 - val_auc: 0.5086 - val_loss: 0.6713 - val_precision: 0.3519 - val_recall: 0.1210\n",
            "Epoch 6/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5627 - auc: 0.5147 - loss: 0.7020 - precision: 0.4013 - recall: 0.3478 - val_accuracy: 0.6038 - val_auc: 0.5169 - val_loss: 0.6663 - val_precision: 0.3226 - val_recall: 0.0637\n",
            "Epoch 7/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5446 - auc: 0.5004 - loss: 0.6984 - precision: 0.3514 - recall: 0.2712 - val_accuracy: 0.6132 - val_auc: 0.5235 - val_loss: 0.6628 - val_precision: 0.3478 - val_recall: 0.0510\n",
            "Epoch 8/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6083 - auc: 0.5510 - loss: 0.6762 - precision: 0.4422 - recall: 0.2734 - val_accuracy: 0.6156 - val_auc: 0.5318 - val_loss: 0.6604 - val_precision: 0.3333 - val_recall: 0.0382\n",
            "Epoch 9/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5609 - auc: 0.5053 - loss: 0.6872 - precision: 0.3244 - recall: 0.1819 - val_accuracy: 0.6226 - val_auc: 0.5313 - val_loss: 0.6597 - val_precision: 0.3846 - val_recall: 0.0318\n",
            "Epoch 10/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5847 - auc: 0.5032 - loss: 0.6855 - precision: 0.3901 - recall: 0.2039 - val_accuracy: 0.6250 - val_auc: 0.5387 - val_loss: 0.6578 - val_precision: 0.4167 - val_recall: 0.0318\n",
            "Epoch 11/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6192 - auc: 0.5167 - loss: 0.6710 - precision: 0.4073 - recall: 0.1984 - val_accuracy: 0.6274 - val_auc: 0.5344 - val_loss: 0.6584 - val_precision: 0.4545 - val_recall: 0.0318\n",
            "Epoch 12/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6070 - auc: 0.5020 - loss: 0.6764 - precision: 0.3685 - recall: 0.1546 - val_accuracy: 0.6321 - val_auc: 0.5389 - val_loss: 0.6572 - val_precision: 0.5455 - val_recall: 0.0382\n",
            "Epoch 13/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5928 - auc: 0.5362 - loss: 0.6758 - precision: 0.4069 - recall: 0.1625 - val_accuracy: 0.6297 - val_auc: 0.5453 - val_loss: 0.6556 - val_precision: 0.5000 - val_recall: 0.0255\n",
            "Epoch 14/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6064 - auc: 0.5288 - loss: 0.6719 - precision: 0.4057 - recall: 0.1207 - val_accuracy: 0.6297 - val_auc: 0.5481 - val_loss: 0.6547 - val_precision: 0.5000 - val_recall: 0.0255\n",
            "Epoch 15/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5787 - auc: 0.5291 - loss: 0.6827 - precision: 0.3745 - recall: 0.1287 - val_accuracy: 0.6297 - val_auc: 0.5532 - val_loss: 0.6536 - val_precision: 0.5000 - val_recall: 0.0191\n",
            "Epoch 16/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6157 - auc: 0.5344 - loss: 0.6703 - precision: 0.4330 - recall: 0.1317 - val_accuracy: 0.6321 - val_auc: 0.5553 - val_loss: 0.6532 - val_precision: 0.5714 - val_recall: 0.0255\n",
            "Epoch 17/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6273 - auc: 0.5499 - loss: 0.6556 - precision: 0.4175 - recall: 0.1388 - val_accuracy: 0.6344 - val_auc: 0.5529 - val_loss: 0.6535 - val_precision: 0.6667 - val_recall: 0.0255\n",
            "Epoch 18/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6242 - auc: 0.5336 - loss: 0.6658 - precision: 0.4391 - recall: 0.1228 - val_accuracy: 0.6344 - val_auc: 0.5601 - val_loss: 0.6530 - val_precision: 0.6667 - val_recall: 0.0255\n",
            "Epoch 19/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6118 - auc: 0.5547 - loss: 0.6659 - precision: 0.4306 - recall: 0.1289 - val_accuracy: 0.6344 - val_auc: 0.5644 - val_loss: 0.6525 - val_precision: 0.6250 - val_recall: 0.0318\n",
            "Epoch 20/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6171 - auc: 0.5460 - loss: 0.6591 - precision: 0.3754 - recall: 0.0976 - val_accuracy: 0.6344 - val_auc: 0.5639 - val_loss: 0.6524 - val_precision: 0.6250 - val_recall: 0.0318\n",
            "Epoch 21/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6223 - auc: 0.5449 - loss: 0.6595 - precision: 0.3959 - recall: 0.1136 - val_accuracy: 0.6368 - val_auc: 0.5670 - val_loss: 0.6514 - val_precision: 0.7143 - val_recall: 0.0318\n",
            "Epoch 22/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5994 - auc: 0.5260 - loss: 0.6803 - precision: 0.4235 - recall: 0.1096 - val_accuracy: 0.6344 - val_auc: 0.5739 - val_loss: 0.6498 - val_precision: 0.6250 - val_recall: 0.0318\n",
            "Epoch 23/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6364 - auc: 0.5688 - loss: 0.6565 - precision: 0.5352 - recall: 0.1234 - val_accuracy: 0.6344 - val_auc: 0.5714 - val_loss: 0.6501 - val_precision: 0.6667 - val_recall: 0.0255\n",
            "Epoch 24/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6139 - auc: 0.5117 - loss: 0.6702 - precision: 0.3923 - recall: 0.1078 - val_accuracy: 0.6321 - val_auc: 0.5722 - val_loss: 0.6509 - val_precision: 0.5714 - val_recall: 0.0255\n",
            "Epoch 25/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6266 - auc: 0.5718 - loss: 0.6576 - precision: 0.5134 - recall: 0.1205 - val_accuracy: 0.6344 - val_auc: 0.5807 - val_loss: 0.6488 - val_precision: 0.6250 - val_recall: 0.0318\n",
            "Epoch 26/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6268 - auc: 0.5458 - loss: 0.6583 - precision: 0.4430 - recall: 0.1284 - val_accuracy: 0.6368 - val_auc: 0.5851 - val_loss: 0.6477 - val_precision: 0.7143 - val_recall: 0.0318\n",
            "Epoch 27/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6342 - auc: 0.5644 - loss: 0.6493 - precision: 0.4613 - recall: 0.1327 - val_accuracy: 0.6344 - val_auc: 0.5954 - val_loss: 0.6462 - val_precision: 0.6250 - val_recall: 0.0318\n",
            "Epoch 28/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6393 - auc: 0.5684 - loss: 0.6492 - precision: 0.4982 - recall: 0.1354 - val_accuracy: 0.6344 - val_auc: 0.5964 - val_loss: 0.6453 - val_precision: 0.6000 - val_recall: 0.0382\n",
            "Epoch 29/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6349 - auc: 0.5879 - loss: 0.6506 - precision: 0.5449 - recall: 0.1398 - val_accuracy: 0.6344 - val_auc: 0.6002 - val_loss: 0.6446 - val_precision: 0.6000 - val_recall: 0.0382\n",
            "Epoch 30/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6160 - auc: 0.5684 - loss: 0.6624 - precision: 0.5020 - recall: 0.1240 - val_accuracy: 0.6344 - val_auc: 0.6075 - val_loss: 0.6424 - val_precision: 0.6000 - val_recall: 0.0382\n",
            "Epoch 31/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6247 - auc: 0.5615 - loss: 0.6558 - precision: 0.4606 - recall: 0.1056 - val_accuracy: 0.6368 - val_auc: 0.6073 - val_loss: 0.6421 - val_precision: 0.6364 - val_recall: 0.0446\n",
            "Epoch 32/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6368 - auc: 0.5312 - loss: 0.6602 - precision: 0.4880 - recall: 0.1210 - val_accuracy: 0.6368 - val_auc: 0.6072 - val_loss: 0.6412 - val_precision: 0.6667 - val_recall: 0.0382\n",
            "Epoch 33/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6291 - auc: 0.5555 - loss: 0.6543 - precision: 0.4479 - recall: 0.1174 - val_accuracy: 0.6392 - val_auc: 0.6119 - val_loss: 0.6398 - val_precision: 0.7000 - val_recall: 0.0446\n",
            "Epoch 34/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6210 - auc: 0.5811 - loss: 0.6503 - precision: 0.4486 - recall: 0.1017 - val_accuracy: 0.6415 - val_auc: 0.6151 - val_loss: 0.6391 - val_precision: 0.7273 - val_recall: 0.0510\n",
            "Epoch 35/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6396 - auc: 0.5758 - loss: 0.6520 - precision: 0.5568 - recall: 0.1391 - val_accuracy: 0.6415 - val_auc: 0.6165 - val_loss: 0.6390 - val_precision: 0.7273 - val_recall: 0.0510\n",
            "Epoch 36/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6326 - auc: 0.5614 - loss: 0.6465 - precision: 0.3775 - recall: 0.0864 - val_accuracy: 0.6392 - val_auc: 0.6166 - val_loss: 0.6394 - val_precision: 0.7000 - val_recall: 0.0446\n",
            "Epoch 37/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6512 - auc: 0.5908 - loss: 0.6415 - precision: 0.5702 - recall: 0.1313 - val_accuracy: 0.6392 - val_auc: 0.6171 - val_loss: 0.6380 - val_precision: 0.6667 - val_recall: 0.0510\n",
            "Epoch 38/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6242 - auc: 0.5580 - loss: 0.6577 - precision: 0.4650 - recall: 0.1120 - val_accuracy: 0.6439 - val_auc: 0.6210 - val_loss: 0.6371 - val_precision: 0.7143 - val_recall: 0.0637\n",
            "Epoch 39/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6498 - auc: 0.5794 - loss: 0.6417 - precision: 0.5242 - recall: 0.1199 - val_accuracy: 0.6415 - val_auc: 0.6206 - val_loss: 0.6370 - val_precision: 0.6923 - val_recall: 0.0573\n",
            "Epoch 40/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6249 - auc: 0.6124 - loss: 0.6468 - precision: 0.5103 - recall: 0.1170 - val_accuracy: 0.6415 - val_auc: 0.6200 - val_loss: 0.6370 - val_precision: 0.6923 - val_recall: 0.0573\n",
            "Epoch 41/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6429 - auc: 0.5760 - loss: 0.6488 - precision: 0.5729 - recall: 0.1203 - val_accuracy: 0.6486 - val_auc: 0.6212 - val_loss: 0.6361 - val_precision: 0.7857 - val_recall: 0.0701\n",
            "Epoch 42/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6369 - auc: 0.5501 - loss: 0.6513 - precision: 0.4072 - recall: 0.1019 - val_accuracy: 0.6462 - val_auc: 0.6202 - val_loss: 0.6363 - val_precision: 0.7333 - val_recall: 0.0701\n",
            "Epoch 43/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6262 - auc: 0.5573 - loss: 0.6546 - precision: 0.4476 - recall: 0.1172 - val_accuracy: 0.6462 - val_auc: 0.6207 - val_loss: 0.6359 - val_precision: 0.7333 - val_recall: 0.0701\n",
            "Epoch 44/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6266 - auc: 0.5969 - loss: 0.6509 - precision: 0.5408 - recall: 0.1237 - val_accuracy: 0.6486 - val_auc: 0.6150 - val_loss: 0.6366 - val_precision: 0.7500 - val_recall: 0.0764\n",
            "Epoch 45/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6501 - auc: 0.5915 - loss: 0.6372 - precision: 0.5601 - recall: 0.1266 - val_accuracy: 0.6509 - val_auc: 0.6178 - val_loss: 0.6357 - val_precision: 0.8000 - val_recall: 0.0764\n",
            "Epoch 46/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6365 - auc: 0.5924 - loss: 0.6454 - precision: 0.5309 - recall: 0.1353 - val_accuracy: 0.6533 - val_auc: 0.6208 - val_loss: 0.6355 - val_precision: 0.8125 - val_recall: 0.0828\n",
            "Epoch 47/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6333 - auc: 0.5796 - loss: 0.6493 - precision: 0.4952 - recall: 0.1155 - val_accuracy: 0.6533 - val_auc: 0.6207 - val_loss: 0.6351 - val_precision: 0.8125 - val_recall: 0.0828\n",
            "Epoch 48/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6177 - auc: 0.6028 - loss: 0.6538 - precision: 0.5196 - recall: 0.1372 - val_accuracy: 0.6533 - val_auc: 0.6182 - val_loss: 0.6345 - val_precision: 0.8125 - val_recall: 0.0828\n",
            "Epoch 49/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6380 - auc: 0.5743 - loss: 0.6493 - precision: 0.5078 - recall: 0.1374 - val_accuracy: 0.6509 - val_auc: 0.6231 - val_loss: 0.6347 - val_precision: 0.8000 - val_recall: 0.0764\n",
            "Epoch 50/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6402 - auc: 0.6126 - loss: 0.6345 - precision: 0.5163 - recall: 0.1332 - val_accuracy: 0.6580 - val_auc: 0.6234 - val_loss: 0.6335 - val_precision: 0.8333 - val_recall: 0.0955\n",
            "Epoch 51/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6547 - auc: 0.6060 - loss: 0.6355 - precision: 0.5861 - recall: 0.1237 - val_accuracy: 0.6580 - val_auc: 0.6265 - val_loss: 0.6323 - val_precision: 0.8333 - val_recall: 0.0955\n",
            "Epoch 52/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6259 - auc: 0.5719 - loss: 0.6522 - precision: 0.4443 - recall: 0.1282 - val_accuracy: 0.6557 - val_auc: 0.6246 - val_loss: 0.6331 - val_precision: 0.8235 - val_recall: 0.0892\n",
            "Epoch 53/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6506 - auc: 0.5953 - loss: 0.6343 - precision: 0.4990 - recall: 0.1168 - val_accuracy: 0.6580 - val_auc: 0.6222 - val_loss: 0.6332 - val_precision: 0.8333 - val_recall: 0.0955\n",
            "Epoch 54/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6461 - auc: 0.6003 - loss: 0.6460 - precision: 0.6077 - recall: 0.1582 - val_accuracy: 0.6604 - val_auc: 0.6224 - val_loss: 0.6332 - val_precision: 0.8421 - val_recall: 0.1019\n",
            "Epoch 55/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6404 - auc: 0.6111 - loss: 0.6362 - precision: 0.5062 - recall: 0.1320 - val_accuracy: 0.6533 - val_auc: 0.6234 - val_loss: 0.6327 - val_precision: 0.7778 - val_recall: 0.0892\n",
            "Epoch 56/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6259 - auc: 0.6187 - loss: 0.6468 - precision: 0.5696 - recall: 0.1582 - val_accuracy: 0.6580 - val_auc: 0.6253 - val_loss: 0.6318 - val_precision: 0.8000 - val_recall: 0.1019\n",
            "Epoch 57/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6201 - auc: 0.6155 - loss: 0.6423 - precision: 0.4885 - recall: 0.1470 - val_accuracy: 0.6580 - val_auc: 0.6286 - val_loss: 0.6311 - val_precision: 0.8000 - val_recall: 0.1019\n",
            "Epoch 58/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6576 - auc: 0.6166 - loss: 0.6290 - precision: 0.5812 - recall: 0.1561 - val_accuracy: 0.6604 - val_auc: 0.6271 - val_loss: 0.6312 - val_precision: 0.8095 - val_recall: 0.1083\n",
            "Epoch 59/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6328 - auc: 0.5904 - loss: 0.6467 - precision: 0.5091 - recall: 0.1287 - val_accuracy: 0.6627 - val_auc: 0.6311 - val_loss: 0.6298 - val_precision: 0.8182 - val_recall: 0.1146\n",
            "Epoch 60/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6608 - auc: 0.5894 - loss: 0.6427 - precision: 0.5935 - recall: 0.1535 - val_accuracy: 0.6627 - val_auc: 0.6322 - val_loss: 0.6294 - val_precision: 0.8182 - val_recall: 0.1146\n",
            "Epoch 61/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6283 - auc: 0.6281 - loss: 0.6482 - precision: 0.6093 - recall: 0.1483 - val_accuracy: 0.6698 - val_auc: 0.6330 - val_loss: 0.6284 - val_precision: 0.8400 - val_recall: 0.1338\n",
            "Epoch 62/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6596 - auc: 0.6392 - loss: 0.6260 - precision: 0.6316 - recall: 0.1745 - val_accuracy: 0.6651 - val_auc: 0.6394 - val_loss: 0.6261 - val_precision: 0.8000 - val_recall: 0.1274\n",
            "Epoch 63/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6295 - auc: 0.5641 - loss: 0.6549 - precision: 0.4733 - recall: 0.1249 - val_accuracy: 0.6604 - val_auc: 0.6413 - val_loss: 0.6254 - val_precision: 0.7826 - val_recall: 0.1146\n",
            "Epoch 64/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6488 - auc: 0.6199 - loss: 0.6338 - precision: 0.5742 - recall: 0.1665 - val_accuracy: 0.6627 - val_auc: 0.6465 - val_loss: 0.6244 - val_precision: 0.7917 - val_recall: 0.1210\n",
            "Epoch 65/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6562 - auc: 0.6421 - loss: 0.6189 - precision: 0.5412 - recall: 0.1619 - val_accuracy: 0.6627 - val_auc: 0.6478 - val_loss: 0.6238 - val_precision: 0.7917 - val_recall: 0.1210\n",
            "Epoch 66/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6479 - auc: 0.6419 - loss: 0.6335 - precision: 0.6250 - recall: 0.1975 - val_accuracy: 0.6651 - val_auc: 0.6491 - val_loss: 0.6230 - val_precision: 0.7778 - val_recall: 0.1338\n",
            "Epoch 67/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6791 - auc: 0.6263 - loss: 0.6224 - precision: 0.6199 - recall: 0.2140 - val_accuracy: 0.6698 - val_auc: 0.6497 - val_loss: 0.6224 - val_precision: 0.8148 - val_recall: 0.1401\n",
            "Epoch 68/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6454 - auc: 0.6265 - loss: 0.6327 - precision: 0.5484 - recall: 0.1673 - val_accuracy: 0.6675 - val_auc: 0.6503 - val_loss: 0.6218 - val_precision: 0.7667 - val_recall: 0.1465\n",
            "Epoch 69/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6321 - auc: 0.5957 - loss: 0.6498 - precision: 0.5420 - recall: 0.1648 - val_accuracy: 0.6675 - val_auc: 0.6487 - val_loss: 0.6219 - val_precision: 0.7667 - val_recall: 0.1465\n",
            "Epoch 70/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6570 - auc: 0.6363 - loss: 0.6276 - precision: 0.6072 - recall: 0.2031 - val_accuracy: 0.6698 - val_auc: 0.6481 - val_loss: 0.6214 - val_precision: 0.7931 - val_recall: 0.1465\n",
            "Epoch 71/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6673 - auc: 0.6325 - loss: 0.6225 - precision: 0.5866 - recall: 0.2090 - val_accuracy: 0.6651 - val_auc: 0.6475 - val_loss: 0.6209 - val_precision: 0.7419 - val_recall: 0.1465\n",
            "Epoch 72/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6654 - auc: 0.6385 - loss: 0.6227 - precision: 0.5857 - recall: 0.2239 - val_accuracy: 0.6698 - val_auc: 0.6446 - val_loss: 0.6209 - val_precision: 0.7576 - val_recall: 0.1592\n",
            "Epoch 73/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6623 - auc: 0.6398 - loss: 0.6241 - precision: 0.6204 - recall: 0.1997 - val_accuracy: 0.6675 - val_auc: 0.6466 - val_loss: 0.6200 - val_precision: 0.7353 - val_recall: 0.1592\n",
            "Epoch 74/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6578 - auc: 0.6439 - loss: 0.6239 - precision: 0.5878 - recall: 0.2058 - val_accuracy: 0.6698 - val_auc: 0.6453 - val_loss: 0.6205 - val_precision: 0.7429 - val_recall: 0.1656\n",
            "Epoch 75/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6505 - auc: 0.6343 - loss: 0.6330 - precision: 0.5793 - recall: 0.2208 - val_accuracy: 0.6792 - val_auc: 0.6470 - val_loss: 0.6196 - val_precision: 0.7692 - val_recall: 0.1911\n",
            "Epoch 76/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6626 - auc: 0.6382 - loss: 0.6255 - precision: 0.6163 - recall: 0.2018 - val_accuracy: 0.6769 - val_auc: 0.6454 - val_loss: 0.6196 - val_precision: 0.7500 - val_recall: 0.1911\n",
            "Epoch 77/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6643 - auc: 0.6668 - loss: 0.6220 - precision: 0.6725 - recall: 0.2273 - val_accuracy: 0.6745 - val_auc: 0.6456 - val_loss: 0.6200 - val_precision: 0.7568 - val_recall: 0.1783\n",
            "Epoch 78/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6516 - auc: 0.6621 - loss: 0.6247 - precision: 0.5588 - recall: 0.2038 - val_accuracy: 0.6722 - val_auc: 0.6422 - val_loss: 0.6210 - val_precision: 0.7250 - val_recall: 0.1847\n",
            "Epoch 79/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6457 - auc: 0.6365 - loss: 0.6327 - precision: 0.5993 - recall: 0.2067 - val_accuracy: 0.6675 - val_auc: 0.6426 - val_loss: 0.6201 - val_precision: 0.6905 - val_recall: 0.1847\n",
            "Epoch 80/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6522 - auc: 0.6540 - loss: 0.6254 - precision: 0.5771 - recall: 0.2170 - val_accuracy: 0.6745 - val_auc: 0.6466 - val_loss: 0.6191 - val_precision: 0.7111 - val_recall: 0.2038\n",
            "Epoch 81/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6584 - auc: 0.6215 - loss: 0.6298 - precision: 0.5438 - recall: 0.2085 - val_accuracy: 0.6745 - val_auc: 0.6453 - val_loss: 0.6193 - val_precision: 0.7209 - val_recall: 0.1975\n",
            "Epoch 82/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6364 - auc: 0.6259 - loss: 0.6370 - precision: 0.5245 - recall: 0.2089 - val_accuracy: 0.6698 - val_auc: 0.6485 - val_loss: 0.6176 - val_precision: 0.6889 - val_recall: 0.1975\n",
            "Epoch 83/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6540 - auc: 0.6426 - loss: 0.6257 - precision: 0.5845 - recall: 0.2175 - val_accuracy: 0.6769 - val_auc: 0.6470 - val_loss: 0.6178 - val_precision: 0.7174 - val_recall: 0.2102\n",
            "Epoch 84/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6660 - auc: 0.6839 - loss: 0.6069 - precision: 0.6361 - recall: 0.2143 - val_accuracy: 0.6745 - val_auc: 0.6522 - val_loss: 0.6167 - val_precision: 0.7021 - val_recall: 0.2102\n",
            "Epoch 85/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6606 - auc: 0.6509 - loss: 0.6165 - precision: 0.5596 - recall: 0.2369 - val_accuracy: 0.6769 - val_auc: 0.6522 - val_loss: 0.6164 - val_precision: 0.7083 - val_recall: 0.2166\n",
            "Epoch 86/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.6411 - auc: 0.6375 - loss: 0.6389 - precision: 0.5857 - recall: 0.2356 - val_accuracy: 0.6792 - val_auc: 0.6513 - val_loss: 0.6163 - val_precision: 0.7143 - val_recall: 0.2229\n",
            "Epoch 87/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6497 - auc: 0.6496 - loss: 0.6220 - precision: 0.5366 - recall: 0.2153 - val_accuracy: 0.6840 - val_auc: 0.6515 - val_loss: 0.6161 - val_precision: 0.7255 - val_recall: 0.2357\n",
            "Epoch 88/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6459 - auc: 0.6234 - loss: 0.6423 - precision: 0.5743 - recall: 0.2251 - val_accuracy: 0.6840 - val_auc: 0.6503 - val_loss: 0.6164 - val_precision: 0.7170 - val_recall: 0.2420\n",
            "Epoch 89/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6661 - auc: 0.6522 - loss: 0.6175 - precision: 0.5988 - recall: 0.2437 - val_accuracy: 0.6910 - val_auc: 0.6493 - val_loss: 0.6162 - val_precision: 0.7500 - val_recall: 0.2484\n",
            "Epoch 90/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6572 - auc: 0.6382 - loss: 0.6243 - precision: 0.5850 - recall: 0.2447 - val_accuracy: 0.6863 - val_auc: 0.6509 - val_loss: 0.6153 - val_precision: 0.7222 - val_recall: 0.2484\n",
            "Epoch 91/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6406 - auc: 0.6365 - loss: 0.6358 - precision: 0.5420 - recall: 0.2207 - val_accuracy: 0.6887 - val_auc: 0.6532 - val_loss: 0.6142 - val_precision: 0.7273 - val_recall: 0.2548\n",
            "Epoch 92/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6741 - auc: 0.6596 - loss: 0.6170 - precision: 0.6383 - recall: 0.2548 - val_accuracy: 0.6910 - val_auc: 0.6506 - val_loss: 0.6155 - val_precision: 0.7407 - val_recall: 0.2548\n",
            "Epoch 93/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6341 - auc: 0.6371 - loss: 0.6349 - precision: 0.5641 - recall: 0.2160 - val_accuracy: 0.6958 - val_auc: 0.6514 - val_loss: 0.6153 - val_precision: 0.7500 - val_recall: 0.2675\n",
            "Epoch 94/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6564 - auc: 0.6807 - loss: 0.6097 - precision: 0.5859 - recall: 0.2479 - val_accuracy: 0.6934 - val_auc: 0.6521 - val_loss: 0.6147 - val_precision: 0.7455 - val_recall: 0.2611\n",
            "Epoch 95/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6594 - auc: 0.6559 - loss: 0.6073 - precision: 0.5240 - recall: 0.2245 - val_accuracy: 0.6958 - val_auc: 0.6530 - val_loss: 0.6140 - val_precision: 0.7414 - val_recall: 0.2739\n",
            "Epoch 96/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6414 - auc: 0.6205 - loss: 0.6459 - precision: 0.5683 - recall: 0.2528 - val_accuracy: 0.6887 - val_auc: 0.6547 - val_loss: 0.6127 - val_precision: 0.7119 - val_recall: 0.2675\n",
            "Epoch 97/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6521 - auc: 0.6549 - loss: 0.6200 - precision: 0.5750 - recall: 0.2370 - val_accuracy: 0.6887 - val_auc: 0.6571 - val_loss: 0.6122 - val_precision: 0.7049 - val_recall: 0.2739\n",
            "Epoch 98/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6462 - auc: 0.6208 - loss: 0.6410 - precision: 0.5765 - recall: 0.2322 - val_accuracy: 0.6934 - val_auc: 0.6596 - val_loss: 0.6121 - val_precision: 0.7288 - val_recall: 0.2739\n",
            "Epoch 99/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6938 - auc: 0.6748 - loss: 0.6065 - precision: 0.6568 - recall: 0.2958 - val_accuracy: 0.6934 - val_auc: 0.6581 - val_loss: 0.6120 - val_precision: 0.7288 - val_recall: 0.2739\n",
            "Epoch 100/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.6671 - auc: 0.6643 - loss: 0.6162 - precision: 0.6247 - recall: 0.2704 - val_accuracy: 0.6910 - val_auc: 0.6586 - val_loss: 0.6116 - val_precision: 0.7167 - val_recall: 0.2739\n",
            "Epoch 101/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6511 - auc: 0.6692 - loss: 0.6148 - precision: 0.5564 - recall: 0.2423 - val_accuracy: 0.6887 - val_auc: 0.6585 - val_loss: 0.6121 - val_precision: 0.7049 - val_recall: 0.2739\n",
            "Epoch 102/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6878 - auc: 0.6840 - loss: 0.6011 - precision: 0.6237 - recall: 0.3001 - val_accuracy: 0.6934 - val_auc: 0.6594 - val_loss: 0.6119 - val_precision: 0.7213 - val_recall: 0.2803\n",
            "Epoch 103/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6516 - auc: 0.6481 - loss: 0.6251 - precision: 0.5692 - recall: 0.2572 - val_accuracy: 0.6934 - val_auc: 0.6586 - val_loss: 0.6109 - val_precision: 0.7213 - val_recall: 0.2803\n",
            "Epoch 104/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6690 - auc: 0.6567 - loss: 0.6160 - precision: 0.5797 - recall: 0.2635 - val_accuracy: 0.6910 - val_auc: 0.6608 - val_loss: 0.6112 - val_precision: 0.7097 - val_recall: 0.2803\n",
            "Epoch 105/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6505 - auc: 0.6699 - loss: 0.6164 - precision: 0.5835 - recall: 0.2537 - val_accuracy: 0.6910 - val_auc: 0.6608 - val_loss: 0.6111 - val_precision: 0.6970 - val_recall: 0.2930\n",
            "Epoch 106/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6687 - auc: 0.6806 - loss: 0.6154 - precision: 0.6533 - recall: 0.2859 - val_accuracy: 0.6934 - val_auc: 0.6597 - val_loss: 0.6114 - val_precision: 0.7143 - val_recall: 0.2866\n",
            "Epoch 107/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6864 - auc: 0.6871 - loss: 0.5992 - precision: 0.6251 - recall: 0.2925 - val_accuracy: 0.6887 - val_auc: 0.6605 - val_loss: 0.6107 - val_precision: 0.6923 - val_recall: 0.2866\n",
            "Epoch 108/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6572 - auc: 0.6796 - loss: 0.6097 - precision: 0.5987 - recall: 0.2725 - val_accuracy: 0.6934 - val_auc: 0.6620 - val_loss: 0.6106 - val_precision: 0.7077 - val_recall: 0.2930\n",
            "Epoch 109/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6632 - auc: 0.6753 - loss: 0.6177 - precision: 0.6419 - recall: 0.2954 - val_accuracy: 0.6910 - val_auc: 0.6623 - val_loss: 0.6103 - val_precision: 0.6970 - val_recall: 0.2930\n",
            "Epoch 110/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6718 - auc: 0.6805 - loss: 0.6064 - precision: 0.6285 - recall: 0.2657 - val_accuracy: 0.6863 - val_auc: 0.6674 - val_loss: 0.6092 - val_precision: 0.6765 - val_recall: 0.2930\n",
            "Epoch 111/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6523 - auc: 0.6455 - loss: 0.6198 - precision: 0.5275 - recall: 0.2373 - val_accuracy: 0.6910 - val_auc: 0.6699 - val_loss: 0.6078 - val_precision: 0.6970 - val_recall: 0.2930\n",
            "Epoch 112/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6528 - auc: 0.6537 - loss: 0.6202 - precision: 0.5646 - recall: 0.2637 - val_accuracy: 0.6910 - val_auc: 0.6708 - val_loss: 0.6075 - val_precision: 0.6970 - val_recall: 0.2930\n",
            "Epoch 113/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6570 - auc: 0.6587 - loss: 0.6087 - precision: 0.5184 - recall: 0.2651 - val_accuracy: 0.6910 - val_auc: 0.6704 - val_loss: 0.6071 - val_precision: 0.6970 - val_recall: 0.2930\n",
            "Epoch 114/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6588 - auc: 0.6639 - loss: 0.6162 - precision: 0.5645 - recall: 0.2737 - val_accuracy: 0.6887 - val_auc: 0.6701 - val_loss: 0.6067 - val_precision: 0.6923 - val_recall: 0.2866\n",
            "Epoch 115/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6637 - auc: 0.6748 - loss: 0.6126 - precision: 0.5816 - recall: 0.3018 - val_accuracy: 0.6910 - val_auc: 0.6689 - val_loss: 0.6072 - val_precision: 0.6970 - val_recall: 0.2930\n",
            "Epoch 116/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.6719 - auc: 0.6664 - loss: 0.6207 - precision: 0.6507 - recall: 0.2843 - val_accuracy: 0.6863 - val_auc: 0.6695 - val_loss: 0.6073 - val_precision: 0.6818 - val_recall: 0.2866\n",
            "Epoch 117/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6606 - auc: 0.6524 - loss: 0.6248 - precision: 0.6038 - recall: 0.2818 - val_accuracy: 0.6863 - val_auc: 0.6681 - val_loss: 0.6082 - val_precision: 0.6818 - val_recall: 0.2866\n",
            "Epoch 118/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6629 - auc: 0.6616 - loss: 0.6159 - precision: 0.5922 - recall: 0.2876 - val_accuracy: 0.6863 - val_auc: 0.6715 - val_loss: 0.6072 - val_precision: 0.6765 - val_recall: 0.2930\n",
            "Epoch 119/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6772 - auc: 0.6894 - loss: 0.6025 - precision: 0.6516 - recall: 0.2908 - val_accuracy: 0.6887 - val_auc: 0.6720 - val_loss: 0.6065 - val_precision: 0.6866 - val_recall: 0.2930\n",
            "Epoch 120/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6526 - auc: 0.6502 - loss: 0.6272 - precision: 0.5815 - recall: 0.3005 - val_accuracy: 0.6887 - val_auc: 0.6716 - val_loss: 0.6058 - val_precision: 0.6866 - val_recall: 0.2930\n",
            "Epoch 121/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6639 - auc: 0.6832 - loss: 0.6052 - precision: 0.5993 - recall: 0.2853 - val_accuracy: 0.6887 - val_auc: 0.6738 - val_loss: 0.6052 - val_precision: 0.6866 - val_recall: 0.2930\n",
            "Epoch 122/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6691 - auc: 0.6612 - loss: 0.6111 - precision: 0.5990 - recall: 0.2910 - val_accuracy: 0.6887 - val_auc: 0.6717 - val_loss: 0.6055 - val_precision: 0.6866 - val_recall: 0.2930\n",
            "Epoch 123/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6570 - auc: 0.6789 - loss: 0.6146 - precision: 0.5968 - recall: 0.2832 - val_accuracy: 0.6863 - val_auc: 0.6699 - val_loss: 0.6063 - val_precision: 0.6714 - val_recall: 0.2994\n",
            "Epoch 124/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6484 - auc: 0.6695 - loss: 0.6140 - precision: 0.5605 - recall: 0.2902 - val_accuracy: 0.6958 - val_auc: 0.6719 - val_loss: 0.6055 - val_precision: 0.7059 - val_recall: 0.3057\n",
            "Epoch 125/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6517 - auc: 0.6749 - loss: 0.6166 - precision: 0.6016 - recall: 0.2768 - val_accuracy: 0.6958 - val_auc: 0.6710 - val_loss: 0.6055 - val_precision: 0.7059 - val_recall: 0.3057\n",
            "Epoch 126/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6742 - auc: 0.6814 - loss: 0.6050 - precision: 0.6281 - recall: 0.3053 - val_accuracy: 0.6934 - val_auc: 0.6724 - val_loss: 0.6053 - val_precision: 0.7015 - val_recall: 0.2994\n",
            "Epoch 127/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6572 - auc: 0.6706 - loss: 0.6180 - precision: 0.6083 - recall: 0.2859 - val_accuracy: 0.6910 - val_auc: 0.6739 - val_loss: 0.6047 - val_precision: 0.6857 - val_recall: 0.3057\n",
            "Epoch 128/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6678 - auc: 0.6814 - loss: 0.6057 - precision: 0.6132 - recall: 0.2863 - val_accuracy: 0.6840 - val_auc: 0.6735 - val_loss: 0.6046 - val_precision: 0.6575 - val_recall: 0.3057\n",
            "Epoch 129/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6623 - auc: 0.6818 - loss: 0.6120 - precision: 0.6063 - recall: 0.2765 - val_accuracy: 0.6840 - val_auc: 0.6731 - val_loss: 0.6050 - val_precision: 0.6575 - val_recall: 0.3057\n",
            "Epoch 130/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6733 - auc: 0.6687 - loss: 0.6141 - precision: 0.6287 - recall: 0.3036 - val_accuracy: 0.6816 - val_auc: 0.6759 - val_loss: 0.6040 - val_precision: 0.6528 - val_recall: 0.2994\n",
            "Epoch 131/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6715 - auc: 0.6957 - loss: 0.6033 - precision: 0.6347 - recall: 0.3087 - val_accuracy: 0.6863 - val_auc: 0.6756 - val_loss: 0.6045 - val_precision: 0.6667 - val_recall: 0.3057\n",
            "Epoch 132/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6807 - auc: 0.6994 - loss: 0.6089 - precision: 0.6737 - recall: 0.3248 - val_accuracy: 0.6816 - val_auc: 0.6737 - val_loss: 0.6057 - val_precision: 0.6486 - val_recall: 0.3057\n",
            "Epoch 133/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6690 - auc: 0.6640 - loss: 0.6097 - precision: 0.5774 - recall: 0.2893 - val_accuracy: 0.6816 - val_auc: 0.6731 - val_loss: 0.6058 - val_precision: 0.6486 - val_recall: 0.3057\n",
            "Epoch 134/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6542 - auc: 0.6664 - loss: 0.6179 - precision: 0.5707 - recall: 0.2502 - val_accuracy: 0.6863 - val_auc: 0.6784 - val_loss: 0.6043 - val_precision: 0.6622 - val_recall: 0.3121\n",
            "Epoch 135/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6803 - auc: 0.6664 - loss: 0.6075 - precision: 0.5924 - recall: 0.3016 - val_accuracy: 0.6816 - val_auc: 0.6779 - val_loss: 0.6052 - val_precision: 0.6486 - val_recall: 0.3057\n",
            "Epoch 136/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6712 - auc: 0.6901 - loss: 0.5974 - precision: 0.5682 - recall: 0.3108 - val_accuracy: 0.6816 - val_auc: 0.6781 - val_loss: 0.6053 - val_precision: 0.6486 - val_recall: 0.3057\n",
            "Epoch 137/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6755 - auc: 0.6810 - loss: 0.6038 - precision: 0.6000 - recall: 0.3362 - val_accuracy: 0.6863 - val_auc: 0.6766 - val_loss: 0.6054 - val_precision: 0.6579 - val_recall: 0.3185\n",
            "Epoch 138/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6518 - auc: 0.6719 - loss: 0.6227 - precision: 0.5836 - recall: 0.3133 - val_accuracy: 0.6840 - val_auc: 0.6764 - val_loss: 0.6054 - val_precision: 0.6494 - val_recall: 0.3185\n",
            "Epoch 139/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6931 - auc: 0.7024 - loss: 0.5997 - precision: 0.6781 - recall: 0.3569 - val_accuracy: 0.6887 - val_auc: 0.6780 - val_loss: 0.6048 - val_precision: 0.6582 - val_recall: 0.3312\n",
            "Epoch 140/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6819 - auc: 0.7167 - loss: 0.5869 - precision: 0.6224 - recall: 0.3185 - val_accuracy: 0.6863 - val_auc: 0.6794 - val_loss: 0.6041 - val_precision: 0.6538 - val_recall: 0.3248\n",
            "Epoch 141/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6654 - auc: 0.6684 - loss: 0.6135 - precision: 0.5647 - recall: 0.3112 - val_accuracy: 0.6863 - val_auc: 0.6776 - val_loss: 0.6044 - val_precision: 0.6538 - val_recall: 0.3248\n",
            "Epoch 142/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6734 - auc: 0.6873 - loss: 0.6041 - precision: 0.6017 - recall: 0.3147 - val_accuracy: 0.6887 - val_auc: 0.6775 - val_loss: 0.6047 - val_precision: 0.6582 - val_recall: 0.3312\n",
            "Epoch 143/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6821 - auc: 0.6855 - loss: 0.6004 - precision: 0.5885 - recall: 0.3267 - val_accuracy: 0.6863 - val_auc: 0.6788 - val_loss: 0.6036 - val_precision: 0.6622 - val_recall: 0.3121\n",
            "Epoch 144/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6447 - auc: 0.6934 - loss: 0.6119 - precision: 0.5999 - recall: 0.2670 - val_accuracy: 0.6887 - val_auc: 0.6798 - val_loss: 0.6035 - val_precision: 0.6667 - val_recall: 0.3185\n",
            "Epoch 145/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6696 - auc: 0.6756 - loss: 0.6113 - precision: 0.5966 - recall: 0.3105 - val_accuracy: 0.6863 - val_auc: 0.6784 - val_loss: 0.6036 - val_precision: 0.6579 - val_recall: 0.3185\n",
            "Epoch 146/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6727 - auc: 0.6635 - loss: 0.6105 - precision: 0.6171 - recall: 0.2750 - val_accuracy: 0.6840 - val_auc: 0.6800 - val_loss: 0.6036 - val_precision: 0.6494 - val_recall: 0.3185\n",
            "Epoch 147/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6835 - auc: 0.6774 - loss: 0.6036 - precision: 0.5976 - recall: 0.3227 - val_accuracy: 0.6887 - val_auc: 0.6793 - val_loss: 0.6043 - val_precision: 0.6582 - val_recall: 0.3312\n",
            "Epoch 148/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6856 - auc: 0.7032 - loss: 0.5955 - precision: 0.6297 - recall: 0.3210 - val_accuracy: 0.6887 - val_auc: 0.6788 - val_loss: 0.6049 - val_precision: 0.6623 - val_recall: 0.3248\n",
            "Epoch 149/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6898 - auc: 0.7033 - loss: 0.6002 - precision: 0.6567 - recall: 0.3498 - val_accuracy: 0.6840 - val_auc: 0.6783 - val_loss: 0.6056 - val_precision: 0.6494 - val_recall: 0.3185\n",
            "Epoch 150/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6721 - auc: 0.6892 - loss: 0.6127 - precision: 0.6539 - recall: 0.3430 - val_accuracy: 0.6816 - val_auc: 0.6783 - val_loss: 0.6056 - val_precision: 0.6410 - val_recall: 0.3185\n",
            "Epoch 151/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6425 - auc: 0.6826 - loss: 0.6225 - precision: 0.5713 - recall: 0.2820 - val_accuracy: 0.6863 - val_auc: 0.6787 - val_loss: 0.6047 - val_precision: 0.6579 - val_recall: 0.3185\n",
            "Epoch 152/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6615 - auc: 0.6686 - loss: 0.6182 - precision: 0.6118 - recall: 0.2734 - val_accuracy: 0.6887 - val_auc: 0.6799 - val_loss: 0.6039 - val_precision: 0.6623 - val_recall: 0.3248\n",
            "Epoch 153/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6773 - auc: 0.7218 - loss: 0.5960 - precision: 0.6647 - recall: 0.3372 - val_accuracy: 0.6887 - val_auc: 0.6784 - val_loss: 0.6050 - val_precision: 0.6543 - val_recall: 0.3376\n",
            "Epoch 154/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6879 - auc: 0.6798 - loss: 0.6029 - precision: 0.6484 - recall: 0.3064 - val_accuracy: 0.6887 - val_auc: 0.6803 - val_loss: 0.6036 - val_precision: 0.6582 - val_recall: 0.3312\n",
            "Epoch 155/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6762 - auc: 0.6918 - loss: 0.6117 - precision: 0.6421 - recall: 0.3325 - val_accuracy: 0.6887 - val_auc: 0.6793 - val_loss: 0.6038 - val_precision: 0.6543 - val_recall: 0.3376\n",
            "Epoch 156/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6842 - auc: 0.7047 - loss: 0.5935 - precision: 0.6650 - recall: 0.3303 - val_accuracy: 0.6887 - val_auc: 0.6796 - val_loss: 0.6038 - val_precision: 0.6543 - val_recall: 0.3376\n",
            "Epoch 157/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6670 - auc: 0.6834 - loss: 0.6100 - precision: 0.6182 - recall: 0.3278 - val_accuracy: 0.6910 - val_auc: 0.6803 - val_loss: 0.6039 - val_precision: 0.6585 - val_recall: 0.3439\n",
            "Epoch 158/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6948 - auc: 0.7168 - loss: 0.5826 - precision: 0.6486 - recall: 0.3398 - val_accuracy: 0.6910 - val_auc: 0.6819 - val_loss: 0.6036 - val_precision: 0.6585 - val_recall: 0.3439\n",
            "Epoch 159/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6910 - auc: 0.7063 - loss: 0.5876 - precision: 0.6255 - recall: 0.3472 - val_accuracy: 0.6934 - val_auc: 0.6817 - val_loss: 0.6044 - val_precision: 0.6667 - val_recall: 0.3439\n",
            "Epoch 160/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6880 - auc: 0.6925 - loss: 0.6013 - precision: 0.6281 - recall: 0.3635 - val_accuracy: 0.6934 - val_auc: 0.6808 - val_loss: 0.6048 - val_precision: 0.6667 - val_recall: 0.3439\n",
            "Epoch 161/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6599 - auc: 0.6965 - loss: 0.6082 - precision: 0.6172 - recall: 0.3478 - val_accuracy: 0.6910 - val_auc: 0.6811 - val_loss: 0.6044 - val_precision: 0.6585 - val_recall: 0.3439\n",
            "Epoch 162/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6721 - auc: 0.6756 - loss: 0.6082 - precision: 0.6086 - recall: 0.3121 - val_accuracy: 0.6910 - val_auc: 0.6810 - val_loss: 0.6037 - val_precision: 0.6625 - val_recall: 0.3376\n",
            "Epoch 163/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6543 - auc: 0.6772 - loss: 0.6011 - precision: 0.5256 - recall: 0.2821 - val_accuracy: 0.6910 - val_auc: 0.6827 - val_loss: 0.6038 - val_precision: 0.6625 - val_recall: 0.3376\n",
            "Epoch 164/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6548 - auc: 0.6855 - loss: 0.6105 - precision: 0.5865 - recall: 0.3301 - val_accuracy: 0.6887 - val_auc: 0.6821 - val_loss: 0.6037 - val_precision: 0.6506 - val_recall: 0.3439\n",
            "Epoch 165/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6807 - auc: 0.7059 - loss: 0.5927 - precision: 0.6235 - recall: 0.3401 - val_accuracy: 0.6863 - val_auc: 0.6824 - val_loss: 0.6036 - val_precision: 0.6429 - val_recall: 0.3439\n",
            "Epoch 166/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6652 - auc: 0.6766 - loss: 0.6051 - precision: 0.5535 - recall: 0.3373 - val_accuracy: 0.6934 - val_auc: 0.6799 - val_loss: 0.6043 - val_precision: 0.6667 - val_recall: 0.3439\n",
            "Epoch 167/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6811 - auc: 0.7054 - loss: 0.5940 - precision: 0.6287 - recall: 0.3271 - val_accuracy: 0.6934 - val_auc: 0.6822 - val_loss: 0.6035 - val_precision: 0.6667 - val_recall: 0.3439\n",
            "Epoch 168/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6901 - auc: 0.7011 - loss: 0.5990 - precision: 0.6397 - recall: 0.3672 - val_accuracy: 0.6934 - val_auc: 0.6823 - val_loss: 0.6037 - val_precision: 0.6667 - val_recall: 0.3439\n",
            "Epoch 169/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6769 - auc: 0.6680 - loss: 0.6082 - precision: 0.5858 - recall: 0.3346 - val_accuracy: 0.6910 - val_auc: 0.6821 - val_loss: 0.6038 - val_precision: 0.6625 - val_recall: 0.3376\n",
            "Epoch 170/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6948 - auc: 0.6905 - loss: 0.5913 - precision: 0.6236 - recall: 0.3357 - val_accuracy: 0.6910 - val_auc: 0.6830 - val_loss: 0.6037 - val_precision: 0.6625 - val_recall: 0.3376\n",
            "Epoch 171/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6718 - auc: 0.6937 - loss: 0.5983 - precision: 0.5919 - recall: 0.3379 - val_accuracy: 0.6887 - val_auc: 0.6836 - val_loss: 0.6031 - val_precision: 0.6506 - val_recall: 0.3439\n",
            "Epoch 172/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6563 - auc: 0.6800 - loss: 0.6130 - precision: 0.5806 - recall: 0.3122 - val_accuracy: 0.6840 - val_auc: 0.6833 - val_loss: 0.6034 - val_precision: 0.6386 - val_recall: 0.3376\n",
            "Epoch 173/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6582 - auc: 0.6811 - loss: 0.6141 - precision: 0.6133 - recall: 0.3326 - val_accuracy: 0.6863 - val_auc: 0.6845 - val_loss: 0.6026 - val_precision: 0.6429 - val_recall: 0.3439\n",
            "Epoch 174/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6455 - auc: 0.6801 - loss: 0.6168 - precision: 0.5763 - recall: 0.3127 - val_accuracy: 0.6863 - val_auc: 0.6848 - val_loss: 0.6026 - val_precision: 0.6395 - val_recall: 0.3503\n",
            "Epoch 175/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6764 - auc: 0.6762 - loss: 0.6086 - precision: 0.6012 - recall: 0.3453 - val_accuracy: 0.6840 - val_auc: 0.6825 - val_loss: 0.6036 - val_precision: 0.6386 - val_recall: 0.3376\n",
            "Epoch 176/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6705 - auc: 0.6887 - loss: 0.6051 - precision: 0.6101 - recall: 0.3432 - val_accuracy: 0.6840 - val_auc: 0.6836 - val_loss: 0.6034 - val_precision: 0.6386 - val_recall: 0.3376\n",
            "Epoch 177/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6755 - auc: 0.6974 - loss: 0.5930 - precision: 0.5749 - recall: 0.3589 - val_accuracy: 0.6887 - val_auc: 0.6820 - val_loss: 0.6037 - val_precision: 0.6543 - val_recall: 0.3376\n",
            "Epoch 178/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6760 - auc: 0.6798 - loss: 0.6109 - precision: 0.6066 - recall: 0.3150 - val_accuracy: 0.6816 - val_auc: 0.6788 - val_loss: 0.6053 - val_precision: 0.6375 - val_recall: 0.3248\n",
            "Epoch 179/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6799 - auc: 0.7014 - loss: 0.6012 - precision: 0.6684 - recall: 0.3384 - val_accuracy: 0.6863 - val_auc: 0.6815 - val_loss: 0.6036 - val_precision: 0.6463 - val_recall: 0.3376\n",
            "Epoch 180/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6640 - auc: 0.6889 - loss: 0.6140 - precision: 0.6154 - recall: 0.3580 - val_accuracy: 0.6887 - val_auc: 0.6839 - val_loss: 0.6027 - val_precision: 0.6543 - val_recall: 0.3376\n",
            "Epoch 181/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6795 - auc: 0.6825 - loss: 0.6008 - precision: 0.5863 - recall: 0.3398 - val_accuracy: 0.6887 - val_auc: 0.6840 - val_loss: 0.6025 - val_precision: 0.6506 - val_recall: 0.3439\n",
            "Epoch 182/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6887 - auc: 0.6984 - loss: 0.5919 - precision: 0.6119 - recall: 0.3444 - val_accuracy: 0.6887 - val_auc: 0.6840 - val_loss: 0.6022 - val_precision: 0.6506 - val_recall: 0.3439\n",
            "Epoch 183/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6768 - auc: 0.6826 - loss: 0.6053 - precision: 0.5927 - recall: 0.3734 - val_accuracy: 0.6887 - val_auc: 0.6860 - val_loss: 0.6012 - val_precision: 0.6506 - val_recall: 0.3439\n",
            "Epoch 184/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6742 - auc: 0.6981 - loss: 0.6070 - precision: 0.6603 - recall: 0.3438 - val_accuracy: 0.6887 - val_auc: 0.6860 - val_loss: 0.6013 - val_precision: 0.6506 - val_recall: 0.3439\n",
            "Epoch 185/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6589 - auc: 0.6902 - loss: 0.6164 - precision: 0.6227 - recall: 0.3350 - val_accuracy: 0.6863 - val_auc: 0.6862 - val_loss: 0.6009 - val_precision: 0.6463 - val_recall: 0.3376\n",
            "Epoch 186/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6717 - auc: 0.6946 - loss: 0.5927 - precision: 0.5805 - recall: 0.3285 - val_accuracy: 0.6887 - val_auc: 0.6887 - val_loss: 0.5996 - val_precision: 0.6506 - val_recall: 0.3439\n",
            "Epoch 187/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6875 - auc: 0.7091 - loss: 0.5984 - precision: 0.6575 - recall: 0.3522 - val_accuracy: 0.6910 - val_auc: 0.6877 - val_loss: 0.6006 - val_precision: 0.6585 - val_recall: 0.3439\n",
            "Epoch 188/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6611 - auc: 0.6942 - loss: 0.6035 - precision: 0.5661 - recall: 0.3276 - val_accuracy: 0.6887 - val_auc: 0.6858 - val_loss: 0.6014 - val_precision: 0.6506 - val_recall: 0.3439\n",
            "Epoch 189/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6879 - auc: 0.6996 - loss: 0.5948 - precision: 0.6364 - recall: 0.3551 - val_accuracy: 0.6934 - val_auc: 0.6864 - val_loss: 0.6009 - val_precision: 0.6588 - val_recall: 0.3567\n",
            "Epoch 190/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6955 - auc: 0.6973 - loss: 0.5880 - precision: 0.5827 - recall: 0.3387 - val_accuracy: 0.6887 - val_auc: 0.6854 - val_loss: 0.6011 - val_precision: 0.6471 - val_recall: 0.3503\n",
            "Epoch 191/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6617 - auc: 0.7054 - loss: 0.5988 - precision: 0.6001 - recall: 0.3353 - val_accuracy: 0.6863 - val_auc: 0.6892 - val_loss: 0.5994 - val_precision: 0.6429 - val_recall: 0.3439\n",
            "Epoch 192/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6837 - auc: 0.7034 - loss: 0.5926 - precision: 0.5893 - recall: 0.3544 - val_accuracy: 0.6910 - val_auc: 0.6877 - val_loss: 0.5998 - val_precision: 0.6512 - val_recall: 0.3567\n",
            "Epoch 193/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6766 - auc: 0.7080 - loss: 0.5899 - precision: 0.6096 - recall: 0.3518 - val_accuracy: 0.6910 - val_auc: 0.6861 - val_loss: 0.6012 - val_precision: 0.6512 - val_recall: 0.3567\n",
            "Epoch 194/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6657 - auc: 0.6984 - loss: 0.6138 - precision: 0.6252 - recall: 0.3644 - val_accuracy: 0.6863 - val_auc: 0.6883 - val_loss: 0.6006 - val_precision: 0.6395 - val_recall: 0.3503\n",
            "Epoch 195/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6920 - auc: 0.7068 - loss: 0.5905 - precision: 0.6324 - recall: 0.3994 - val_accuracy: 0.6887 - val_auc: 0.6879 - val_loss: 0.6012 - val_precision: 0.6506 - val_recall: 0.3439\n",
            "Epoch 196/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6775 - auc: 0.6970 - loss: 0.5944 - precision: 0.5974 - recall: 0.3499 - val_accuracy: 0.6863 - val_auc: 0.6903 - val_loss: 0.6003 - val_precision: 0.6395 - val_recall: 0.3503\n",
            "Epoch 197/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6971 - auc: 0.7165 - loss: 0.5927 - precision: 0.6692 - recall: 0.3771 - val_accuracy: 0.6887 - val_auc: 0.6899 - val_loss: 0.6002 - val_precision: 0.6437 - val_recall: 0.3567\n",
            "Epoch 198/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6913 - auc: 0.6910 - loss: 0.5928 - precision: 0.6042 - recall: 0.3562 - val_accuracy: 0.6840 - val_auc: 0.6886 - val_loss: 0.6008 - val_precision: 0.6322 - val_recall: 0.3503\n",
            "Epoch 199/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6879 - auc: 0.7248 - loss: 0.5819 - precision: 0.6206 - recall: 0.3897 - val_accuracy: 0.6840 - val_auc: 0.6906 - val_loss: 0.6001 - val_precision: 0.6322 - val_recall: 0.3503\n",
            "Epoch 200/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6653 - auc: 0.6973 - loss: 0.6034 - precision: 0.5956 - recall: 0.3525 - val_accuracy: 0.6910 - val_auc: 0.6899 - val_loss: 0.5994 - val_precision: 0.6512 - val_recall: 0.3567\n",
            "Epoch 201/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6763 - auc: 0.7068 - loss: 0.5954 - precision: 0.6208 - recall: 0.3469 - val_accuracy: 0.6887 - val_auc: 0.6906 - val_loss: 0.5991 - val_precision: 0.6437 - val_recall: 0.3567\n",
            "Epoch 202/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6677 - auc: 0.6999 - loss: 0.6011 - precision: 0.6157 - recall: 0.3153 - val_accuracy: 0.6958 - val_auc: 0.6899 - val_loss: 0.5997 - val_precision: 0.6556 - val_recall: 0.3758\n",
            "Epoch 203/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6536 - auc: 0.6905 - loss: 0.6156 - precision: 0.6115 - recall: 0.3259 - val_accuracy: 0.6887 - val_auc: 0.6910 - val_loss: 0.5992 - val_precision: 0.6374 - val_recall: 0.3694\n",
            "Epoch 204/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6765 - auc: 0.6831 - loss: 0.6015 - precision: 0.5999 - recall: 0.3161 - val_accuracy: 0.6863 - val_auc: 0.6909 - val_loss: 0.5995 - val_precision: 0.6333 - val_recall: 0.3631\n",
            "Epoch 205/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7009 - auc: 0.7216 - loss: 0.5750 - precision: 0.6470 - recall: 0.3515 - val_accuracy: 0.6792 - val_auc: 0.6896 - val_loss: 0.6000 - val_precision: 0.6180 - val_recall: 0.3503\n",
            "Epoch 206/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6895 - auc: 0.7036 - loss: 0.5873 - precision: 0.6087 - recall: 0.3529 - val_accuracy: 0.6816 - val_auc: 0.6902 - val_loss: 0.6003 - val_precision: 0.6196 - val_recall: 0.3631\n",
            "Epoch 207/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6975 - auc: 0.7228 - loss: 0.5748 - precision: 0.6307 - recall: 0.3634 - val_accuracy: 0.6792 - val_auc: 0.6891 - val_loss: 0.6009 - val_precision: 0.6154 - val_recall: 0.3567\n",
            "Epoch 208/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7064 - auc: 0.7234 - loss: 0.5805 - precision: 0.6822 - recall: 0.3946 - val_accuracy: 0.6792 - val_auc: 0.6920 - val_loss: 0.5988 - val_precision: 0.6154 - val_recall: 0.3567\n",
            "Epoch 209/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6753 - auc: 0.7201 - loss: 0.5953 - precision: 0.6333 - recall: 0.3824 - val_accuracy: 0.6792 - val_auc: 0.6916 - val_loss: 0.5989 - val_precision: 0.6154 - val_recall: 0.3567\n",
            "Epoch 210/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6860 - auc: 0.7181 - loss: 0.5918 - precision: 0.6420 - recall: 0.3578 - val_accuracy: 0.6840 - val_auc: 0.6921 - val_loss: 0.5988 - val_precision: 0.6264 - val_recall: 0.3631\n",
            "Epoch 211/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6750 - auc: 0.6984 - loss: 0.6031 - precision: 0.6327 - recall: 0.3549 - val_accuracy: 0.6816 - val_auc: 0.6943 - val_loss: 0.5987 - val_precision: 0.6222 - val_recall: 0.3567\n",
            "Epoch 212/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6974 - auc: 0.7436 - loss: 0.5656 - precision: 0.6337 - recall: 0.3835 - val_accuracy: 0.6792 - val_auc: 0.6926 - val_loss: 0.5996 - val_precision: 0.6154 - val_recall: 0.3567\n",
            "Epoch 213/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6871 - auc: 0.7176 - loss: 0.5895 - precision: 0.6266 - recall: 0.3855 - val_accuracy: 0.6840 - val_auc: 0.6929 - val_loss: 0.5990 - val_precision: 0.6264 - val_recall: 0.3631\n",
            "Epoch 214/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6624 - auc: 0.6827 - loss: 0.6146 - precision: 0.5924 - recall: 0.3354 - val_accuracy: 0.6863 - val_auc: 0.6929 - val_loss: 0.5985 - val_precision: 0.6333 - val_recall: 0.3631\n",
            "Epoch 215/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6897 - auc: 0.7100 - loss: 0.5878 - precision: 0.6261 - recall: 0.3511 - val_accuracy: 0.6863 - val_auc: 0.6913 - val_loss: 0.5998 - val_precision: 0.6304 - val_recall: 0.3694\n",
            "Epoch 216/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6768 - auc: 0.7003 - loss: 0.5978 - precision: 0.6175 - recall: 0.3684 - val_accuracy: 0.6769 - val_auc: 0.6892 - val_loss: 0.6012 - val_precision: 0.6042 - val_recall: 0.3694\n",
            "Epoch 217/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6836 - auc: 0.7118 - loss: 0.5901 - precision: 0.6108 - recall: 0.3744 - val_accuracy: 0.6840 - val_auc: 0.6918 - val_loss: 0.6004 - val_precision: 0.6139 - val_recall: 0.3949\n",
            "Epoch 218/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6678 - auc: 0.7055 - loss: 0.5985 - precision: 0.5899 - recall: 0.3459 - val_accuracy: 0.6816 - val_auc: 0.6916 - val_loss: 0.6003 - val_precision: 0.6146 - val_recall: 0.3758\n",
            "Epoch 219/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6741 - auc: 0.7163 - loss: 0.5943 - precision: 0.6468 - recall: 0.3850 - val_accuracy: 0.6792 - val_auc: 0.6926 - val_loss: 0.5997 - val_precision: 0.6129 - val_recall: 0.3631\n",
            "Epoch 220/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6674 - auc: 0.6848 - loss: 0.6116 - precision: 0.5953 - recall: 0.3538 - val_accuracy: 0.6816 - val_auc: 0.6920 - val_loss: 0.5995 - val_precision: 0.6196 - val_recall: 0.3631\n",
            "Epoch 221/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6901 - auc: 0.7083 - loss: 0.5921 - precision: 0.6348 - recall: 0.3823 - val_accuracy: 0.6816 - val_auc: 0.6928 - val_loss: 0.5989 - val_precision: 0.6196 - val_recall: 0.3631\n",
            "Epoch 222/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6916 - auc: 0.7079 - loss: 0.5902 - precision: 0.6295 - recall: 0.3758 - val_accuracy: 0.6816 - val_auc: 0.6923 - val_loss: 0.5999 - val_precision: 0.6170 - val_recall: 0.3694\n",
            "Epoch 223/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6887 - auc: 0.7027 - loss: 0.5866 - precision: 0.6018 - recall: 0.3704 - val_accuracy: 0.6840 - val_auc: 0.6940 - val_loss: 0.5992 - val_precision: 0.6211 - val_recall: 0.3758\n",
            "Epoch 224/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6873 - auc: 0.7138 - loss: 0.5873 - precision: 0.6286 - recall: 0.3683 - val_accuracy: 0.6840 - val_auc: 0.6924 - val_loss: 0.5999 - val_precision: 0.6211 - val_recall: 0.3758\n",
            "Epoch 225/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6887 - auc: 0.7188 - loss: 0.5857 - precision: 0.6509 - recall: 0.3933 - val_accuracy: 0.6816 - val_auc: 0.6931 - val_loss: 0.5994 - val_precision: 0.6170 - val_recall: 0.3694\n",
            "Epoch 226/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6727 - auc: 0.7083 - loss: 0.5979 - precision: 0.6165 - recall: 0.3572 - val_accuracy: 0.6792 - val_auc: 0.6934 - val_loss: 0.5994 - val_precision: 0.6105 - val_recall: 0.3694\n",
            "Epoch 227/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6846 - auc: 0.6947 - loss: 0.6033 - precision: 0.6214 - recall: 0.3649 - val_accuracy: 0.6816 - val_auc: 0.6935 - val_loss: 0.5993 - val_precision: 0.6146 - val_recall: 0.3758\n",
            "Epoch 228/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6774 - auc: 0.7242 - loss: 0.5853 - precision: 0.6221 - recall: 0.3660 - val_accuracy: 0.6816 - val_auc: 0.6947 - val_loss: 0.5990 - val_precision: 0.6146 - val_recall: 0.3758\n",
            "Epoch 229/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6950 - auc: 0.7306 - loss: 0.5785 - precision: 0.6343 - recall: 0.4009 - val_accuracy: 0.6863 - val_auc: 0.6943 - val_loss: 0.5989 - val_precision: 0.6250 - val_recall: 0.3822\n",
            "Epoch 230/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6874 - auc: 0.7155 - loss: 0.5855 - precision: 0.6255 - recall: 0.3989 - val_accuracy: 0.6840 - val_auc: 0.6964 - val_loss: 0.5977 - val_precision: 0.6186 - val_recall: 0.3822\n",
            "Epoch 231/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6951 - auc: 0.7307 - loss: 0.5834 - precision: 0.6769 - recall: 0.4044 - val_accuracy: 0.6840 - val_auc: 0.6951 - val_loss: 0.5985 - val_precision: 0.6186 - val_recall: 0.3822\n",
            "Epoch 232/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6821 - auc: 0.7094 - loss: 0.6000 - precision: 0.6500 - recall: 0.3834 - val_accuracy: 0.6863 - val_auc: 0.6957 - val_loss: 0.5983 - val_precision: 0.6224 - val_recall: 0.3885\n",
            "Epoch 233/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6883 - auc: 0.7205 - loss: 0.5866 - precision: 0.6211 - recall: 0.4127 - val_accuracy: 0.6863 - val_auc: 0.6947 - val_loss: 0.5981 - val_precision: 0.6250 - val_recall: 0.3822\n",
            "Epoch 234/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6977 - auc: 0.7282 - loss: 0.5790 - precision: 0.6510 - recall: 0.4041 - val_accuracy: 0.6887 - val_auc: 0.6950 - val_loss: 0.5978 - val_precision: 0.6289 - val_recall: 0.3885\n",
            "Epoch 235/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6915 - auc: 0.7122 - loss: 0.5871 - precision: 0.6174 - recall: 0.4169 - val_accuracy: 0.6863 - val_auc: 0.6939 - val_loss: 0.5977 - val_precision: 0.6250 - val_recall: 0.3822\n",
            "Epoch 236/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6786 - auc: 0.7138 - loss: 0.5869 - precision: 0.6030 - recall: 0.3868 - val_accuracy: 0.6792 - val_auc: 0.6938 - val_loss: 0.5981 - val_precision: 0.6154 - val_recall: 0.3567\n",
            "Epoch 237/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7035 - auc: 0.7334 - loss: 0.5750 - precision: 0.6665 - recall: 0.3928 - val_accuracy: 0.6792 - val_auc: 0.6958 - val_loss: 0.5972 - val_precision: 0.6082 - val_recall: 0.3758\n",
            "Epoch 238/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6826 - auc: 0.6997 - loss: 0.5960 - precision: 0.6244 - recall: 0.3681 - val_accuracy: 0.6863 - val_auc: 0.6947 - val_loss: 0.5975 - val_precision: 0.6224 - val_recall: 0.3885\n",
            "Epoch 239/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6864 - auc: 0.7216 - loss: 0.5802 - precision: 0.6228 - recall: 0.3569 - val_accuracy: 0.6792 - val_auc: 0.6959 - val_loss: 0.5975 - val_precision: 0.6040 - val_recall: 0.3885\n",
            "Epoch 240/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6878 - auc: 0.7179 - loss: 0.5831 - precision: 0.6163 - recall: 0.3681 - val_accuracy: 0.6840 - val_auc: 0.6946 - val_loss: 0.5981 - val_precision: 0.6139 - val_recall: 0.3949\n",
            "Epoch 241/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6945 - auc: 0.7311 - loss: 0.5833 - precision: 0.6714 - recall: 0.4045 - val_accuracy: 0.6840 - val_auc: 0.6936 - val_loss: 0.5989 - val_precision: 0.6162 - val_recall: 0.3885\n",
            "Epoch 242/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6799 - auc: 0.6992 - loss: 0.5979 - precision: 0.5919 - recall: 0.3749 - val_accuracy: 0.6840 - val_auc: 0.6935 - val_loss: 0.5992 - val_precision: 0.6162 - val_recall: 0.3885\n",
            "Epoch 243/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6756 - auc: 0.6888 - loss: 0.6023 - precision: 0.5936 - recall: 0.3708 - val_accuracy: 0.6816 - val_auc: 0.6952 - val_loss: 0.5982 - val_precision: 0.6122 - val_recall: 0.3822\n",
            "Epoch 244/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6845 - auc: 0.7192 - loss: 0.5837 - precision: 0.6062 - recall: 0.3999 - val_accuracy: 0.6840 - val_auc: 0.6956 - val_loss: 0.5976 - val_precision: 0.6186 - val_recall: 0.3822\n",
            "Epoch 245/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6838 - auc: 0.7299 - loss: 0.5784 - precision: 0.6175 - recall: 0.3571 - val_accuracy: 0.6816 - val_auc: 0.6954 - val_loss: 0.5978 - val_precision: 0.6122 - val_recall: 0.3822\n",
            "Epoch 246/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6813 - auc: 0.7067 - loss: 0.5928 - precision: 0.6114 - recall: 0.3792 - val_accuracy: 0.6863 - val_auc: 0.6956 - val_loss: 0.5973 - val_precision: 0.6224 - val_recall: 0.3885\n",
            "Epoch 247/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7017 - auc: 0.7322 - loss: 0.5746 - precision: 0.6572 - recall: 0.4151 - val_accuracy: 0.6887 - val_auc: 0.6949 - val_loss: 0.5976 - val_precision: 0.6316 - val_recall: 0.3822\n",
            "Epoch 248/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6877 - auc: 0.7206 - loss: 0.5707 - precision: 0.5816 - recall: 0.3929 - val_accuracy: 0.6934 - val_auc: 0.6946 - val_loss: 0.5981 - val_precision: 0.6392 - val_recall: 0.3949\n",
            "Epoch 249/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7050 - auc: 0.7368 - loss: 0.5736 - precision: 0.6614 - recall: 0.4114 - val_accuracy: 0.6863 - val_auc: 0.6944 - val_loss: 0.5981 - val_precision: 0.6250 - val_recall: 0.3822\n",
            "Epoch 250/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7024 - auc: 0.7228 - loss: 0.5729 - precision: 0.6320 - recall: 0.3799 - val_accuracy: 0.6816 - val_auc: 0.6933 - val_loss: 0.5984 - val_precision: 0.6100 - val_recall: 0.3885\n",
            "Epoch 251/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6967 - auc: 0.7306 - loss: 0.5851 - precision: 0.6676 - recall: 0.4055 - val_accuracy: 0.6863 - val_auc: 0.6925 - val_loss: 0.5987 - val_precision: 0.6176 - val_recall: 0.4013\n",
            "Epoch 252/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6793 - auc: 0.7154 - loss: 0.5924 - precision: 0.6226 - recall: 0.3739 - val_accuracy: 0.6887 - val_auc: 0.6935 - val_loss: 0.5987 - val_precision: 0.6238 - val_recall: 0.4013\n",
            "Epoch 253/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6816 - auc: 0.7175 - loss: 0.5879 - precision: 0.6126 - recall: 0.3818 - val_accuracy: 0.6816 - val_auc: 0.6941 - val_loss: 0.5981 - val_precision: 0.6078 - val_recall: 0.3949\n",
            "Epoch 254/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6933 - auc: 0.7354 - loss: 0.5742 - precision: 0.6582 - recall: 0.3669 - val_accuracy: 0.6863 - val_auc: 0.6933 - val_loss: 0.5986 - val_precision: 0.6154 - val_recall: 0.4076\n",
            "Epoch 255/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6711 - auc: 0.7071 - loss: 0.6068 - precision: 0.6378 - recall: 0.3730 - val_accuracy: 0.6887 - val_auc: 0.6930 - val_loss: 0.5994 - val_precision: 0.6190 - val_recall: 0.4140\n",
            "Epoch 256/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6991 - auc: 0.7393 - loss: 0.5660 - precision: 0.5985 - recall: 0.4185 - val_accuracy: 0.6840 - val_auc: 0.6938 - val_loss: 0.5987 - val_precision: 0.6162 - val_recall: 0.3885\n",
            "Epoch 257/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7044 - auc: 0.7131 - loss: 0.5830 - precision: 0.6303 - recall: 0.3883 - val_accuracy: 0.6887 - val_auc: 0.6949 - val_loss: 0.5974 - val_precision: 0.6190 - val_recall: 0.4140\n",
            "Epoch 258/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6821 - auc: 0.7173 - loss: 0.5937 - precision: 0.6397 - recall: 0.3782 - val_accuracy: 0.6887 - val_auc: 0.6947 - val_loss: 0.5978 - val_precision: 0.6190 - val_recall: 0.4140\n",
            "Epoch 259/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6839 - auc: 0.7281 - loss: 0.5756 - precision: 0.6028 - recall: 0.4051 - val_accuracy: 0.6934 - val_auc: 0.6949 - val_loss: 0.5976 - val_precision: 0.6286 - val_recall: 0.4204\n",
            "Epoch 260/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6867 - auc: 0.7365 - loss: 0.5731 - precision: 0.6197 - recall: 0.4050 - val_accuracy: 0.6910 - val_auc: 0.6954 - val_loss: 0.5975 - val_precision: 0.6226 - val_recall: 0.4204\n",
            "Epoch 261/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6974 - auc: 0.7075 - loss: 0.5795 - precision: 0.5820 - recall: 0.3947 - val_accuracy: 0.6887 - val_auc: 0.6945 - val_loss: 0.5978 - val_precision: 0.6190 - val_recall: 0.4140\n",
            "Epoch 262/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6838 - auc: 0.7169 - loss: 0.5924 - precision: 0.6387 - recall: 0.3934 - val_accuracy: 0.6863 - val_auc: 0.6944 - val_loss: 0.5977 - val_precision: 0.6154 - val_recall: 0.4076\n",
            "Epoch 263/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6820 - auc: 0.7012 - loss: 0.5960 - precision: 0.6154 - recall: 0.3894 - val_accuracy: 0.6816 - val_auc: 0.6943 - val_loss: 0.5979 - val_precision: 0.6078 - val_recall: 0.3949\n",
            "Epoch 264/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7068 - auc: 0.7358 - loss: 0.5805 - precision: 0.6650 - recall: 0.4161 - val_accuracy: 0.6840 - val_auc: 0.6933 - val_loss: 0.5981 - val_precision: 0.6117 - val_recall: 0.4013\n",
            "Epoch 265/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6981 - auc: 0.7368 - loss: 0.5771 - precision: 0.6590 - recall: 0.4149 - val_accuracy: 0.6840 - val_auc: 0.6941 - val_loss: 0.5978 - val_precision: 0.6139 - val_recall: 0.3949\n",
            "Epoch 266/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7018 - auc: 0.7185 - loss: 0.5733 - precision: 0.6299 - recall: 0.3871 - val_accuracy: 0.6840 - val_auc: 0.6949 - val_loss: 0.5978 - val_precision: 0.6117 - val_recall: 0.4013\n",
            "Epoch 267/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7250 - auc: 0.7533 - loss: 0.5587 - precision: 0.7035 - recall: 0.4413 - val_accuracy: 0.6863 - val_auc: 0.6957 - val_loss: 0.5971 - val_precision: 0.6132 - val_recall: 0.4140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_epoch = np.argmin(history.history['val_loss'])\n",
        "print(f\"Best Epoch: {best_epoch+1}\")\n",
        "print(f\"Train Accuracy at Best Epoch: {history.history['accuracy'][best_epoch]:.4f}\")\n",
        "print(f\"Val Accuracy at Best Epoch: {history.history['val_accuracy'][best_epoch]:.4f}\")"
      ],
      "metadata": {
        "id": "nIQiApSSMZR8",
        "outputId": "974af313-a129-4da2-f189-5182c0cfaeb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Epoch: 267\n",
            "Train Accuracy at Best Epoch: 0.7017\n",
            "Val Accuracy at Best Epoch: 0.6863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy, test_precision, test_recall, test_auc = gaius_model.evaluate(X_test, y_test, verbose=1)\n",
        "\n",
        "# Print results with clear formatting\n",
        "print(\"\\nTest Evaluation Metrics:\")\n",
        "print(f\"  Loss      : {test_loss:.4f}\")\n",
        "print(f\"  Accuracy  : {test_accuracy:.4f}\")\n",
        "print(f\"  Precision : {test_precision:.4f}\")\n",
        "print(f\"  Recall    : {test_recall:.4f}\")\n",
        "print(f\"  AUC       : {test_auc:.4f}\")\n"
      ],
      "metadata": {
        "id": "FaanMjPsMpYH",
        "outputId": "ee990357-2545-42bb-c989-46b6a0693cc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6524 - auc: 0.6456 - loss: 0.6305 - precision: 0.5521 - recall: 0.3555\n",
            "\n",
            "Test Evaluation Metrics:\n",
            "  Loss      : 0.6095\n",
            "  Accuracy  : 0.6706\n",
            "  Precision : 0.5914\n",
            "  Recall    : 0.3503\n",
            "  AUC       : 0.6737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Definition by member 3 (RMSprop variant)\n",
        "def model_david():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(128, input_shape=(X_train.shape[1],), activation=\"relu\",\n",
        "                                   kernel_regularizer=tf.keras.regularizers.l2(0.0005)))\n",
        "  model.add(tf.keras.layers.Dense(64, activation=\"relu\",\n",
        "                                   kernel_regularizer=tf.keras.regularizers.l2(0.0005)))\n",
        "  model.add(tf.keras.layers.Dense(32, activation=\"relu\",\n",
        "                                   kernel_regularizer=tf.keras.regularizers.l2(0.0005)))\n",
        "  model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\",\n",
        "                                   kernel_regularizer=tf.keras.regularizers.l2(0.0005)))\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "                loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "  return model\n",
        "\n",
        "model3 = model_david()\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping_3 = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=50,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history3 = model3.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=300,\n",
        "    batch_size=32,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping_3]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "0R8q1MuJ-mJd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fb64e1d-9093-43a0-809c-ff597f8c7c53"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5902 - loss: 0.7444 - val_accuracy: 0.6321 - val_loss: 0.7122\n",
            "Epoch 2/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6379 - loss: 0.7041 - val_accuracy: 0.6415 - val_loss: 0.6940\n",
            "Epoch 3/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6550 - loss: 0.6883 - val_accuracy: 0.6745 - val_loss: 0.6834\n",
            "Epoch 4/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6699 - loss: 0.6680 - val_accuracy: 0.6863 - val_loss: 0.6721\n",
            "Epoch 5/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6831 - loss: 0.6414 - val_accuracy: 0.6863 - val_loss: 0.6672\n",
            "Epoch 6/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7029 - loss: 0.6344 - val_accuracy: 0.6816 - val_loss: 0.6599\n",
            "Epoch 7/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7181 - loss: 0.6219 - val_accuracy: 0.6887 - val_loss: 0.6553\n",
            "Epoch 8/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7134 - loss: 0.6191 - val_accuracy: 0.6722 - val_loss: 0.6657\n",
            "Epoch 9/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7041 - loss: 0.6138 - val_accuracy: 0.7028 - val_loss: 0.6443\n",
            "Epoch 10/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7218 - loss: 0.6110 - val_accuracy: 0.6769 - val_loss: 0.6680\n",
            "Epoch 11/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7232 - loss: 0.5979 - val_accuracy: 0.7028 - val_loss: 0.6426\n",
            "Epoch 12/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7166 - loss: 0.6053 - val_accuracy: 0.6792 - val_loss: 0.6543\n",
            "Epoch 13/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7206 - loss: 0.6026 - val_accuracy: 0.6958 - val_loss: 0.6445\n",
            "Epoch 14/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7055 - loss: 0.6066 - val_accuracy: 0.6769 - val_loss: 0.6652\n",
            "Epoch 15/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7245 - loss: 0.6010 - val_accuracy: 0.6910 - val_loss: 0.6546\n",
            "Epoch 16/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7416 - loss: 0.5650 - val_accuracy: 0.6887 - val_loss: 0.6557\n",
            "Epoch 17/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7572 - loss: 0.5619 - val_accuracy: 0.6604 - val_loss: 0.6630\n",
            "Epoch 18/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7687 - loss: 0.5605 - val_accuracy: 0.6958 - val_loss: 0.6547\n",
            "Epoch 19/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7504 - loss: 0.5655 - val_accuracy: 0.6651 - val_loss: 0.6645\n",
            "Epoch 20/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7737 - loss: 0.5433 - val_accuracy: 0.6910 - val_loss: 0.6697\n",
            "Epoch 21/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7697 - loss: 0.5409 - val_accuracy: 0.6533 - val_loss: 0.6656\n",
            "Epoch 22/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7698 - loss: 0.5355 - val_accuracy: 0.6651 - val_loss: 0.6711\n",
            "Epoch 23/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7697 - loss: 0.5408 - val_accuracy: 0.6297 - val_loss: 0.6976\n",
            "Epoch 24/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7739 - loss: 0.5276 - val_accuracy: 0.6415 - val_loss: 0.7095\n",
            "Epoch 25/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7786 - loss: 0.5357 - val_accuracy: 0.6627 - val_loss: 0.6813\n",
            "Epoch 26/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7914 - loss: 0.5061 - val_accuracy: 0.6651 - val_loss: 0.7073\n",
            "Epoch 27/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7803 - loss: 0.5205 - val_accuracy: 0.6675 - val_loss: 0.6974\n",
            "Epoch 28/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7757 - loss: 0.5327 - val_accuracy: 0.6226 - val_loss: 0.7177\n",
            "Epoch 29/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8009 - loss: 0.5017 - val_accuracy: 0.6557 - val_loss: 0.7069\n",
            "Epoch 30/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8000 - loss: 0.4913 - val_accuracy: 0.6769 - val_loss: 0.7472\n",
            "Epoch 31/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7716 - loss: 0.5066 - val_accuracy: 0.6179 - val_loss: 0.7283\n",
            "Epoch 32/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8161 - loss: 0.4756 - val_accuracy: 0.6250 - val_loss: 0.7346\n",
            "Epoch 33/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8196 - loss: 0.4663 - val_accuracy: 0.6321 - val_loss: 0.7435\n",
            "Epoch 34/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8220 - loss: 0.4568 - val_accuracy: 0.6274 - val_loss: 0.7395\n",
            "Epoch 35/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8190 - loss: 0.4712 - val_accuracy: 0.6745 - val_loss: 0.7549\n",
            "Epoch 36/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8193 - loss: 0.4489 - val_accuracy: 0.6392 - val_loss: 0.7809\n",
            "Epoch 37/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8309 - loss: 0.4473 - val_accuracy: 0.6651 - val_loss: 0.7980\n",
            "Epoch 38/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8427 - loss: 0.4314 - val_accuracy: 0.6462 - val_loss: 0.7549\n",
            "Epoch 39/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8256 - loss: 0.4480 - val_accuracy: 0.6250 - val_loss: 0.8424\n",
            "Epoch 40/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8351 - loss: 0.4282 - val_accuracy: 0.6226 - val_loss: 0.7998\n",
            "Epoch 41/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8430 - loss: 0.4216 - val_accuracy: 0.6321 - val_loss: 0.7802\n",
            "Epoch 42/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8551 - loss: 0.4194 - val_accuracy: 0.5991 - val_loss: 0.8772\n",
            "Epoch 43/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8568 - loss: 0.4040 - val_accuracy: 0.6462 - val_loss: 0.8194\n",
            "Epoch 44/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8418 - loss: 0.4201 - val_accuracy: 0.6156 - val_loss: 0.8465\n",
            "Epoch 45/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8541 - loss: 0.4044 - val_accuracy: 0.5849 - val_loss: 0.9133\n",
            "Epoch 46/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8418 - loss: 0.4141 - val_accuracy: 0.6274 - val_loss: 0.8534\n",
            "Epoch 47/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8737 - loss: 0.3716 - val_accuracy: 0.5802 - val_loss: 0.9155\n",
            "Epoch 48/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8694 - loss: 0.3863 - val_accuracy: 0.6061 - val_loss: 0.8956\n",
            "Epoch 49/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8820 - loss: 0.3608 - val_accuracy: 0.6297 - val_loss: 0.8551\n",
            "Epoch 50/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8657 - loss: 0.3715 - val_accuracy: 0.6250 - val_loss: 0.8803\n",
            "Epoch 51/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8736 - loss: 0.3610 - val_accuracy: 0.6533 - val_loss: 0.9309\n",
            "Epoch 52/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8775 - loss: 0.3608 - val_accuracy: 0.5660 - val_loss: 1.0383\n",
            "Epoch 53/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8864 - loss: 0.3563 - val_accuracy: 0.5873 - val_loss: 0.9400\n",
            "Epoch 54/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8608 - loss: 0.3842 - val_accuracy: 0.6132 - val_loss: 0.9685\n",
            "Epoch 55/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8967 - loss: 0.3366 - val_accuracy: 0.6368 - val_loss: 0.9164\n",
            "Epoch 56/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8690 - loss: 0.3665 - val_accuracy: 0.6203 - val_loss: 0.9369\n",
            "Epoch 57/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8940 - loss: 0.3311 - val_accuracy: 0.6038 - val_loss: 1.0297\n",
            "Epoch 58/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9014 - loss: 0.3294 - val_accuracy: 0.6250 - val_loss: 0.9571\n",
            "Epoch 59/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8833 - loss: 0.3567 - val_accuracy: 0.6486 - val_loss: 1.0046\n",
            "Epoch 60/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8909 - loss: 0.3399 - val_accuracy: 0.6557 - val_loss: 1.0832\n",
            "Epoch 61/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8663 - loss: 0.3639 - val_accuracy: 0.5920 - val_loss: 1.0739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get best epoch based on validation loss\n",
        "best_epoch = history3.history['val_loss'].index(min(history3.history['val_loss']))\n",
        "\n",
        "# Get train and validation accuracy at best epoch\n",
        "train_acc_at_best = history3.history['accuracy'][best_epoch]\n",
        "val_acc_at_best = history3.history['val_accuracy'][best_epoch]\n",
        "\n",
        "print(f\"Best Epoch: {best_epoch + 1}\")  # +1 for human-readable epoch number\n",
        "print(f\"Train Accuracy at Best Epoch: {train_acc_at_best:.4f}\")\n",
        "print(f\"Validation Accuracy at Best Epoch: {val_acc_at_best:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh4Z094Tl1oJ",
        "outputId": "bde8d2c3-6988-4ccf-d2f2-72b3983c05a5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Epoch: 16\n",
            "Train Accuracy at Best Epoch: 0.7314\n",
            "Validation Accuracy at Best Epoch: 0.6934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_probs = model3.predict(X_test).ravel()\n",
        "\n",
        "# Predict binary classes\n",
        "y_pred_classes = (y_pred_probs > 0.5).astype(\"int32\")\n",
        "\n",
        "# Evaluate loss and accuracy\n",
        "test_loss, test_accuracy = model3.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "# Calculate precision, recall, and AUC\n",
        "test_precision = precision_score(y_test, y_pred_classes)\n",
        "test_recall = recall_score(y_test, y_pred_classes)\n",
        "test_auc = roc_auc_score(y_test, y_pred_probs)\n",
        "\n",
        "# Print results\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test AUC: {test_auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oczDl65Sl1SH",
        "outputId": "631daac1-8df3-43bb-b2fa-b3bdd6fa54f3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Test Loss: 0.6773\n",
            "Test Accuracy: 0.6447\n",
            "Test Precision: 0.5238\n",
            "Test Recall: 0.4204\n",
            "Test AUC: 0.6710\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Definition by member 4\n",
        "def model_name_of_student():\n",
        "\n",
        "  return"
      ],
      "metadata": {
        "id": "TKoFpxX6_B7D"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Definition by member 5\n",
        "def model_name_of_student():\n",
        "\n",
        "  return"
      ],
      "metadata": {
        "id": "Dd3m8M3dKcfe"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start the training Process"
      ],
      "metadata": {
        "id": "hDSPmAB9jkrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#fit model\n",
        "history = model.fit(X, Y, validation_data=(testX, testy), epochs=4000, verbose=0, callbacks=[es])\n",
        "# evaluate the model\n",
        "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
        "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
        "# plot training history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "OWQHapf3jlYH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "ff09317e-ae97-4661-ac6d-602530c1db74"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Y' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-fd04eeab69b9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Y' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy"
      ],
      "metadata": {
        "id": "dKZ2T8TOIYxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Loading and Preprocessing\n",
        "# The coach will never do this!!\n",
        "regularizer = 'l1'"
      ],
      "metadata": {
        "id": "qMNag3BGIuwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(32, activation ='relu', kernel_regularizer= regularizer , input_shape = (2224,224)))\n",
        "model.add(Dropout(0.2))\n",
        "#adding Dropout\n",
        "model.add(Dense(64, activation ='relu', kernel_regularizer= regularizer , input_shape = (2224,224)))\n",
        "#adding Dropout\n",
        "model.add(Dense(128, activation ='relu', kernel_regularizer= regularizer , input_shape = (2224,224)))\n",
        "model.add(Dropout(0.2))\n",
        "#adding Dropout\n",
        "model.add(Dense(2, activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "fsmEC739I4lG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback =EarlyStopping(monitor='loss',patience=3)"
      ],
      "metadata": {
        "id": "BbyPgkZlLu37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss= 'rmse', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "Fw9XQj_ZMWUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, Y, epochs=1000, batch_size= 128, callbacks=[callback], verbose=0)"
      ],
      "metadata": {
        "id": "GPhb-1k7LGx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "wLlhrOCpJWF5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}