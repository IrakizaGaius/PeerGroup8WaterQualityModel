{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrXv0rU9sIma"
      },
      "source": [
        "# Excercise - Creating our own custom Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJyZUDbzBTIG"
      },
      "source": [
        "This is a notebook that provides a quick overview of how to create your own custom model. You will be creating a simple model.\n",
        "You will be utilizing Keras and Tensorflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvLegMMvBZYg"
      },
      "source": [
        "## Water Quality Dataset\n",
        "\n",
        "This dataset contains water quality measurements and assessments related to potability, which is the suitability of water for human consumption. The dataset's primary objective is to provide insights into water quality parameters and assist in determining whether the water is potable or not. Each row in the dataset represents a water sample with specific attributes, and the \"Potability\" column indicates whether the water is suitable for consumption.\n",
        "\n",
        "https://www.kaggle.com/datasets/uom190346a/water-quality-and-potability?select=water_potability.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LOAD THE DATA\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"/content/water_potability.csv\")\n",
        "\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "\n",
        "data.head(20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "id": "Qvnx0_dT3JEq",
        "outputId": "bcf121cf-9ea0-44d3-c786-4f6a4d69ea9d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           ph    Hardness        Solids  Chloramines     Sulfate  \\\n",
              "0         NaN  204.890455  20791.318981     7.300212  368.516441   \n",
              "1    3.716080  129.422921  18630.057858     6.635246         NaN   \n",
              "2    8.099124  224.236259  19909.541732     9.275884         NaN   \n",
              "3    8.316766  214.373394  22018.417441     8.059332  356.886136   \n",
              "4    9.092223  181.101509  17978.986339     6.546600  310.135738   \n",
              "5    5.584087  188.313324  28748.687739     7.544869  326.678363   \n",
              "6   10.223862  248.071735  28749.716544     7.513408  393.663396   \n",
              "7    8.635849  203.361523  13672.091764     4.563009  303.309771   \n",
              "8         NaN  118.988579  14285.583854     7.804174  268.646941   \n",
              "9   11.180284  227.231469  25484.508491     9.077200  404.041635   \n",
              "10   7.360640  165.520797  32452.614409     7.550701  326.624353   \n",
              "11   7.974522  218.693300  18767.656682     8.110385         NaN   \n",
              "12   7.119824  156.704993  18730.813653     3.606036  282.344050   \n",
              "13        NaN  150.174923  27331.361962     6.838223  299.415781   \n",
              "14   7.496232  205.344982  28388.004887     5.072558         NaN   \n",
              "15   6.347272  186.732881  41065.234765     9.629596  364.487687   \n",
              "16   7.051786  211.049406  30980.600787    10.094796         NaN   \n",
              "17   9.181560  273.813807  24041.326280     6.904990  398.350517   \n",
              "18   8.975464  279.357167  19460.398131     6.204321         NaN   \n",
              "19   7.371050  214.496610  25630.320037     4.432669  335.754439   \n",
              "\n",
              "    Conductivity  Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
              "0     564.308654       10.379783        86.990970   2.963135           0  \n",
              "1     592.885359       15.180013        56.329076   4.500656           0  \n",
              "2     418.606213       16.868637        66.420093   3.055934           0  \n",
              "3     363.266516       18.436524       100.341674   4.628771           0  \n",
              "4     398.410813       11.558279        31.997993   4.075075           0  \n",
              "5     280.467916        8.399735        54.917862   2.559708           0  \n",
              "6     283.651634       13.789695        84.603556   2.672989           0  \n",
              "7     474.607645       12.363817        62.798309   4.401425           0  \n",
              "8     389.375566       12.706049        53.928846   3.595017           0  \n",
              "9     563.885481       17.927806        71.976601   4.370562           0  \n",
              "10    425.383419       15.586810        78.740016   3.662292           0  \n",
              "11    364.098230       14.525746        76.485911   4.011718           0  \n",
              "12    347.715027       15.929536        79.500778   3.445756           0  \n",
              "13    379.761835       19.370807        76.509996   4.413974           0  \n",
              "14    444.645352       13.228311        70.300213   4.777382           0  \n",
              "15    516.743282       11.539781        75.071617   4.376348           0  \n",
              "16    315.141267       20.397022        56.651604   4.268429           0  \n",
              "17    477.974642       13.387341        71.457362   4.503661           0  \n",
              "18    431.443990       12.888759        63.821237   2.436086           0  \n",
              "19    469.914551       12.509164        62.797277   2.560299           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de5d981f-db29-4763-ad4f-ff88caabd1d2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>204.890455</td>\n",
              "      <td>20791.318981</td>\n",
              "      <td>7.300212</td>\n",
              "      <td>368.516441</td>\n",
              "      <td>564.308654</td>\n",
              "      <td>10.379783</td>\n",
              "      <td>86.990970</td>\n",
              "      <td>2.963135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.716080</td>\n",
              "      <td>129.422921</td>\n",
              "      <td>18630.057858</td>\n",
              "      <td>6.635246</td>\n",
              "      <td>NaN</td>\n",
              "      <td>592.885359</td>\n",
              "      <td>15.180013</td>\n",
              "      <td>56.329076</td>\n",
              "      <td>4.500656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.099124</td>\n",
              "      <td>224.236259</td>\n",
              "      <td>19909.541732</td>\n",
              "      <td>9.275884</td>\n",
              "      <td>NaN</td>\n",
              "      <td>418.606213</td>\n",
              "      <td>16.868637</td>\n",
              "      <td>66.420093</td>\n",
              "      <td>3.055934</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.316766</td>\n",
              "      <td>214.373394</td>\n",
              "      <td>22018.417441</td>\n",
              "      <td>8.059332</td>\n",
              "      <td>356.886136</td>\n",
              "      <td>363.266516</td>\n",
              "      <td>18.436524</td>\n",
              "      <td>100.341674</td>\n",
              "      <td>4.628771</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.092223</td>\n",
              "      <td>181.101509</td>\n",
              "      <td>17978.986339</td>\n",
              "      <td>6.546600</td>\n",
              "      <td>310.135738</td>\n",
              "      <td>398.410813</td>\n",
              "      <td>11.558279</td>\n",
              "      <td>31.997993</td>\n",
              "      <td>4.075075</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.584087</td>\n",
              "      <td>188.313324</td>\n",
              "      <td>28748.687739</td>\n",
              "      <td>7.544869</td>\n",
              "      <td>326.678363</td>\n",
              "      <td>280.467916</td>\n",
              "      <td>8.399735</td>\n",
              "      <td>54.917862</td>\n",
              "      <td>2.559708</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10.223862</td>\n",
              "      <td>248.071735</td>\n",
              "      <td>28749.716544</td>\n",
              "      <td>7.513408</td>\n",
              "      <td>393.663396</td>\n",
              "      <td>283.651634</td>\n",
              "      <td>13.789695</td>\n",
              "      <td>84.603556</td>\n",
              "      <td>2.672989</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8.635849</td>\n",
              "      <td>203.361523</td>\n",
              "      <td>13672.091764</td>\n",
              "      <td>4.563009</td>\n",
              "      <td>303.309771</td>\n",
              "      <td>474.607645</td>\n",
              "      <td>12.363817</td>\n",
              "      <td>62.798309</td>\n",
              "      <td>4.401425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NaN</td>\n",
              "      <td>118.988579</td>\n",
              "      <td>14285.583854</td>\n",
              "      <td>7.804174</td>\n",
              "      <td>268.646941</td>\n",
              "      <td>389.375566</td>\n",
              "      <td>12.706049</td>\n",
              "      <td>53.928846</td>\n",
              "      <td>3.595017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>11.180284</td>\n",
              "      <td>227.231469</td>\n",
              "      <td>25484.508491</td>\n",
              "      <td>9.077200</td>\n",
              "      <td>404.041635</td>\n",
              "      <td>563.885481</td>\n",
              "      <td>17.927806</td>\n",
              "      <td>71.976601</td>\n",
              "      <td>4.370562</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>7.360640</td>\n",
              "      <td>165.520797</td>\n",
              "      <td>32452.614409</td>\n",
              "      <td>7.550701</td>\n",
              "      <td>326.624353</td>\n",
              "      <td>425.383419</td>\n",
              "      <td>15.586810</td>\n",
              "      <td>78.740016</td>\n",
              "      <td>3.662292</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>7.974522</td>\n",
              "      <td>218.693300</td>\n",
              "      <td>18767.656682</td>\n",
              "      <td>8.110385</td>\n",
              "      <td>NaN</td>\n",
              "      <td>364.098230</td>\n",
              "      <td>14.525746</td>\n",
              "      <td>76.485911</td>\n",
              "      <td>4.011718</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>7.119824</td>\n",
              "      <td>156.704993</td>\n",
              "      <td>18730.813653</td>\n",
              "      <td>3.606036</td>\n",
              "      <td>282.344050</td>\n",
              "      <td>347.715027</td>\n",
              "      <td>15.929536</td>\n",
              "      <td>79.500778</td>\n",
              "      <td>3.445756</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>NaN</td>\n",
              "      <td>150.174923</td>\n",
              "      <td>27331.361962</td>\n",
              "      <td>6.838223</td>\n",
              "      <td>299.415781</td>\n",
              "      <td>379.761835</td>\n",
              "      <td>19.370807</td>\n",
              "      <td>76.509996</td>\n",
              "      <td>4.413974</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>7.496232</td>\n",
              "      <td>205.344982</td>\n",
              "      <td>28388.004887</td>\n",
              "      <td>5.072558</td>\n",
              "      <td>NaN</td>\n",
              "      <td>444.645352</td>\n",
              "      <td>13.228311</td>\n",
              "      <td>70.300213</td>\n",
              "      <td>4.777382</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>6.347272</td>\n",
              "      <td>186.732881</td>\n",
              "      <td>41065.234765</td>\n",
              "      <td>9.629596</td>\n",
              "      <td>364.487687</td>\n",
              "      <td>516.743282</td>\n",
              "      <td>11.539781</td>\n",
              "      <td>75.071617</td>\n",
              "      <td>4.376348</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>7.051786</td>\n",
              "      <td>211.049406</td>\n",
              "      <td>30980.600787</td>\n",
              "      <td>10.094796</td>\n",
              "      <td>NaN</td>\n",
              "      <td>315.141267</td>\n",
              "      <td>20.397022</td>\n",
              "      <td>56.651604</td>\n",
              "      <td>4.268429</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>9.181560</td>\n",
              "      <td>273.813807</td>\n",
              "      <td>24041.326280</td>\n",
              "      <td>6.904990</td>\n",
              "      <td>398.350517</td>\n",
              "      <td>477.974642</td>\n",
              "      <td>13.387341</td>\n",
              "      <td>71.457362</td>\n",
              "      <td>4.503661</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>8.975464</td>\n",
              "      <td>279.357167</td>\n",
              "      <td>19460.398131</td>\n",
              "      <td>6.204321</td>\n",
              "      <td>NaN</td>\n",
              "      <td>431.443990</td>\n",
              "      <td>12.888759</td>\n",
              "      <td>63.821237</td>\n",
              "      <td>2.436086</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>7.371050</td>\n",
              "      <td>214.496610</td>\n",
              "      <td>25630.320037</td>\n",
              "      <td>4.432669</td>\n",
              "      <td>335.754439</td>\n",
              "      <td>469.914551</td>\n",
              "      <td>12.509164</td>\n",
              "      <td>62.797277</td>\n",
              "      <td>2.560299</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de5d981f-db29-4763-ad4f-ff88caabd1d2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-de5d981f-db29-4763-ad4f-ff88caabd1d2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-de5d981f-db29-4763-ad4f-ff88caabd1d2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c049e580-f3b7-40b2-b0c3-e7fc3b9df12e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c049e580-f3b7-40b2-b0c3-e7fc3b9df12e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c049e580-f3b7-40b2-b0c3-e7fc3b9df12e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 3276,\n  \"fields\": [\n    {\n      \"column\": \"ph\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5943195187088117,\n        \"min\": 0.0,\n        \"max\": 13.999999999999998,\n        \"num_unique_values\": 2785,\n        \"samples\": [\n          6.569053876389385,\n          9.271355446767778,\n          8.92790592593881\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hardness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32.879761476294185,\n        \"min\": 47.432,\n        \"max\": 323.124,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          183.5211070261417,\n          188.9135411469536,\n          224.05887682392927\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8768.570827785932,\n        \"min\": 320.942611274359,\n        \"max\": 61227.19600771213,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          20461.252710219946,\n          32873.820021715685,\n          23264.10996772913\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chloramines\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.58308488903971,\n        \"min\": 0.3520000000000003,\n        \"max\": 13.127000000000002,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          7.333212177578906,\n          6.791509363412849,\n          5.92236704115349\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sulfate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 41.416840461672685,\n        \"min\": 129.00000000000003,\n        \"max\": 481.0306423059972,\n        \"num_unique_values\": 2495,\n        \"samples\": [\n          324.64407957923544,\n          370.121384654358,\n          329.12773842254506\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conductivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80.82406405111182,\n        \"min\": 181.483753985146,\n        \"max\": 753.3426195583046,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          356.3690224100897,\n          336.56150104700754,\n          387.971335796834\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Organic_carbon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.308161999126868,\n        \"min\": 2.1999999999999886,\n        \"max\": 28.30000000000001,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          20.179028868493845,\n          14.706810313722087,\n          13.40673745495127\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Trihalomethanes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.17500842221865,\n        \"min\": 0.7379999999999995,\n        \"max\": 124.0,\n        \"num_unique_values\": 3114,\n        \"samples\": [\n          66.163439242252,\n          42.844510851301166,\n          47.06639219544294\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Turbidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7803824084854116,\n        \"min\": 1.45,\n        \"max\": 6.739,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          4.886633785371213,\n          4.562197671215202,\n          2.487968647002356\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Potability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "akPkVCo4_7jt",
        "outputId": "35a360e6-e629-41fb-b9b6-0c0342df1dce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Information on the data\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mn2ks1y4rG2i",
        "outputId": "3e9b8514-9d41-47cc-a78a-1dcdd261c9c8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3276 entries, 0 to 3275\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   ph               2785 non-null   float64\n",
            " 1   Hardness         3276 non-null   float64\n",
            " 2   Solids           3276 non-null   float64\n",
            " 3   Chloramines      3276 non-null   float64\n",
            " 4   Sulfate          2495 non-null   float64\n",
            " 5   Conductivity     3276 non-null   float64\n",
            " 6   Organic_carbon   3276 non-null   float64\n",
            " 7   Trihalomethanes  3114 non-null   float64\n",
            " 8   Turbidity        3276 non-null   float64\n",
            " 9   Potability       3276 non-null   int64  \n",
            "dtypes: float64(9), int64(1)\n",
            "memory usage: 256.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Brief overview of the dataset statistics\n",
        "data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "fJvnnIxav4N2",
        "outputId": "9d611340-36ac-48b1-8f2f-59a3f9c33d74"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                ph     Hardness        Solids  Chloramines      Sulfate  \\\n",
              "count  2785.000000  3276.000000   3276.000000  3276.000000  2495.000000   \n",
              "mean      7.080795   196.369496  22014.092526     7.122277   333.775777   \n",
              "std       1.594320    32.879761   8768.570828     1.583085    41.416840   \n",
              "min       0.000000    47.432000    320.942611     0.352000   129.000000   \n",
              "25%       6.093092   176.850538  15666.690297     6.127421   307.699498   \n",
              "50%       7.036752   196.967627  20927.833607     7.130299   333.073546   \n",
              "75%       8.062066   216.667456  27332.762127     8.114887   359.950170   \n",
              "max      14.000000   323.124000  61227.196008    13.127000   481.030642   \n",
              "\n",
              "       Conductivity  Organic_carbon  Trihalomethanes    Turbidity   Potability  \n",
              "count   3276.000000     3276.000000      3114.000000  3276.000000  3276.000000  \n",
              "mean     426.205111       14.284970        66.396293     3.966786     0.390110  \n",
              "std       80.824064        3.308162        16.175008     0.780382     0.487849  \n",
              "min      181.483754        2.200000         0.738000     1.450000     0.000000  \n",
              "25%      365.734414       12.065801        55.844536     3.439711     0.000000  \n",
              "50%      421.884968       14.218338        66.622485     3.955028     0.000000  \n",
              "75%      481.792304       16.557652        77.337473     4.500320     1.000000  \n",
              "max      753.342620       28.300000       124.000000     6.739000     1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6b3a9496-f460-4231-8bc5-71156b925cda\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2785.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>2495.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3114.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "      <td>3276.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.080795</td>\n",
              "      <td>196.369496</td>\n",
              "      <td>22014.092526</td>\n",
              "      <td>7.122277</td>\n",
              "      <td>333.775777</td>\n",
              "      <td>426.205111</td>\n",
              "      <td>14.284970</td>\n",
              "      <td>66.396293</td>\n",
              "      <td>3.966786</td>\n",
              "      <td>0.390110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.594320</td>\n",
              "      <td>32.879761</td>\n",
              "      <td>8768.570828</td>\n",
              "      <td>1.583085</td>\n",
              "      <td>41.416840</td>\n",
              "      <td>80.824064</td>\n",
              "      <td>3.308162</td>\n",
              "      <td>16.175008</td>\n",
              "      <td>0.780382</td>\n",
              "      <td>0.487849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>47.432000</td>\n",
              "      <td>320.942611</td>\n",
              "      <td>0.352000</td>\n",
              "      <td>129.000000</td>\n",
              "      <td>181.483754</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>0.738000</td>\n",
              "      <td>1.450000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6.093092</td>\n",
              "      <td>176.850538</td>\n",
              "      <td>15666.690297</td>\n",
              "      <td>6.127421</td>\n",
              "      <td>307.699498</td>\n",
              "      <td>365.734414</td>\n",
              "      <td>12.065801</td>\n",
              "      <td>55.844536</td>\n",
              "      <td>3.439711</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7.036752</td>\n",
              "      <td>196.967627</td>\n",
              "      <td>20927.833607</td>\n",
              "      <td>7.130299</td>\n",
              "      <td>333.073546</td>\n",
              "      <td>421.884968</td>\n",
              "      <td>14.218338</td>\n",
              "      <td>66.622485</td>\n",
              "      <td>3.955028</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.062066</td>\n",
              "      <td>216.667456</td>\n",
              "      <td>27332.762127</td>\n",
              "      <td>8.114887</td>\n",
              "      <td>359.950170</td>\n",
              "      <td>481.792304</td>\n",
              "      <td>16.557652</td>\n",
              "      <td>77.337473</td>\n",
              "      <td>4.500320</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>14.000000</td>\n",
              "      <td>323.124000</td>\n",
              "      <td>61227.196008</td>\n",
              "      <td>13.127000</td>\n",
              "      <td>481.030642</td>\n",
              "      <td>753.342620</td>\n",
              "      <td>28.300000</td>\n",
              "      <td>124.000000</td>\n",
              "      <td>6.739000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b3a9496-f460-4231-8bc5-71156b925cda')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6b3a9496-f460-4231-8bc5-71156b925cda button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6b3a9496-f460-4231-8bc5-71156b925cda');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ff99fc79-def4-4410-ac21-1f97f0122382\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ff99fc79-def4-4410-ac21-1f97f0122382')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ff99fc79-def4-4410-ac21-1f97f0122382 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"ph\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 982.4396919342113,\n        \"min\": 0.0,\n        \"max\": 2785.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          7.080794504276835,\n          7.036752103833548,\n          2785.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hardness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1102.077573149784,\n        \"min\": 32.879761476294185,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          196.36949601730151,\n          196.96762686363076,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19161.79774847418,\n        \"min\": 320.942611274359,\n        \"max\": 61227.19600771213,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          22014.092526077104,\n          20927.833606520187,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chloramines\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1156.0476760135623,\n        \"min\": 0.3520000000000003,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          7.122276793425786,\n          7.130298973883081,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sulfate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 793.8602821876343,\n        \"min\": 41.416840461672685,\n        \"max\": 2495.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          333.7757766108135,\n          333.073545745888,\n          2495.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conductivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1040.8631085884185,\n        \"min\": 80.82406405111182,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          426.20511068255325,\n          421.8849682800544,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Organic_carbon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1153.6765632294614,\n        \"min\": 2.1999999999999886,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          14.284970247677318,\n          14.218337937208588,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Trihalomethanes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1081.0577228535572,\n        \"min\": 0.7379999999999995,\n        \"max\": 3114.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          66.39629294676803,\n          66.62248509808484,\n          3114.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Turbidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1156.9881922638967,\n        \"min\": 0.7803824084854116,\n        \"max\": 3276.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3.966786169791058,\n          3.955027562993039,\n          3276.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Potability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1158.0956231418108,\n        \"min\": 0.0,\n        \"max\": 3276.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3901098901098901,\n          1.0,\n          0.4878491696702489\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop duplicates rows of data\n",
        "\n",
        "data = data.drop_duplicates()"
      ],
      "metadata": {
        "id": "f5Rjjxwg5XnF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# percentage of missingness in the data for each column\n",
        "\n",
        "missing = data.isnull().mean()*100\n",
        "print(missing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjFnkhc35ekL",
        "outputId": "7c6faa1e-d11f-4ac0-f9f6-52355ad07ece"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ph                 14.987790\n",
            "Hardness            0.000000\n",
            "Solids              0.000000\n",
            "Chloramines         0.000000\n",
            "Sulfate            23.840049\n",
            "Conductivity        0.000000\n",
            "Organic_carbon      0.000000\n",
            "Trihalomethanes     4.945055\n",
            "Turbidity           0.000000\n",
            "Potability          0.000000\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MICE IMPUTATION to fill the missing data\n",
        "# create the imputer using MICE\n",
        "\n",
        "# separate the target variable from the rest of the data to make sure it is not changed or imputed\n",
        "features = data.drop(columns='Potability')\n",
        "target = data.Potability\n",
        "imputer = IterativeImputer(random_state=0)\n",
        "features_imputed = imputer.fit_transform(features)\n",
        "\n",
        "# convert the data back into a dataframe\n",
        "features_imputed = pd.DataFrame(features_imputed, columns=features.columns)\n",
        "\n",
        "# merge target variable and data\n",
        "data_imputed = pd.concat([features_imputed, target], axis=1)\n",
        "data_imputed.head(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "RlhnFruS2q0X",
        "outputId": "2c928524-0a52-43fb-e875-9365005e1c75"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
              "0   7.190863  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
              "1   3.716080  129.422921  18630.057858     6.635246  344.836463    592.885359   \n",
              "2   8.099124  224.236259  19909.541732     9.275884  331.981769    418.606213   \n",
              "3   8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
              "4   9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
              "5   5.584087  188.313324  28748.687739     7.544869  326.678363    280.467916   \n",
              "6  10.223862  248.071735  28749.716544     7.513408  393.663396    283.651634   \n",
              "7   8.635849  203.361523  13672.091764     4.563009  303.309771    474.607645   \n",
              "8   6.927779  118.988579  14285.583854     7.804174  268.646941    389.375566   \n",
              "9  11.180284  227.231469  25484.508491     9.077200  404.041635    563.885481   \n",
              "\n",
              "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
              "0       10.379783        86.990970   2.963135           0  \n",
              "1       15.180013        56.329076   4.500656           0  \n",
              "2       16.868637        66.420093   3.055934           0  \n",
              "3       18.436524       100.341674   4.628771           0  \n",
              "4       11.558279        31.997993   4.075075           0  \n",
              "5        8.399735        54.917862   2.559708           0  \n",
              "6       13.789695        84.603556   2.672989           0  \n",
              "7       12.363817        62.798309   4.401425           0  \n",
              "8       12.706049        53.928846   3.595017           0  \n",
              "9       17.927806        71.976601   4.370562           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-267b9d52-ed52-4116-9b2b-4d51b25853c2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.190863</td>\n",
              "      <td>204.890455</td>\n",
              "      <td>20791.318981</td>\n",
              "      <td>7.300212</td>\n",
              "      <td>368.516441</td>\n",
              "      <td>564.308654</td>\n",
              "      <td>10.379783</td>\n",
              "      <td>86.990970</td>\n",
              "      <td>2.963135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.716080</td>\n",
              "      <td>129.422921</td>\n",
              "      <td>18630.057858</td>\n",
              "      <td>6.635246</td>\n",
              "      <td>344.836463</td>\n",
              "      <td>592.885359</td>\n",
              "      <td>15.180013</td>\n",
              "      <td>56.329076</td>\n",
              "      <td>4.500656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.099124</td>\n",
              "      <td>224.236259</td>\n",
              "      <td>19909.541732</td>\n",
              "      <td>9.275884</td>\n",
              "      <td>331.981769</td>\n",
              "      <td>418.606213</td>\n",
              "      <td>16.868637</td>\n",
              "      <td>66.420093</td>\n",
              "      <td>3.055934</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.316766</td>\n",
              "      <td>214.373394</td>\n",
              "      <td>22018.417441</td>\n",
              "      <td>8.059332</td>\n",
              "      <td>356.886136</td>\n",
              "      <td>363.266516</td>\n",
              "      <td>18.436524</td>\n",
              "      <td>100.341674</td>\n",
              "      <td>4.628771</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.092223</td>\n",
              "      <td>181.101509</td>\n",
              "      <td>17978.986339</td>\n",
              "      <td>6.546600</td>\n",
              "      <td>310.135738</td>\n",
              "      <td>398.410813</td>\n",
              "      <td>11.558279</td>\n",
              "      <td>31.997993</td>\n",
              "      <td>4.075075</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.584087</td>\n",
              "      <td>188.313324</td>\n",
              "      <td>28748.687739</td>\n",
              "      <td>7.544869</td>\n",
              "      <td>326.678363</td>\n",
              "      <td>280.467916</td>\n",
              "      <td>8.399735</td>\n",
              "      <td>54.917862</td>\n",
              "      <td>2.559708</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10.223862</td>\n",
              "      <td>248.071735</td>\n",
              "      <td>28749.716544</td>\n",
              "      <td>7.513408</td>\n",
              "      <td>393.663396</td>\n",
              "      <td>283.651634</td>\n",
              "      <td>13.789695</td>\n",
              "      <td>84.603556</td>\n",
              "      <td>2.672989</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8.635849</td>\n",
              "      <td>203.361523</td>\n",
              "      <td>13672.091764</td>\n",
              "      <td>4.563009</td>\n",
              "      <td>303.309771</td>\n",
              "      <td>474.607645</td>\n",
              "      <td>12.363817</td>\n",
              "      <td>62.798309</td>\n",
              "      <td>4.401425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6.927779</td>\n",
              "      <td>118.988579</td>\n",
              "      <td>14285.583854</td>\n",
              "      <td>7.804174</td>\n",
              "      <td>268.646941</td>\n",
              "      <td>389.375566</td>\n",
              "      <td>12.706049</td>\n",
              "      <td>53.928846</td>\n",
              "      <td>3.595017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>11.180284</td>\n",
              "      <td>227.231469</td>\n",
              "      <td>25484.508491</td>\n",
              "      <td>9.077200</td>\n",
              "      <td>404.041635</td>\n",
              "      <td>563.885481</td>\n",
              "      <td>17.927806</td>\n",
              "      <td>71.976601</td>\n",
              "      <td>4.370562</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-267b9d52-ed52-4116-9b2b-4d51b25853c2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-267b9d52-ed52-4116-9b2b-4d51b25853c2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-267b9d52-ed52-4116-9b2b-4d51b25853c2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f3f75c07-beb5-4ee9-b792-ef89c457c8db\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f3f75c07-beb5-4ee9-b792-ef89c457c8db')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f3f75c07-beb5-4ee9-b792-ef89c457c8db button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_imputed",
              "summary": "{\n  \"name\": \"data_imputed\",\n  \"rows\": 3276,\n  \"fields\": [\n    {\n      \"column\": \"ph\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4715740629117464,\n        \"min\": 0.0,\n        \"max\": 13.999999999999998,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          7.042483377815478,\n          6.643158712135614,\n          7.846057926337261\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hardness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32.879761476294185,\n        \"min\": 47.432,\n        \"max\": 323.124,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          183.5211070261417,\n          188.9135411469536,\n          224.05887682392927\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8768.570827785932,\n        \"min\": 320.942611274359,\n        \"max\": 61227.19600771213,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          20461.252710219946,\n          32873.820021715685,\n          23264.10996772913\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chloramines\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.58308488903971,\n        \"min\": 0.3520000000000003,\n        \"max\": 13.127000000000002,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          7.333212177578906,\n          6.791509363412849,\n          5.92236704115349\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sulfate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36.38783888533828,\n        \"min\": 129.00000000000003,\n        \"max\": 481.0306423059972,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          333.1194758732444,\n          333.8488418801131,\n          300.40262012672275\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conductivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80.82406405111182,\n        \"min\": 181.483753985146,\n        \"max\": 753.3426195583046,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          356.3690224100897,\n          336.56150104700754,\n          387.971335796834\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Organic_carbon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.308161999126868,\n        \"min\": 2.1999999999999886,\n        \"max\": 28.30000000000001,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          20.179028868493845,\n          14.706810313722087,\n          13.40673745495127\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Trihalomethanes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.769921510590814,\n        \"min\": 0.7379999999999995,\n        \"max\": 124.0,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          67.01990322225635,\n          67.84484886059036,\n          43.07518646611747\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Turbidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7803824084854116,\n        \"min\": 1.45,\n        \"max\": 6.739,\n        \"num_unique_values\": 3276,\n        \"samples\": [\n          4.886633785371213,\n          4.562197671215202,\n          2.487968647002356\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Potability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# confirm imputed data\n",
        "data_imputed.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58zqnGV23ZSx",
        "outputId": "6ef82a8b-c5b9-4869-fdf9-dbf808bbdbac"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3276 entries, 0 to 3275\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   ph               3276 non-null   float64\n",
            " 1   Hardness         3276 non-null   float64\n",
            " 2   Solids           3276 non-null   float64\n",
            " 3   Chloramines      3276 non-null   float64\n",
            " 4   Sulfate          3276 non-null   float64\n",
            " 5   Conductivity     3276 non-null   float64\n",
            " 6   Organic_carbon   3276 non-null   float64\n",
            " 7   Trihalomethanes  3276 non-null   float64\n",
            " 8   Turbidity        3276 non-null   float64\n",
            " 9   Potability       3276 non-null   int64  \n",
            "dtypes: float64(9), int64(1)\n",
            "memory usage: 256.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove outliers that may affect the neural network's accuracy using IQR method\n",
        "def remove_outliers_iqr(df, column_name):\n",
        "    Q1 = df[column_name].quantile(0.25)\n",
        "    Q3 = df[column_name].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    # anything above or below this is an outlier\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # place outliers in a data frame\n",
        "    print(f\"{df[column_name]}\")\n",
        "    outliers = df[(df[column_name] < lower_bound) | (df[column_name] > upper_bound)]\n",
        "    print(f\"Number of outliers: {len(outliers)}\")\n",
        "    print(f\"Percentage of outliers: {len(outliers)/len(df)*100:.2f}%\")\n",
        "\n",
        "\n",
        "    # remove outliers\n",
        "\n",
        "    df_clean = df[(df[column_name] >= lower_bound) & (df[column_name] <= upper_bound)]\n",
        "\n",
        "\n",
        "\n",
        "    return df_clean\n",
        "\n",
        "# columns to remove outliers in\n",
        "columns = ['Hardness', 'Solids', 'Sulfate', 'Conductivity', 'Organic_carbon', 'Trihalomethanes', 'Turbidity']\n",
        "\n",
        "data_imputed_copy = data_imputed.copy()\n",
        "\n",
        "for i in columns:\n",
        "  data_imputed_copy = remove_outliers_iqr(data_imputed_copy, i)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIdMxexk47Qa",
        "outputId": "325c0412-0c1a-458b-b54c-deb784a20ef8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       204.890455\n",
            "1       129.422921\n",
            "2       224.236259\n",
            "3       214.373394\n",
            "4       181.101509\n",
            "           ...    \n",
            "3271    193.681735\n",
            "3272    193.553212\n",
            "3273    175.762646\n",
            "3274    230.603758\n",
            "3275    195.102299\n",
            "Name: Hardness, Length: 3276, dtype: float64\n",
            "Number of outliers: 83\n",
            "Percentage of outliers: 2.53%\n",
            "0       20791.318981\n",
            "1       18630.057858\n",
            "2       19909.541732\n",
            "3       22018.417441\n",
            "4       17978.986339\n",
            "            ...     \n",
            "3271    47580.991603\n",
            "3272    17329.802160\n",
            "3273    33155.578218\n",
            "3274    11983.869376\n",
            "3275    17404.177061\n",
            "Name: Solids, Length: 3193, dtype: float64\n",
            "Number of outliers: 42\n",
            "Percentage of outliers: 1.32%\n",
            "0       368.516441\n",
            "1       344.836463\n",
            "2       331.981769\n",
            "3       356.886136\n",
            "4       310.135738\n",
            "           ...    \n",
            "3270    345.700257\n",
            "3272    338.612062\n",
            "3273    326.848982\n",
            "3274    336.993878\n",
            "3275    338.025733\n",
            "Name: Sulfate, Length: 3151, dtype: float64\n",
            "Number of outliers: 230\n",
            "Percentage of outliers: 7.30%\n",
            "0       564.308654\n",
            "1       592.885359\n",
            "2       418.606213\n",
            "3       363.266516\n",
            "4       398.410813\n",
            "           ...    \n",
            "3270    415.886955\n",
            "3272    392.449580\n",
            "3273    432.044783\n",
            "3274    402.883113\n",
            "3275    327.459760\n",
            "Name: Conductivity, Length: 2921, dtype: float64\n",
            "Number of outliers: 9\n",
            "Percentage of outliers: 0.31%\n",
            "0       10.379783\n",
            "1       15.180013\n",
            "2       16.868637\n",
            "3       18.436524\n",
            "4       11.558279\n",
            "          ...    \n",
            "3270    12.067620\n",
            "3272    19.903225\n",
            "3273    11.039070\n",
            "3274    11.168946\n",
            "3275    16.140368\n",
            "Name: Organic_carbon, Length: 2912, dtype: float64\n",
            "Number of outliers: 18\n",
            "Percentage of outliers: 0.62%\n",
            "0        86.990970\n",
            "1        56.329076\n",
            "2        66.420093\n",
            "3       100.341674\n",
            "4        31.997993\n",
            "           ...    \n",
            "3270     60.419921\n",
            "3272     66.474992\n",
            "3273     69.845400\n",
            "3274     77.488213\n",
            "3275     78.698446\n",
            "Name: Trihalomethanes, Length: 2894, dtype: float64\n",
            "Number of outliers: 47\n",
            "Percentage of outliers: 1.62%\n",
            "0       2.963135\n",
            "1       4.500656\n",
            "2       3.055934\n",
            "3       4.628771\n",
            "4       4.075075\n",
            "          ...   \n",
            "3270    3.669712\n",
            "3272    2.798243\n",
            "3273    3.298875\n",
            "3274    4.708658\n",
            "3275    2.309149\n",
            "Name: Turbidity, Length: 2847, dtype: float64\n",
            "Number of outliers: 17\n",
            "Percentage of outliers: 0.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the Data Appropriately"
      ],
      "metadata": {
        "id": "2QfR0r8cGVU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# generate 2d classification dataset\n",
        "\n",
        "# X, y = pass\n",
        "\n",
        "# Transforms data to have mean=0 and standard deviation=1\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X = data_imputed_copy.drop(columns='Potability', axis=1)\n",
        "y= data_imputed_copy['Potability']\n",
        "\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# from sklearn.decomposition import PCA\n",
        "# pca = PCA(n_components=2)\n",
        "# X_2d_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "X_scaled.shape\n"
      ],
      "metadata": {
        "id": "PF9lHguSY2vB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db037c08-388d-41a9-9125-28123f4887c1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2830, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the data into training validation and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3,random_state=42,\n",
        "    stratify=y               # Keep same class distribution in all splits\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5,stratify=y_temp)\n",
        "\n",
        "print(f\"\\n=== FINAL SHAPES ===\")\n",
        "print(f\"X_train: {X_train.shape}\")\n",
        "print(f\"X_val: {X_val.shape}\")\n",
        "print(f\"X_test: {X_test.shape}\")\n",
        "print(f\"y_train: {y_train.shape}\")\n",
        "print(f\"y_val: {y_val.shape}\")\n",
        "print(f\"y_test: {y_test.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "wfSk1lXRYjrh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eba4f86-6646-4838-cd63-53cc5136c7d9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== FINAL SHAPES ===\n",
            "X_train: (1981, 9)\n",
            "X_val: (424, 9)\n",
            "X_test: (425, 9)\n",
            "y_train: (1981,)\n",
            "y_val: (424,)\n",
            "y_test: (425,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Each Member Defines their model Here"
      ],
      "metadata": {
        "id": "LvjIHLrcGhzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Definition by member 1\n",
        "def model_jeremiah_agbaje():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(128, input_shape=(X_train.shape[1],), name='dense_layer', activation=\"relu\",kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))  # 50% dropout after first layer\n",
        "  model.add(tf.keras.layers.Dense(64, name='dense_layer2', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))  # 50% dropout after second layer\n",
        "  model.add(tf.keras.layers.Dense(32, name='dense_layer3', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.00001)))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))\n",
        "  model.add(tf.keras.layers.Dense(1, name='output_layer', activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.00001)))\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "model = model_jeremiah_agbaje()\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "      monitor='val_loss',    # Monitor validation loss\n",
        "      patience=50,\n",
        "      restore_best_weights=True  # Restore weights from best epoch\n",
        "  )\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "  X_train, y_train,\n",
        "  validation_data=(X_val, y_val),\n",
        "  epochs=200,\n",
        "  batch_size=32,\n",
        "  verbose=1,\n",
        "  callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "FLwYoJG9jvDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15f79834-78d0-4f2b-f9d7-3be95db8630c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.6051 - loss: 0.7033 - val_accuracy: 0.6297 - val_loss: 0.6785\n",
            "Epoch 2/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5904 - loss: 0.6934 - val_accuracy: 0.6274 - val_loss: 0.6789\n",
            "Epoch 3/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6182 - loss: 0.6820 - val_accuracy: 0.6250 - val_loss: 0.6792\n",
            "Epoch 4/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5860 - loss: 0.6983 - val_accuracy: 0.6250 - val_loss: 0.6793\n",
            "Epoch 5/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6106 - loss: 0.6757 - val_accuracy: 0.6274 - val_loss: 0.6785\n",
            "Epoch 6/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6026 - loss: 0.6912 - val_accuracy: 0.6321 - val_loss: 0.6781\n",
            "Epoch 7/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6142 - loss: 0.6806 - val_accuracy: 0.6321 - val_loss: 0.6783\n",
            "Epoch 8/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5997 - loss: 0.6865 - val_accuracy: 0.6344 - val_loss: 0.6778\n",
            "Epoch 9/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5935 - loss: 0.6860 - val_accuracy: 0.6368 - val_loss: 0.6776\n",
            "Epoch 10/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6068 - loss: 0.6848 - val_accuracy: 0.6392 - val_loss: 0.6771\n",
            "Epoch 11/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5973 - loss: 0.6821 - val_accuracy: 0.6368 - val_loss: 0.6769\n",
            "Epoch 12/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5959 - loss: 0.6784 - val_accuracy: 0.6344 - val_loss: 0.6762\n",
            "Epoch 13/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6147 - loss: 0.6768 - val_accuracy: 0.6344 - val_loss: 0.6763\n",
            "Epoch 14/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5922 - loss: 0.6900 - val_accuracy: 0.6344 - val_loss: 0.6762\n",
            "Epoch 15/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6224 - loss: 0.6805 - val_accuracy: 0.6344 - val_loss: 0.6760\n",
            "Epoch 16/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6198 - loss: 0.6766 - val_accuracy: 0.6344 - val_loss: 0.6758\n",
            "Epoch 17/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6203 - loss: 0.6723 - val_accuracy: 0.6344 - val_loss: 0.6754\n",
            "Epoch 18/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6210 - loss: 0.6725 - val_accuracy: 0.6344 - val_loss: 0.6748\n",
            "Epoch 19/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6228 - loss: 0.6699 - val_accuracy: 0.6368 - val_loss: 0.6745\n",
            "Epoch 20/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6215 - loss: 0.6788 - val_accuracy: 0.6368 - val_loss: 0.6739\n",
            "Epoch 21/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6091 - loss: 0.6876 - val_accuracy: 0.6368 - val_loss: 0.6736\n",
            "Epoch 22/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6067 - loss: 0.6783 - val_accuracy: 0.6368 - val_loss: 0.6732\n",
            "Epoch 23/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6149 - loss: 0.6729 - val_accuracy: 0.6321 - val_loss: 0.6729\n",
            "Epoch 24/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6345 - loss: 0.6602 - val_accuracy: 0.6321 - val_loss: 0.6725\n",
            "Epoch 25/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6093 - loss: 0.6762 - val_accuracy: 0.6321 - val_loss: 0.6723\n",
            "Epoch 26/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6170 - loss: 0.6702 - val_accuracy: 0.6321 - val_loss: 0.6720\n",
            "Epoch 27/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6268 - loss: 0.6741 - val_accuracy: 0.6321 - val_loss: 0.6718\n",
            "Epoch 28/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6052 - loss: 0.6780 - val_accuracy: 0.6297 - val_loss: 0.6710\n",
            "Epoch 29/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6100 - loss: 0.6817 - val_accuracy: 0.6297 - val_loss: 0.6707\n",
            "Epoch 30/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6110 - loss: 0.6821 - val_accuracy: 0.6297 - val_loss: 0.6705\n",
            "Epoch 31/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6197 - loss: 0.6811 - val_accuracy: 0.6297 - val_loss: 0.6705\n",
            "Epoch 32/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6246 - loss: 0.6664 - val_accuracy: 0.6297 - val_loss: 0.6704\n",
            "Epoch 33/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6225 - loss: 0.6694 - val_accuracy: 0.6297 - val_loss: 0.6704\n",
            "Epoch 34/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6321 - loss: 0.6670 - val_accuracy: 0.6297 - val_loss: 0.6698\n",
            "Epoch 35/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6157 - loss: 0.6737 - val_accuracy: 0.6297 - val_loss: 0.6692\n",
            "Epoch 36/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6508 - loss: 0.6541 - val_accuracy: 0.6297 - val_loss: 0.6688\n",
            "Epoch 37/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6119 - loss: 0.6731 - val_accuracy: 0.6297 - val_loss: 0.6687\n",
            "Epoch 38/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6434 - loss: 0.6602 - val_accuracy: 0.6297 - val_loss: 0.6680\n",
            "Epoch 39/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6184 - loss: 0.6704 - val_accuracy: 0.6297 - val_loss: 0.6679\n",
            "Epoch 40/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6300 - loss: 0.6628 - val_accuracy: 0.6297 - val_loss: 0.6672\n",
            "Epoch 41/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6155 - loss: 0.6764 - val_accuracy: 0.6297 - val_loss: 0.6668\n",
            "Epoch 42/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6265 - loss: 0.6677 - val_accuracy: 0.6297 - val_loss: 0.6668\n",
            "Epoch 43/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6454 - loss: 0.6633 - val_accuracy: 0.6297 - val_loss: 0.6667\n",
            "Epoch 44/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6321 - loss: 0.6604 - val_accuracy: 0.6297 - val_loss: 0.6662\n",
            "Epoch 45/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6207 - loss: 0.6660 - val_accuracy: 0.6297 - val_loss: 0.6660\n",
            "Epoch 46/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6084 - loss: 0.6674 - val_accuracy: 0.6297 - val_loss: 0.6656\n",
            "Epoch 47/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6296 - loss: 0.6541 - val_accuracy: 0.6297 - val_loss: 0.6651\n",
            "Epoch 48/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6519 - loss: 0.6566 - val_accuracy: 0.6297 - val_loss: 0.6646\n",
            "Epoch 49/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6413 - loss: 0.6637 - val_accuracy: 0.6297 - val_loss: 0.6640\n",
            "Epoch 50/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6234 - loss: 0.6735 - val_accuracy: 0.6297 - val_loss: 0.6638\n",
            "Epoch 51/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6448 - loss: 0.6492 - val_accuracy: 0.6297 - val_loss: 0.6631\n",
            "Epoch 52/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6303 - loss: 0.6659 - val_accuracy: 0.6297 - val_loss: 0.6630\n",
            "Epoch 53/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6247 - loss: 0.6548 - val_accuracy: 0.6297 - val_loss: 0.6623\n",
            "Epoch 54/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6144 - loss: 0.6672 - val_accuracy: 0.6297 - val_loss: 0.6622\n",
            "Epoch 55/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6339 - loss: 0.6600 - val_accuracy: 0.6297 - val_loss: 0.6620\n",
            "Epoch 56/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6336 - loss: 0.6655 - val_accuracy: 0.6297 - val_loss: 0.6620\n",
            "Epoch 57/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6299 - loss: 0.6561 - val_accuracy: 0.6297 - val_loss: 0.6616\n",
            "Epoch 58/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6268 - loss: 0.6574 - val_accuracy: 0.6297 - val_loss: 0.6611\n",
            "Epoch 59/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6241 - loss: 0.6702 - val_accuracy: 0.6297 - val_loss: 0.6608\n",
            "Epoch 60/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6403 - loss: 0.6511 - val_accuracy: 0.6297 - val_loss: 0.6603\n",
            "Epoch 61/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6165 - loss: 0.6731 - val_accuracy: 0.6297 - val_loss: 0.6599\n",
            "Epoch 62/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6322 - loss: 0.6547 - val_accuracy: 0.6297 - val_loss: 0.6596\n",
            "Epoch 63/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6311 - loss: 0.6599 - val_accuracy: 0.6297 - val_loss: 0.6594\n",
            "Epoch 64/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6301 - loss: 0.6616 - val_accuracy: 0.6297 - val_loss: 0.6593\n",
            "Epoch 65/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6244 - loss: 0.6593 - val_accuracy: 0.6297 - val_loss: 0.6592\n",
            "Epoch 66/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6117 - loss: 0.6691 - val_accuracy: 0.6297 - val_loss: 0.6592\n",
            "Epoch 67/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6238 - loss: 0.6574 - val_accuracy: 0.6297 - val_loss: 0.6586\n",
            "Epoch 68/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6383 - loss: 0.6554 - val_accuracy: 0.6297 - val_loss: 0.6581\n",
            "Epoch 69/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6420 - loss: 0.6582 - val_accuracy: 0.6297 - val_loss: 0.6581\n",
            "Epoch 70/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6265 - loss: 0.6637 - val_accuracy: 0.6297 - val_loss: 0.6576\n",
            "Epoch 71/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6391 - loss: 0.6559 - val_accuracy: 0.6297 - val_loss: 0.6576\n",
            "Epoch 72/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6293 - loss: 0.6517 - val_accuracy: 0.6297 - val_loss: 0.6572\n",
            "Epoch 73/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6127 - loss: 0.6670 - val_accuracy: 0.6297 - val_loss: 0.6570\n",
            "Epoch 74/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6224 - loss: 0.6621 - val_accuracy: 0.6297 - val_loss: 0.6567\n",
            "Epoch 75/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6096 - loss: 0.6665 - val_accuracy: 0.6297 - val_loss: 0.6564\n",
            "Epoch 76/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6272 - loss: 0.6600 - val_accuracy: 0.6297 - val_loss: 0.6562\n",
            "Epoch 77/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6368 - loss: 0.6563 - val_accuracy: 0.6297 - val_loss: 0.6562\n",
            "Epoch 78/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6410 - loss: 0.6456 - val_accuracy: 0.6297 - val_loss: 0.6558\n",
            "Epoch 79/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6188 - loss: 0.6600 - val_accuracy: 0.6297 - val_loss: 0.6552\n",
            "Epoch 80/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6230 - loss: 0.6555 - val_accuracy: 0.6297 - val_loss: 0.6548\n",
            "Epoch 81/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6287 - loss: 0.6449 - val_accuracy: 0.6297 - val_loss: 0.6540\n",
            "Epoch 82/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6275 - loss: 0.6545 - val_accuracy: 0.6321 - val_loss: 0.6539\n",
            "Epoch 83/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6255 - loss: 0.6521 - val_accuracy: 0.6321 - val_loss: 0.6537\n",
            "Epoch 84/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6392 - loss: 0.6489 - val_accuracy: 0.6321 - val_loss: 0.6535\n",
            "Epoch 85/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6312 - loss: 0.6504 - val_accuracy: 0.6321 - val_loss: 0.6531\n",
            "Epoch 86/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6569 - loss: 0.6418 - val_accuracy: 0.6321 - val_loss: 0.6526\n",
            "Epoch 87/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6422 - loss: 0.6377 - val_accuracy: 0.6321 - val_loss: 0.6520\n",
            "Epoch 88/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6269 - loss: 0.6490 - val_accuracy: 0.6321 - val_loss: 0.6521\n",
            "Epoch 89/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6255 - loss: 0.6538 - val_accuracy: 0.6321 - val_loss: 0.6518\n",
            "Epoch 90/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6261 - loss: 0.6481 - val_accuracy: 0.6321 - val_loss: 0.6515\n",
            "Epoch 91/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6248 - loss: 0.6515 - val_accuracy: 0.6321 - val_loss: 0.6514\n",
            "Epoch 92/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6255 - loss: 0.6575 - val_accuracy: 0.6321 - val_loss: 0.6511\n",
            "Epoch 93/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6387 - loss: 0.6543 - val_accuracy: 0.6321 - val_loss: 0.6511\n",
            "Epoch 94/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6458 - loss: 0.6481 - val_accuracy: 0.6321 - val_loss: 0.6510\n",
            "Epoch 95/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6437 - loss: 0.6430 - val_accuracy: 0.6321 - val_loss: 0.6505\n",
            "Epoch 96/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6141 - loss: 0.6559 - val_accuracy: 0.6321 - val_loss: 0.6503\n",
            "Epoch 97/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6374 - loss: 0.6524 - val_accuracy: 0.6321 - val_loss: 0.6501\n",
            "Epoch 98/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6442 - loss: 0.6435 - val_accuracy: 0.6321 - val_loss: 0.6500\n",
            "Epoch 99/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6288 - loss: 0.6534 - val_accuracy: 0.6321 - val_loss: 0.6496\n",
            "Epoch 100/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6457 - loss: 0.6431 - val_accuracy: 0.6321 - val_loss: 0.6493\n",
            "Epoch 101/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6268 - loss: 0.6483 - val_accuracy: 0.6321 - val_loss: 0.6489\n",
            "Epoch 102/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6439 - loss: 0.6526 - val_accuracy: 0.6321 - val_loss: 0.6486\n",
            "Epoch 103/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6497 - loss: 0.6451 - val_accuracy: 0.6321 - val_loss: 0.6484\n",
            "Epoch 104/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6532 - loss: 0.6260 - val_accuracy: 0.6321 - val_loss: 0.6478\n",
            "Epoch 105/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6392 - loss: 0.6441 - val_accuracy: 0.6321 - val_loss: 0.6475\n",
            "Epoch 106/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6347 - loss: 0.6520 - val_accuracy: 0.6321 - val_loss: 0.6475\n",
            "Epoch 107/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6408 - loss: 0.6428 - val_accuracy: 0.6321 - val_loss: 0.6472\n",
            "Epoch 108/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6091 - loss: 0.6660 - val_accuracy: 0.6321 - val_loss: 0.6473\n",
            "Epoch 109/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6338 - loss: 0.6426 - val_accuracy: 0.6344 - val_loss: 0.6471\n",
            "Epoch 110/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6364 - loss: 0.6443 - val_accuracy: 0.6321 - val_loss: 0.6468\n",
            "Epoch 111/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6498 - loss: 0.6342 - val_accuracy: 0.6321 - val_loss: 0.6462\n",
            "Epoch 112/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6274 - loss: 0.6372 - val_accuracy: 0.6344 - val_loss: 0.6455\n",
            "Epoch 113/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6305 - loss: 0.6425 - val_accuracy: 0.6344 - val_loss: 0.6450\n",
            "Epoch 114/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6350 - loss: 0.6489 - val_accuracy: 0.6344 - val_loss: 0.6447\n",
            "Epoch 115/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6507 - loss: 0.6314 - val_accuracy: 0.6344 - val_loss: 0.6443\n",
            "Epoch 116/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6296 - loss: 0.6425 - val_accuracy: 0.6344 - val_loss: 0.6439\n",
            "Epoch 117/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6340 - loss: 0.6466 - val_accuracy: 0.6344 - val_loss: 0.6437\n",
            "Epoch 118/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6400 - loss: 0.6490 - val_accuracy: 0.6344 - val_loss: 0.6435\n",
            "Epoch 119/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6301 - loss: 0.6500 - val_accuracy: 0.6368 - val_loss: 0.6432\n",
            "Epoch 120/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6340 - loss: 0.6546 - val_accuracy: 0.6392 - val_loss: 0.6432\n",
            "Epoch 121/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6487 - loss: 0.6348 - val_accuracy: 0.6392 - val_loss: 0.6425\n",
            "Epoch 122/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6379 - loss: 0.6405 - val_accuracy: 0.6392 - val_loss: 0.6425\n",
            "Epoch 123/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6339 - loss: 0.6483 - val_accuracy: 0.6392 - val_loss: 0.6424\n",
            "Epoch 124/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6440 - loss: 0.6426 - val_accuracy: 0.6392 - val_loss: 0.6423\n",
            "Epoch 125/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6556 - loss: 0.6387 - val_accuracy: 0.6392 - val_loss: 0.6418\n",
            "Epoch 126/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6318 - loss: 0.6368 - val_accuracy: 0.6392 - val_loss: 0.6411\n",
            "Epoch 127/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6494 - loss: 0.6389 - val_accuracy: 0.6415 - val_loss: 0.6409\n",
            "Epoch 128/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6322 - loss: 0.6456 - val_accuracy: 0.6439 - val_loss: 0.6410\n",
            "Epoch 129/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6533 - loss: 0.6316 - val_accuracy: 0.6439 - val_loss: 0.6405\n",
            "Epoch 130/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6410 - loss: 0.6375 - val_accuracy: 0.6439 - val_loss: 0.6405\n",
            "Epoch 131/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6377 - loss: 0.6377 - val_accuracy: 0.6486 - val_loss: 0.6407\n",
            "Epoch 132/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6609 - loss: 0.6234 - val_accuracy: 0.6486 - val_loss: 0.6404\n",
            "Epoch 133/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6425 - loss: 0.6401 - val_accuracy: 0.6486 - val_loss: 0.6403\n",
            "Epoch 134/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6469 - loss: 0.6372 - val_accuracy: 0.6486 - val_loss: 0.6398\n",
            "Epoch 135/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6360 - loss: 0.6432 - val_accuracy: 0.6509 - val_loss: 0.6399\n",
            "Epoch 136/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6383 - loss: 0.6399 - val_accuracy: 0.6486 - val_loss: 0.6397\n",
            "Epoch 137/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6552 - loss: 0.6380 - val_accuracy: 0.6486 - val_loss: 0.6395\n",
            "Epoch 138/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6349 - loss: 0.6414 - val_accuracy: 0.6509 - val_loss: 0.6394\n",
            "Epoch 139/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6381 - loss: 0.6431 - val_accuracy: 0.6486 - val_loss: 0.6393\n",
            "Epoch 140/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6385 - loss: 0.6446 - val_accuracy: 0.6486 - val_loss: 0.6390\n",
            "Epoch 141/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6490 - loss: 0.6215 - val_accuracy: 0.6486 - val_loss: 0.6383\n",
            "Epoch 142/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6523 - loss: 0.6313 - val_accuracy: 0.6462 - val_loss: 0.6381\n",
            "Epoch 143/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6418 - loss: 0.6297 - val_accuracy: 0.6462 - val_loss: 0.6379\n",
            "Epoch 144/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6505 - loss: 0.6269 - val_accuracy: 0.6462 - val_loss: 0.6379\n",
            "Epoch 145/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6491 - loss: 0.6351 - val_accuracy: 0.6462 - val_loss: 0.6381\n",
            "Epoch 146/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6436 - loss: 0.6338 - val_accuracy: 0.6462 - val_loss: 0.6383\n",
            "Epoch 147/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6238 - loss: 0.6433 - val_accuracy: 0.6462 - val_loss: 0.6381\n",
            "Epoch 148/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6205 - loss: 0.6325 - val_accuracy: 0.6486 - val_loss: 0.6376\n",
            "Epoch 149/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6544 - loss: 0.6307 - val_accuracy: 0.6486 - val_loss: 0.6378\n",
            "Epoch 150/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6387 - loss: 0.6332 - val_accuracy: 0.6486 - val_loss: 0.6378\n",
            "Epoch 151/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6290 - loss: 0.6367 - val_accuracy: 0.6486 - val_loss: 0.6379\n",
            "Epoch 152/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6384 - loss: 0.6333 - val_accuracy: 0.6486 - val_loss: 0.6376\n",
            "Epoch 153/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6483 - loss: 0.6341 - val_accuracy: 0.6486 - val_loss: 0.6377\n",
            "Epoch 154/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6310 - loss: 0.6391 - val_accuracy: 0.6486 - val_loss: 0.6376\n",
            "Epoch 155/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6488 - loss: 0.6328 - val_accuracy: 0.6486 - val_loss: 0.6374\n",
            "Epoch 156/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6666 - loss: 0.6272 - val_accuracy: 0.6462 - val_loss: 0.6374\n",
            "Epoch 157/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6612 - loss: 0.6246 - val_accuracy: 0.6462 - val_loss: 0.6375\n",
            "Epoch 158/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6295 - loss: 0.6387 - val_accuracy: 0.6486 - val_loss: 0.6373\n",
            "Epoch 159/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6531 - loss: 0.6357 - val_accuracy: 0.6462 - val_loss: 0.6372\n",
            "Epoch 160/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.6408 - loss: 0.6305 - val_accuracy: 0.6462 - val_loss: 0.6366\n",
            "Epoch 161/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6411 - loss: 0.6370 - val_accuracy: 0.6462 - val_loss: 0.6362\n",
            "Epoch 162/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6619 - loss: 0.6208 - val_accuracy: 0.6439 - val_loss: 0.6358\n",
            "Epoch 163/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6102 - loss: 0.6415 - val_accuracy: 0.6486 - val_loss: 0.6355\n",
            "Epoch 164/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6436 - loss: 0.6227 - val_accuracy: 0.6486 - val_loss: 0.6353\n",
            "Epoch 165/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6473 - loss: 0.6297 - val_accuracy: 0.6533 - val_loss: 0.6355\n",
            "Epoch 166/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6579 - loss: 0.6268 - val_accuracy: 0.6533 - val_loss: 0.6354\n",
            "Epoch 167/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6472 - loss: 0.6316 - val_accuracy: 0.6557 - val_loss: 0.6354\n",
            "Epoch 168/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6678 - loss: 0.6175 - val_accuracy: 0.6509 - val_loss: 0.6351\n",
            "Epoch 169/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6436 - loss: 0.6382 - val_accuracy: 0.6509 - val_loss: 0.6349\n",
            "Epoch 170/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6487 - loss: 0.6283 - val_accuracy: 0.6557 - val_loss: 0.6344\n",
            "Epoch 171/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6525 - loss: 0.6350 - val_accuracy: 0.6557 - val_loss: 0.6347\n",
            "Epoch 172/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6513 - loss: 0.6293 - val_accuracy: 0.6533 - val_loss: 0.6352\n",
            "Epoch 173/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6556 - loss: 0.6240 - val_accuracy: 0.6533 - val_loss: 0.6351\n",
            "Epoch 174/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6642 - loss: 0.6265 - val_accuracy: 0.6509 - val_loss: 0.6349\n",
            "Epoch 175/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6691 - loss: 0.6194 - val_accuracy: 0.6533 - val_loss: 0.6344\n",
            "Epoch 176/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6397 - loss: 0.6343 - val_accuracy: 0.6533 - val_loss: 0.6345\n",
            "Epoch 177/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6321 - loss: 0.6408 - val_accuracy: 0.6533 - val_loss: 0.6344\n",
            "Epoch 178/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6273 - loss: 0.6409 - val_accuracy: 0.6557 - val_loss: 0.6341\n",
            "Epoch 179/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6300 - loss: 0.6395 - val_accuracy: 0.6580 - val_loss: 0.6336\n",
            "Epoch 180/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6450 - loss: 0.6341 - val_accuracy: 0.6557 - val_loss: 0.6332\n",
            "Epoch 181/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6394 - loss: 0.6477 - val_accuracy: 0.6533 - val_loss: 0.6334\n",
            "Epoch 182/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6306 - loss: 0.6286 - val_accuracy: 0.6509 - val_loss: 0.6331\n",
            "Epoch 183/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6541 - loss: 0.6200 - val_accuracy: 0.6533 - val_loss: 0.6331\n",
            "Epoch 184/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6680 - loss: 0.6148 - val_accuracy: 0.6509 - val_loss: 0.6326\n",
            "Epoch 185/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6124 - loss: 0.6423 - val_accuracy: 0.6557 - val_loss: 0.6326\n",
            "Epoch 186/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6478 - loss: 0.6323 - val_accuracy: 0.6557 - val_loss: 0.6321\n",
            "Epoch 187/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6315 - loss: 0.6416 - val_accuracy: 0.6580 - val_loss: 0.6317\n",
            "Epoch 188/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6439 - loss: 0.6418 - val_accuracy: 0.6604 - val_loss: 0.6323\n",
            "Epoch 189/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6436 - loss: 0.6255 - val_accuracy: 0.6604 - val_loss: 0.6325\n",
            "Epoch 190/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6394 - loss: 0.6362 - val_accuracy: 0.6604 - val_loss: 0.6323\n",
            "Epoch 191/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6562 - loss: 0.6273 - val_accuracy: 0.6604 - val_loss: 0.6322\n",
            "Epoch 192/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6536 - loss: 0.6251 - val_accuracy: 0.6604 - val_loss: 0.6320\n",
            "Epoch 193/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6482 - loss: 0.6243 - val_accuracy: 0.6604 - val_loss: 0.6319\n",
            "Epoch 194/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6535 - loss: 0.6139 - val_accuracy: 0.6604 - val_loss: 0.6316\n",
            "Epoch 195/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6530 - loss: 0.6282 - val_accuracy: 0.6604 - val_loss: 0.6312\n",
            "Epoch 196/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6420 - loss: 0.6290 - val_accuracy: 0.6651 - val_loss: 0.6315\n",
            "Epoch 197/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6601 - loss: 0.6275 - val_accuracy: 0.6627 - val_loss: 0.6316\n",
            "Epoch 198/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6494 - loss: 0.6224 - val_accuracy: 0.6627 - val_loss: 0.6312\n",
            "Epoch 199/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6510 - loss: 0.6308 - val_accuracy: 0.6580 - val_loss: 0.6312\n",
            "Epoch 200/200\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6436 - loss: 0.6183 - val_accuracy: 0.6580 - val_loss: 0.6312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_epoch = np.argmin(history.history['val_loss'])\n",
        "print(f\"Best Epoch: {best_epoch+1}\")\n",
        "print(f\"Train Accuracy at Best Epoch: {history.history['accuracy'][best_epoch]:.4f}\")\n",
        "print(f\"Val Accuracy at Best Epoch: {history.history['val_accuracy'][best_epoch]:.4f}\")"
      ],
      "metadata": {
        "id": "1z30otXZnPVI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38e73999-b34d-4fa4-e8b2-7c4cd11b536a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Epoch: 199\n",
            "Train Accuracy at Best Epoch: 0.6446\n",
            "Val Accuracy at Best Epoch: 0.6580\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}, Test Loss: {test_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8-xUOoyJk5_",
        "outputId": "27ce6803-c482-46cf-b311-ab8d26afb1e5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6282 - loss: 0.6210 \n",
            "Test Accuracy: 0.6518, Test Loss: 0.6178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_gaius_irakiza():\n",
        "    model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Nadam(learning_rate=0.0001)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            tf.keras.metrics.Precision(name='precision'),\n",
        "            tf.keras.metrics.Recall(name='recall'),\n",
        "            tf.keras.metrics.AUC(name='auc')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "gaius_model = model_gaius_irakiza()\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=30,\n",
        "    min_delta=0.0001,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "history = gaius_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=300,\n",
        "    batch_size=32,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "hmWIUNw0-l0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52da76b3-4075-4493-b025-ae0b8f7dcfec"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.4561 - auc: 0.5133 - loss: 0.8778 - precision: 0.3954 - recall: 0.7865 - val_accuracy: 0.4976 - val_auc: 0.5073 - val_loss: 0.6988 - val_precision: 0.3871 - val_recall: 0.6115\n",
            "Epoch 2/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4577 - auc: 0.5034 - loss: 0.8252 - precision: 0.3744 - recall: 0.6699 - val_accuracy: 0.6014 - val_auc: 0.5259 - val_loss: 0.6785 - val_precision: 0.4167 - val_recall: 0.1911\n",
            "Epoch 3/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4904 - auc: 0.4900 - loss: 0.7758 - precision: 0.3532 - recall: 0.5470 - val_accuracy: 0.6156 - val_auc: 0.5420 - val_loss: 0.6657 - val_precision: 0.4167 - val_recall: 0.0955\n",
            "Epoch 4/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5105 - auc: 0.5098 - loss: 0.7356 - precision: 0.3738 - recall: 0.4511 - val_accuracy: 0.6203 - val_auc: 0.5471 - val_loss: 0.6603 - val_precision: 0.4000 - val_recall: 0.0510\n",
            "Epoch 5/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5487 - auc: 0.5062 - loss: 0.7187 - precision: 0.3810 - recall: 0.3673 - val_accuracy: 0.6250 - val_auc: 0.5474 - val_loss: 0.6567 - val_precision: 0.4375 - val_recall: 0.0446\n",
            "Epoch 6/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5615 - auc: 0.5053 - loss: 0.7149 - precision: 0.4098 - recall: 0.3367 - val_accuracy: 0.6274 - val_auc: 0.5543 - val_loss: 0.6542 - val_precision: 0.4615 - val_recall: 0.0382\n",
            "Epoch 7/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6080 - auc: 0.5647 - loss: 0.6783 - precision: 0.4607 - recall: 0.3437 - val_accuracy: 0.6274 - val_auc: 0.5661 - val_loss: 0.6517 - val_precision: 0.4444 - val_recall: 0.0255\n",
            "Epoch 8/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5587 - auc: 0.5193 - loss: 0.6949 - precision: 0.3680 - recall: 0.2675 - val_accuracy: 0.6344 - val_auc: 0.5670 - val_loss: 0.6509 - val_precision: 0.6667 - val_recall: 0.0255\n",
            "Epoch 9/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5626 - auc: 0.5120 - loss: 0.6951 - precision: 0.3839 - recall: 0.2586 - val_accuracy: 0.6321 - val_auc: 0.5668 - val_loss: 0.6511 - val_precision: 0.6000 - val_recall: 0.0191\n",
            "Epoch 10/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5808 - auc: 0.5061 - loss: 0.6930 - precision: 0.3664 - recall: 0.2008 - val_accuracy: 0.6297 - val_auc: 0.5787 - val_loss: 0.6497 - val_precision: 0.5000 - val_recall: 0.0127\n",
            "Epoch 11/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6017 - auc: 0.5190 - loss: 0.6850 - precision: 0.4050 - recall: 0.2064 - val_accuracy: 0.6274 - val_auc: 0.5732 - val_loss: 0.6510 - val_precision: 0.3333 - val_recall: 0.0064\n",
            "Epoch 12/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5875 - auc: 0.5223 - loss: 0.6834 - precision: 0.3676 - recall: 0.2026 - val_accuracy: 0.6274 - val_auc: 0.5789 - val_loss: 0.6504 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 13/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5947 - auc: 0.5344 - loss: 0.6733 - precision: 0.3827 - recall: 0.1954 - val_accuracy: 0.6274 - val_auc: 0.5864 - val_loss: 0.6497 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 14/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6073 - auc: 0.5444 - loss: 0.6643 - precision: 0.3860 - recall: 0.1712 - val_accuracy: 0.6274 - val_auc: 0.5947 - val_loss: 0.6481 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 15/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6132 - auc: 0.5339 - loss: 0.6701 - precision: 0.3885 - recall: 0.1736 - val_accuracy: 0.6297 - val_auc: 0.5971 - val_loss: 0.6473 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 16/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6108 - auc: 0.5479 - loss: 0.6707 - precision: 0.4429 - recall: 0.1459 - val_accuracy: 0.6297 - val_auc: 0.5969 - val_loss: 0.6476 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 17/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5890 - auc: 0.5153 - loss: 0.6862 - precision: 0.4028 - recall: 0.1444 - val_accuracy: 0.6297 - val_auc: 0.5976 - val_loss: 0.6475 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 18/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6173 - auc: 0.5597 - loss: 0.6638 - precision: 0.4686 - recall: 0.1677 - val_accuracy: 0.6297 - val_auc: 0.5935 - val_loss: 0.6481 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 19/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5922 - auc: 0.5338 - loss: 0.6786 - precision: 0.3930 - recall: 0.1459 - val_accuracy: 0.6321 - val_auc: 0.5924 - val_loss: 0.6484 - val_precision: 1.0000 - val_recall: 0.0064\n",
            "Epoch 20/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6243 - auc: 0.5670 - loss: 0.6575 - precision: 0.4839 - recall: 0.1675 - val_accuracy: 0.6321 - val_auc: 0.5877 - val_loss: 0.6484 - val_precision: 1.0000 - val_recall: 0.0064\n",
            "Epoch 21/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6072 - auc: 0.5283 - loss: 0.6668 - precision: 0.3735 - recall: 0.1539 - val_accuracy: 0.6297 - val_auc: 0.5868 - val_loss: 0.6488 - val_precision: 0.5000 - val_recall: 0.0064\n",
            "Epoch 22/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6179 - auc: 0.5638 - loss: 0.6632 - precision: 0.4691 - recall: 0.1336 - val_accuracy: 0.6321 - val_auc: 0.5854 - val_loss: 0.6489 - val_precision: 1.0000 - val_recall: 0.0064\n",
            "Epoch 23/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6073 - auc: 0.5544 - loss: 0.6633 - precision: 0.4028 - recall: 0.1595 - val_accuracy: 0.6297 - val_auc: 0.5807 - val_loss: 0.6492 - val_precision: 0.5000 - val_recall: 0.0064\n",
            "Epoch 24/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6174 - auc: 0.5696 - loss: 0.6610 - precision: 0.5060 - recall: 0.1554 - val_accuracy: 0.6297 - val_auc: 0.5787 - val_loss: 0.6495 - val_precision: 0.5000 - val_recall: 0.0064\n",
            "Epoch 25/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6264 - auc: 0.5351 - loss: 0.6595 - precision: 0.4029 - recall: 0.1133 - val_accuracy: 0.6297 - val_auc: 0.5821 - val_loss: 0.6489 - val_precision: 0.5000 - val_recall: 0.0064\n",
            "Epoch 26/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5997 - auc: 0.5389 - loss: 0.6710 - precision: 0.4247 - recall: 0.1374 - val_accuracy: 0.6297 - val_auc: 0.5866 - val_loss: 0.6482 - val_precision: 0.5000 - val_recall: 0.0064\n",
            "Epoch 27/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6273 - auc: 0.5457 - loss: 0.6690 - precision: 0.5122 - recall: 0.1545 - val_accuracy: 0.6297 - val_auc: 0.5820 - val_loss: 0.6484 - val_precision: 0.5000 - val_recall: 0.0064\n",
            "Epoch 28/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6280 - auc: 0.5729 - loss: 0.6570 - precision: 0.5099 - recall: 0.1698 - val_accuracy: 0.6321 - val_auc: 0.5856 - val_loss: 0.6472 - val_precision: 1.0000 - val_recall: 0.0064\n",
            "Epoch 29/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6294 - auc: 0.5407 - loss: 0.6599 - precision: 0.4505 - recall: 0.1181 - val_accuracy: 0.6321 - val_auc: 0.5890 - val_loss: 0.6461 - val_precision: 1.0000 - val_recall: 0.0064\n",
            "Epoch 30/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6150 - auc: 0.5671 - loss: 0.6600 - precision: 0.4610 - recall: 0.1652 - val_accuracy: 0.6321 - val_auc: 0.5863 - val_loss: 0.6461 - val_precision: 1.0000 - val_recall: 0.0064\n",
            "Epoch 31/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6083 - auc: 0.5663 - loss: 0.6650 - precision: 0.4233 - recall: 0.1161 - val_accuracy: 0.6321 - val_auc: 0.5840 - val_loss: 0.6462 - val_precision: 1.0000 - val_recall: 0.0064\n",
            "Epoch 32/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6201 - auc: 0.5756 - loss: 0.6573 - precision: 0.4492 - recall: 0.1276 - val_accuracy: 0.6344 - val_auc: 0.5906 - val_loss: 0.6452 - val_precision: 1.0000 - val_recall: 0.0127\n",
            "Epoch 33/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6238 - auc: 0.5441 - loss: 0.6655 - precision: 0.4618 - recall: 0.1181 - val_accuracy: 0.6344 - val_auc: 0.5928 - val_loss: 0.6445 - val_precision: 1.0000 - val_recall: 0.0127\n",
            "Epoch 34/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6070 - auc: 0.5700 - loss: 0.6663 - precision: 0.4541 - recall: 0.1109 - val_accuracy: 0.6368 - val_auc: 0.5908 - val_loss: 0.6448 - val_precision: 1.0000 - val_recall: 0.0191\n",
            "Epoch 35/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6202 - auc: 0.5422 - loss: 0.6614 - precision: 0.3811 - recall: 0.1097 - val_accuracy: 0.6368 - val_auc: 0.5881 - val_loss: 0.6445 - val_precision: 1.0000 - val_recall: 0.0191\n",
            "Epoch 36/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6160 - auc: 0.5594 - loss: 0.6622 - precision: 0.4517 - recall: 0.1138 - val_accuracy: 0.6368 - val_auc: 0.5883 - val_loss: 0.6441 - val_precision: 0.8000 - val_recall: 0.0255\n",
            "Epoch 37/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6296 - auc: 0.5789 - loss: 0.6518 - precision: 0.4943 - recall: 0.1481 - val_accuracy: 0.6321 - val_auc: 0.5929 - val_loss: 0.6436 - val_precision: 0.6000 - val_recall: 0.0191\n",
            "Epoch 38/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6276 - auc: 0.5538 - loss: 0.6567 - precision: 0.4620 - recall: 0.1375 - val_accuracy: 0.6321 - val_auc: 0.5934 - val_loss: 0.6432 - val_precision: 0.6000 - val_recall: 0.0191\n",
            "Epoch 39/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6148 - auc: 0.5592 - loss: 0.6625 - precision: 0.4519 - recall: 0.1351 - val_accuracy: 0.6344 - val_auc: 0.5927 - val_loss: 0.6434 - val_precision: 0.6667 - val_recall: 0.0255\n",
            "Epoch 40/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6311 - auc: 0.5741 - loss: 0.6557 - precision: 0.5100 - recall: 0.1458 - val_accuracy: 0.6368 - val_auc: 0.5979 - val_loss: 0.6420 - val_precision: 0.8000 - val_recall: 0.0255\n",
            "Epoch 41/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6297 - auc: 0.5734 - loss: 0.6529 - precision: 0.4795 - recall: 0.1252 - val_accuracy: 0.6368 - val_auc: 0.6025 - val_loss: 0.6406 - val_precision: 0.8000 - val_recall: 0.0255\n",
            "Epoch 42/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6400 - auc: 0.5879 - loss: 0.6491 - precision: 0.5594 - recall: 0.1357 - val_accuracy: 0.6368 - val_auc: 0.6047 - val_loss: 0.6403 - val_precision: 0.8000 - val_recall: 0.0255\n",
            "Epoch 43/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6413 - auc: 0.5663 - loss: 0.6528 - precision: 0.5460 - recall: 0.1341 - val_accuracy: 0.6392 - val_auc: 0.6073 - val_loss: 0.6395 - val_precision: 0.8333 - val_recall: 0.0318\n",
            "Epoch 44/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6337 - auc: 0.5787 - loss: 0.6501 - precision: 0.5209 - recall: 0.1247 - val_accuracy: 0.6368 - val_auc: 0.6099 - val_loss: 0.6391 - val_precision: 0.7143 - val_recall: 0.0318\n",
            "Epoch 45/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6133 - auc: 0.5623 - loss: 0.6612 - precision: 0.4493 - recall: 0.1208 - val_accuracy: 0.6368 - val_auc: 0.6051 - val_loss: 0.6399 - val_precision: 0.7143 - val_recall: 0.0318\n",
            "Epoch 46/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6155 - auc: 0.5903 - loss: 0.6506 - precision: 0.4225 - recall: 0.1141 - val_accuracy: 0.6344 - val_auc: 0.6058 - val_loss: 0.6396 - val_precision: 0.6667 - val_recall: 0.0255\n",
            "Epoch 47/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6478 - auc: 0.5967 - loss: 0.6371 - precision: 0.5207 - recall: 0.1323 - val_accuracy: 0.6344 - val_auc: 0.6100 - val_loss: 0.6380 - val_precision: 0.6667 - val_recall: 0.0255\n",
            "Epoch 48/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6286 - auc: 0.6017 - loss: 0.6471 - precision: 0.5534 - recall: 0.1633 - val_accuracy: 0.6392 - val_auc: 0.6126 - val_loss: 0.6372 - val_precision: 0.8333 - val_recall: 0.0318\n",
            "Epoch 49/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6447 - auc: 0.6165 - loss: 0.6337 - precision: 0.5189 - recall: 0.1369 - val_accuracy: 0.6368 - val_auc: 0.6127 - val_loss: 0.6369 - val_precision: 0.7143 - val_recall: 0.0318\n",
            "Epoch 50/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6347 - auc: 0.5717 - loss: 0.6499 - precision: 0.5011 - recall: 0.1310 - val_accuracy: 0.6368 - val_auc: 0.6165 - val_loss: 0.6367 - val_precision: 0.6667 - val_recall: 0.0382\n",
            "Epoch 51/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6146 - auc: 0.6014 - loss: 0.6494 - precision: 0.4561 - recall: 0.1243 - val_accuracy: 0.6415 - val_auc: 0.6183 - val_loss: 0.6365 - val_precision: 0.7778 - val_recall: 0.0446\n",
            "Epoch 52/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6128 - auc: 0.5761 - loss: 0.6588 - precision: 0.4782 - recall: 0.1267 - val_accuracy: 0.6415 - val_auc: 0.6202 - val_loss: 0.6349 - val_precision: 0.7778 - val_recall: 0.0446\n",
            "Epoch 53/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6329 - auc: 0.5680 - loss: 0.6546 - precision: 0.5241 - recall: 0.1305 - val_accuracy: 0.6392 - val_auc: 0.6239 - val_loss: 0.6343 - val_precision: 0.7000 - val_recall: 0.0446\n",
            "Epoch 54/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6451 - auc: 0.5738 - loss: 0.6422 - precision: 0.4736 - recall: 0.1346 - val_accuracy: 0.6392 - val_auc: 0.6252 - val_loss: 0.6342 - val_precision: 0.7000 - val_recall: 0.0446\n",
            "Epoch 55/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6284 - auc: 0.5864 - loss: 0.6543 - precision: 0.5544 - recall: 0.1302 - val_accuracy: 0.6368 - val_auc: 0.6288 - val_loss: 0.6329 - val_precision: 0.6667 - val_recall: 0.0382\n",
            "Epoch 56/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6333 - auc: 0.6029 - loss: 0.6469 - precision: 0.5665 - recall: 0.1385 - val_accuracy: 0.6439 - val_auc: 0.6318 - val_loss: 0.6319 - val_precision: 0.8000 - val_recall: 0.0510\n",
            "Epoch 57/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6144 - auc: 0.5990 - loss: 0.6510 - precision: 0.4741 - recall: 0.1193 - val_accuracy: 0.6392 - val_auc: 0.6348 - val_loss: 0.6310 - val_precision: 0.7000 - val_recall: 0.0446\n",
            "Epoch 58/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6053 - auc: 0.5984 - loss: 0.6509 - precision: 0.4232 - recall: 0.1179 - val_accuracy: 0.6368 - val_auc: 0.6334 - val_loss: 0.6309 - val_precision: 0.6364 - val_recall: 0.0446\n",
            "Epoch 59/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6280 - auc: 0.5961 - loss: 0.6491 - precision: 0.5000 - recall: 0.1578 - val_accuracy: 0.6368 - val_auc: 0.6368 - val_loss: 0.6305 - val_precision: 0.6364 - val_recall: 0.0446\n",
            "Epoch 60/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6317 - auc: 0.6162 - loss: 0.6415 - precision: 0.5376 - recall: 0.1694 - val_accuracy: 0.6344 - val_auc: 0.6372 - val_loss: 0.6293 - val_precision: 0.5714 - val_recall: 0.0510\n",
            "Epoch 61/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6199 - auc: 0.5889 - loss: 0.6557 - precision: 0.4967 - recall: 0.1468 - val_accuracy: 0.6321 - val_auc: 0.6404 - val_loss: 0.6283 - val_precision: 0.5333 - val_recall: 0.0510\n",
            "Epoch 62/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6442 - auc: 0.6343 - loss: 0.6313 - precision: 0.5572 - recall: 0.1681 - val_accuracy: 0.6368 - val_auc: 0.6403 - val_loss: 0.6275 - val_precision: 0.5882 - val_recall: 0.0637\n",
            "Epoch 63/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6442 - auc: 0.6119 - loss: 0.6390 - precision: 0.5475 - recall: 0.1603 - val_accuracy: 0.6415 - val_auc: 0.6385 - val_loss: 0.6273 - val_precision: 0.6667 - val_recall: 0.0637\n",
            "Epoch 64/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6402 - auc: 0.6193 - loss: 0.6379 - precision: 0.5618 - recall: 0.1479 - val_accuracy: 0.6392 - val_auc: 0.6398 - val_loss: 0.6276 - val_precision: 0.6111 - val_recall: 0.0701\n",
            "Epoch 65/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6495 - auc: 0.6602 - loss: 0.6229 - precision: 0.5546 - recall: 0.1822 - val_accuracy: 0.6368 - val_auc: 0.6383 - val_loss: 0.6272 - val_precision: 0.5789 - val_recall: 0.0701\n",
            "Epoch 66/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6399 - auc: 0.6031 - loss: 0.6425 - precision: 0.5196 - recall: 0.1617 - val_accuracy: 0.6392 - val_auc: 0.6389 - val_loss: 0.6268 - val_precision: 0.6111 - val_recall: 0.0701\n",
            "Epoch 67/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6463 - auc: 0.6224 - loss: 0.6362 - precision: 0.5835 - recall: 0.1744 - val_accuracy: 0.6368 - val_auc: 0.6365 - val_loss: 0.6268 - val_precision: 0.5789 - val_recall: 0.0701\n",
            "Epoch 68/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6406 - auc: 0.6184 - loss: 0.6413 - precision: 0.5322 - recall: 0.1850 - val_accuracy: 0.6392 - val_auc: 0.6395 - val_loss: 0.6255 - val_precision: 0.6000 - val_recall: 0.0764\n",
            "Epoch 69/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6409 - auc: 0.6408 - loss: 0.6249 - precision: 0.5148 - recall: 0.1844 - val_accuracy: 0.6368 - val_auc: 0.6378 - val_loss: 0.6254 - val_precision: 0.5714 - val_recall: 0.0764\n",
            "Epoch 70/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6343 - auc: 0.6394 - loss: 0.6372 - precision: 0.5292 - recall: 0.1774 - val_accuracy: 0.6439 - val_auc: 0.6381 - val_loss: 0.6251 - val_precision: 0.6364 - val_recall: 0.0892\n",
            "Epoch 71/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6407 - auc: 0.6284 - loss: 0.6459 - precision: 0.6003 - recall: 0.2014 - val_accuracy: 0.6415 - val_auc: 0.6373 - val_loss: 0.6251 - val_precision: 0.6190 - val_recall: 0.0828\n",
            "Epoch 72/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6188 - auc: 0.6310 - loss: 0.6348 - precision: 0.4563 - recall: 0.1569 - val_accuracy: 0.6439 - val_auc: 0.6387 - val_loss: 0.6243 - val_precision: 0.6500 - val_recall: 0.0828\n",
            "Epoch 73/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6467 - auc: 0.6227 - loss: 0.6383 - precision: 0.5703 - recall: 0.1978 - val_accuracy: 0.6439 - val_auc: 0.6377 - val_loss: 0.6238 - val_precision: 0.6364 - val_recall: 0.0892\n",
            "Epoch 74/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6477 - auc: 0.6347 - loss: 0.6273 - precision: 0.5173 - recall: 0.1778 - val_accuracy: 0.6415 - val_auc: 0.6397 - val_loss: 0.6231 - val_precision: 0.6087 - val_recall: 0.0892\n",
            "Epoch 75/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6241 - auc: 0.6224 - loss: 0.6430 - precision: 0.5292 - recall: 0.1956 - val_accuracy: 0.6392 - val_auc: 0.6386 - val_loss: 0.6231 - val_precision: 0.5909 - val_recall: 0.0828\n",
            "Epoch 76/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6594 - auc: 0.6286 - loss: 0.6308 - precision: 0.6174 - recall: 0.2034 - val_accuracy: 0.6439 - val_auc: 0.6384 - val_loss: 0.6227 - val_precision: 0.6250 - val_recall: 0.0955\n",
            "Epoch 77/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6432 - auc: 0.6338 - loss: 0.6337 - precision: 0.5671 - recall: 0.2023 - val_accuracy: 0.6486 - val_auc: 0.6359 - val_loss: 0.6226 - val_precision: 0.6429 - val_recall: 0.1146\n",
            "Epoch 78/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6522 - auc: 0.6457 - loss: 0.6205 - precision: 0.5154 - recall: 0.1888 - val_accuracy: 0.6486 - val_auc: 0.6383 - val_loss: 0.6218 - val_precision: 0.6429 - val_recall: 0.1146\n",
            "Epoch 79/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6629 - auc: 0.6598 - loss: 0.6156 - precision: 0.5896 - recall: 0.2146 - val_accuracy: 0.6509 - val_auc: 0.6388 - val_loss: 0.6217 - val_precision: 0.6552 - val_recall: 0.1210\n",
            "Epoch 80/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6561 - auc: 0.6298 - loss: 0.6272 - precision: 0.5798 - recall: 0.1927 - val_accuracy: 0.6486 - val_auc: 0.6393 - val_loss: 0.6218 - val_precision: 0.6333 - val_recall: 0.1210\n",
            "Epoch 81/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6479 - auc: 0.6386 - loss: 0.6289 - precision: 0.5571 - recall: 0.2209 - val_accuracy: 0.6486 - val_auc: 0.6404 - val_loss: 0.6209 - val_precision: 0.6429 - val_recall: 0.1146\n",
            "Epoch 82/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6221 - auc: 0.6080 - loss: 0.6466 - precision: 0.5014 - recall: 0.1825 - val_accuracy: 0.6486 - val_auc: 0.6443 - val_loss: 0.6203 - val_precision: 0.6429 - val_recall: 0.1146\n",
            "Epoch 83/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6411 - auc: 0.6513 - loss: 0.6252 - precision: 0.5607 - recall: 0.2314 - val_accuracy: 0.6462 - val_auc: 0.6405 - val_loss: 0.6205 - val_precision: 0.6207 - val_recall: 0.1146\n",
            "Epoch 84/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6403 - auc: 0.6122 - loss: 0.6347 - precision: 0.4773 - recall: 0.1832 - val_accuracy: 0.6462 - val_auc: 0.6409 - val_loss: 0.6201 - val_precision: 0.6061 - val_recall: 0.1274\n",
            "Epoch 85/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6619 - auc: 0.6368 - loss: 0.6286 - precision: 0.5962 - recall: 0.2385 - val_accuracy: 0.6509 - val_auc: 0.6415 - val_loss: 0.6198 - val_precision: 0.6286 - val_recall: 0.1401\n",
            "Epoch 86/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6576 - auc: 0.6570 - loss: 0.6246 - precision: 0.6416 - recall: 0.2251 - val_accuracy: 0.6509 - val_auc: 0.6409 - val_loss: 0.6200 - val_precision: 0.6286 - val_recall: 0.1401\n",
            "Epoch 87/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6349 - auc: 0.6461 - loss: 0.6317 - precision: 0.5648 - recall: 0.2178 - val_accuracy: 0.6486 - val_auc: 0.6403 - val_loss: 0.6197 - val_precision: 0.6111 - val_recall: 0.1401\n",
            "Epoch 88/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6652 - auc: 0.6603 - loss: 0.6183 - precision: 0.6267 - recall: 0.2378 - val_accuracy: 0.6486 - val_auc: 0.6426 - val_loss: 0.6191 - val_precision: 0.6111 - val_recall: 0.1401\n",
            "Epoch 89/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6766 - auc: 0.6469 - loss: 0.6154 - precision: 0.5813 - recall: 0.2568 - val_accuracy: 0.6580 - val_auc: 0.6418 - val_loss: 0.6191 - val_precision: 0.6579 - val_recall: 0.1592\n",
            "Epoch 90/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6507 - auc: 0.6486 - loss: 0.6285 - precision: 0.5865 - recall: 0.2206 - val_accuracy: 0.6580 - val_auc: 0.6427 - val_loss: 0.6188 - val_precision: 0.6579 - val_recall: 0.1592\n",
            "Epoch 91/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6548 - auc: 0.6630 - loss: 0.6196 - precision: 0.5900 - recall: 0.2454 - val_accuracy: 0.6580 - val_auc: 0.6433 - val_loss: 0.6186 - val_precision: 0.6500 - val_recall: 0.1656\n",
            "Epoch 92/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6609 - auc: 0.6466 - loss: 0.6204 - precision: 0.5641 - recall: 0.2293 - val_accuracy: 0.6580 - val_auc: 0.6457 - val_loss: 0.6181 - val_precision: 0.6579 - val_recall: 0.1592\n",
            "Epoch 93/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6491 - auc: 0.6373 - loss: 0.6292 - precision: 0.5691 - recall: 0.2304 - val_accuracy: 0.6604 - val_auc: 0.6426 - val_loss: 0.6189 - val_precision: 0.6667 - val_recall: 0.1656\n",
            "Epoch 94/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6658 - auc: 0.6427 - loss: 0.6302 - precision: 0.6384 - recall: 0.2556 - val_accuracy: 0.6580 - val_auc: 0.6447 - val_loss: 0.6186 - val_precision: 0.6429 - val_recall: 0.1720\n",
            "Epoch 95/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6750 - auc: 0.6651 - loss: 0.6157 - precision: 0.6649 - recall: 0.2684 - val_accuracy: 0.6604 - val_auc: 0.6467 - val_loss: 0.6178 - val_precision: 0.6383 - val_recall: 0.1911\n",
            "Epoch 96/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6428 - auc: 0.6444 - loss: 0.6355 - precision: 0.5976 - recall: 0.2066 - val_accuracy: 0.6580 - val_auc: 0.6461 - val_loss: 0.6171 - val_precision: 0.6364 - val_recall: 0.1783\n",
            "Epoch 97/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6607 - auc: 0.6446 - loss: 0.6240 - precision: 0.5770 - recall: 0.2472 - val_accuracy: 0.6533 - val_auc: 0.6466 - val_loss: 0.6174 - val_precision: 0.6136 - val_recall: 0.1720\n",
            "Epoch 98/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6504 - auc: 0.6505 - loss: 0.6247 - precision: 0.5596 - recall: 0.2533 - val_accuracy: 0.6509 - val_auc: 0.6475 - val_loss: 0.6172 - val_precision: 0.6000 - val_recall: 0.1720\n",
            "Epoch 99/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6532 - auc: 0.6628 - loss: 0.6190 - precision: 0.5843 - recall: 0.2555 - val_accuracy: 0.6533 - val_auc: 0.6461 - val_loss: 0.6178 - val_precision: 0.6087 - val_recall: 0.1783\n",
            "Epoch 100/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6355 - auc: 0.6206 - loss: 0.6439 - precision: 0.5295 - recall: 0.2272 - val_accuracy: 0.6533 - val_auc: 0.6462 - val_loss: 0.6180 - val_precision: 0.6087 - val_recall: 0.1783\n",
            "Epoch 101/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6660 - auc: 0.6390 - loss: 0.6216 - precision: 0.5796 - recall: 0.2241 - val_accuracy: 0.6509 - val_auc: 0.6475 - val_loss: 0.6178 - val_precision: 0.6000 - val_recall: 0.1720\n",
            "Epoch 102/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6683 - auc: 0.6943 - loss: 0.6077 - precision: 0.6445 - recall: 0.2754 - val_accuracy: 0.6580 - val_auc: 0.6480 - val_loss: 0.6178 - val_precision: 0.6250 - val_recall: 0.1911\n",
            "Epoch 103/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.6661 - auc: 0.6358 - loss: 0.6190 - precision: 0.5517 - recall: 0.2592 - val_accuracy: 0.6557 - val_auc: 0.6484 - val_loss: 0.6174 - val_precision: 0.6170 - val_recall: 0.1847\n",
            "Epoch 104/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6471 - auc: 0.6725 - loss: 0.6160 - precision: 0.5748 - recall: 0.2589 - val_accuracy: 0.6557 - val_auc: 0.6461 - val_loss: 0.6181 - val_precision: 0.6122 - val_recall: 0.1911\n",
            "Epoch 105/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6534 - auc: 0.6467 - loss: 0.6204 - precision: 0.5656 - recall: 0.2447 - val_accuracy: 0.6604 - val_auc: 0.6459 - val_loss: 0.6179 - val_precision: 0.6226 - val_recall: 0.2102\n",
            "Epoch 106/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6774 - auc: 0.6719 - loss: 0.6077 - precision: 0.6135 - recall: 0.2723 - val_accuracy: 0.6533 - val_auc: 0.6468 - val_loss: 0.6184 - val_precision: 0.5962 - val_recall: 0.1975\n",
            "Epoch 107/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6677 - auc: 0.6342 - loss: 0.6245 - precision: 0.5973 - recall: 0.2577 - val_accuracy: 0.6580 - val_auc: 0.6472 - val_loss: 0.6178 - val_precision: 0.6111 - val_recall: 0.2102\n",
            "Epoch 108/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6723 - auc: 0.6737 - loss: 0.6133 - precision: 0.6377 - recall: 0.2913 - val_accuracy: 0.6557 - val_auc: 0.6459 - val_loss: 0.6179 - val_precision: 0.6038 - val_recall: 0.2038\n",
            "Epoch 109/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6632 - auc: 0.6603 - loss: 0.6164 - precision: 0.5819 - recall: 0.2505 - val_accuracy: 0.6557 - val_auc: 0.6478 - val_loss: 0.6173 - val_precision: 0.6038 - val_recall: 0.2038\n",
            "Epoch 110/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6660 - auc: 0.6861 - loss: 0.6079 - precision: 0.6178 - recall: 0.2822 - val_accuracy: 0.6533 - val_auc: 0.6482 - val_loss: 0.6173 - val_precision: 0.5962 - val_recall: 0.1975\n",
            "Epoch 111/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6471 - auc: 0.6896 - loss: 0.6125 - precision: 0.5876 - recall: 0.2623 - val_accuracy: 0.6580 - val_auc: 0.6492 - val_loss: 0.6175 - val_precision: 0.6154 - val_recall: 0.2038\n",
            "Epoch 112/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6677 - auc: 0.6602 - loss: 0.6139 - precision: 0.5741 - recall: 0.2695 - val_accuracy: 0.6557 - val_auc: 0.6500 - val_loss: 0.6171 - val_precision: 0.6038 - val_recall: 0.2038\n",
            "Epoch 113/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6599 - auc: 0.6792 - loss: 0.6126 - precision: 0.5980 - recall: 0.2931 - val_accuracy: 0.6580 - val_auc: 0.6524 - val_loss: 0.6157 - val_precision: 0.6154 - val_recall: 0.2038\n",
            "Epoch 114/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6544 - auc: 0.6350 - loss: 0.6275 - precision: 0.5389 - recall: 0.2447 - val_accuracy: 0.6557 - val_auc: 0.6532 - val_loss: 0.6151 - val_precision: 0.6038 - val_recall: 0.2038\n",
            "Epoch 115/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6844 - auc: 0.6870 - loss: 0.6035 - precision: 0.6375 - recall: 0.2846 - val_accuracy: 0.6651 - val_auc: 0.6528 - val_loss: 0.6152 - val_precision: 0.6415 - val_recall: 0.2166\n",
            "Epoch 116/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6801 - auc: 0.6677 - loss: 0.6133 - precision: 0.6134 - recall: 0.2817 - val_accuracy: 0.6627 - val_auc: 0.6532 - val_loss: 0.6156 - val_precision: 0.6346 - val_recall: 0.2102\n",
            "Epoch 117/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6542 - auc: 0.6690 - loss: 0.6118 - precision: 0.5597 - recall: 0.2755 - val_accuracy: 0.6557 - val_auc: 0.6517 - val_loss: 0.6161 - val_precision: 0.6038 - val_recall: 0.2038\n",
            "Epoch 118/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6610 - auc: 0.6633 - loss: 0.6196 - precision: 0.5854 - recall: 0.2726 - val_accuracy: 0.6651 - val_auc: 0.6510 - val_loss: 0.6158 - val_precision: 0.6316 - val_recall: 0.2293\n",
            "Epoch 119/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6602 - auc: 0.6775 - loss: 0.6168 - precision: 0.5888 - recall: 0.2962 - val_accuracy: 0.6627 - val_auc: 0.6517 - val_loss: 0.6159 - val_precision: 0.6250 - val_recall: 0.2229\n",
            "Epoch 120/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6654 - auc: 0.6656 - loss: 0.6218 - precision: 0.5910 - recall: 0.2939 - val_accuracy: 0.6627 - val_auc: 0.6522 - val_loss: 0.6162 - val_precision: 0.6296 - val_recall: 0.2166\n",
            "Epoch 121/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6596 - auc: 0.6682 - loss: 0.6179 - precision: 0.6037 - recall: 0.2779 - val_accuracy: 0.6675 - val_auc: 0.6517 - val_loss: 0.6165 - val_precision: 0.6429 - val_recall: 0.2293\n",
            "Epoch 122/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6586 - auc: 0.6673 - loss: 0.6127 - precision: 0.5438 - recall: 0.2621 - val_accuracy: 0.6604 - val_auc: 0.6505 - val_loss: 0.6176 - val_precision: 0.6226 - val_recall: 0.2102\n",
            "Epoch 123/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6581 - auc: 0.6815 - loss: 0.6172 - precision: 0.6016 - recall: 0.2806 - val_accuracy: 0.6627 - val_auc: 0.6496 - val_loss: 0.6182 - val_precision: 0.6296 - val_recall: 0.2166\n",
            "Epoch 124/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6720 - auc: 0.6830 - loss: 0.6044 - precision: 0.5903 - recall: 0.3061 - val_accuracy: 0.6651 - val_auc: 0.6509 - val_loss: 0.6174 - val_precision: 0.6271 - val_recall: 0.2357\n",
            "Epoch 125/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6621 - auc: 0.6931 - loss: 0.6015 - precision: 0.5816 - recall: 0.3158 - val_accuracy: 0.6627 - val_auc: 0.6520 - val_loss: 0.6180 - val_precision: 0.6167 - val_recall: 0.2357\n",
            "Epoch 126/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6605 - auc: 0.6684 - loss: 0.6252 - precision: 0.6023 - recall: 0.3041 - val_accuracy: 0.6604 - val_auc: 0.6521 - val_loss: 0.6179 - val_precision: 0.6140 - val_recall: 0.2229\n",
            "Epoch 127/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6661 - auc: 0.6735 - loss: 0.6190 - precision: 0.6333 - recall: 0.2991 - val_accuracy: 0.6651 - val_auc: 0.6509 - val_loss: 0.6186 - val_precision: 0.6271 - val_recall: 0.2357\n",
            "Epoch 128/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6589 - auc: 0.6630 - loss: 0.6184 - precision: 0.5931 - recall: 0.2759 - val_accuracy: 0.6675 - val_auc: 0.6535 - val_loss: 0.6173 - val_precision: 0.6333 - val_recall: 0.2420\n",
            "Epoch 129/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6617 - auc: 0.6512 - loss: 0.6185 - precision: 0.5646 - recall: 0.2799 - val_accuracy: 0.6698 - val_auc: 0.6531 - val_loss: 0.6175 - val_precision: 0.6349 - val_recall: 0.2548\n",
            "Epoch 130/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6497 - auc: 0.6697 - loss: 0.6150 - precision: 0.5560 - recall: 0.2704 - val_accuracy: 0.6698 - val_auc: 0.6514 - val_loss: 0.6177 - val_precision: 0.6393 - val_recall: 0.2484\n",
            "Epoch 131/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6836 - auc: 0.6640 - loss: 0.6072 - precision: 0.5940 - recall: 0.2932 - val_accuracy: 0.6722 - val_auc: 0.6510 - val_loss: 0.6176 - val_precision: 0.6500 - val_recall: 0.2484\n",
            "Epoch 132/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6803 - auc: 0.6974 - loss: 0.5969 - precision: 0.6240 - recall: 0.3343 - val_accuracy: 0.6698 - val_auc: 0.6512 - val_loss: 0.6174 - val_precision: 0.6393 - val_recall: 0.2484\n",
            "Epoch 133/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6530 - auc: 0.6642 - loss: 0.6256 - precision: 0.5886 - recall: 0.2791 - val_accuracy: 0.6745 - val_auc: 0.6526 - val_loss: 0.6167 - val_precision: 0.6610 - val_recall: 0.2484\n",
            "Epoch 134/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6734 - auc: 0.6972 - loss: 0.5952 - precision: 0.6118 - recall: 0.2959 - val_accuracy: 0.6604 - val_auc: 0.6527 - val_loss: 0.6169 - val_precision: 0.6066 - val_recall: 0.2357\n",
            "Epoch 135/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6446 - auc: 0.6498 - loss: 0.6300 - precision: 0.5629 - recall: 0.2850 - val_accuracy: 0.6627 - val_auc: 0.6537 - val_loss: 0.6163 - val_precision: 0.6129 - val_recall: 0.2420\n",
            "Epoch 136/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6852 - auc: 0.6767 - loss: 0.6070 - precision: 0.6290 - recall: 0.3231 - val_accuracy: 0.6651 - val_auc: 0.6546 - val_loss: 0.6159 - val_precision: 0.6154 - val_recall: 0.2548\n",
            "Epoch 137/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6574 - auc: 0.6835 - loss: 0.6108 - precision: 0.6056 - recall: 0.3024 - val_accuracy: 0.6675 - val_auc: 0.6545 - val_loss: 0.6167 - val_precision: 0.6250 - val_recall: 0.2548\n",
            "Epoch 138/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6486 - auc: 0.6681 - loss: 0.6257 - precision: 0.5765 - recall: 0.2914 - val_accuracy: 0.6745 - val_auc: 0.6550 - val_loss: 0.6162 - val_precision: 0.6462 - val_recall: 0.2675\n",
            "Epoch 139/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6736 - auc: 0.6906 - loss: 0.6027 - precision: 0.6053 - recall: 0.3267 - val_accuracy: 0.6627 - val_auc: 0.6545 - val_loss: 0.6169 - val_precision: 0.6129 - val_recall: 0.2420\n",
            "Epoch 140/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6770 - auc: 0.6861 - loss: 0.6098 - precision: 0.6312 - recall: 0.3237 - val_accuracy: 0.6722 - val_auc: 0.6560 - val_loss: 0.6168 - val_precision: 0.6452 - val_recall: 0.2548\n",
            "Epoch 141/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6565 - auc: 0.6631 - loss: 0.6223 - precision: 0.5818 - recall: 0.3200 - val_accuracy: 0.6698 - val_auc: 0.6551 - val_loss: 0.6168 - val_precision: 0.6441 - val_recall: 0.2420\n",
            "Epoch 142/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6771 - auc: 0.6895 - loss: 0.6020 - precision: 0.6237 - recall: 0.3146 - val_accuracy: 0.6675 - val_auc: 0.6545 - val_loss: 0.6172 - val_precision: 0.6290 - val_recall: 0.2484\n",
            "Epoch 143/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6797 - auc: 0.6934 - loss: 0.5962 - precision: 0.5982 - recall: 0.3078 - val_accuracy: 0.6651 - val_auc: 0.6554 - val_loss: 0.6167 - val_precision: 0.6271 - val_recall: 0.2357\n",
            "Epoch 144/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6586 - auc: 0.6669 - loss: 0.6206 - precision: 0.5837 - recall: 0.2966 - val_accuracy: 0.6580 - val_auc: 0.6543 - val_loss: 0.6163 - val_precision: 0.5938 - val_recall: 0.2420\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_epoch = np.argmin(history.history['val_loss'])\n",
        "print(f\"Best Epoch: {best_epoch+1}\")\n",
        "print(f\"Train Accuracy at Best Epoch: {history.history['accuracy'][best_epoch]:.4f}\")\n",
        "print(f\"Val Accuracy at Best Epoch: {history.history['val_accuracy'][best_epoch]:.4f}\")"
      ],
      "metadata": {
        "id": "nIQiApSSMZR8",
        "outputId": "33dc2421-c40b-46e9-88bf-eab243d23480",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Epoch: 114\n",
            "Train Accuracy at Best Epoch: 0.6552\n",
            "Val Accuracy at Best Epoch: 0.6557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy, test_precision, test_recall, test_auc = gaius_model.evaluate(X_test, y_test, verbose=1)\n",
        "\n",
        "# Print results with clear formatting\n",
        "print(\"\\nTest Evaluation Metrics:\")\n",
        "print(f\"  Loss      : {test_loss:.4f}\")\n",
        "print(f\"  Accuracy  : {test_accuracy:.4f}\")\n",
        "print(f\"  Precision : {test_precision:.4f}\")\n",
        "print(f\"  Recall    : {test_recall:.4f}\")\n",
        "print(f\"  AUC       : {test_auc:.4f}\")\n"
      ],
      "metadata": {
        "id": "FaanMjPsMpYH",
        "outputId": "585f57b7-858e-4dd6-f37f-d9a5985c5d42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6555 - auc: 0.6818 - loss: 0.6155 - precision: 0.6358 - recall: 0.2532 \n",
            "\n",
            "Test Evaluation Metrics:\n",
            "  Loss      : 0.6050\n",
            "  Accuracy  : 0.6800\n",
            "  Precision : 0.6667\n",
            "  Recall    : 0.2675\n",
            "  AUC       : 0.6799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Definition by member 3 (RMSprop variant)\n",
        "def model_david():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(128, input_shape=(X_train.shape[1],), activation=\"relu\",\n",
        "                                   kernel_regularizer=tf.keras.regularizers.l2(0.0005)))\n",
        "  model.add(tf.keras.layers.Dense(64, activation=\"relu\",\n",
        "                                   kernel_regularizer=tf.keras.regularizers.l2(0.0005)))\n",
        "  model.add(tf.keras.layers.Dense(32, activation=\"relu\",\n",
        "                                   kernel_regularizer=tf.keras.regularizers.l2(0.0005)))\n",
        "  model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\",\n",
        "                                   kernel_regularizer=tf.keras.regularizers.l2(0.0005)))\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "                loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "  return model\n",
        "\n",
        "model3 = model_david()\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping_3 = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=50,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history3 = model3.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=300,\n",
        "    batch_size=32,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping_3]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "0R8q1MuJ-mJd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30ec28c1-74ad-48a3-f526-03951f9ca4c0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - accuracy: 0.6246 - loss: 0.7315 - val_accuracy: 0.6321 - val_loss: 0.7154\n",
            "Epoch 2/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6477 - loss: 0.6954 - val_accuracy: 0.6509 - val_loss: 0.6962\n",
            "Epoch 3/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6472 - loss: 0.6846 - val_accuracy: 0.6226 - val_loss: 0.7004\n",
            "Epoch 4/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6770 - loss: 0.6538 - val_accuracy: 0.6509 - val_loss: 0.6796\n",
            "Epoch 5/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6920 - loss: 0.6420 - val_accuracy: 0.6509 - val_loss: 0.6762\n",
            "Epoch 6/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6909 - loss: 0.6291 - val_accuracy: 0.6557 - val_loss: 0.6733\n",
            "Epoch 7/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6952 - loss: 0.6323 - val_accuracy: 0.6132 - val_loss: 0.6874\n",
            "Epoch 8/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7030 - loss: 0.6171 - val_accuracy: 0.6368 - val_loss: 0.6738\n",
            "Epoch 9/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7200 - loss: 0.5961 - val_accuracy: 0.6274 - val_loss: 0.7005\n",
            "Epoch 10/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7001 - loss: 0.6053 - val_accuracy: 0.5920 - val_loss: 0.6967\n",
            "Epoch 11/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7236 - loss: 0.6000 - val_accuracy: 0.6509 - val_loss: 0.6773\n",
            "Epoch 12/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7231 - loss: 0.5929 - val_accuracy: 0.6462 - val_loss: 0.6750\n",
            "Epoch 13/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7119 - loss: 0.6012 - val_accuracy: 0.6486 - val_loss: 0.6873\n",
            "Epoch 14/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7196 - loss: 0.5923 - val_accuracy: 0.6392 - val_loss: 0.6815\n",
            "Epoch 15/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7174 - loss: 0.5977 - val_accuracy: 0.6627 - val_loss: 0.6787\n",
            "Epoch 16/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7294 - loss: 0.5877 - val_accuracy: 0.6533 - val_loss: 0.6791\n",
            "Epoch 17/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7596 - loss: 0.5491 - val_accuracy: 0.6604 - val_loss: 0.6804\n",
            "Epoch 18/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7393 - loss: 0.5632 - val_accuracy: 0.6156 - val_loss: 0.7010\n",
            "Epoch 19/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7435 - loss: 0.5671 - val_accuracy: 0.6462 - val_loss: 0.6810\n",
            "Epoch 20/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7460 - loss: 0.5630 - val_accuracy: 0.6226 - val_loss: 0.6890\n",
            "Epoch 21/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7511 - loss: 0.5560 - val_accuracy: 0.5920 - val_loss: 0.7130\n",
            "Epoch 22/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7751 - loss: 0.5393 - val_accuracy: 0.5967 - val_loss: 0.7124\n",
            "Epoch 23/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7818 - loss: 0.5346 - val_accuracy: 0.6722 - val_loss: 0.7112\n",
            "Epoch 24/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7731 - loss: 0.5307 - val_accuracy: 0.6321 - val_loss: 0.7018\n",
            "Epoch 25/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7613 - loss: 0.5271 - val_accuracy: 0.6132 - val_loss: 0.7056\n",
            "Epoch 26/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7839 - loss: 0.5133 - val_accuracy: 0.6415 - val_loss: 0.7093\n",
            "Epoch 27/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7884 - loss: 0.5035 - val_accuracy: 0.6061 - val_loss: 0.7022\n",
            "Epoch 28/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7795 - loss: 0.5214 - val_accuracy: 0.6344 - val_loss: 0.7167\n",
            "Epoch 29/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8010 - loss: 0.4833 - val_accuracy: 0.6415 - val_loss: 0.7123\n",
            "Epoch 30/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8066 - loss: 0.4956 - val_accuracy: 0.6297 - val_loss: 0.7187\n",
            "Epoch 31/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8002 - loss: 0.4938 - val_accuracy: 0.6108 - val_loss: 0.7277\n",
            "Epoch 32/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8161 - loss: 0.4750 - val_accuracy: 0.6462 - val_loss: 0.7287\n",
            "Epoch 33/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8181 - loss: 0.4731 - val_accuracy: 0.6274 - val_loss: 0.7352\n",
            "Epoch 34/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8119 - loss: 0.4678 - val_accuracy: 0.6415 - val_loss: 0.7503\n",
            "Epoch 35/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8301 - loss: 0.4487 - val_accuracy: 0.6250 - val_loss: 0.7563\n",
            "Epoch 36/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8269 - loss: 0.4583 - val_accuracy: 0.6038 - val_loss: 0.7777\n",
            "Epoch 37/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8216 - loss: 0.4346 - val_accuracy: 0.6226 - val_loss: 0.7815\n",
            "Epoch 38/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8610 - loss: 0.4344 - val_accuracy: 0.6132 - val_loss: 0.7899\n",
            "Epoch 39/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8355 - loss: 0.4368 - val_accuracy: 0.6439 - val_loss: 0.7979\n",
            "Epoch 40/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8588 - loss: 0.4078 - val_accuracy: 0.6156 - val_loss: 0.8108\n",
            "Epoch 41/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8488 - loss: 0.4053 - val_accuracy: 0.6462 - val_loss: 0.8141\n",
            "Epoch 42/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8595 - loss: 0.3999 - val_accuracy: 0.5896 - val_loss: 0.8746\n",
            "Epoch 43/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8563 - loss: 0.4037 - val_accuracy: 0.6462 - val_loss: 0.8225\n",
            "Epoch 44/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8716 - loss: 0.3935 - val_accuracy: 0.6274 - val_loss: 0.8609\n",
            "Epoch 45/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8382 - loss: 0.4343 - val_accuracy: 0.6156 - val_loss: 0.8732\n",
            "Epoch 46/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8557 - loss: 0.3934 - val_accuracy: 0.6203 - val_loss: 0.8578\n",
            "Epoch 47/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8797 - loss: 0.3736 - val_accuracy: 0.6014 - val_loss: 0.8911\n",
            "Epoch 48/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8814 - loss: 0.3917 - val_accuracy: 0.6321 - val_loss: 0.8992\n",
            "Epoch 49/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8606 - loss: 0.3811 - val_accuracy: 0.6226 - val_loss: 0.9295\n",
            "Epoch 50/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8791 - loss: 0.3716 - val_accuracy: 0.6108 - val_loss: 0.9265\n",
            "Epoch 51/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8819 - loss: 0.3663 - val_accuracy: 0.6061 - val_loss: 0.9042\n",
            "Epoch 52/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8938 - loss: 0.3546 - val_accuracy: 0.6061 - val_loss: 0.9470\n",
            "Epoch 53/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8837 - loss: 0.3504 - val_accuracy: 0.6014 - val_loss: 0.9685\n",
            "Epoch 54/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8882 - loss: 0.3432 - val_accuracy: 0.6085 - val_loss: 0.9456\n",
            "Epoch 55/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8999 - loss: 0.3393 - val_accuracy: 0.5849 - val_loss: 1.0236\n",
            "Epoch 56/300\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8964 - loss: 0.3245 - val_accuracy: 0.6156 - val_loss: 1.0120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get best epoch based on validation loss\n",
        "best_epoch = history3.history['val_loss'].index(min(history3.history['val_loss']))\n",
        "\n",
        "# Get train and validation accuracy at best epoch\n",
        "train_acc_at_best = history3.history['accuracy'][best_epoch]\n",
        "val_acc_at_best = history3.history['val_accuracy'][best_epoch]\n",
        "\n",
        "print(f\"Best Epoch: {best_epoch + 1}\")  # +1 for human-readable epoch number\n",
        "print(f\"Train Accuracy at Best Epoch: {train_acc_at_best:.4f}\")\n",
        "print(f\"Validation Accuracy at Best Epoch: {val_acc_at_best:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh4Z094Tl1oJ",
        "outputId": "fd53eebe-b743-4ca6-8c28-20b831867089"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Epoch: 6\n",
            "Train Accuracy at Best Epoch: 0.6936\n",
            "Validation Accuracy at Best Epoch: 0.6557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_probs = model3.predict(X_test).ravel()\n",
        "\n",
        "# Predict binary classes\n",
        "y_pred_classes = (y_pred_probs > 0.5).astype(\"int32\")\n",
        "\n",
        "# Evaluate loss and accuracy\n",
        "test_loss, test_accuracy = model3.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "# Calculate precision, recall, and AUC\n",
        "test_precision = precision_score(y_test, y_pred_classes)\n",
        "test_recall = recall_score(y_test, y_pred_classes)\n",
        "test_auc = roc_auc_score(y_test, y_pred_probs)\n",
        "\n",
        "# Print results\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test AUC: {test_auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oczDl65Sl1SH",
        "outputId": "21bd0b07-c0e8-4126-c802-a2225f43e213"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Test Loss: 0.6443\n",
            "Test Accuracy: 0.6800\n",
            "Test Precision: 0.6400\n",
            "Test Recall: 0.3057\n",
            "Test AUC: 0.7112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Definition by member 4\n",
        "!pip install tensorflow\n",
        "def model_tamanda_kaunda():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(96, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.001)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(48, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.0005)),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Dense(24, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.0005)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(12, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.0001)),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            tf.keras.metrics.Precision(name='precision'),\n",
        "            tf.keras.metrics.Recall(name='recall'),\n",
        "            tf.keras.metrics.AUC(name='auc')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "tamanda_model = model_tamanda_kaunda()\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=25,\n",
        "    min_delta=0.001,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = tamanda_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=150,\n",
        "    batch_size=64,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "TKoFpxX6_B7D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea1c3ef4-3c01-473b-a8b3-a3445e5b2583"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.72.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Epoch 1/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.5335 - auc: 0.5002 - loss: 1.1086 - precision: 0.3798 - recall: 0.3421 - val_accuracy: 0.6297 - val_auc: 0.4878 - val_loss: 1.0599 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6185 - auc: 0.5096 - loss: 1.0572 - precision: 0.4519 - recall: 0.0216 - val_accuracy: 0.6297 - val_auc: 0.5069 - val_loss: 1.0299 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6192 - auc: 0.5207 - loss: 1.0263 - precision: 0.0273 - recall: 3.2438e-04 - val_accuracy: 0.6297 - val_auc: 0.5235 - val_loss: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6366 - auc: 0.5402 - loss: 0.9858 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5240 - val_loss: 0.9701 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 5/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6310 - auc: 0.5188 - loss: 0.9653 - precision: 0.9062 - recall: 0.0029 - val_accuracy: 0.6297 - val_auc: 0.5304 - val_loss: 0.9407 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 6/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6504 - auc: 0.5593 - loss: 0.9194 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5377 - val_loss: 0.9130 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 7/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6474 - auc: 0.5291 - loss: 0.8968 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5413 - val_loss: 0.8861 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 8/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6405 - auc: 0.5725 - loss: 0.8679 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5462 - val_loss: 0.8601 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 9/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6188 - auc: 0.5639 - loss: 0.8558 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5611 - val_loss: 0.8345 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 10/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6445 - auc: 0.5853 - loss: 0.8171 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5610 - val_loss: 0.8122 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 11/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6344 - auc: 0.5763 - loss: 0.8009 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5763 - val_loss: 0.7913 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 12/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6475 - auc: 0.6207 - loss: 0.7697 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5760 - val_loss: 0.7724 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 13/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6220 - auc: 0.6043 - loss: 0.7656 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5690 - val_loss: 0.7581 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 14/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6315 - auc: 0.6139 - loss: 0.7451 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5865 - val_loss: 0.7444 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 15/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6319 - auc: 0.6313 - loss: 0.7300 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5819 - val_loss: 0.7338 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 16/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6427 - auc: 0.6163 - loss: 0.7164 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5831 - val_loss: 0.7234 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 17/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6283 - auc: 0.6270 - loss: 0.7148 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5888 - val_loss: 0.7148 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 18/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6397 - auc: 0.6309 - loss: 0.6967 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.5915 - val_loss: 0.7080 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 19/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6288 - auc: 0.6665 - loss: 0.6954 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6006 - val_loss: 0.7016 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 20/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6479 - auc: 0.6267 - loss: 0.6868 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6047 - val_loss: 0.6970 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 21/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6292 - auc: 0.6744 - loss: 0.6833 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6052 - val_loss: 0.6926 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 22/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6484 - auc: 0.6631 - loss: 0.6692 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6095 - val_loss: 0.6901 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 23/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6326 - auc: 0.6628 - loss: 0.6781 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6090 - val_loss: 0.6876 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 24/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6524 - auc: 0.6478 - loss: 0.6675 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6159 - val_loss: 0.6858 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 25/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6364 - auc: 0.6314 - loss: 0.6833 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6173 - val_loss: 0.6827 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 26/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6200 - auc: 0.6669 - loss: 0.6761 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6214 - val_loss: 0.6803 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 27/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6412 - auc: 0.6577 - loss: 0.6678 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6201 - val_loss: 0.6795 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 28/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6396 - auc: 0.6669 - loss: 0.6635 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6223 - val_loss: 0.6777 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 29/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6289 - auc: 0.6677 - loss: 0.6637 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6216 - val_loss: 0.6766 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 30/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6488 - auc: 0.6488 - loss: 0.6622 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6197 - val_loss: 0.6772 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 31/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6318 - auc: 0.6269 - loss: 0.6729 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6245 - val_loss: 0.6741 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 32/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6337 - auc: 0.6573 - loss: 0.6657 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6293 - val_loss: 0.6720 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 33/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6454 - auc: 0.6873 - loss: 0.6517 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6256 - val_loss: 0.6724 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 34/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6230 - auc: 0.6749 - loss: 0.6607 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6299 - val_loss: 0.6702 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 35/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6334 - auc: 0.6495 - loss: 0.6657 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6323 - val_loss: 0.6687 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 36/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6101 - auc: 0.6989 - loss: 0.6619 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6274 - val_loss: 0.6690 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 37/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6244 - auc: 0.6966 - loss: 0.6520 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.6297 - val_auc: 0.6313 - val_loss: 0.6686 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 38/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6238 - auc: 0.6861 - loss: 0.6645 - precision: 0.5766 - recall: 0.0201 - val_accuracy: 0.6297 - val_auc: 0.6339 - val_loss: 0.6669 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 39/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6419 - auc: 0.6441 - loss: 0.6611 - precision: 0.1786 - recall: 8.9514e-04 - val_accuracy: 0.6368 - val_auc: 0.6360 - val_loss: 0.6660 - val_precision: 0.6364 - val_recall: 0.0446\n",
            "Epoch 40/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6343 - auc: 0.6747 - loss: 0.6646 - precision: 0.6572 - recall: 0.0712 - val_accuracy: 0.6297 - val_auc: 0.6313 - val_loss: 0.6664 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 41/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6335 - auc: 0.6793 - loss: 0.6624 - precision: 0.7022 - recall: 0.0609 - val_accuracy: 0.6297 - val_auc: 0.6326 - val_loss: 0.6666 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 42/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6409 - auc: 0.6753 - loss: 0.6551 - precision: 0.6889 - recall: 0.0469 - val_accuracy: 0.6392 - val_auc: 0.6346 - val_loss: 0.6656 - val_precision: 0.8333 - val_recall: 0.0318\n",
            "Epoch 43/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6353 - auc: 0.6661 - loss: 0.6666 - precision: 0.6430 - recall: 0.0698 - val_accuracy: 0.6368 - val_auc: 0.6355 - val_loss: 0.6658 - val_precision: 1.0000 - val_recall: 0.0191\n",
            "Epoch 44/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6451 - auc: 0.6777 - loss: 0.6520 - precision: 0.6534 - recall: 0.0266 - val_accuracy: 0.6368 - val_auc: 0.6307 - val_loss: 0.6659 - val_precision: 0.5517 - val_recall: 0.1019\n",
            "Epoch 45/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6479 - auc: 0.6909 - loss: 0.6520 - precision: 0.6710 - recall: 0.1124 - val_accuracy: 0.6439 - val_auc: 0.6337 - val_loss: 0.6646 - val_precision: 0.7500 - val_recall: 0.0573\n",
            "Epoch 46/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6330 - auc: 0.6805 - loss: 0.6612 - precision: 0.6807 - recall: 0.0906 - val_accuracy: 0.6415 - val_auc: 0.6336 - val_loss: 0.6659 - val_precision: 0.7778 - val_recall: 0.0446\n",
            "Epoch 47/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6461 - auc: 0.6665 - loss: 0.6569 - precision: 0.6058 - recall: 0.0815 - val_accuracy: 0.6415 - val_auc: 0.6326 - val_loss: 0.6638 - val_precision: 0.6471 - val_recall: 0.0701\n",
            "Epoch 48/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6328 - auc: 0.6429 - loss: 0.6666 - precision: 0.4848 - recall: 0.0607 - val_accuracy: 0.6392 - val_auc: 0.6317 - val_loss: 0.6641 - val_precision: 0.5714 - val_recall: 0.1019\n",
            "Epoch 49/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6443 - auc: 0.6572 - loss: 0.6664 - precision: 0.6842 - recall: 0.1263 - val_accuracy: 0.6486 - val_auc: 0.6326 - val_loss: 0.6636 - val_precision: 0.7000 - val_recall: 0.0892\n",
            "Epoch 50/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6643 - auc: 0.6872 - loss: 0.6410 - precision: 0.6926 - recall: 0.0905 - val_accuracy: 0.6439 - val_auc: 0.6283 - val_loss: 0.6650 - val_precision: 0.6000 - val_recall: 0.1146\n",
            "Epoch 51/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6397 - auc: 0.6813 - loss: 0.6659 - precision: 0.6654 - recall: 0.1474 - val_accuracy: 0.6344 - val_auc: 0.6268 - val_loss: 0.6665 - val_precision: 0.5312 - val_recall: 0.1083\n",
            "Epoch 52/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6559 - auc: 0.6793 - loss: 0.6562 - precision: 0.6546 - recall: 0.1480 - val_accuracy: 0.6392 - val_auc: 0.6247 - val_loss: 0.6655 - val_precision: 0.5526 - val_recall: 0.1338\n",
            "Epoch 53/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6629 - auc: 0.6724 - loss: 0.6474 - precision: 0.6309 - recall: 0.1641 - val_accuracy: 0.6392 - val_auc: 0.6289 - val_loss: 0.6644 - val_precision: 0.5476 - val_recall: 0.1465\n",
            "Epoch 54/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6674 - auc: 0.6777 - loss: 0.6462 - precision: 0.7254 - recall: 0.1504 - val_accuracy: 0.6392 - val_auc: 0.6273 - val_loss: 0.6658 - val_precision: 0.5556 - val_recall: 0.1274\n",
            "Epoch 55/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6470 - auc: 0.6945 - loss: 0.6508 - precision: 0.6469 - recall: 0.1934 - val_accuracy: 0.6462 - val_auc: 0.6288 - val_loss: 0.6652 - val_precision: 0.5778 - val_recall: 0.1656\n",
            "Epoch 56/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6580 - auc: 0.6961 - loss: 0.6521 - precision: 0.6681 - recall: 0.1971 - val_accuracy: 0.6415 - val_auc: 0.6253 - val_loss: 0.6673 - val_precision: 0.5862 - val_recall: 0.1083\n",
            "Epoch 57/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6515 - auc: 0.6805 - loss: 0.6549 - precision: 0.6663 - recall: 0.1604 - val_accuracy: 0.6392 - val_auc: 0.6242 - val_loss: 0.6653 - val_precision: 0.5385 - val_recall: 0.1783\n",
            "Epoch 58/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6626 - auc: 0.6592 - loss: 0.6652 - precision: 0.6475 - recall: 0.2304 - val_accuracy: 0.6486 - val_auc: 0.6303 - val_loss: 0.6632 - val_precision: 0.7222 - val_recall: 0.0828\n",
            "Epoch 59/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6430 - auc: 0.7072 - loss: 0.6429 - precision: 0.6023 - recall: 0.1322 - val_accuracy: 0.6392 - val_auc: 0.6249 - val_loss: 0.6661 - val_precision: 0.5526 - val_recall: 0.1338\n",
            "Epoch 60/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6710 - auc: 0.6934 - loss: 0.6421 - precision: 0.6673 - recall: 0.1826 - val_accuracy: 0.6368 - val_auc: 0.6302 - val_loss: 0.6630 - val_precision: 0.5273 - val_recall: 0.1847\n",
            "Epoch 61/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6512 - auc: 0.6705 - loss: 0.6537 - precision: 0.6050 - recall: 0.2090 - val_accuracy: 0.6368 - val_auc: 0.6311 - val_loss: 0.6623 - val_precision: 0.5333 - val_recall: 0.1529\n",
            "Epoch 62/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6520 - auc: 0.6541 - loss: 0.6617 - precision: 0.6224 - recall: 0.2188 - val_accuracy: 0.6415 - val_auc: 0.6298 - val_loss: 0.6626 - val_precision: 0.5610 - val_recall: 0.1465\n",
            "Epoch 63/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6497 - auc: 0.6686 - loss: 0.6570 - precision: 0.6115 - recall: 0.2012 - val_accuracy: 0.6297 - val_auc: 0.6275 - val_loss: 0.6652 - val_precision: 0.5000 - val_recall: 0.1720\n",
            "Epoch 64/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6689 - auc: 0.6825 - loss: 0.6463 - precision: 0.6507 - recall: 0.2361 - val_accuracy: 0.6439 - val_auc: 0.6220 - val_loss: 0.6648 - val_precision: 0.5484 - val_recall: 0.2166\n",
            "Epoch 65/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6552 - auc: 0.6733 - loss: 0.6563 - precision: 0.5967 - recall: 0.2549 - val_accuracy: 0.6392 - val_auc: 0.6204 - val_loss: 0.6667 - val_precision: 0.5312 - val_recall: 0.2166\n",
            "Epoch 66/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.6683 - auc: 0.6854 - loss: 0.6470 - precision: 0.6319 - recall: 0.2951 - val_accuracy: 0.6344 - val_auc: 0.6276 - val_loss: 0.6637 - val_precision: 0.5167 - val_recall: 0.1975\n",
            "Epoch 67/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6828 - auc: 0.6817 - loss: 0.6392 - precision: 0.6873 - recall: 0.2091 - val_accuracy: 0.6415 - val_auc: 0.6246 - val_loss: 0.6644 - val_precision: 0.5397 - val_recall: 0.2166\n",
            "Epoch 68/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6625 - auc: 0.6854 - loss: 0.6480 - precision: 0.6234 - recall: 0.2487 - val_accuracy: 0.6392 - val_auc: 0.6305 - val_loss: 0.6628 - val_precision: 0.5333 - val_recall: 0.2038\n",
            "Epoch 69/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6661 - auc: 0.6945 - loss: 0.6435 - precision: 0.6446 - recall: 0.2265 - val_accuracy: 0.6368 - val_auc: 0.6288 - val_loss: 0.6630 - val_precision: 0.5238 - val_recall: 0.2102\n",
            "Epoch 70/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6663 - auc: 0.6660 - loss: 0.6463 - precision: 0.5924 - recall: 0.2089 - val_accuracy: 0.6415 - val_auc: 0.6286 - val_loss: 0.6620 - val_precision: 0.5410 - val_recall: 0.2102\n",
            "Epoch 71/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6679 - auc: 0.6867 - loss: 0.6524 - precision: 0.6292 - recall: 0.2697 - val_accuracy: 0.6368 - val_auc: 0.6271 - val_loss: 0.6619 - val_precision: 0.5254 - val_recall: 0.1975\n",
            "Epoch 72/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6738 - auc: 0.6873 - loss: 0.6374 - precision: 0.6237 - recall: 0.1955 - val_accuracy: 0.6439 - val_auc: 0.6268 - val_loss: 0.6641 - val_precision: 0.5429 - val_recall: 0.2420\n",
            "Epoch 73/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6628 - auc: 0.6730 - loss: 0.6548 - precision: 0.6069 - recall: 0.2923 - val_accuracy: 0.6297 - val_auc: 0.6321 - val_loss: 0.6609 - val_precision: 0.5000 - val_recall: 0.1783\n",
            "Epoch 74/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6734 - auc: 0.6770 - loss: 0.6456 - precision: 0.6372 - recall: 0.2415 - val_accuracy: 0.6321 - val_auc: 0.6277 - val_loss: 0.6619 - val_precision: 0.5088 - val_recall: 0.1847\n",
            "Epoch 75/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6839 - auc: 0.6725 - loss: 0.6464 - precision: 0.6500 - recall: 0.2533 - val_accuracy: 0.6392 - val_auc: 0.6299 - val_loss: 0.6620 - val_precision: 0.5286 - val_recall: 0.2357\n",
            "Epoch 76/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6834 - auc: 0.6914 - loss: 0.6439 - precision: 0.6580 - recall: 0.2911 - val_accuracy: 0.6392 - val_auc: 0.6315 - val_loss: 0.6604 - val_precision: 0.5323 - val_recall: 0.2102\n",
            "Epoch 77/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6714 - auc: 0.6815 - loss: 0.6400 - precision: 0.6023 - recall: 0.2354 - val_accuracy: 0.6297 - val_auc: 0.6364 - val_loss: 0.6595 - val_precision: 0.5000 - val_recall: 0.1847\n",
            "Epoch 78/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6785 - auc: 0.6957 - loss: 0.6333 - precision: 0.6340 - recall: 0.2550 - val_accuracy: 0.6368 - val_auc: 0.6348 - val_loss: 0.6599 - val_precision: 0.5238 - val_recall: 0.2102\n",
            "Epoch 79/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6679 - auc: 0.6747 - loss: 0.6492 - precision: 0.6200 - recall: 0.2657 - val_accuracy: 0.6344 - val_auc: 0.6395 - val_loss: 0.6579 - val_precision: 0.5135 - val_recall: 0.2420\n",
            "Epoch 80/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6683 - auc: 0.6767 - loss: 0.6527 - precision: 0.6136 - recall: 0.3310 - val_accuracy: 0.6439 - val_auc: 0.6299 - val_loss: 0.6643 - val_precision: 0.5750 - val_recall: 0.1465\n",
            "Epoch 81/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6635 - auc: 0.6659 - loss: 0.6543 - precision: 0.6227 - recall: 0.2114 - val_accuracy: 0.6368 - val_auc: 0.6339 - val_loss: 0.6616 - val_precision: 0.5333 - val_recall: 0.1529\n",
            "Epoch 82/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6572 - auc: 0.6816 - loss: 0.6589 - precision: 0.6638 - recall: 0.2998 - val_accuracy: 0.6462 - val_auc: 0.6300 - val_loss: 0.6660 - val_precision: 0.5897 - val_recall: 0.1465\n",
            "Epoch 83/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6476 - auc: 0.6679 - loss: 0.6542 - precision: 0.6083 - recall: 0.2104 - val_accuracy: 0.6321 - val_auc: 0.6322 - val_loss: 0.6606 - val_precision: 0.5098 - val_recall: 0.1656\n",
            "Epoch 84/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6769 - auc: 0.6845 - loss: 0.6412 - precision: 0.6498 - recall: 0.2529 - val_accuracy: 0.6297 - val_auc: 0.6296 - val_loss: 0.6616 - val_precision: 0.5000 - val_recall: 0.1975\n",
            "Epoch 85/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6684 - auc: 0.6826 - loss: 0.6529 - precision: 0.6366 - recall: 0.2927 - val_accuracy: 0.6344 - val_auc: 0.6298 - val_loss: 0.6610 - val_precision: 0.5139 - val_recall: 0.2357\n",
            "Epoch 86/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6660 - auc: 0.6836 - loss: 0.6468 - precision: 0.6055 - recall: 0.2957 - val_accuracy: 0.6344 - val_auc: 0.6290 - val_loss: 0.6619 - val_precision: 0.5147 - val_recall: 0.2229\n",
            "Epoch 87/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6753 - auc: 0.6820 - loss: 0.6498 - precision: 0.6143 - recall: 0.2704 - val_accuracy: 0.6321 - val_auc: 0.6287 - val_loss: 0.6624 - val_precision: 0.5091 - val_recall: 0.1783\n",
            "Epoch 88/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6657 - auc: 0.6848 - loss: 0.6495 - precision: 0.6534 - recall: 0.2751 - val_accuracy: 0.6368 - val_auc: 0.6315 - val_loss: 0.6601 - val_precision: 0.5231 - val_recall: 0.2166\n",
            "Epoch 89/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6742 - auc: 0.6850 - loss: 0.6445 - precision: 0.6102 - recall: 0.3242 - val_accuracy: 0.6392 - val_auc: 0.6290 - val_loss: 0.6607 - val_precision: 0.5303 - val_recall: 0.2229\n",
            "Epoch 90/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6967 - auc: 0.7007 - loss: 0.6311 - precision: 0.6704 - recall: 0.3302 - val_accuracy: 0.6344 - val_auc: 0.6298 - val_loss: 0.6605 - val_precision: 0.5147 - val_recall: 0.2229\n",
            "Epoch 91/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6958 - auc: 0.6834 - loss: 0.6335 - precision: 0.6242 - recall: 0.3191 - val_accuracy: 0.6368 - val_auc: 0.6269 - val_loss: 0.6622 - val_precision: 0.5200 - val_recall: 0.2484\n",
            "Epoch 92/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6531 - auc: 0.6787 - loss: 0.6543 - precision: 0.5879 - recall: 0.3149 - val_accuracy: 0.6297 - val_auc: 0.6279 - val_loss: 0.6636 - val_precision: 0.5000 - val_recall: 0.1656\n",
            "Epoch 93/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6733 - auc: 0.6786 - loss: 0.6469 - precision: 0.6255 - recall: 0.2709 - val_accuracy: 0.6392 - val_auc: 0.6314 - val_loss: 0.6613 - val_precision: 0.5357 - val_recall: 0.1911\n",
            "Epoch 94/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6777 - auc: 0.7022 - loss: 0.6494 - precision: 0.6774 - recall: 0.3296 - val_accuracy: 0.6274 - val_auc: 0.6354 - val_loss: 0.6584 - val_precision: 0.4915 - val_recall: 0.1847\n",
            "Epoch 95/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6588 - auc: 0.6805 - loss: 0.6465 - precision: 0.5922 - recall: 0.2850 - val_accuracy: 0.6297 - val_auc: 0.6327 - val_loss: 0.6600 - val_precision: 0.5000 - val_recall: 0.1720\n",
            "Epoch 96/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6806 - auc: 0.6857 - loss: 0.6435 - precision: 0.6413 - recall: 0.2930 - val_accuracy: 0.6344 - val_auc: 0.6350 - val_loss: 0.6588 - val_precision: 0.5167 - val_recall: 0.1975\n",
            "Epoch 97/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6651 - auc: 0.6679 - loss: 0.6519 - precision: 0.6064 - recall: 0.3021 - val_accuracy: 0.6321 - val_auc: 0.6331 - val_loss: 0.6597 - val_precision: 0.5085 - val_recall: 0.1911\n",
            "Epoch 98/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6663 - auc: 0.6856 - loss: 0.6462 - precision: 0.5991 - recall: 0.2859 - val_accuracy: 0.6321 - val_auc: 0.6327 - val_loss: 0.6598 - val_precision: 0.5072 - val_recall: 0.2229\n",
            "Epoch 99/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6863 - auc: 0.6935 - loss: 0.6396 - precision: 0.6385 - recall: 0.3610 - val_accuracy: 0.6226 - val_auc: 0.6300 - val_loss: 0.6627 - val_precision: 0.4754 - val_recall: 0.1847\n",
            "Epoch 100/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6777 - auc: 0.6886 - loss: 0.6396 - precision: 0.6230 - recall: 0.3069 - val_accuracy: 0.6274 - val_auc: 0.6327 - val_loss: 0.6594 - val_precision: 0.4923 - val_recall: 0.2038\n",
            "Epoch 101/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6858 - auc: 0.7068 - loss: 0.6254 - precision: 0.6128 - recall: 0.3003 - val_accuracy: 0.6274 - val_auc: 0.6321 - val_loss: 0.6608 - val_precision: 0.4930 - val_recall: 0.2229\n",
            "Epoch 102/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6732 - auc: 0.6751 - loss: 0.6387 - precision: 0.5825 - recall: 0.3161 - val_accuracy: 0.6226 - val_auc: 0.6366 - val_loss: 0.6579 - val_precision: 0.4776 - val_recall: 0.2038\n",
            "Epoch 103/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6850 - auc: 0.6890 - loss: 0.6364 - precision: 0.6268 - recall: 0.2991 - val_accuracy: 0.6297 - val_auc: 0.6341 - val_loss: 0.6585 - val_precision: 0.5000 - val_recall: 0.1911\n",
            "Epoch 104/150\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6710 - auc: 0.6743 - loss: 0.6471 - precision: 0.5985 - recall: 0.3199 - val_accuracy: 0.6368 - val_auc: 0.6277 - val_loss: 0.6616 - val_precision: 0.5195 - val_recall: 0.2548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_epoch = np.argmin(history.history['val_loss'])\n",
        "print(f\"Best Epoch: {best_epoch+1}\")\n",
        "print(f\"Train Accuracy at Best Epoch: {history.history['accuracy'][best_epoch]:.4f}\")\n",
        "print(f\"Val Accuracy at Best Epoch: {history.history['val_accuracy'][best_epoch]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBK6hXpY5xre",
        "outputId": "78786dcc-5ccb-439f-bc97-d1f06ed67135"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Epoch: 102\n",
            "Train Accuracy at Best Epoch: 0.6683\n",
            "Val Accuracy at Best Epoch: 0.6226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy, test_precision, test_recall, test_auc = tamanda_model.evaluate(X_test, y_test, verbose=1)\n",
        "\n",
        "# Print results with clear formatting\n",
        "print(\"\\nTest Evaluation Metrics:\")\n",
        "print(f\"  Loss      : {test_loss:.4f}\")\n",
        "print(f\"  Accuracy  : {test_accuracy:.4f}\")\n",
        "print(f\"  Precision : {test_precision:.4f}\")\n",
        "print(f\"  Recall    : {test_recall:.4f}\")\n",
        "print(f\"  AUC       : {test_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5tLv1NT56Xr",
        "outputId": "351c15a2-db0b-4689-8d16-542b40805ed8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6803 - auc: 0.7034 - loss: 0.6448 - precision: 0.6429 - recall: 0.3840\n",
            "\n",
            "Test Evaluation Metrics:\n",
            "  Loss      : 0.6439\n",
            "  Accuracy  : 0.6988\n",
            "  Precision : 0.6747\n",
            "  Recall    : 0.3567\n",
            "  AUC       : 0.6926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Definition by member 5\n",
        "def model_name_of_student():\n",
        "\n",
        "  return"
      ],
      "metadata": {
        "id": "Dd3m8M3dKcfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start the training Process"
      ],
      "metadata": {
        "id": "hDSPmAB9jkrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#fit model\n",
        "history = model.fit(X, Y, validation_data=(testX, testy), epochs=4000, verbose=0, callbacks=[es])\n",
        "# evaluate the model\n",
        "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
        "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
        "# plot training history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "OWQHapf3jlYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy"
      ],
      "metadata": {
        "id": "dKZ2T8TOIYxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Loading and Preprocessing\n",
        "# The coach will never do this!!\n",
        "regularizer = 'l1'"
      ],
      "metadata": {
        "id": "qMNag3BGIuwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(32, activation ='relu', kernel_regularizer= regularizer , input_shape = (2224,224)))\n",
        "model.add(Dropout(0.2))\n",
        "#adding Dropout\n",
        "model.add(Dense(64, activation ='relu', kernel_regularizer= regularizer , input_shape = (2224,224)))\n",
        "#adding Dropout\n",
        "model.add(Dense(128, activation ='relu', kernel_regularizer= regularizer , input_shape = (2224,224)))\n",
        "model.add(Dropout(0.2))\n",
        "#adding Dropout\n",
        "model.add(Dense(2, activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "fsmEC739I4lG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback =EarlyStopping(monitor='loss',patience=3)"
      ],
      "metadata": {
        "id": "BbyPgkZlLu37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss= 'rmse', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "Fw9XQj_ZMWUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, Y, epochs=1000, batch_size= 128, callbacks=[callback], verbose=0)"
      ],
      "metadata": {
        "id": "GPhb-1k7LGx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "wLlhrOCpJWF5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}