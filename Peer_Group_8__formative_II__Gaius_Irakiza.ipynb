{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IrakizaGaius/PeerGroup8WaterQualityModel/blob/main/Peer_Group_8__formative_II__Gaius_Irakiza.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrXv0rU9sIma"
      },
      "source": [
        "# Excercise - Creating our own custom Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJyZUDbzBTIG"
      },
      "source": [
        "This is a notebook that provides a quick overview of how to create your own custom model. You will be creating a simple model.\n",
        "You will be utilizing Keras and Tensorflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvLegMMvBZYg"
      },
      "source": [
        "## Water Quality Dataset\n",
        "\n",
        "This dataset contains water quality measurements and assessments related to potability, which is the suitability of water for human consumption. The dataset's primary objective is to provide insights into water quality parameters and assist in determining whether the water is potable or not. Each row in the dataset represents a water sample with specific attributes, and the \"Potability\" column indicates whether the water is suitable for consumption.\n",
        "\n",
        "https://www.kaggle.com/datasets/uom190346a/water-quality-and-potability?select=water_potability.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qvnx0_dT3JEq"
      },
      "outputs": [],
      "source": [
        "#LOAD THE DATA\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "data = pd.read_csv(\"/content/water_potability.csv\")\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, roc_auc_score, f1_score\n",
        "\n",
        "data.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mn2ks1y4rG2i"
      },
      "outputs": [],
      "source": [
        "# Information on the data\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJvnnIxav4N2"
      },
      "outputs": [],
      "source": [
        "# Brief overview of the dataset statistics\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5Rjjxwg5XnF"
      },
      "outputs": [],
      "source": [
        "# drop duplicates rows of data\n",
        "\n",
        "data = data.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjFnkhc35ekL"
      },
      "outputs": [],
      "source": [
        "# percentage of missingness in the data for each column\n",
        "\n",
        "missing = data.isnull().mean()*100\n",
        "print(missing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlhnFruS2q0X"
      },
      "outputs": [],
      "source": [
        "# MICE IMPUTATION to fill the missing data\n",
        "# create the imputer using MICE\n",
        "\n",
        "# separate the target variable from the rest of the data to make sure it is not changed or imputed\n",
        "features = data.drop(columns='Potability')\n",
        "target = data.Potability\n",
        "imputer = IterativeImputer(random_state=0)\n",
        "features_imputed = imputer.fit_transform(features)\n",
        "\n",
        "# convert the data back into a dataframe\n",
        "features_imputed = pd.DataFrame(features_imputed, columns=features.columns)\n",
        "\n",
        "# merge target variable and data\n",
        "data_imputed = pd.concat([features_imputed, target], axis=1)\n",
        "data_imputed.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58zqnGV23ZSx"
      },
      "outputs": [],
      "source": [
        "# confirm imputed data\n",
        "data_imputed.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIdMxexk47Qa"
      },
      "outputs": [],
      "source": [
        "# Remove outliers that may affect the neural network's accuracy using IQR method\n",
        "def remove_outliers_iqr(df, column_name):\n",
        "    Q1 = df[column_name].quantile(0.25)\n",
        "    Q3 = df[column_name].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    # anything above or below this is an outlier\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # place outliers in a data frame\n",
        "    print(f\"{df[column_name]}\")\n",
        "    outliers = df[(df[column_name] < lower_bound) | (df[column_name] > upper_bound)]\n",
        "    print(f\"Number of outliers: {len(outliers)}\")\n",
        "    print(f\"Percentage of outliers: {len(outliers)/len(df)*100:.2f}%\")\n",
        "\n",
        "    # remove outliers\n",
        "\n",
        "    df_clean = df[(df[column_name] >= lower_bound) & (df[column_name] <= upper_bound)]\n",
        "\n",
        "    return df_clean\n",
        "\n",
        "# columns to remove outliers in\n",
        "columns = ['Hardness', 'Solids', 'Sulfate', 'Conductivity', 'Organic_carbon', 'Trihalomethanes', 'Turbidity']\n",
        "\n",
        "data_imputed_copy = data_imputed.copy()\n",
        "\n",
        "for i in columns:\n",
        "  data_imputed_copy = remove_outliers_iqr(data_imputed_copy, i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QfR0r8cGVU7"
      },
      "source": [
        "Plot the Data Appropriately"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PF9lHguSY2vB"
      },
      "outputs": [],
      "source": [
        "# Transforms data to have mean=0 and standard deviation=1\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X = data_imputed_copy.drop(columns='Potability', axis=1)\n",
        "y= data_imputed_copy['Potability']\n",
        "\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "X_scaled.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfSk1lXRYjrh"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Split the data into training validation and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3,random_state=42,\n",
        "    stratify=y               # Keep same class distribution in all splits\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5,stratify=y_temp)\n",
        "\n",
        "print(f\"\\n=== FINAL SHAPES ===\")\n",
        "print(f\"X_train: {X_train.shape}\")\n",
        "print(f\"X_val: {X_val.shape}\")\n",
        "print(f\"X_test: {X_test.shape}\")\n",
        "print(f\"y_train: {y_train.shape}\")\n",
        "print(f\"y_val: {y_val.shape}\")\n",
        "print(f\"y_test: {y_test.shape}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvjIHLrcGhzc"
      },
      "source": [
        "# Each Member Defines their model Here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "hmWIUNw0-l0y",
        "outputId": "59e2272d-efb0-4e14-e710-fd739d2c2afa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.6041 - auc: 0.4948 - loss: 1.3957 - precision: 0.3826 - recall: 0.0671 - val_accuracy: 0.5255 - val_auc: 0.5393 - val_loss: 1.1891 - val_precision: 0.4045 - val_recall: 0.4660\n",
            "Epoch 2/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6032 - auc: 0.5069 - loss: 1.1196 - precision: 0.3519 - recall: 0.0387 - val_accuracy: 0.6110 - val_auc: 0.5117 - val_loss: 0.9760 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5936 - auc: 0.5307 - loss: 0.9454 - precision: 0.4276 - recall: 0.0508 - val_accuracy: 0.6110 - val_auc: 0.5411 - val_loss: 0.8574 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5971 - auc: 0.5416 - loss: 0.8506 - precision: 0.3406 - recall: 0.0273 - val_accuracy: 0.6110 - val_auc: 0.5419 - val_loss: 0.8036 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 5/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6210 - auc: 0.5921 - loss: 0.7825 - precision: 0.5644 - recall: 0.1091 - val_accuracy: 0.6293 - val_auc: 0.5855 - val_loss: 0.7589 - val_precision: 0.9091 - val_recall: 0.0524\n",
            "Epoch 6/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6450 - auc: 0.6000 - loss: 0.7438 - precision: 0.6218 - recall: 0.1786 - val_accuracy: 0.6436 - val_auc: 0.6513 - val_loss: 0.7132 - val_precision: 0.7353 - val_recall: 0.1309\n",
            "Epoch 7/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6466 - auc: 0.6319 - loss: 0.7066 - precision: 0.5774 - recall: 0.2390 - val_accuracy: 0.5906 - val_auc: 0.5594 - val_loss: 0.7388 - val_precision: 0.4324 - val_recall: 0.1675\n",
            "Epoch 8/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6366 - auc: 0.6106 - loss: 0.7280 - precision: 0.5895 - recall: 0.2986 - val_accuracy: 0.6253 - val_auc: 0.6240 - val_loss: 0.7136 - val_precision: 0.5220 - val_recall: 0.4346\n",
            "Epoch 9/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6507 - auc: 0.6359 - loss: 0.7019 - precision: 0.5978 - recall: 0.2776 - val_accuracy: 0.6741 - val_auc: 0.6540 - val_loss: 0.6817 - val_precision: 0.6220 - val_recall: 0.4136\n",
            "Epoch 10/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6420 - auc: 0.6568 - loss: 0.6850 - precision: 0.5651 - recall: 0.3245 - val_accuracy: 0.6517 - val_auc: 0.6348 - val_loss: 0.6916 - val_precision: 0.6087 - val_recall: 0.2932\n",
            "Epoch 11/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6597 - auc: 0.6451 - loss: 0.6854 - precision: 0.6186 - recall: 0.3152 - val_accuracy: 0.6130 - val_auc: 0.6295 - val_loss: 0.7025 - val_precision: 0.5032 - val_recall: 0.4084\n",
            "Epoch 12/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6461 - auc: 0.6617 - loss: 0.6819 - precision: 0.5880 - recall: 0.3194 - val_accuracy: 0.6619 - val_auc: 0.6723 - val_loss: 0.6714 - val_precision: 0.6344 - val_recall: 0.3089\n",
            "Epoch 13/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6653 - auc: 0.6488 - loss: 0.6741 - precision: 0.6278 - recall: 0.2973 - val_accuracy: 0.6619 - val_auc: 0.6748 - val_loss: 0.6636 - val_precision: 0.6147 - val_recall: 0.3508\n",
            "Epoch 14/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6564 - auc: 0.6677 - loss: 0.6812 - precision: 0.6450 - recall: 0.3535 - val_accuracy: 0.6599 - val_auc: 0.6647 - val_loss: 0.6631 - val_precision: 0.6224 - val_recall: 0.3194\n",
            "Epoch 15/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6494 - auc: 0.6673 - loss: 0.6733 - precision: 0.6083 - recall: 0.2974 - val_accuracy: 0.6599 - val_auc: 0.6595 - val_loss: 0.6782 - val_precision: 0.6364 - val_recall: 0.2932\n",
            "Epoch 16/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6558 - auc: 0.6688 - loss: 0.6768 - precision: 0.6028 - recall: 0.3371 - val_accuracy: 0.5703 - val_auc: 0.5883 - val_loss: 0.7307 - val_precision: 0.4545 - val_recall: 0.5236\n",
            "Epoch 17/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6536 - auc: 0.6783 - loss: 0.6839 - precision: 0.6684 - recall: 0.3430 - val_accuracy: 0.6191 - val_auc: 0.6359 - val_loss: 0.6914 - val_precision: 0.5135 - val_recall: 0.3979\n",
            "Epoch 18/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6680 - auc: 0.6790 - loss: 0.6693 - precision: 0.6499 - recall: 0.3132 - val_accuracy: 0.6599 - val_auc: 0.6789 - val_loss: 0.6671 - val_precision: 0.5923 - val_recall: 0.4031\n",
            "Epoch 19/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6544 - auc: 0.6668 - loss: 0.6813 - precision: 0.6288 - recall: 0.3563 - val_accuracy: 0.6599 - val_auc: 0.6789 - val_loss: 0.6693 - val_precision: 0.5968 - val_recall: 0.3874\n",
            "Epoch 20/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6697 - auc: 0.6800 - loss: 0.6684 - precision: 0.6193 - recall: 0.3848 - val_accuracy: 0.6151 - val_auc: 0.6502 - val_loss: 0.6882 - val_precision: 0.5052 - val_recall: 0.5131\n",
            "Epoch 21/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6480 - auc: 0.6753 - loss: 0.6731 - precision: 0.5747 - recall: 0.3687 - val_accuracy: 0.6721 - val_auc: 0.6683 - val_loss: 0.6706 - val_precision: 0.6190 - val_recall: 0.4084\n",
            "Epoch 22/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6650 - auc: 0.6742 - loss: 0.6771 - precision: 0.6755 - recall: 0.3691 - val_accuracy: 0.6456 - val_auc: 0.6560 - val_loss: 0.7123 - val_precision: 0.5630 - val_recall: 0.3979\n",
            "Epoch 23/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6760 - auc: 0.6770 - loss: 0.6663 - precision: 0.6247 - recall: 0.3407 - val_accuracy: 0.6741 - val_auc: 0.6692 - val_loss: 0.6798 - val_precision: 0.6598 - val_recall: 0.3351\n",
            "Epoch 24/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6552 - auc: 0.6843 - loss: 0.6757 - precision: 0.5947 - recall: 0.4153 - val_accuracy: 0.6517 - val_auc: 0.6704 - val_loss: 0.6719 - val_precision: 0.5820 - val_recall: 0.3717\n",
            "Epoch 25/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6740 - auc: 0.6873 - loss: 0.6640 - precision: 0.6121 - recall: 0.3931 - val_accuracy: 0.6517 - val_auc: 0.6430 - val_loss: 0.7223 - val_precision: 0.6250 - val_recall: 0.2618\n",
            "Epoch 26/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6617 - auc: 0.6667 - loss: 0.6856 - precision: 0.6600 - recall: 0.3454 - val_accuracy: 0.5967 - val_auc: 0.6245 - val_loss: 0.7081 - val_precision: 0.4837 - val_recall: 0.5445\n",
            "Epoch 27/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6684 - auc: 0.7035 - loss: 0.6593 - precision: 0.6251 - recall: 0.3866 - val_accuracy: 0.6578 - val_auc: 0.6756 - val_loss: 0.6677 - val_precision: 0.6055 - val_recall: 0.3455\n",
            "Epoch 28/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6625 - auc: 0.6889 - loss: 0.6637 - precision: 0.5925 - recall: 0.3751 - val_accuracy: 0.6701 - val_auc: 0.6920 - val_loss: 0.6618 - val_precision: 0.6058 - val_recall: 0.4346\n",
            "Epoch 29/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6664 - auc: 0.6834 - loss: 0.6685 - precision: 0.6180 - recall: 0.3851 - val_accuracy: 0.6680 - val_auc: 0.6885 - val_loss: 0.6619 - val_precision: 0.6628 - val_recall: 0.2984\n",
            "Epoch 30/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6620 - auc: 0.6899 - loss: 0.6667 - precision: 0.6103 - recall: 0.3935 - val_accuracy: 0.5621 - val_auc: 0.6405 - val_loss: 0.7578 - val_precision: 0.4577 - val_recall: 0.6806\n",
            "Epoch 31/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6520 - auc: 0.6775 - loss: 0.6701 - precision: 0.5610 - recall: 0.3312 - val_accuracy: 0.6049 - val_auc: 0.6362 - val_loss: 0.7032 - val_precision: 0.4921 - val_recall: 0.4869\n",
            "Epoch 32/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6589 - auc: 0.7105 - loss: 0.6565 - precision: 0.6050 - recall: 0.4444 - val_accuracy: 0.6538 - val_auc: 0.6580 - val_loss: 0.7492 - val_precision: 0.7143 - val_recall: 0.1832\n",
            "Epoch 33/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6537 - auc: 0.6846 - loss: 0.6732 - precision: 0.5920 - recall: 0.4173 - val_accuracy: 0.6640 - val_auc: 0.6748 - val_loss: 0.6779 - val_precision: 0.6806 - val_recall: 0.2565\n",
            "Epoch 34/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6709 - auc: 0.7040 - loss: 0.6562 - precision: 0.6283 - recall: 0.3914 - val_accuracy: 0.6130 - val_auc: 0.6491 - val_loss: 0.6982 - val_precision: 0.5023 - val_recall: 0.5654\n",
            "Epoch 35/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6756 - auc: 0.6987 - loss: 0.6604 - precision: 0.6556 - recall: 0.3929 - val_accuracy: 0.6151 - val_auc: 0.6310 - val_loss: 0.7070 - val_precision: 0.5058 - val_recall: 0.4555\n",
            "Epoch 36/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6611 - auc: 0.6915 - loss: 0.6691 - precision: 0.6129 - recall: 0.3506 - val_accuracy: 0.6640 - val_auc: 0.6743 - val_loss: 0.6632 - val_precision: 0.6226 - val_recall: 0.3455\n",
            "Epoch 37/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6889 - auc: 0.7113 - loss: 0.6523 - precision: 0.6543 - recall: 0.4550 - val_accuracy: 0.6273 - val_auc: 0.6707 - val_loss: 0.6862 - val_precision: 0.5204 - val_recall: 0.5340\n",
            "Epoch 38/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6674 - auc: 0.6843 - loss: 0.6703 - precision: 0.6473 - recall: 0.3563 - val_accuracy: 0.6782 - val_auc: 0.6769 - val_loss: 0.6937 - val_precision: 0.8511 - val_recall: 0.2094\n",
            "Epoch 39/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6542 - auc: 0.6617 - loss: 0.6795 - precision: 0.5949 - recall: 0.3335 - val_accuracy: 0.6619 - val_auc: 0.6769 - val_loss: 0.6688 - val_precision: 0.6238 - val_recall: 0.3298\n",
            "Epoch 40/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6746 - auc: 0.6946 - loss: 0.6595 - precision: 0.6223 - recall: 0.3833 - val_accuracy: 0.5682 - val_auc: 0.6537 - val_loss: 0.7145 - val_precision: 0.4613 - val_recall: 0.6545\n",
            "Epoch 41/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6822 - auc: 0.6766 - loss: 0.6697 - precision: 0.6702 - recall: 0.3781 - val_accuracy: 0.6640 - val_auc: 0.6888 - val_loss: 0.6603 - val_precision: 0.6083 - val_recall: 0.3822\n",
            "Epoch 42/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6607 - auc: 0.6740 - loss: 0.6705 - precision: 0.5799 - recall: 0.3933 - val_accuracy: 0.6578 - val_auc: 0.6757 - val_loss: 0.6662 - val_precision: 0.5804 - val_recall: 0.4346\n",
            "Epoch 43/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6722 - auc: 0.6992 - loss: 0.6579 - precision: 0.6219 - recall: 0.3867 - val_accuracy: 0.6762 - val_auc: 0.6679 - val_loss: 0.6692 - val_precision: 0.7000 - val_recall: 0.2932\n",
            "Epoch 44/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6673 - auc: 0.6867 - loss: 0.6698 - precision: 0.6203 - recall: 0.3539 - val_accuracy: 0.6721 - val_auc: 0.6814 - val_loss: 0.6688 - val_precision: 0.6000 - val_recall: 0.4712\n",
            "Epoch 45/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6657 - auc: 0.6895 - loss: 0.6601 - precision: 0.5774 - recall: 0.3577 - val_accuracy: 0.6415 - val_auc: 0.6697 - val_loss: 0.6636 - val_precision: 0.5472 - val_recall: 0.4555\n",
            "Epoch 46/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6567 - auc: 0.6962 - loss: 0.6526 - precision: 0.5746 - recall: 0.4552 - val_accuracy: 0.6273 - val_auc: 0.6668 - val_loss: 0.6875 - val_precision: 0.5182 - val_recall: 0.5969\n",
            "Epoch 47/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6619 - auc: 0.7046 - loss: 0.6545 - precision: 0.6054 - recall: 0.4156 - val_accuracy: 0.6599 - val_auc: 0.6662 - val_loss: 0.6640 - val_precision: 0.5789 - val_recall: 0.4607\n",
            "Epoch 48/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6639 - auc: 0.6899 - loss: 0.6612 - precision: 0.6108 - recall: 0.3896 - val_accuracy: 0.6701 - val_auc: 0.6690 - val_loss: 0.6633 - val_precision: 0.6107 - val_recall: 0.4188\n",
            "Epoch 49/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6806 - auc: 0.6865 - loss: 0.6587 - precision: 0.6684 - recall: 0.3772 - val_accuracy: 0.6477 - val_auc: 0.6882 - val_loss: 0.6586 - val_precision: 0.5643 - val_recall: 0.4136\n",
            "Epoch 50/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6565 - auc: 0.6881 - loss: 0.6733 - precision: 0.6065 - recall: 0.3632 - val_accuracy: 0.6762 - val_auc: 0.6721 - val_loss: 0.6613 - val_precision: 0.6538 - val_recall: 0.3560\n",
            "Epoch 51/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6676 - auc: 0.7099 - loss: 0.6496 - precision: 0.6300 - recall: 0.3792 - val_accuracy: 0.5458 - val_auc: 0.6583 - val_loss: 0.7626 - val_precision: 0.4524 - val_recall: 0.7958\n",
            "Epoch 52/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6748 - auc: 0.7077 - loss: 0.6595 - precision: 0.6354 - recall: 0.3648 - val_accuracy: 0.6375 - val_auc: 0.6695 - val_loss: 0.6762 - val_precision: 0.5344 - val_recall: 0.5288\n",
            "Epoch 53/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6816 - auc: 0.7042 - loss: 0.6518 - precision: 0.6718 - recall: 0.3873 - val_accuracy: 0.6497 - val_auc: 0.6696 - val_loss: 0.6687 - val_precision: 0.5760 - val_recall: 0.3770\n",
            "Epoch 54/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6708 - auc: 0.7016 - loss: 0.6566 - precision: 0.6206 - recall: 0.3763 - val_accuracy: 0.6701 - val_auc: 0.6670 - val_loss: 0.6744 - val_precision: 0.7458 - val_recall: 0.2304\n",
            "Epoch 55/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6771 - auc: 0.7116 - loss: 0.6460 - precision: 0.5992 - recall: 0.4169 - val_accuracy: 0.6354 - val_auc: 0.6737 - val_loss: 0.6757 - val_precision: 0.5280 - val_recall: 0.5916\n",
            "Epoch 56/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6682 - auc: 0.7093 - loss: 0.6594 - precision: 0.6410 - recall: 0.4255 - val_accuracy: 0.6701 - val_auc: 0.6968 - val_loss: 0.6522 - val_precision: 0.6835 - val_recall: 0.2827\n",
            "Epoch 57/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6825 - auc: 0.7169 - loss: 0.6540 - precision: 0.6751 - recall: 0.3917 - val_accuracy: 0.6008 - val_auc: 0.6664 - val_loss: 0.7021 - val_precision: 0.4894 - val_recall: 0.6021\n",
            "Epoch 58/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6750 - auc: 0.7089 - loss: 0.6634 - precision: 0.6263 - recall: 0.4287 - val_accuracy: 0.5988 - val_auc: 0.6513 - val_loss: 0.6989 - val_precision: 0.4876 - val_recall: 0.6178\n",
            "Epoch 59/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6773 - auc: 0.7125 - loss: 0.6518 - precision: 0.6776 - recall: 0.3638 - val_accuracy: 0.6640 - val_auc: 0.6750 - val_loss: 0.6634 - val_precision: 0.6444 - val_recall: 0.3037\n",
            "Epoch 60/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6794 - auc: 0.6984 - loss: 0.6497 - precision: 0.6160 - recall: 0.3824 - val_accuracy: 0.6660 - val_auc: 0.6795 - val_loss: 0.6593 - val_precision: 0.7368 - val_recall: 0.2199\n",
            "Epoch 61/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6680 - auc: 0.6934 - loss: 0.6580 - precision: 0.6294 - recall: 0.3814 - val_accuracy: 0.6701 - val_auc: 0.6850 - val_loss: 0.6628 - val_precision: 0.7636 - val_recall: 0.2199\n",
            "Epoch 62/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6650 - auc: 0.6929 - loss: 0.6573 - precision: 0.6107 - recall: 0.3978 - val_accuracy: 0.6456 - val_auc: 0.6512 - val_loss: 0.6652 - val_precision: 0.5659 - val_recall: 0.3822\n",
            "Epoch 63/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6825 - auc: 0.6853 - loss: 0.6472 - precision: 0.6047 - recall: 0.3715 - val_accuracy: 0.6558 - val_auc: 0.6679 - val_loss: 0.6806 - val_precision: 0.6170 - val_recall: 0.3037\n",
            "Epoch 64/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6567 - auc: 0.7009 - loss: 0.6577 - precision: 0.5895 - recall: 0.4139 - val_accuracy: 0.6395 - val_auc: 0.6648 - val_loss: 0.6673 - val_precision: 0.5522 - val_recall: 0.3874\n",
            "Epoch 65/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6650 - auc: 0.6963 - loss: 0.6614 - precision: 0.6153 - recall: 0.4049 - val_accuracy: 0.6110 - val_auc: 0.6453 - val_loss: 0.6884 - val_precision: 0.5000 - val_recall: 0.5288\n",
            "Epoch 66/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6839 - auc: 0.7003 - loss: 0.6536 - precision: 0.6528 - recall: 0.3770 - val_accuracy: 0.6130 - val_auc: 0.6552 - val_loss: 0.6816 - val_precision: 0.5026 - val_recall: 0.5079\n",
            "Epoch 67/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6634 - auc: 0.7070 - loss: 0.6526 - precision: 0.6057 - recall: 0.3844 - val_accuracy: 0.6375 - val_auc: 0.6517 - val_loss: 0.6661 - val_precision: 0.5520 - val_recall: 0.3613\n",
            "Epoch 68/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6808 - auc: 0.7179 - loss: 0.6392 - precision: 0.6436 - recall: 0.3978 - val_accuracy: 0.6069 - val_auc: 0.6560 - val_loss: 0.6905 - val_precision: 0.4952 - val_recall: 0.5393\n",
            "Epoch 69/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6851 - auc: 0.7088 - loss: 0.6487 - precision: 0.6734 - recall: 0.4080 - val_accuracy: 0.6334 - val_auc: 0.6725 - val_loss: 0.6565 - val_precision: 0.5433 - val_recall: 0.3613\n",
            "Epoch 70/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6652 - auc: 0.6995 - loss: 0.6689 - precision: 0.6491 - recall: 0.4209 - val_accuracy: 0.6701 - val_auc: 0.6743 - val_loss: 0.6615 - val_precision: 0.6495 - val_recall: 0.3298\n",
            "Epoch 71/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6726 - auc: 0.6852 - loss: 0.6601 - precision: 0.6237 - recall: 0.3702 - val_accuracy: 0.6517 - val_auc: 0.6701 - val_loss: 0.6674 - val_precision: 0.5806 - val_recall: 0.3770\n",
            "Epoch 72/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6692 - auc: 0.7071 - loss: 0.6514 - precision: 0.6429 - recall: 0.3875 - val_accuracy: 0.6762 - val_auc: 0.6877 - val_loss: 0.6776 - val_precision: 0.6778 - val_recall: 0.3194\n",
            "Epoch 73/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6794 - auc: 0.7090 - loss: 0.6663 - precision: 0.6328 - recall: 0.4494 - val_accuracy: 0.6599 - val_auc: 0.6544 - val_loss: 0.6806 - val_precision: 0.6132 - val_recall: 0.3403\n",
            "Epoch 74/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6873 - auc: 0.7123 - loss: 0.6523 - precision: 0.6597 - recall: 0.4127 - val_accuracy: 0.6680 - val_auc: 0.6880 - val_loss: 0.6986 - val_precision: 0.7121 - val_recall: 0.2461\n",
            "Epoch 75/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6839 - auc: 0.7170 - loss: 0.6498 - precision: 0.6529 - recall: 0.4349 - val_accuracy: 0.6660 - val_auc: 0.6803 - val_loss: 0.6569 - val_precision: 0.5957 - val_recall: 0.4398\n",
            "Epoch 76/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6860 - auc: 0.7205 - loss: 0.6420 - precision: 0.6440 - recall: 0.4169 - val_accuracy: 0.6477 - val_auc: 0.6791 - val_loss: 0.6668 - val_precision: 0.5692 - val_recall: 0.3874\n",
            "Epoch 77/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6823 - auc: 0.7211 - loss: 0.6419 - precision: 0.6182 - recall: 0.4250 - val_accuracy: 0.6864 - val_auc: 0.6840 - val_loss: 0.6611 - val_precision: 0.7126 - val_recall: 0.3246\n",
            "Epoch 78/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6792 - auc: 0.7115 - loss: 0.6477 - precision: 0.6147 - recall: 0.3929 - val_accuracy: 0.6273 - val_auc: 0.6746 - val_loss: 0.6722 - val_precision: 0.5217 - val_recall: 0.5026\n",
            "Epoch 79/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6719 - auc: 0.7086 - loss: 0.6557 - precision: 0.6491 - recall: 0.4126 - val_accuracy: 0.6578 - val_auc: 0.6826 - val_loss: 0.6568 - val_precision: 0.6075 - val_recall: 0.3403\n",
            "Epoch 80/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6732 - auc: 0.7169 - loss: 0.6449 - precision: 0.6328 - recall: 0.3766 - val_accuracy: 0.6660 - val_auc: 0.6846 - val_loss: 0.6608 - val_precision: 0.8293 - val_recall: 0.1780\n",
            "Epoch 81/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6681 - auc: 0.7162 - loss: 0.6462 - precision: 0.6330 - recall: 0.4195 - val_accuracy: 0.6660 - val_auc: 0.6802 - val_loss: 0.6570 - val_precision: 0.6452 - val_recall: 0.3141\n",
            "Epoch 82/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6457 - auc: 0.6963 - loss: 0.6532 - precision: 0.5773 - recall: 0.3964 - val_accuracy: 0.6558 - val_auc: 0.6818 - val_loss: 0.6525 - val_precision: 0.5764 - val_recall: 0.4346\n",
            "Epoch 83/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6635 - auc: 0.7050 - loss: 0.6503 - precision: 0.5981 - recall: 0.3876 - val_accuracy: 0.6578 - val_auc: 0.6716 - val_loss: 0.6613 - val_precision: 0.6237 - val_recall: 0.3037\n",
            "Epoch 84/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6709 - auc: 0.7004 - loss: 0.6439 - precision: 0.5802 - recall: 0.4154 - val_accuracy: 0.6558 - val_auc: 0.6842 - val_loss: 0.6556 - val_precision: 0.5873 - val_recall: 0.3874\n",
            "Epoch 85/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6717 - auc: 0.7078 - loss: 0.6474 - precision: 0.6373 - recall: 0.4418 - val_accuracy: 0.6599 - val_auc: 0.6629 - val_loss: 0.6639 - val_precision: 0.5822 - val_recall: 0.4450\n",
            "Epoch 86/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6843 - auc: 0.6976 - loss: 0.6455 - precision: 0.6400 - recall: 0.4012 - val_accuracy: 0.6660 - val_auc: 0.6887 - val_loss: 0.6502 - val_precision: 0.6154 - val_recall: 0.3770\n",
            "Epoch 87/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6770 - auc: 0.7064 - loss: 0.6467 - precision: 0.6488 - recall: 0.4081 - val_accuracy: 0.6640 - val_auc: 0.6855 - val_loss: 0.6625 - val_precision: 0.6204 - val_recall: 0.3508\n",
            "Epoch 88/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6666 - auc: 0.6917 - loss: 0.6570 - precision: 0.6090 - recall: 0.3826 - val_accuracy: 0.6477 - val_auc: 0.6689 - val_loss: 0.6643 - val_precision: 0.5662 - val_recall: 0.4031\n",
            "Epoch 89/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6624 - auc: 0.7029 - loss: 0.6572 - precision: 0.6076 - recall: 0.4121 - val_accuracy: 0.6619 - val_auc: 0.6703 - val_loss: 0.6531 - val_precision: 0.6316 - val_recall: 0.3141\n",
            "Epoch 90/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6773 - auc: 0.7036 - loss: 0.6459 - precision: 0.6377 - recall: 0.4067 - val_accuracy: 0.6680 - val_auc: 0.6997 - val_loss: 0.6423 - val_precision: 0.6148 - val_recall: 0.3927\n",
            "Epoch 91/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6678 - auc: 0.6986 - loss: 0.6425 - precision: 0.5726 - recall: 0.3891 - val_accuracy: 0.6599 - val_auc: 0.6855 - val_loss: 0.6532 - val_precision: 0.5811 - val_recall: 0.4503\n",
            "Epoch 92/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6943 - auc: 0.7266 - loss: 0.6315 - precision: 0.6374 - recall: 0.4633 - val_accuracy: 0.6823 - val_auc: 0.6897 - val_loss: 0.6444 - val_precision: 0.6471 - val_recall: 0.4031\n",
            "Epoch 93/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6667 - auc: 0.6920 - loss: 0.6519 - precision: 0.6240 - recall: 0.3579 - val_accuracy: 0.6660 - val_auc: 0.6763 - val_loss: 0.6480 - val_precision: 0.6484 - val_recall: 0.3089\n",
            "Epoch 94/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6944 - auc: 0.7281 - loss: 0.6229 - precision: 0.6544 - recall: 0.4273 - val_accuracy: 0.6334 - val_auc: 0.6543 - val_loss: 0.6847 - val_precision: 0.5369 - val_recall: 0.4188\n",
            "Epoch 95/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6664 - auc: 0.7187 - loss: 0.6540 - precision: 0.6440 - recall: 0.4150 - val_accuracy: 0.6619 - val_auc: 0.6835 - val_loss: 0.6594 - val_precision: 0.5776 - val_recall: 0.4869\n",
            "Epoch 96/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6671 - auc: 0.6897 - loss: 0.6660 - precision: 0.6653 - recall: 0.3765 - val_accuracy: 0.6558 - val_auc: 0.6656 - val_loss: 0.6690 - val_precision: 0.5797 - val_recall: 0.4188\n",
            "Epoch 97/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6977 - auc: 0.7189 - loss: 0.6366 - precision: 0.6652 - recall: 0.4197 - val_accuracy: 0.6599 - val_auc: 0.6741 - val_loss: 0.6529 - val_precision: 0.5938 - val_recall: 0.3979\n",
            "Epoch 98/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6768 - auc: 0.7004 - loss: 0.6446 - precision: 0.5963 - recall: 0.4025 - val_accuracy: 0.6782 - val_auc: 0.6771 - val_loss: 0.6664 - val_precision: 0.6737 - val_recall: 0.3351\n",
            "Epoch 99/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6850 - auc: 0.7206 - loss: 0.6428 - precision: 0.6428 - recall: 0.4386 - val_accuracy: 0.6660 - val_auc: 0.6826 - val_loss: 0.6659 - val_precision: 0.6517 - val_recall: 0.3037\n",
            "Epoch 100/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6534 - auc: 0.6796 - loss: 0.6587 - precision: 0.5583 - recall: 0.3596 - val_accuracy: 0.6782 - val_auc: 0.6817 - val_loss: 0.6519 - val_precision: 0.6737 - val_recall: 0.3351\n",
            "Epoch 101/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6639 - auc: 0.6957 - loss: 0.6517 - precision: 0.5819 - recall: 0.4284 - val_accuracy: 0.6599 - val_auc: 0.6796 - val_loss: 0.6558 - val_precision: 0.6364 - val_recall: 0.2932\n",
            "Epoch 102/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6699 - auc: 0.7111 - loss: 0.6414 - precision: 0.6027 - recall: 0.4191 - val_accuracy: 0.6578 - val_auc: 0.6662 - val_loss: 0.6593 - val_precision: 0.6162 - val_recall: 0.3194\n",
            "Epoch 103/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6610 - auc: 0.6905 - loss: 0.6573 - precision: 0.6329 - recall: 0.3721 - val_accuracy: 0.6375 - val_auc: 0.6734 - val_loss: 0.6691 - val_precision: 0.5436 - val_recall: 0.4241\n",
            "Epoch 104/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6704 - auc: 0.7059 - loss: 0.6499 - precision: 0.6170 - recall: 0.4105 - val_accuracy: 0.6415 - val_auc: 0.6675 - val_loss: 0.6689 - val_precision: 0.5455 - val_recall: 0.4712\n",
            "Epoch 105/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.6704 - auc: 0.7009 - loss: 0.6506 - precision: 0.6319 - recall: 0.3878 - val_accuracy: 0.6477 - val_auc: 0.6723 - val_loss: 0.6666 - val_precision: 0.5682 - val_recall: 0.3927\n",
            "Epoch 106/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6692 - auc: 0.6972 - loss: 0.6667 - precision: 0.6486 - recall: 0.3966 - val_accuracy: 0.6578 - val_auc: 0.6718 - val_loss: 0.6844 - val_precision: 0.7255 - val_recall: 0.1937\n",
            "Epoch 107/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.6751 - auc: 0.7239 - loss: 0.6294 - precision: 0.6151 - recall: 0.4031 - val_accuracy: 0.6619 - val_auc: 0.6676 - val_loss: 0.6960 - val_precision: 0.5839 - val_recall: 0.4555\n",
            "Epoch 108/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.6715 - auc: 0.7169 - loss: 0.6485 - precision: 0.6159 - recall: 0.4070 - val_accuracy: 0.6680 - val_auc: 0.6654 - val_loss: 0.6929 - val_precision: 0.6346 - val_recall: 0.3455\n",
            "Epoch 109/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.6809 - auc: 0.7013 - loss: 0.6488 - precision: 0.6042 - recall: 0.3880 - val_accuracy: 0.6354 - val_auc: 0.6751 - val_loss: 0.6640 - val_precision: 0.5361 - val_recall: 0.4660\n",
            "Epoch 110/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6598 - auc: 0.6986 - loss: 0.6565 - precision: 0.6024 - recall: 0.3902 - val_accuracy: 0.6538 - val_auc: 0.6715 - val_loss: 0.6685 - val_precision: 0.5587 - val_recall: 0.5236\n",
            "Epoch 111/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.6644 - auc: 0.6865 - loss: 0.6607 - precision: 0.6099 - recall: 0.3937 - val_accuracy: 0.6660 - val_auc: 0.6796 - val_loss: 0.6497 - val_precision: 0.6452 - val_recall: 0.3141\n",
            "Epoch 112/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6592 - auc: 0.7169 - loss: 0.6443 - precision: 0.6321 - recall: 0.4036 - val_accuracy: 0.6497 - val_auc: 0.6856 - val_loss: 0.6461 - val_precision: 0.6067 - val_recall: 0.2827\n",
            "Epoch 113/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6906 - auc: 0.7132 - loss: 0.6357 - precision: 0.6355 - recall: 0.4260 - val_accuracy: 0.6599 - val_auc: 0.6936 - val_loss: 0.6560 - val_precision: 0.5600 - val_recall: 0.5864\n",
            "Epoch 114/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6934 - auc: 0.7290 - loss: 0.6294 - precision: 0.6612 - recall: 0.4366 - val_accuracy: 0.6599 - val_auc: 0.6874 - val_loss: 0.6437 - val_precision: 0.6333 - val_recall: 0.2984\n",
            "Epoch 115/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6795 - auc: 0.7203 - loss: 0.6266 - precision: 0.5934 - recall: 0.4113 - val_accuracy: 0.6701 - val_auc: 0.6788 - val_loss: 0.6542 - val_precision: 0.6107 - val_recall: 0.4188\n",
            "Epoch 116/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6879 - auc: 0.7250 - loss: 0.6313 - precision: 0.6176 - recall: 0.4780 - val_accuracy: 0.6538 - val_auc: 0.6775 - val_loss: 0.6519 - val_precision: 0.5652 - val_recall: 0.4764\n",
            "Epoch 117/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6988 - auc: 0.7259 - loss: 0.6333 - precision: 0.6600 - recall: 0.4516 - val_accuracy: 0.6436 - val_auc: 0.6615 - val_loss: 0.6653 - val_precision: 0.5563 - val_recall: 0.4136\n",
            "Epoch 118/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6700 - auc: 0.7137 - loss: 0.6341 - precision: 0.5997 - recall: 0.4207 - val_accuracy: 0.6191 - val_auc: 0.6647 - val_loss: 0.6772 - val_precision: 0.5099 - val_recall: 0.5393\n",
            "Epoch 119/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6769 - auc: 0.6976 - loss: 0.6559 - precision: 0.6215 - recall: 0.4247 - val_accuracy: 0.6395 - val_auc: 0.6861 - val_loss: 0.6666 - val_precision: 0.5522 - val_recall: 0.3874\n",
            "Epoch 120/300\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6779 - auc: 0.7091 - loss: 0.6462 - precision: 0.6331 - recall: 0.4114 - val_accuracy: 0.6599 - val_auc: 0.6918 - val_loss: 0.6481 - val_precision: 0.6304 - val_recall: 0.3037\n"
          ]
        }
      ],
      "source": [
        "def model_gaius_irakiza(input_shape):\n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape=input_shape),\n",
        "\n",
        "    tf.keras.layers.Dense(128, kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.PReLU(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "    tf.keras.layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.PReLU(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "    tf.keras.layers.Dense(32, kernel_regularizer=tf.keras.regularizers.l2(0.006)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.PReLU(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "    tf.keras.layers.Dense(24, kernel_regularizer=tf.keras.regularizers.l2(0.006)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.PReLU(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "    tf.keras.layers.Dense(16, kernel_regularizer=tf.keras.regularizers.l2(0.006)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.PReLU(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "    tf.keras.layers.Dense(8, kernel_regularizer= tf.keras.regularizers.l2(0.006)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.PReLU(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(4),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.PReLU(),\n",
        "\n",
        "\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Nadam(\n",
        "    learning_rate=0.0061,\n",
        ")\n",
        "\n",
        "  model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            tf.keras.metrics.Precision(name='precision'),\n",
        "            tf.keras.metrics.Recall(name='recall'),\n",
        "            tf.keras.metrics.AUC(name='auc')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "  return model\n",
        "\n",
        "input_shape = X_train.shape[1:]\n",
        "\n",
        "gaius_model = model_gaius_irakiza(input_shape)\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=30,\n",
        "    min_delta=0.0001,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Training\n",
        "history = gaius_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=300,\n",
        "    batch_size=48,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "a2tWPbsFDc93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Best epoch based on validation loss\n",
        "best_epoch = np.argmin(history.history['val_loss'])\n",
        "print(f\"📌 Best Epoch: {best_epoch + 1}\")\n",
        "print(f\"Train Accuracy at Best Epoch: {history.history['accuracy'][best_epoch]:.4f}\")\n",
        "print(f\"Val Accuracy at Best Epoch  : {history.history['val_accuracy'][best_epoch]:.4f}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss, test_accuracy, test_precision, test_recall, test_auc = gaius_model.evaluate(X_test, y_test, verbose=1)\n",
        "\n",
        "print(\"\\n📊 Test Evaluation Metrics\")\n",
        "print(f\"Loss      : {test_loss:.4f}\")\n",
        "print(f\"Accuracy  : {test_accuracy:.4f}\")\n",
        "print(f\"Precision : {test_precision:.4f}\")\n",
        "print(f\"Recall    : {test_recall:.4f}\")\n",
        "print(f\"AUC       : {test_auc:.4f}\")\n",
        "\n",
        "# Predictions (binary classification threshold at 0.5)\n",
        "y_pred_probs = gaius_model.predict(X_test)\n",
        "y_pred_classes = (y_pred_probs > 0.5).astype(\"int32\")\n",
        "\n",
        "# Precision, Recall, F1\n",
        "precision = precision_score(y_test, y_pred_classes)\n",
        "recall = recall_score(y_test, y_pred_classes)\n",
        "f1 = f1_score(y_test, y_pred_classes)\n",
        "auc = roc_auc_score(y_test, y_pred_probs)\n",
        "\n",
        "print(\"\\n🧠 Additional Classification Metrics\")\n",
        "print(f\"F1 Score  : {f1:.4f}\")\n",
        "print(f\"AUC (sklearn): {auc:.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred_classes)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Potable', 'Potable'], yticklabels=['Not Potable', 'Potable'])\n",
        "plt.title(\"🧪 Confusion Matrix on Test Data\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EHhVgb6fDfcB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}